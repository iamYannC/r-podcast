[
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_46_highlights",
        "ep_date": "2024-11-15",
        "ep_duration": 41,
        "ep_description_short": "The innovations of the R community never cease to amaze us! How a programmatic approach to generating markdown was vital to a high-profile Quarto site, a novel infograph of Bob's Burgers sentiment analysis, and updates to the next evolution of object-oriented programming in R. Episode Links This week's curator: Ryo Nakagawara -…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_46_highlights",
        "description_long": "\r \r The innovations of the R community never cease to amaze us! How a programmatic approach to generating markdown was vital to a high-profile Quarto site, a novel infograph of Bob's Burgers sentiment analysis, and updates to the next evolution of object-oriented programming in R.\nEpisode Links\n\nThis week's curator: Ryo Nakagawara - @[email protected] (Mastodon) & @R_by_Ryo) (X/Twitter)\nGuide to generating and rendering computational markdown content programmatically with Quarto\nBob’s Burgers Episode Fingerprints by Season\nS7 0.2.0\nEntire issue available at rweekly.org/2024-W46\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @mike-thomas.bsky.social & @[email protected] (Mastodon) & @mike_ketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nCammy's London Drizzle - Super Street Fighter II: The New Challengers - MkVaff - https://ocremix.org/remix/OCR00453\nBar Hopping - Streets of Rage 2 - jaxx - https://ocremix.org/remix/OCR00437"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://mstdn.social/@R_by_Ryo"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://www.andrewheiss.com/blog/2024/11/04/render-generated-r-chunks-quarto/"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://stevenponce.netlify.app/projects/standalone_visualizations/sa_2024-11-11.html"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://www.tidyverse.org/blog/2024/11/s7-0-2-0/"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://rweekly.org/2024-W46.html"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://bsky.app/profile/mike-thomas.bsky.social"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://ocremix.org/remix/OCR00453"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "links": "https://ocremix.org/remix/OCR00437"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with episode a 185 of the R Weekly Highlights podcast.\r \r This is the weekly podcast where we talk about the excellent resources that are shared in the highlights section\r \r and elsewhere in this week's current our weekly issue.\r \r My name is Eric Nantz, and I'm delighted you join us wherever you are around the world.\r \r And he is back. He couldn't stay away forever, but my awesome cohost, Mike Thomas, has graced us with his presence again. Mike, how are you doing? Not that you've had any, like, free time or anything. I'm doing well, Eric. Calling in from a new location,\r \r\n\n[00:00:33] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Mike Thomas",
        "trans_text": "full 2 miles away from my old location.\r \r Settling in pretty well so far,\r \r and\r \r I have also migrated\r \r locations\r \r virtually.\r \r And as of last night, I am on Blue Sky.\r \r\n\n[00:00:50] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Oh, you are? Okay. I'm feeling the the peer pressure now if you're there. It sounds like it's the place to be.\r \r Definitely taken an awful lot in the in the data science sector. Now, of course, I do still have a a very, vested interest in the mess, the the fediverse as well, which is just kind of a part of, but kind of it's a little dicey folks. And I'm still trying to sort out just like anyone else. But,\r \r yeah, you may see me on there in the future. We, actually did spin up a new account for the R pharma team on Blue Sky that we just put out there before the conference that took place\r \r a couple weeks ago, which I'll have a lot more to say about that once we get through the editing of all the recordings. But, nonetheless, that was a major event. But we're here to talk on our weekly, of course. And this week,\r \r our issue was curated by Ryo Nakagorora\r \r with, as always, tremendous help from our fellow, our weekly team members, and contributors like all of you around the world with your poll request and other suggestions.\r \r\n\nAnd my goodness, Mike, we're gonna lead off with one that\r \r really is a both mind blowing,\r \r you know, showcase of what's possible with our end portal and just really inspiring as well to see just how far you can take these dynamically generated reports. And this has been\r \r authored by a a good friend of ours, from the highlights, Andrew Heist,\r \r who speaking of free time, I don't know how he has a free time to knock this stuff out. My goodness. I need whatever he's eating. And Andrew Heist blog, yeah, is always gonna be super detailed,\r \r\n\n[00:02:24] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Mike Thomas",
        "trans_text": "probably pretty long, and\r \r again, blow me away with\r \r how much he was able to accomplish.\r \r\n\n[00:02:32] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 32,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. And we'll dive into those details now because this post is talking about how\r \r he approached\r \r generating and rendering\r \r dynamically\r \r computed\r \r content\r \r written in markdown, but programmatically\r \r with quarto,\r \r which is something I've had a little bit of diving into with the r markdown days with various snippets, especially of reusable\r \r kind of sections in a report.\r \r But Andrew just blows my stuff out of the water, what he accomplishes here. So let's let's set the stage here because there's a big picture here. So,\r \r yeah, there was a little thing called the election that happened a a weekend or so ago. And apparently, Andrew was helping out in the state of Idaho with\r \r assembling the election results and then surfacing them into a really fancy quartile website, which\r \r love to see that quartile in the real world, so to speak in a not so,\r \r not so boring situation to say the least. Lots of eyes on that on that side of the news.\r \r\n\nAnd apparently,\r \r Andrew has put this in a very sophisticated\r \r ETL pipeline,\r \r which is merging\r \r ETL concepts with,\r \r wait for it, targets\r \r to help process the data from different sources, whether they're online\r \r or from another storage and then creating\r \r a tidy, I guess, data store, he calls it, that everything else can be built upon.\r \r And then another pipeline is gonna take that tidy set of results\r \r and then actually generate the Cortl report and website programmatically.\r \r He teased that he's gonna share more about that, but I'm saying, Andrew, not that you have infinite time. I'd love to see a deep dive into those target pipelines because I'm always eager to see just the directions you take with that.\r \r But diving into the rest of the poster, he talks about kind of the, the meat and potatoes of what the website was surfacing, which was taking advantage of. It's really neat features in the quarto UI for HTML,\r \r where you can have these tabbed, you know, tab,\r \r panels much like you do in a shiny app and in quartile as well,\r \r which gave both a tabular visualization\r \r and an interactive map\r \r of the election results across districts in Idaho.\r \r\n\nSo you could kind of choose which which display you like.\r \r And then he shows kind of in general,\r \r you might have in the portal dashboard\r \r set up these different sections\r \r with code chunks to actually generate that table\r \r or that map.\r \r And sure, for maybe 1 or 2 races, so to speak in that particular state's election, you could, you know, you could just dive into that. But what if you have a 100 or more of these?\r \r Yeah. You don't wanna copy paste that stuff left and right. So he looked at\r \r how can we generate these, these table and mapping\r \r code chunks and the output from that more dynamically,\r \r not just the code itself, but where it's actually being placed\r \r in the Quartal website,\r \r IE, the Quartal syntax that's gonna be built and marked down for that.\r \r\n\nSo he first knocks out probably an elephant in the room for those that have done this before is that in code chunks,\r \r you can use the results parameter and call it as is\r \r to basically not escape that content and the basically take it as it is so that if there's an HTML report\r \r and you're spinning out markdown or HTML, it's just gonna surface that out right away when you compile the website or the report.\r \r But it doesn't always work the way you want. And he shows an example of like\r \r the, a bullet list of like the,\r \r gap minder country data\r \r where it just doesn't\r \r quite work\r \r when you need to have\r \r additional work in these chunks.\r \r\n\nAnd he shows that in an example where he's trying to round\r \r certain numbers, just hypothetically the the number pi,\r \r it's only spitting out, like, the code that makes the result in the bullet list, not the actual\r \r result of that computation.\r \r So it didn't render the inline chunks of these items in the bullet list. And, of course, that's a that's a nonstarter if you're gonna do this more dynamically.\r \r So the trick that this is all built upon\r \r is to actually pre render these in line chunks\r \r before\r \r they actually appear in the document. So this is a little different. Right? This is not dynamically\r \r rendering\r \r the content, what I call just in time\r \r of the website compilation.\r \r\n\nHe is saying, let me re precompute that first\r \r and then show it into the actual quartile content.\r \r In this case, now you get the rounded versions of the pie number\r \r in that markdown text.\r \r Took me a little bit to grasp this, but I kind of see where he's going with this. And, of course, this is a trivial example.\r \r But back to the election website he was creating,\r \r he wanted to do a similar idea, but now with those tab sets of the visuals\r \r of the table and the map.\r \r So the concept does generalize. First, he's using the Gapminder data\r \r to kind of show a tidy data set that would be a scatter plot of the GDP\r \r per capital and then life expectancy.\r \r\n\nStuff you've seen many times before in presentations about Gapminder.\r \r And then he shows, okay, what if I want in my portal dashboard,\r \r the panel tab set,\r \r and then within each of these continents splitting up 1 by 1,\r \r echoing that particular continents,\r \r result from that tidy dataset and tidy visualization.\r \r Again, you could copy that over and over from icon in 1234\r \r 5. But again, going back to the election result, what if you have, you know, 100 of these or, you know, thousands of these potentially if you're doing a lot of, like, biomarker data or something like that?\r \r So, again, he's going to use a hybrid of the glue package\r \r and other tricks to precompute\r \r these panels\r \r dynamically. He's got a handy utility function called build panel\r \r where he's feeding in what's gonna be the chunk label,\r \r the output that is in string format, the markdown syntax as injecting that\r \r set of like the panel title, the index of the plot.\r \r\n\nSo that then that's going to render\r \r dynamically\r \r in the report itself. He does verify it works first by running the function and he gets the markdown\r \r of the heading and the continent name and then the coach on as if he typed it himself.\r \r So mission accomplished on that front.\r \r And then he's able to basically loop through this at one point\r \r with a combination of the knitter functions,\r \r knit\r \r function, which again,\r \r quarto with the r execution engine is built upon knitters. So knitter,\r \r like, we've we've spoken for years on this show, Mike, about the praise for knitter and what the doors had opened.\r \r People need to realize if they don't already, that quarto itself is building upon\r \r these types of execution engines. And without knitter,\r \r there is no quarto. I'll just be\r \r hot take 101 with Eric on that. I don't think it's such a hot take. But No. I would agree with that. It is\r \r\n\n[00:10:03] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Mike Thomas",
        "trans_text": "almost,\r \r impossible\r \r to\r \r not take for granted\r \r everything that Knitter has done for us.\r \r As much as you appreciate it, you should appreciate it even more.\r \r\n\n[00:10:17] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Absolutely. Absolutely. So, again, just this knit function alone, you may take it for granted. That's when you're in the r markdown Jaysus hitting that, you know, compile report button in the IDE.\r \r But this is the engine behind all that. So he shows a great great,\r \r great example of using that in action. And then sure enough, he's got a nice little tab panel of the different continents and the scatter plots.\r \r And that\r \r really saves you a boatload of time there.\r \r And then he's got another example later on where you could use this in more of a teaching aspect.\r \r Let's say you wanna show the different\r \r stages of building up an effective visualization.\r \r\n\nAnd he does this with what he calls the evolution of a ggplot\r \r visualization,\r \r where you can have these plots saved as objects,\r \r say, from the first stage of it to the last stage of it.\r \r You can make a tidy, you know, dataset with the actual plot object that is in a list column that has, like, the actual object itself, the text around it, and a description.\r \r And guess what? You can use the same logic to create a tab panel\r \r going from stage 1 all the way to the last stage\r \r and just grabbing these different plot objects from this list in that data frame.\r \r My goodness. That's a great way to help teach your students. Like, you may start of initial plot that looks, you know, very utilitarian and all the way to last step. You got a nice theme with it. You got the nice color choices, the background looking much sharper,\r \r changing default labels.\r \r\n\nSo quartile is a teaching tool. I mean, it's already getting very popular in education sector, but, man, this is really,\r \r really top notch stuff here.\r \r So again, you can take this even further\r \r with the concept\r \r of making now going back to the election results,\r \r you got all this, you know, content\r \r kind of stitched together.\r \r Quarto does have the concept of kinda having these child reports\r \r inside an overall,\r \r you know, website or or report or what have you.\r \r So he kinda takes this into\r \r a bunch of our chunks again that are dynamically generated.\r \r And you you can, you know, do this in quartile 2. Again, built on Knitter,\r \r you can have child documents\r \r filtered into\r \r an overall report.\r \r\n\nBut, again, he's showing then\r \r that these report texts is all just marked down in the end. Right? The key is just being able to loop through that. Maybe you have a tidy data frame that's like or or overarching all of this.\r \r And then to be able to use the knit function to paste this all in together.\r \r And that's where he shows then in this generated output.\r \r Instead of, like, separate reports like verbatim or separate files, he has different sections of this continents report\r \r where the user can quickly, you know, go through the different continents, figure out what countries are involved,\r \r looking at the details in one table, looking at the plot in another.\r \r\n\nAnd you put a TOC with that and you got yourself a really intricate,\r \r dynamically driven report or dashboard, whatever have you.\r \r But all this is powered by rendering that markdown content ahead of time\r \r and then using it to inject that into the overall portal website.\r \r I literally\r \r literally yesterday\r \r did something very similar to this. Albeit, I did take the manual approach, but I regretted it for reasons.\r \r But now knowing what Andrew's done here, I can have\r \r a function that generates a snippet of this case iframes\r \r of another quartile dashboard inside another quartile reveal JS slide deck.\r \r\n\nI could just have a tidy data frame that has, like, the links to these iframes of the quartile dashboard,\r \r loop through that,\r \r get the markdown chunks, and then put that into my main reveal JS document,\r \r deploy that on pause and connect, and I'm off to the races.\r \r I have eliminated the need for PowerPoint\r \r of these one pagers of results that I had to assemble. So,\r \r Andrew, you blew my mind yet again. Credit to you for sharing sharing your knowledge here. And, yeah, the possibilities seem endless with dynamic generation of portal content.\r \r So mission accomplished, buddy.\r \r\n\n\n\n[00:14:51] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 51,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. This is fantastic.\r \r If you were to try to,\r \r you know, create some sort of a quartile or R Markdown document that\r \r displayed these 100 different\r \r is it counties in Idaho, I think that we're trying to, track or districts in Idaho. I think that's that's what it is. I mean, you could do it by hand if you wanted to, but it would it would take you forever and a whole lot of copy and paste, and God forbid you wanna change one little aesthetic, right, that you wanna propagate\r \r everywhere else. You're you're stuck doing a find, replace all. And and I think, you know, we've\r \r discussed in the past,\r \r the the benefits of of functional programming,\r \r and they apply very similarly to quarto. And one of my favorite things about quarto, and it's interesting to me because I just came off a project where we did a lot of work exactly like this. So I can't I can't, praise this type of workflow\r \r enough. I think, Eric, you probably have this experience with Knitter as well, where\r \r if you try to do some our\r \r run some our code, execute some our process\r \r within Knitter,\r \r it'll run a little bit slower than if you did it outside of Knitter.\r \r\n\nSo what that means is that you will be able to save time,\r \r in your rendering if you have pre computed and pre created\r \r any of those R objects\r \r ahead of time instead of asking them to be created during the knit process.\r \r You extend that one\r \r rung further and and we start to get into targets. Right? And that's sort of, you know, the exact goal of targets is to be able to pre process things in your pipeline and only re execute things that need to be\r \r updated. So it's a fantastic,\r \r complement\r \r to the workflow here that Andrew has put together to demonstrate this. And,\r \r you know, one other thing that I do wanna highlight\r \r is the use of child documents. I'm not sure if Andrew Andrew called it out in the blog post. I'm not sure if at the the end of his whole process, which we don't necessarily have full insight into yet. Right?\r \r\n\nIn terms of this election quarter report that he's put together. If he leveraged child documents or not, he talks about that when you you take a look at some of these code chunks that are in line in the blog post that are some pretty large glue\r \r based chunk, code chunks that he he's putting together that we can, you know, execute\r \r as a function.\r \r At the end of the day, he talks about how some of this this code in his current workflow,\r \r might be able to be condensed,\r \r if you took advantage of child documents\r \r as well. And what that means in a in a quarto,\r \r sense is\r \r using this special tag, I think, that starts with 2,\r \r arrows pointing to the left and and ends with 2 arrows pointing to the right and,\r \r includes, no pun intended,\r \r the include\r \r verb.\r \r\n\nI think that allows you to reference another file, another QMD file that you can have, sort of inserted into maybe like a main dotqmd\r \r file. And if you're familiar with child documents in our markdown, it's the same type of concept, just a different syntax.\r \r Those are things that we leverage heavily because if you're putting together a a large report,\r \r or a large document like the one Andrew is is putting together that has a lot of moving pieces,\r \r I think it it sort of always makes sense to try to manage those pieces as separately\r \r as possible, especially if you're working on a collaborative team. Right? Somebody can just focus on on one piece and another person can be dedicated to focus on another piece. And I think it just allows you to,\r \r sort of\r \r piece together your final product in a way that's easier to manage and easier to maintain than if you were trying to do it in some sort of a monolith.\r \r\n\nSo I can't I can't say enough about,\r \r child documents within quarto. The syntax that they have makes it really easy to do so if you're on the quarto website and you're not familiar\r \r with how to leverage child documents.\r \r Just search it on on quarto.org\r \r and and the,\r \r function syntax to be able to do that,\r \r the markdown syntax, excuse me, will be right there for you. I can't can't harp targets enough as well and sort of bringing these technologies together. I would love to see\r \r how he leverages that remote storage with targets and that local DuckDb\r \r database as well to sort of bring this whole entire solution together.\r \r\n\nBut but top to bottom, I think it's a fantastic resource for anyone who is building a large\r \r scale quarto type of document or looking to just\r \r get a better understanding and better feel for best practices\r \r around authoring quarto reports.\r \r I think the tips in here will be invaluable for you.\r \r\n\n[00:19:35] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 35,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And, I do have it on good authority from the, author himself that there's some big enhancements coming to Target\r \r with respect to potentially DuckDV integration\r \r and\r \r even better performance. Like, Target's already performs great. But what Will has in store for us, oh, you all are gonna love it, especially with those that have these, you know, 10,000 plus,\r \r you know, branches and pipeline, you know, targets themselves. So, yeah, stay tuned, folks. It's getting better. But, yeah, this this whole thing has\r \r so many nuggets to to choose from here that I've gotta I gotta look at this even more.\r \r\n\nBut we literally at our day job have a couple teams I wanna\r \r they're they're not satisfied with the SharePoint world, man. They want to build\r \r dynamically\r \r data driven websites\r \r of these reports that can be shared broadly across the organization\r \r that take advantage of the interactivity\r \r that the portal offers, whether it's through, you know, things like the portal dashboard, which I've become a big fan of. Obviously, we have some people looking into the observable JS side of it. But you're not gonna get this to SharePoint folks. That's my hot take too for the podcast\r \r that the this this in particular, if they can be used in a high profile situation\r \r like tracking election results,\r \r good grief. It can be used almost anywhere.\r \r\n\n\n\n[00:21:00] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 0,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Not fully satisfied with SharePoint? Are you sure?\r \r You have that right?\r \r\n\n[00:21:05] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 5,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I may have to double check my references on that.\r \r\n\n[00:21:08] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 8,
        "trans_speaker": "Mike Thomas",
        "trans_text": "A little satire for the audience.\r \r\n\n[00:21:10] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 10,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. That that hopefully, they got. But, yeah, we've had some internal debates on that one too. And I was,\r \r but I I did like I said, I I've used principles of this, albeit not so elegantly,\r \r where I was able to get away from having the creative a rather haphazard PowerPoint slide, but I used Cortl Dashboard instead.\r \r And because of the integrations we can have with Cortl websites and\r \r and iframes going as backgrounds in a presentation deck,\r \r I was able to create what that team really wanted, which was basically\r \r an HTML based slide\r \r of a bunch of quartile dashboards\r \r without having to put the quartile dashboards in the slide deck. But as background iframes, folks, like, this is\r \r so many mind blowing things we can do with this. I I hope I can give a talk about that later because I I've learned I've learned some tricks, man, but this is this is tricks on another level. What what Andrew's done here? I'm looking forward to that too.\r \r\n\nSo as I said, yeah, it was about a week and a half ago that there was a little thing called the election, and maybe somebody needed a little pick me up after that thing which side of the fence you're on. Maybe, you know, having a little bite to eat if you had a long night.\r \r Well,\r \r who knew that this next highlight was gonna\r \r high,\r \r showcase\r \r on a show that I admittedly have not seen before.\r \r I've heard about it. But this is coming from Steven Ponce, and he has put together a web a blog post, albeit\r \r mostly a notebook, I would say,\r \r about looking at the fingerprints\r \r used in each of the seasons of the show Bob's Burgers. And admittedly, I have not seen this show before as I'm Kabooie\r \r out of my wheelhouse for this. But it's basically an infograph\r \r as the meat of this post that is looking at across the different seasons\r \r where and I have to zoom in here on my fancy 4 k monitor to look at this more carefully.\r \r\n\nThe looking at the the transcripts of this, the dialogue and looking at, say, the the length of the sentences, the unique words,\r \r variance among the sentiment of the transcripts, a little text mining action here.\r \r How many questions there were? How many explanations\r \r there were?\r \r And it's a pretty neat infograph that for each, you know, faceted by season,\r \r you get I believe they call these like the spider plots or the radial charts. I forgot the exact name of them. But it's a it's a good way to put like multiple dimensions in a circular like fashion,\r \r but not be confined to the infamous pie chart limitation. So\r \r a pretty pretty neat visual there. And it's and again, the big picture is looking at the patterns and dialogue\r \r across the 14 seasons of this show, which again, I'm I'm an old timer. I haven't seen this yet. So maybe it has to be in my, in my,\r \r queue of shows to watch when I actually get a free time moment. Nonetheless,\r \r the notebook\r \r and style is that he's got the different steps\r \r in the building this visualization\r \r much like a tidy verse kind of, you know, flowchart that you would see often in our for data science and whatnot.\r \r\n\nLoading the packages, of course. And this is a little interesting here.\r \r We don't see as much of this lately,\r \r but Steven is using the Pac man package to orchestrate packages, which some have had great success with. I admit my my,\r \r my attempts with, Pac man were\r \r mixed at best. But,\r \r hey, if it works, it works. So he's got the snippet to\r \r load the various packages. And yes, Mike and I were remarking before the show.\r \r There is a package called Bob's Burgers R that's got the data sets that are being used in this.\r \r There's a package for everything, isn't there?\r \r\n\n\n\n[00:25:13] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Literally, at this point. Yes. It contains the transcripts. It looks like for every episode across,\r \r all the seasons that are available.\r \r\n\n[00:25:22] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 22,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Absolutely. So I'll have to look at that in my spare time, but he's also loading\r \r additional packages to help do the text analysis,\r \r tidy verse, of course,\r \r and patchwork, which we've spoken very highly about for being able to compose multiple ggplot\r \r objects together\r \r in any way you see fit, basically. So\r \r and then, also, he's using the camcorder\r \r package, which you heard about at positconf\r \r as well,\r \r to record\r \r the different plots as PNGs as you're going through it. So that will come in play later.\r \r So, first, the data which again, thanks to the Bob Burgers r package just simply using the transcript data data frame, and he's got it right off the bat. So that that part's done.\r \r It does a little exploration of it. Although, we don't see the result of it, but there is a handy handy function from the skimmer package\r \r called skim, which lets you it's not shown here in the output,\r \r but get like a terminal base glance of that data set or a data frame.\r \r\n\nReally handy, especially if you're in a terminal environment.\r \r Then comes the tidying stuff. So we got a lot of dplyr\r \r grouping by summarizations.\r \r And notice that in his syntax of the summary summarize\r \r function, he's taken advantage of the dot groups\r \r declaration,\r \r which again is\r \r thanks to the dplyr version 1.8 or later, I believe.\r \r They introduced the dot by\r \r and the dot groups parameters in key functions like mutate\r \r and summarize. So you don't you don't always have to do the old\r \r dplyr group by,\r \r summarize,\r \r dplyr ungroup afterwards because, Davis Vahn and others from the Tinyverse team were saying that got annoying on a lot of users. So that's a nice little trick\r \r\n\n[00:27:14] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 14,
        "trans_speaker": "Mike Thomas",
        "trans_text": "that that Steven shows here. Couldn't agree more. Yes. I\r \r love the dot buy argument.\r \r\n\n[00:27:20] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. I literally just started using that for a high high priority project and it's like I can never go back to group buy anymore if I can avoid it. So And the dot keep argument within mutate, so you don't have to use transmute anymore.\r \r That's right. Yeah. I need to explore that one too. Another great quality quality of life enhancement, I should say.\r \r Next comes the visualization. So he does a lot of setup up front\r \r to get the\r \r the the labels all in order as well as kind of the the CSS, I believe, is gonna be applied to these\r \r plots, a little bit of CSS, and then using glue to dynamically\r \r put in various things,\r \r and then\r \r managing the fonts.\r \r\n\nLots of, fonts are added from Google with the, I believe it's the fonts package, if I'm not mistaken.\r \r I have to double check that.\r \r\n\n[00:28:13] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I think it's\r \r I thought it was called Google Fonts, but I'm not seeing\r \r\n\n[00:28:19] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I'm not seeing where he got that from.\r \r\n\n[00:28:23] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 23,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'll take a look. Keep going.\r \r\n\n[00:28:25] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 25,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. We'll keep going. Yeah. We're we're learning here, guys.\r \r So nonetheless,\r \r then he's able to assemble the theme object in ggplot2, which again is a great way\r \r if you wanted to find that upfront\r \r with the the theme set and then a theme update.\r \r That way he can use that theme\r \r anywhere he goes from that point on or the rest of the visualizations.\r \r And then comes the main plot where it's a\r \r the the nugget here is using the geom polygon to get that\r \r nice little polygon superimposed\r \r inside this, you know, circular\r \r type display. Again, people call that a spider plot or a radial plot. Some to that effect. And then adding\r \r average lines on that. But again, flipping that to polar coordinates towards the end.\r \r\n\nAnd then defining the labels and the facets by season.\r \r And then adding on top of that kind of this\r \r pattern type visualization,\r \r which, again, you wanna look at the post to to get to get the meat of it. But there's a nice little pattern. I think that's kind of serving as the background, so to speak,\r \r on the plot itself. Again, really neat to play with. I haven't done this myself before. So\r \r really intricate annotations that he makes\r \r here. And then\r \r afterwards, he's gonna save all this\r \r as, PNGs\r \r for, I believe, at least one PNG I should say for the the whole plot itself.\r \r But he assembled that with patchwork before that\r \r to combine everything together.\r \r\n\nAnd then to be able to draw that, clean things up,\r \r and then using the magic package\r \r able to create neat little thumbnails of the visualization\r \r that he used, I believe, in the post itself. So little\r \r nice lot of visualization tricks here that if you're want to up your game with ggplot too. There's some really some real nuggets to share here. And then like any any good, data science citizen, he's got the nice session info at the end here.\r \r And link to the GitHub repository so you can actually see how this is composed in action. So great notebook setup here. Love the way that you can collapse the different code chunks and just get to what you're interested in. But, yeah, with a nice little, tidy dataset of\r \r transcripts and Boss Burgers,\r \r got yourself a nice little visualization\r \r to,\r \r you know, satisfy your appetite.\r \r\n\n\n\n[00:30:48] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Puns galore. Mike, what did you think about the visualizations here? Well, the final output that is at the top of the blog, it's a beautiful infographic. It's really nicely done. I like the contrast between\r \r the background that's just sort of off white a little bit and the the purple,\r \r gradient sort of that that, ticks the spider plot,\r \r on values are are represented by. Really, really cool. Turns out it's the show text package that allows you to manage Google Fonts,\r \r has the the font add Google, I think is the,\r \r particular function within the show text package that allows you to import certain Google fonts and leverage them in your, ggplot graphics.\r \r\n\nOne thing that I don't do well enough or understand\r \r well enough\r \r is adjusting, I guess, the graphics device itself.\r \r That, you know, arguments like DPI, which I think are dots per inch. Is that what that means? Yes. Correct.\r \r The units,\r \r I don't do that enough, unfortunately. I usually just in my,\r \r quarto documents, I'm just specifying fig height, fig width, things like that, and and messing around with it until it looks\r \r halfway decent. That's stuff that I need to learn a little bit more about, but Steven,\r \r has a few different places within this notebook\r \r where he is is setting those specific configurations. So I've definitely learned a lot there and you will as well if, that's something that you struggle with like me.\r \r\n\nOne other sort of cool\r \r function that I here's a little today I learned\r \r that I can't believe I don't even know if I want to admit that I'm just learning this today\r \r but there's a ggplot\r \r argument called theme underscore update.\r \r Eric, I'm sure you knew about this one.\r \r\n\n[00:32:35] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 35,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I knew it sporadically. I never actually used it. So I love theme minimal,\r \r\n\n[00:32:40] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Mike Thomas",
        "trans_text": "but obviously, occasionally, there's some additional things that that I wanna do on top of theme minimal,\r \r that aren't within\r \r aren't doesn't, aren't contained within arguments of the theme minimal function.\r \r And\r \r typically I'll just add a theme\r \r function after that. And I think\r \r ggplot2\r \r knows well enough to\r \r use sort of the the last,\r \r you know, value for a particular,\r \r theme argument\r \r to set that as what's gonna be shown in the plot.\r \r But I think theme update\r \r sounds like it is probably doing a better job of that as opposed to sort of overriding,\r \r what you had written before it in your theme minimal\r \r call. So this was a new one for me. A little embarrassed to say that this is the first time that I'm coming across it but it is one that I am for sure going to be using from now on in many many many places.\r \r\n\nJust excellent blog posts top to bottom.\r \r Love the code, love the layout here, and the end deliverable is is absolutely beautiful. So take a look for yourself.\r \r\n\n[00:33:47] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I'm I'm doing you know,\r \r first, you're you're you're too, kind or too hard on yourself, I should say. There are so many things in ggplot too that I\r \r always scratch the surface of. But let's put things in perspective, folks, as I'm I'm gonna take a quick look at the archive of ggplot too. Did you know that jigapotwo,\r \r the first grand release\r \r was all the way back in 2007?\r \r So it's got a lot going on. I mean, that we're coming there 20 years on that thing. I mean, we're over 15 now. So it's not surprising that there are things in there that we we didn't expect to see. But, yeah, that's why we're having this post from Steven. It's a great great reminder of the capabilities of it. So I'll like you, I'm gonna take note of that theme update function.\r \r Lots, yeah, lots of attention to detail here. I absolutely love\r \r seeing how the sausage is made. And, yeah, the font add function, I did a little digging while you were talking, is from the show text package.\r \r\n\nI don't use that a lot in my daily work, but I definitely will take a look at that for my next\r \r Gigi Pot visualization.\r \r But, yeah, nonetheless,\r \r really\r \r great design choices. So this is a great showcase of using the principles\r \r that I've seen outlined in various workshops, such as some Cedric Sure or others about what are the best ways to build up an effective infograph\r \r that, by the way, you don't need to go to Adobe Illustrator for. You don't need to go to some proprietary product, jiji plot 2. We have a little, little getting your hands dirty, so to speak, and get you\r \r really the whole way there. It's just a a wonderful plot here. Absolutely wonderful.\r \r\n\n\n\n[00:35:27] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Mike Thomas",
        "trans_text": "2007, you say, for ggplot. Well, it's\r \r incredible to think how much, that package has evolved. And you know what else has evolved in the R ecosystem?\r \r Object oriented\r \r\n\n[00:35:40] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Eric Nantz",
        "trans_text": "programming.\r \r You got it. You got it. And,\r \r you know, you may be as an our user, you've probably used this\r \r many, many times, sometimes without even realizing it because of the elegance of the language itself.\r \r So what are we teasing here is that\r \r since about a a year or so ago,\r \r there has been a new effort sanctioned by the art consortium no less\r \r to build a new\r \r object oriented paradigm into art itself eventually.\r \r And right now, it is a new package called s 7.\r \r The post comes to us from the Tidyverse blog written by Tomas Kalamazowski\r \r and Hadley Wickham himself on\r \r the new updates to s 7 version 0.2.0.\r \r\n\nAnd for the uninitiated wondering,\r \r wait, why\r \r is s 7 even exist?\r \r Well, in r itself\r \r for historically a very long time since practically the very beginning,\r \r there have been\r \r at least 2 or 3\r \r class systems in the language. 1 of which is s 3,\r \r which is leveraged heavily by the tidyverse packages\r \r and a lot of base art functions itself\r \r to give you that kind of very easy way to say,\r \r create a visualization with the plot function.\r \r But if you feed it a data frame, it's gonna know the treat that differently than if you feed it like a\r \r single vector or, 2 vectors of say, x and y. It's a dispatching system. I'll be it\r \r very general, almost to its detriment to some people's eyes.\r \r\n\nThen you have s 4,\r \r which brings a lot of formality,\r \r a lot of guardrails around your object oriented structures.\r \r But I can attest that it is not for the faint of heart. It is quite complex\r \r to get into the nuts and bolts of. And when I was doing bioconductor\r \r stuff back in the early part of my career,\r \r I got to know s 4 almost unwillingly well,\r \r because of that. But it never felt natural to me. And again, that's just my opinion. There are others that use us for a great success. More power to you.\r \r S 7 is trying to be kind of in between that of and sorts,\r \r giving some of the simplicity of the syntax of s 3\r \r with some of the guardrails\r \r and, you know, safety\r \r net and more, you know, formal\r \r definitions\r \r that s 4 has.\r \r\n\nSo in this update, what's new here, there's a few, you know, minor, I would say, bug fixes, but also\r \r building blocks for new bigger features in place.\r \r Some of which include\r \r being able to support lazy property defaults,\r \r which they're saying makes the actual setup of a class much more flexible.\r \r One other idea that caught one other item that caught my eye was that they made an enhanced speed improvements\r \r for when you set and get properties using the at sign\r \r or the at sign with the assignment operator. Apparently, there were some bottlenecks with that in previous version\r \r that they've, fixed this now.\r \r\n\nThey've also expanded the compatibility\r \r with additional s three classes\r \r to help bring that transition a little more optimal for those coming from the s three side of things.\r \r And then also\r \r be able to have be able to convert a class into a subclass with the new,\r \r convert function or a modified version of the convert function.\r \r Lots more that are in the release notes, but the post also talks about how do you actually use this thing. So there's a great\r \r great kind of, example\r \r where they use this new class they call it range\r \r to help look at kind of the range between numbers, I believe.\r \r\n\nAnd you can kinda see how the class methods,\r \r the class properties,\r \r the generics are defined with this. And you'll see there is a lot of\r \r shared\r \r syntax or paradigms of shared syntax of s 3,\r \r but yet you're able to define things more formally\r \r with the s 4 kind of language inside as well.\r \r They realize there are so some limitations here. It's not quite production ready, I would say, for getting into\r \r the actual R language itself, which is the end goal here.\r \r But\r \r they know that they are actively working on it. But like I said, there is a huge goal here for this.\r \r Not just to be a standalone package for the foreseeable future,\r \r but to actually get into base r. That's as opposed to things like r 6, the object oriented class used by Shiny and many other packages,\r \r that's always gonna kinda stay as is because that's a very at rapidly evolving\r \r class system often with its own needs compared to what s 3, s 4, and now s 7 are bringing. So I'll be obviously watching this space quite closely. I have not used s 7 yet, but I know some packages are starting to use it now. So I'll be very curious kind of what the what the developer, you know, shared learning is as\r \r authors start to use this more formally. So great to see updates in this space, and I guess we'll stay tuned to see what else is out there. Yeah. It's interesting, Eric. You know, you know, a lot to\r \r\n\n[00:41:07] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 7,
        "trans_speaker": "Mike Thomas",
        "trans_text": "digest here. You know, I think that the idea,\r \r as\r \r noted in the blog post is that hopefully s seven eventually becomes part of BaseR.\r \r It is going to be, you know, an additional learning curve for some folks. Although, hopefully, if you've been doing some object oriented programming in s 3 and or s 4,\r \r some of the syntax and the concepts will be fairly familiar and fairly easy to migrate\r \r for you. This looks like a project that has now fallen under the R Consortium,\r \r which is cool. You can check out the GitHub there to take a look at the project itself.\r \r And, there's 2 limitations\r \r that they\r \r want to point out. The first is that s seven objects can be serialized,\r \r with Save RDS\r \r but the way that it's currently\r \r authored, saves the entire class specification\r \r with each object and that may change\r \r in the future. And then, the second is that support for implicit s three classes of array or matrix,\r \r is still in development. So some things to watch out for for the the hardcore object oriented program,\r \r programming\r \r developers\r \r out there. But I'm excited to see version 0.2.0\r \r drop, and\r \r this looks\r \r definitely a little more digestible to me than s 4.\r \r\n\nSo I'm excited to, learn a little bit more about s 7 and hopefully\r \r incorporate it into our projects going forward.\r \r\n\n[00:42:36] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And I know I've seen in the community our our friend John Harman's put s 7 for the paces on some of his\r \r exploration efforts, and I see some others. You know, I'm sure they're learning on it. And I'm doing a quick check on the CRAN page. There are, as of now, 4 packages that are importing s 7. So there are there are a few to choose from, and they,\r \r admittedly, there is one called Monad.\r \r Remember Monad's from our shiny Oh, gosh. Learnings from Joe Chang. So I want to check that one out.\r \r But but, yeah, nonetheless, it does seem to be moving along, and I'll be watching\r \r the space quite closely and seeing where that fits in my adventures both in Shiny and also in\r \r generic package development.\r \r\n\nBut you could have lots of adventures in the r side of things when data science, and this rest of the r weekly issue would give you, I'm sure, lots of directions\r \r to go down different adventures, different rabbit holes, and really ways to supercharge your data science exploits. And we'll take a couple minutes to talk about\r \r our additional finds here. And,\r \r fellow curator, good friend of ours, Jonathan Carroll,\r \r has released on crayon\r \r a very cool r package that he's had in development for a bit of time\r \r called Nifty.\r \r And what Nifty is is, our wrapper\r \r around a completely open source,\r \r self hostable\r \r notification\r \r service called nifty\r \r that you could spin up on, say, a cloud VPS or on your internal network\r \r and be able to, from r,\r \r push out a push notification\r \r using this package\r \r to go to wherever it needs to go.\r \r\n\nSo let's imagine you're running that big old simulation.\r \r You're away from your computer while you let the HPC, Matt, do its magic.\r \r What if you want that notification on your mobile device to say it's done? Right?\r \r Nifty might be a way to do that. So I may have to take a look at that. I've seen other packages in this space called pushbullet, I believe, from Dirk Eddybuttel. It's doing a similar thing with the Pushbullet service.\r \r But it's great to see our use in in novel ways too. So congrats to Jonathan for getting\r \r nifty on the crayon. And I saw on Mastodon, there was already a few very excited users for what they can do with that package. So that'll be in my, things to work look at during my holiday break.\r \r\n\n\n\n[00:44:59] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Mike Thomas",
        "trans_text": "And, Mike, what did you find? Well, one thing I wanna shout out is a package\r \r called Survey Down. I'm not sure if we've talked about this on the highlights before\r \r or not. It had a new release out there,\r \r and it's a pretty cool open source way for making surveys with R, quarto, Shiny,\r \r and a technology called Supabase, which looks like,\r \r how the back end data is stored. It's some type of, database.\r \r And I think it's\r \r I have a lot of use cases potentially where I need to make small\r \r forms, things like that, surveys,\r \r and\r \r I always sort of tend to wanna go overkill and develop a Shiny app instead of using something off the shelf like, I don't know, a Microsoft product or SurveyMonkey or or things like that, just because\r \r I'm I like doing those things to myself. Right? Make making my life more difficult.\r \r\n\nSo I would check out this package if you, like me, have a need to create a form or a survey\r \r and wanna do it open source and leverage some leg work that's that's already been done by a great team.\r \r\n\n[00:46:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I I've seen this come through, but I haven't dived into it much. But boy oh boy, that would be terrific for, you know, wherever you have, like, surveys you wanna conduct in your organization or some other robust\r \r data collection, great to take advantage of the R ecosystem\r \r with that space. And,\r \r before we get gentle comments, it turns out I pronounced that package completely wrong. I went to the GitHub page. It's actually pronounced notify. It's n t f y. So sorry, John. I I I should have looked at that before I started saying that. Pronouncing things is hard, so correction noted. Yes. It is.\r \r Yep. But, luckily, you don't need to correct anything else with our weekly itself. We we strive on giving you authentic content. You don't have to worry about\r \r some, AI generated bots putting that populated feed into you. This is all human generated.\r \r\n\nWe definitely wanna take advantage of automation and certain pieces of it, but, no, that's the value of this project.\r \r Completely human element and, you know, written by the community for all of you in the community. And since it is a community effort,\r \r we rely on your help. One of the best ways to help is to share those great resources you find you found online. Whether it's a new package, a new blog post,\r \r new tutorial,\r \r we're all game for all of it. You can send us a poll request, all written in markdown using that top right\r \r banner link in the corner of our weekly dotorg. You know, it can be taken directly to the GitHub poll request template.\r \r\n\nWe show you kind of the things we're expecting. It's very minimal,\r \r but we always value your contributions there.\r \r We also value hearing from you in the audience as well. We got a little contact page in the episode show notes. We love hearing from you and what you've learned from our weekly.\r \r You can also find us on the social medias as well.\r \r Apparently, we're gonna we have a new source for Mike that he'll talk about shortly. But for me, it is still the, tried and true, Mastodon account with at our podcast at podcast index dot social\r \r as well as LinkedIn.\r \r\n\nSearch my name, you'll find me there. And I'll be at very much minimal now, the Weapon X thing at the r cast. But maybe I needed to pay attention to another one, Mike. What about you?\r \r\n\n[00:48:13] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. I guess the latest for me, which I hope to check a little bit more often than I did on Mastodon, it it feels,\r \r like like I'm pretty excited about it. It's gonna be bluesky.\r \r You can find me at mikedashthomas.bsky.social.\r \r Otherwise, you can,\r \r check me out on LinkedIn if you search, Catchbrook Analytics, ketchb\r \r r o o k. You can figure out what I'm up to.\r \r\n\n[00:48:42] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Looks like I need to update my markdown tempo in the show notes, buddy.\r \r Sorry to do that to you. No. No. That's easy. That's easy. All marked out all the time for me. So all all good here. Well, with that, we will put a bow on this episode of our weekly highlights, and I admit I was remarking to Mike before the show.\r \r We're at a 185\r \r now. That means we're running close to that 200 mark eventually, I should say.\r \r And, shout out to our good friends,\r \r Ellis Hughes and Patrick Ward. They're on the similar journey. It looks like they're at a 180 some episodes of IDX. So,\r \r how about a friendly wager who gets there first? Hashtag just saying.\r \r\n\n\n\n[00:49:19] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I don't know if I wanna make that bet.\r \r\n\n[00:49:21] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Eric Nantz",
        "trans_text": "No. I don't either. Holidays coming up.\r \r Holidays are coming up, so that'll put a wrench in things. But, nonetheless, we hope you enjoyed this episode of our weekly,\r \r and we will be back with another episode. Maybe next week, maybe not. We'll see,\r \r soon.\r \r Don't know how to close those out. Alright. We're done."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_46_highlights",
        "chap_timestamp": 50,
        "chap_text": "Programmatic markdown in Quarto",
        "chap_href": "https://www.andrewheiss.com/blog/2024/11/04/render-generated-r-chunks-quarto/"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "chap_timestamp": 20,
        "chap_text": "Bob's Burgers Episode Fingerprints",
        "chap_href": "https://stevenponce.netlify.app/projects/standalone_visualizations/sa_2024-11-11.html"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "chap_timestamp": 51,
        "chap_text": "S7 0.2.0",
        "chap_href": "https://www.tidyverse.org/blog/2024/11/s7-0-2-0/"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "chap_timestamp": 18,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_46_highlights",
        "chap_timestamp": 40,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_45_highlights",
        "ep_date": "2024-11-06",
        "ep_duration": 4,
        "ep_description_short": "Eric's flying solo this week, but the show goes on! The eagerly-anticipated recordings of the 2024 Posit conference are now available and Eric shares a few of his favorite gems, plus the Quarto publishing system takes center stage with how GitHub actions brings automation to report generation, and a terrific batch of answers to the recent R/Pharma…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_45_highlights",
        "description_long": "\r \r Eric's flying solo this week, but the show goes on! The eagerly-anticipated recordings of the 2024 Posit conference are now available and Eric shares a few of his favorite gems, plus the Quarto publishing system takes center stage with how GitHub actions brings automation to report generation, and a terrific batch of answers to the recent R/Pharma workshop on building parameterized Quarto reports in R.\n\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq - @batool664 (X/Twitter)\nTalk recordings and workshop materials from posit::conf(2024)\n3MW (Automate Anything With R & GitHub Actions)\nParameterized plots and reports with R and Quarto\nEntire issue available at rweekly.org/2024-W45\nSupplement Resources\n\nEric's recap of the Posit conference experience in episode 174 https://serve.podhome.fm/episodepage/r-weekly-highlights/174\nEric's talk on web-assembly for shiny-based clinical submissions https://www.youtube.com/watch?v=iC78WbnwnIs\nIntroducing Positron https://youtu.be/8uRcB34Hhsw\nWe CAN have nice Shiny apps: What's new in Shiny's UI & UX (Greg Swinehart) https://youtu.be/FPc5PJRWHsk\nCloseread: Bringing Scrollytelling to Quarto (Andrew Bray) https://youtu.be/KqLxy66B3lQ\nCloseread Posit Contest https://posit.co/blog/closeread-prize-announcement/\nCollection of Quarto GitHub Actions https://github.com/quarto-dev/quarto-actions\nData Wrangling for Python or R Like a Boss With DuckDB https://www.youtube.com/watch?v=GELhdezYmP0\nEric's advanced use of GitHub actions for the R Pilot Submissions web-assembly app infrastructure: https://github.com/RConsortium/submissions-pilot4-webR\nNicola Rennie's R/Pharma workshop materials for parameterized reports with R and Quarto https://nrennie.rbind.io/r-pharma-2024-parameterized-reports/\nThe Ultimate Guide to Creating Lists in R: From Basics to Advanced Examples https://www.spsanderson.com/steveondata/posts/2024-10-29/\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @[email protected] (Mastodon) and @mike_ketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nDivinity - The Legend of Zelda: A Link to the Past - Nostalvania - https://ocremix.org/remix/OCR03442\nSmoke & Marbles - Castlevania: Symphony of the Night - Emunator, ZackParrish, Lucas Guimaraes - https://ocremix.org/remix/OCR04714\n\n\n"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://posit.co/blog/talks-and-workshops-from-posit-conf-2024/"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://3mw.albert-rapp.de/p/automate-anything-with-r-github-actions"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://nrennie.rbind.io/blog/parameterized-plots-reports-r-quarto/"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://rweekly.org/2024-W45.html"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://serve.podhome.fm/episodepage/r-weekly-highlights/174"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://www.youtube.com/watch?v=iC78WbnwnIs"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://youtu.be/8uRcB34Hhsw"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://youtu.be/FPc5PJRWHsk"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://youtu.be/KqLxy66B3lQ"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://posit.co/blog/closeread-prize-announcement/"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://github.com/quarto-dev/quarto-actions"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://www.youtube.com/watch?v=GELhdezYmP0"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://github.com/RConsortium/submissions-pilot4-webR"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://nrennie.rbind.io/r-pharma-2024-parameterized-reports/"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://www.spsanderson.com/steveondata/posts/2024-10-29/"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://ocremix.org/remix/OCR03442"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "links": "https://ocremix.org/remix/OCR04714"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_45_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We are back of episode 184 of the R Weekly Highlights podcast.\r \r This is the usually weekly podcast,\r \r where we talk about the great resources that are shared in the highlights section and elsewhere\r \r on this week's our weekly issue.\r \r My name is Eric Nantz, and, yes, we were off last week because yours truly was\r \r knee deep helping with a lot behind the scenes as well as in front of the camera, so to speak, with the virtual Our Pharma conference, which was, in my humble estimation,\r \r a smashing success.\r \r I think we had over 25 100 registrants at one point, tuning in during the conference days as well as some really awesome work shops.\r \r\n\nAnd you'll be hearing more about those workshops in a little bit in our last highlight, but nonetheless,\r \r that's why we were off last week. But I am here this week. Unfortunately, I'm by myself, so to speak, because\r \r my, truly awesome cohost, Mike Thomas, is knee deep in his day job projects, trying to get things done, and then he look for he looks forward to being back next week with all of you. Nonetheless, I'll hold the fort down for this week, and I got some fun things to talk about and share with our highlights here, which this week's issue has been curated\r \r by Batool Almruzak. And as always, she had tremendous help from our fellow Arruky team members\r \r and contributors like all of you around the world with your poll request and other suggestions.\r \r\n\nSpeaking of conferences,\r \r I'm happy to announce in our first highlight here that after a couple months of in the editing can, so to speak,\r \r the recordings from the 2024\r \r Posit Conference\r \r have finally landed on Posit's YouTube channel.\r \r We knew these were coming soon, but we weren't quite sure when.\r \r But this is a terrific way to catch up on what you may have missed if you were not able to attend\r \r the conference itself back in August.\r \r And if you wanna hear more of my take on the event itself, especially from the in person experience,\r \r I invite you to check out our back catalog here where I talked at length about this\r \r in episode 174\r \r of our weekly highlights. I'll have that linked in the show notes if you want to check that out. But, nonetheless,\r \r another great benefit of the recordings, even for someone like me who was able to attend,\r \r is that it is a multitrack conference. Right? And you can't possibly see all the talks that you want because inevitably there will be some that overlap,\r \r And especially in the case of\r \r when I gave my talk on the power of WebAssembly\r \r for\r \r the future of Shiny and clinical submissions, which, by the way, I will have re directly linked in the show notes. It's great to see the recording back, albeit I haven't watched it yet because\r \r even though I had a podcast and I've been doing podcasting for over, what, 10 years or whatever,\r \r it's hard to listen to watch myself on video, but I will at some point.\r \r\n\nNonetheless,\r \r when I was giving that presentation\r \r across the hallway, I believe one of the other rooms,\r \r was Pazit's kind of team presentation\r \r on the new Positron\r \r IDE. So that's a great one I'm gonna be catching up with to see kind of the genesis of that, the comparisons\r \r with your studio IDE, and it was kind of the, coming out party, if you will, Even though positron is still not, you know, quote unquote in production yet,\r \r it was, posit's first crack at really sharing their story behind the development of positron, and I'll be watching that\r \r space quite closely.\r \r\n\nAnd there are a lot of, and I do mean a lot of, other terrific talks. And I dare say there's something for everyone,\r \r whether you're knee deep in industry, health care.\r \r Certainly, shout out to my friends in life sciences. We had a lot of great talks on the life sciences tracks.\r \r Also, utilizing\r \r automated reporting\r \r and things in quartile, which you'll be hearing about\r \r throughout this, segment and the rest of the episode.\r \r And, yeah, for the shiny enthusiasts, there's a lot here too.\r \r I was watching a little bit, this weekend when I saw the recordings are up.\r \r I rewatched a talk from,\r \r the designer, so to speak, of the shiny UX side of things, Greg Swinehart.\r \r\n\nHe gave a terrific talk on the recent advancements in the user interface components of Shiny both for the r side\r \r and the Python side and lots of great resources that he shared.\r \r And he he always has a unique style to his talks. I I definitely resonate with it.\r \r And you would never know the importance of a HEX logo until you really watch his talk and how it kicked off a lot of their, design efforts for the shiny user interface function, especially with bslib.\r \r My goodness. Have you seen the hex sticker for bslib?\r \r That thing is ace, and I can't wait to get a hard copy of that.\r \r\n\nNonetheless, another great talk going back to the Quarto side of things\r \r that I wasn't able to see in person,\r \r was\r \r by Andrew Bray, where he talked about\r \r the new close read quarto extension,\r \r how the development journey of that began, and it was a close collaboration\r \r with another developer named Jeremy.\r \r And, also, it really brings to light\r \r a way that you can get that scrolly\r \r towing look that you might see on, say,\r \r you know, some\r \r data readout or data posts from, like, the New York Times\r \r or other groups that kinda use that technique.\r \r Well, if you're writing a portal doc, this close reads extension\r \r is definitely something worth your time to check out.\r \r\n\nAnd speaking of close read, that definitely relates to a little, ad hoc,\r \r addition here.\r \r I just learned a few days ago that posit is now running\r \r a close read\r \r contest\r \r to see what you can build for an engaging either data storytelling,\r \r an engaging tutorial, but really seeing what you can do\r \r to push close read to new heights. So I have a link to that, blog post from Pazit in the show notes as well. I dare say I've I've had attempts at doing a scrolly telling kind of presentation before.\r \r Ironically, at a very earlier version of what was then the art studio conference\r \r when I had a poster session.\r \r\n\nAnd, of course, a poster session in these days means like an electronic display that you're you're standing next to and and kind of walking through with people as they walk by and answer questions. But my my poster session back then\r \r was about kind of my take on the shiny community and the awesome advancements and my hope for a future shiny verse.\r \r I recall using a package from John Coon, good friend of mine,\r \r that kind of gave a somewhat scrolly telling look to a web based presentation.\r \r Albeit there were some quirks and no fault of his own. It was just the the HTML,\r \r package he was wrapping under the hood.\r \r\n\nBut I do think, closer to something I really wanna pay attention to, both for some day job tutorials or readouts,\r \r but also for some fun narratives too. So I might have to throw my hat in that contest. I don't know. I'm just saying.\r \r And there is a lot and a lot more resources in in the recordings that you'll see,\r \r on the blog post from posit.\r \r Also, speaking of resources,\r \r posit also\r \r at every positconf, you also have terrific workshops.\r \r And, unfortunately, they're not recorded. However, every workshop has made their materials online,\r \r and I have been referring back to the workshop that I was attending in person,\r \r databases with R and DuckDB by Kiro Muir. It was a fantastic\r \r workshop,\r \r and I'm all in on the DuckDB craze right now, which, again, speaking of the recordings,\r \r you can hear the keynote from the author of DuckDV,\r \r in the recording of the POSITIVE Talks as well. Another great\r \r great, development story of DuckDV and where we think the benefits are, and I dare say that we all can benefit from it in my, usage of it thus far.\r \r\n\nSo, again, lots more to check out. Obviously, I can't do everything justice in this segment here, but I'm really intrigued by catching up on what I wasn't able to attend in person\r \r and lots of great ideas that I think you'll generate\r \r in your daily work or your fun adventures with R and data science.\r \r We're gonna switch gears here to a more automation\r \r play story, if you will.\r \r I'll be at a mechanism that I think many, many in both the open source community as well as in their particular industry day jobs\r \r are leveraging,\r \r especially in the piece of automation\r \r and making sure that we can, you know, release the most robust code\r \r possible, say, for developing packages\r \r or if you wanna take away the manual steps of compiling things\r \r ourselves when we can let the magical machines in the cloud do it for us, and that is exposed\r \r via GitHub actions.\r \r\n\nAnd if you are new to GitHub actions and you just want a quick take on what it's actually doing\r \r and getting a really, you know, fit for purpose tutorial\r \r that you can use today to kinda get your feet wet a little bit and then give yourself the appetite to dive into further,\r \r then this next highlight here is just for you. And is author by friend of the show, Albert Rapp. He is back again with his, 3 minute Wednesday segment\r \r where he talks about getting up to speed with quarto\r \r with GitHub actions\r \r for compiling\r \r a quartal document.\r \r\n\nAnd this is not gonna get in so much the theory behind GitHub actions. You're not really meant to you're not expected to understand, not that you even have to, kinda what is happening behind the scenes of actions, but this is about how would you set up a report\r \r that you could automatically\r \r regenerate\r \r whenever you have a a change in the repository\r \r where this, report is hosted\r \r and to be able to automate this more in the future. So\r \r the post starts off with creating a new project, in this case, in the RStudio IDE,\r \r and he is careful to enable 2 options that you'll need for this is because this is relying on GitHub acts after all. You're gonna need to get repository locally for it, and he's also checking r env as well.\r \r\n\nR env is, of course, a,\r \r package in in the r community\r \r offered by Kevin Ushay, a a posit,\r \r to help you manage the dependencies\r \r for your project via its r packages, but in a self contained way.\r \r Usually, r m works really well. I will admit though,\r \r If I was recording this yesterday, I may not have been the biggest fan of it because I had a almost knockout drag out fight trying to get my app in production\r \r with some dependency, h e double l, that I had to deal with.\r \r Somewhat self inflicted, but, nonetheless, sometimes RM can be slightly cryptic with its messaging.\r \r Anyway,\r \r things happen just like anything in life.\r \r\n\nNonetheless, that's gonna be important for the rest of this tutorial when we get the GitHub action actually created.\r \r So the report itself that he's demonstrating here is nothing radical. It's simply a HTML based report\r \r that's gonna say that this report was rendered at a time,\r \r but this time is printed\r \r and executed via a code chunk in quarto,\r \r which would be very familiar to anybody that's used quarto or markdown before, just a typical code chunk.\r \r With that,\r \r you may notice that if you may have initialized r m, and then when you hit that render report button and pause it, it's gonna complain that there are some packages missing. So that's where you do need to install\r \r in your r mv library\r \r the r packages\r \r needed for r execution, which is which are, of course, our knitter and r markdown. So once you once you do that with rmd, then you try to render it again, then your local version\r \r of the report will compile correctly. And then you can see that, depending on when you ran it, that current day time printed right inside.\r \r\n\nGreat. You got yourself a report.\r \r Now let's imagine instead of just using the typical HTML format\r \r for the report output,\r \r you would like to render this as an actual\r \r document in markdown format going from quartal markdown to markdown,\r \r but in a way that GitHub especially\r \r can render that in a nice way.\r \r That's using what's called GitHub flavored markdown.\r \r And Quarto itself\r \r is a command line utility as well as integrated with various IDEs.\r \r So\r \r Albert switches and pivots to a new way of rendering the quartal doc instead of through the click button.\r \r He now shows you how to use the quartal render function to render that, and then there's a parameter\r \r tac tac 2\r \r to you to put in GFM, forget a flavor mock markdown.\r \r\n\nAnd then he's changing the name of the output file\r \r to reme.md.\r \r So now you've got a file that can be rendered\r \r in a special syntax\r \r or special file name. So when you go to the GitHub repository for the project, that readme is gonna be what's displayed automatically under the code,\r \r file listing there.\r \r Great. Now we got that working. You can push out on GitHub, and you could just simply\r \r run that report occasionally,\r \r manually compile it, manually push it up.\r \r But, no, that's not why we're here. We're gonna learn about GitHub actions. How does this work? So\r \r this is interesting because\r \r there is a package, of course, called use this that will let you\r \r define a GitHub action right away based on a template of current of more you just\r \r of, like, workflows that are pretty typical for an R, you know, developer, whether it's package development\r \r or R markdown compilation or whatnot.\r \r\n\nAlbert is gonna show you how to build this from the ground up. And I do think this is important\r \r because there are times when you're new to a framework which is an abstraction\r \r that, in fact, GitHub actions\r \r are really an abstraction on top of building a container\r \r with various bells and whistles to do something.\r \r That's really what GitHub,\r \r actions are under the hood,\r \r and the way you interface of it is constructing a special YAML file that's gonna define your workflow.\r \r So Albert leads us through with what do we need in our local repository to make this happen.\r \r That is you need a dot GitHub folder and then you need a subdirectory in that called workflows, and this is specific to GitHub here.\r \r\n\nAnd then once you have that, then you're gonna create a YAML file inside that workflows file.\r \r You can name this anything you want, but\r \r in in the end, it's got to be a YAML file, and it's gonna have specific syntax that he's gonna walk you through\r \r in the rest of this post. Now it'd be pretty boring for me to read all the bits verbatim here, but I'm gonna highlight\r \r at a high level the really important parts to make sure that you're setting yourself up for success\r \r the right way.\r \r 1st of which\r \r is how do you define when the action is going to be run.\r \r In this case, it's gonna be run on every push to the main or master branch of the repository,\r \r depending on what you call that that that, quote unquote main branch,\r \r that's in a certain directive at the beginning under the the narrative where you name it. There's this on declarative where you define, okay, on what operations will this operate?\r \r\n\nIn this case the push operation\r \r from there below that then you have the jobs the declaration and this is where you could have 1\r \r or more jobs which you can think of are a collection of steps to accomplish a task\r \r So in this case, the task that he's gonna call it is render,\r \r and each job\r \r needs\r \r an environment\r \r defined for what you're gonna run this on.\r \r Typically speaking,\r \r you want to stick with a Linux based environment, especially if it's not like a,\r \r a situation where you have to check all multiple OSes, in this case, combiner report.\r \r Ubuntu dash latest will be your friend for this because you're not really caring about the version of it. You just want something that can quickly get quartile up and running and run this report and be on with your way.\r \r\n\nSo that's in the runs on declarative.\r \r And then if you want\r \r this action to be able to\r \r write or commit things on your behalf,\r \r you'll wanna make sure to give it the right permissions, and that's in the permissions declarative where you have to explicitly tell it, I want you to write to this repo. And that's another declarative here.\r \r And then the post talks about the different steps. And at a high level, what they are,\r \r our first getting quartile installed itself, which is done via another GitHub action.\r \r So that's another thing to keep in mind. Just like in functions in r, you can run other functions inside of them.\r \r You can run other GitHub actions as steps inside\r \r your overall GitHub action. And so the Coral team\r \r has generally set up an action for getting Quartle installed, so you really just have to declare it and then define which version of Quartle you wanna install,\r \r which in this case is the latest version.\r \r\n\nAnd in this case, Albert is actually being very explicit with this particular step in the pipeline for installing the R dependencies\r \r where he is simply calling\r \r arbitrary\r \r code\r \r via a bash line calling r script\r \r to install packages that he needs\r \r to first get r m up and running and then using r m itself to restore the library.\r \r Now to be transparent,\r \r there is an action that'll let you do this as well or a couple of actions to do this, but it's good to see kind of how you can do this in your own way when you have to do things more custom. I'll get to that in a little bit.\r \r But assuming you got the dependencies up and running, now the next step is actually rendering the portal document, and that is simply\r \r in the run declarative just like how Albert used the r script\r \r in that run declarative to\r \r install rm, but then run rm restore.\r \r\n\nYou can use this run declarative to run that same chordal render\r \r the chordal render, function or I should say command line call\r \r in the exact same way he did earlier in the post. So nothing changes. It's as if you're typing that in the command line. You're just doing it in the GitHub action.\r \r And then this part will look a little odd at first if you're not used to it, but then there is a step about,\r \r okay, the readme has been updated in the action.\r \r I need to push this up to the repository\r \r so that it can actually render that finished product.\r \r And that's where you can run, again, via the run declarative,\r \r the various git commands to tell git who you are. In this case, you're\r \r gonna actually define it as a GitHub action bot. You can put anything you want there.\r \r\n\nAnd then literally as if you're in git command line mode, adding the readme, committing of a commit message, and then pushing it up. In order to do that, though, the GitHub,\r \r action needs to be able to\r \r do this on your behalf\r \r using your repository\r \r secret token. Otherwise, it's gonna complain that it's not authorized. They do it. So every action step lets you have an ENV or an environment declaration\r \r where he's able to say the GitHub token, but not put in the token like string verbatim\r \r to use, like, this glue like syntax with the curly brackets to inject\r \r that variable from the secrets\r \r kind of store, if you will.\r \r\n\nIt there is every repository in GitHub action will have the secrets thing\r \r available where you could put almost any environment variable you want that you define ahead of time, but the GitHub token one is there for you free of charge. So\r \r that explains that stuff. And then lastly,\r \r you push this YAML file to the repository. And if all goes to plan, your report will render automatically via GitHub actions.\r \r I say if it goes according to plan because I have never once,\r \r in all the times I've used GitHub actions, gotten it right the first time. There is always something that happens\r \r whether I mistype a package name in my dependency installation\r \r or I'm doing something really crazy with bash scripting and I have no idea how to debug it, and then I get that infamous red x\r \r in the actions\r \r output in the in the GitHub repo. I've\r \r literally went through this yesterday. I was banging my head against the desk almost on this one.\r \r\n\nSo\r \r budget a bit of time. You're gonna need it. I I I wish I could sugarcoat it, but I can't. But once you get up and running with it and you get it working,\r \r give yourself a pat on the back because that's a major achievement.\r \r It really is.\r \r So this is scratching the surface so I can do GitHub actions. I am even if I joke about the the kind of debugging process,\r \r when it works, all goodness, does it save a lot of time?\r \r To illustrate that, I'll invite you to check the show notes where I link into the show notes of the repository\r \r that we've built\r \r for this, Shiny app that we're using as a template\r \r for a web assembly version of a Shiny app going into a clinical submission.\r \r\n\nI use GitHub actions\r \r quite a bit,\r \r for this this workflow,\r \r and the ways I use it are pretty\r \r pretty novel to me anyway because I never done anything this in-depth before.\r \r I have 3 actions here.\r \r One of which is to indeed render a quarto based document in multiple formats, both a PDF format\r \r and an HTML format for this reviewer guide.\r \r And for the HTML format,\r \r I wanna publish that\r \r actually to,\r \r s 3 bucket\r \r so that I can render this as a viewable link in the public domain for our reviewers in case they wanna see the latest and greatest draft of it without having to download it themselves.\r \r So that was a clever thing I was able to to hook in there\r \r and be able to render 2 formats. There's a lot of, you know, interesting points on that you can check out on the repo.\r \r\n\nThe other action was to actually publish the WebAssembly application\r \r compiled\r \r and then publish it to Netlify.\r \r Before I knew about GitHub Pages being a a first class citizen for WebAssembly apps. I did Netlify because that's all I knew back then, so there's an action that helps with that. And also to publish a more,\r \r standard bundle of this whole project that's gonna be used\r \r in what we call a transfer to the regulators directly. That's the 3rd action.\r \r And in each in each of these cases, I'm using bash scripts that are sourced in the action itself via a scripts folder.\r \r And I won't pretend I'm the best bash script there out there, but that's another handy thing. If you found yourself adding a whole bunch of commands in that run declarative,\r \r you could outsource that to a bash script and then be able to run that on the fly.\r \r\n\nAnd so there's some interesting learnings from that as well. So\r \r I have done a lot with GitHub actions.\r \r I won't pretend that I'm an expert at all of it,\r \r but I do admit they have helped my workflows\r \r immensely.\r \r And, yes, there are versions of this available on other platforms as well. GitLab in particular has their own take on it. We're gonna what they call GitLab runners.\r \r Very similar\r \r YAML type syntax. There'll be some differences here and there. I believe in codeberg does this as well. So it's not\r \r the automation play, even though GitHub gets the most of the mind share, it's not just strictly related to them. There are many other ways\r \r you could implement this as well. So\r \r wonderful post by Albert. He goes, gets you up and running quickly.\r \r\n\nAnd, yes, you'll wanna check out the community of resources for\r \r the GitHub actions that deposit team maintains\r \r that are a many there are many, parts of their workflow\r \r that you can get from the use this package.\r \r There's even GitHub actions for the shiny test 2 pack. It was to help get shiny, the test of shiny app with shiny test 2 and a GitHub action. There's lots of things you can do here,\r \r and I've already blabbered enough about it, but definitely check out the resources and Albert does a terrific job getting you up and running quickly. You have a very relatable issue.\r \r We love ourselves continuity on this very show even, and we've been talking about that GitHub action that would render\r \r a quarto document. Well, quarto itself,\r \r there are so many things you can do with it, and I do mean many. And one of the, you know, the features that it carried forward from what you might call the previous generation of quartile, which has been our, you know, our markdown,\r \r is the idea of using parameters\r \r inside your reports\r \r so that instead of hard coding everything in the body of the report itself\r \r and then having to, like, you know,\r \r find, modify, replace when you want to change, like, a parameter value\r \r or you want to change, like, a dataset name or a dataset variable,\r \r you can use parameters\r \r in your Chordal report so that you could define those ahead of time,\r \r kind of like function arguments,\r \r and render a document dynamically\r \r injecting those values\r \r into the body of the report. And our last highlight\r \r is actually a wrap up kind of follow-up q and a portion\r \r from Nicola Rennie, who was terrific\r \r and once again being very generous of her time for Doctor Pharma conference where she led a workshop\r \r on creating parameterized reports with with quarto\r \r and\r \r it was a spectacular\r \r workshop. We have linked in the show notes\r \r the resources from this workshop with the slides as well. So the recordings should be out in a couple months, so you'll be able to watch a recording of it.\r \r\n\nYours truly is gonna be helping with editing on that, and I can't wait to watch it because I'm I'm gonna learn something new, I'm sure.\r \r But Nicole is, blog post here\r \r is getting into some of the questions that they didn't have time to address in that, 2 to 3 hour workshop.\r \r And, well, I'm gonna pick out a few that were nuggets to me,\r \r especially in the intersection of what you can do with r itself in the in the compilation of these parameter\r \r reports\r \r and also with quartile itself.\r \r There were some great questions\r \r about\r \r well, when you have a function,\r \r is it safe to add an argument for, say, the data frame itself? Because she's using, I believe, the Gapminder dataset to illustrate the parameterized reports,\r \r and she kind of shows the best of both worlds where\r \r maybe in a in a first version of the function, you're assuming that the gap miner data is the one loaded,\r \r and you're just gonna let them choose put in a parameter for, like, the continent to summarize in the filter statement.\r \r\n\nBut you could still have that continent as the as the first parameter, but then have a default argument for data\r \r that just happens to be the Gapminder.\r \r And in that way, if for some reason you wanna change the name of the data frame, you can still do that\r \r and be able to leverage all the benefits of the quartile, you know, parameters and everything like that\r \r with that data argument.\r \r Speaking of which,\r \r in order to evaluate that as an object, if you have, like, the name of an R object as one of your parameters,\r \r you can use the get function in R to basically\r \r translate that string of that object name\r \r into the object itself and then do whatever you need to do for further processing.\r \r\n\nShe also mentions there was questions about could we could we use,\r \r the parameters to generate dynamic tables instead of just plots.\r \r And absolutely, yes. Right? I mean, you could easily\r \r create a table with another handy function\r \r to be able to have, say, a a reactable type structure\r \r just as much as a as a plot. It all depends on you and what you wanna what you wanna define with it.\r \r And then there were also questions about her use of the\r \r walk function and the map function from the per package as part of this iteration of creating these\r \r multiple reports based on different configurations of parameters.\r \r\n\nThe walk function\r \r is really used for it's not so much you care about the output in R itself. You care about what it's doing as a side effect, like creating files,\r \r creating images, creating or doing some kind of uploading of a file or whatever.\r \r You don't really care about the object coming back from it. It could be invisible for you all you care.\r \r But if you have iteration where you wanna do something with that result,\r \r map is the way to go. So there's there's a nuance there, but once you get the hang of purr, it'll it'll hopefully be easy to grasp once you have that.\r \r There are some fundamental\r \r questions\r \r in that.\r \r\n\nWhat is the biggest difference doing quarto and r markdown in this case? Well, again,\r \r r markdown is great,\r \r you know, expect I mean, look, I've built so many things of r markdown. Right? You don't have to switch a quartile if you don't need to. I mean,\r \r quartile is gonna, you know, get probably some more utilities added to it. There is a lot of developer resources behind it now. And with its cross language\r \r capability, we're seeing a lot of data science teams really embracing that. But, hey, r markdown is stable.\r \r R markdown is very dependable in the r ecosystem.\r \r\n\nYou're not compelled to switch if you don't have a need to, so don't feel like just because you're seeing all this material\r \r that you have to go away from r markdown. I mean, it's still very much a fundamental\r \r pillar of the r community in my humble opinion.\r \r Another nugget that I didn't know about in respect to let's say you have a lot of R code in this report and you want to just\r \r source the or execute that R script itself in your quota report.\r \r I didn't realize about the, parameter called file\r \r where you give it the path to that particular script, and it will basically,\r \r source that into your your execution.\r \r\n\nAnd that is pretty handy. That that means you could, you know, do a good job of modularizing\r \r your code structure\r \r instead of having everything in one big, you know, setup chunk if you will. You could, you know, export that into different scripts and then use them use them as you need to throughout your report.\r \r And there are also great great questions about the concept of styling and formatting,\r \r such as do those fancy call out blocks that you get in quartile that look great in HTML, do they also work in PDF?\r \r Well, yes, they can. You just may not be able to do the collapsing stuff because it's a static representation.\r \r\n\nBut quartile is very careful to make sure that you can get most of the features\r \r in each output format.\r \r And in the case of\r \r interactivity,\r \r at least getting static versions of those.\r \r And I was able to, you know, learn this earlier this year and last year\r \r with that reviewer document that I was making as part of that submissions pilot project,\r \r I could use the call out blocks and it looks really darn good in the PDF. Like, I I'm pretty happy with it.\r \r So much so that now we have another work stream about the spin up about\r \r using quarto and more of these, submission documents. So I'm really excited for that. But getting those nice enhancements in the style,\r \r and, of course, we're keeping an eye on typest as well,\r \r it's a great time\r \r for those that still have to live in the world of static documents. I think, you know, Chordle is still gonna be\r \r very helpful for you.\r \r\n\nAnd, also, there are some real nuggets here about how\r \r you can generate these multiple reports\r \r from the command line. One thing that took me some getting used to, and, again, I haven't watched the workshop yet,\r \r is that you can have a YAML file\r \r with these params\r \r defined, like, say, a default value of them. And that can be fed into the command line version of quartile render\r \r so that you can just feed in that YAML file and then you'll be able to render\r \r that document\r \r on the fly. But if you want to do this within R,\r \r you've got to do a little trick here that I didn't really realize\r \r is that if you want\r \r if you have to get these parameters\r \r as kind of these key value name pairs,\r \r and if that's where in the quartal render function\r \r that the quartal package itself exposes the r package, I should say.\r \r\n\nYou have to give it\r \r the name, the list rather than just the YAML file name.\r \r And she has this great tip of using the yaml.loadfile\r \r function from the YAML package.\r \r And that way, you can just feed that\r \r that evaluation\r \r of that function\r \r in the execute params parameter itself\r \r instead of you having to manually do, like, the list, if you will, yourself of those parameters. That is awesome.\r \r Man. I I'm so glad I learned that tip because I was dealing with that just recently with a project at work and I kinda\r \r kinda gave up on doing it from the our side of things, but now we can definitely do that. So\r \r that just is my quick take on it. There are lots of terrific resources I mentioned that Nicola\r \r Nicola has has shared. At the end of the post, some more workshop materials from others, some more blog posts, and like I said, the recording should be up in a month or 2 depending on how fast I can get the editing chops on. And I can't wait to to watch this one again because I\r \r literally use quartal parameterized reports for a pretty fun daytime project\r \r where I was able to escape the confines of a PowerPoint\r \r and have a dynamically rendered quartal dashboard, but tailored for each project\r \r using parameters. It was awesome once I got it working, and I was like, I I've gotta be able to push this more into the mainstream\r \r of how we communicate these results. So\r \r I'm I'm definitely excited to see where this takes us and\r \r another wonderful workshop in the space of parameterized\r \r reporting.\r \r\n\nThis is a great companion to another resource we shared in previous episodes from JD Ryan\r \r on her workshop on parameterized reports or quartile. So you got 2\r \r top notch instructors from the art community\r \r giving you level up knowledge on quartile parameterized reports. What what a time to be alive, folks.\r \r And there is a lot more I could talk about here, but, you know, this episode is getting long already, so So I'm gonna close out the episode here of an additional find that caught my attention when I was perusing this issue here.\r \r And in my additional find this week, I'm gonna, you know, put a great spotlight on another great post from Steven Sanderson. He has been,\r \r you know, a machine almost or some of his great, tutorials\r \r on the fundamentals of R and data science. And he has this great post, this great guide, if you will,\r \r on how you can create lists in R.\r \r\n\nList is one of the most important object types I have had in my, you know, last probably 5, 6 years of my day to day work because there are so many creative things you can do with it. A list for those uninitiated\r \r is simply a collection of other objects and r, but they don't all have to be the same.\r \r Unlike a vector where all the say if you have a numeric vector expecting that they're all numeric,\r \r But if you have a string in there, it's gonna automatically convert it to string the moment it sees one string in there because they have to be the same type. You can't mix the\r \r number and string.\r \r\n\nSo the list is a way around that sort of thing. And, plus, the list, you can create as much of a hierarchical structure as you like.\r \r And that can be really important, especially some of these more complicated data structures with, like,\r \r digital readouts,\r \r digital machines, and we call it digital biomarkers in our\r \r line of work. A lot of web data is coming as list type structure from JSON.\r \r Being able to know the ways you can create lists, name them, and do various operations with them\r \r using either the built in apply family of functions or the per package.\r \r Lots of awesome things you can do with lists\r \r and they are again a huge huge part of my my daily workflow.\r \r\n\nOnce you once you get a hang of them, there are so many things you can do with it,\r \r such as a package I've learned about from our pharma.\r \r I've heard in the grapevine, but I I saw a talk about it,\r \r about the cards package by Daniel Sjoberg and Becca Kraus,\r \r where you're creating basically a results type data frame of these different, like, statistics for a given variable or a set of variables.\r \r But these statistics may be different.\r \r And some may be a numeric result, and some may actually be more of a character result, especially when you're dealing with model attributes or things like that.\r \r Their way around it\r \r to mix all these different types of results together\r \r is to use, wait for it,\r \r a list column inside your data frame.\r \r\n\nThis is\r \r awesome because then you get to have a lot more control\r \r and flexibility\r \r in what you're doing with these, you might say, wrapper type data frames\r \r than either putting, like, entire data frames as, like, a cell value in a list column or another\r \r model fit object, which the broom package does that cards is kinda taking inspiration from.\r \r So with the list object, you can do so much stuff. I highly recommend this post to get get up and running quickly, so it was great to great to see this featured in the issue.\r \r My goodness. Even flying solo here, I realized I've taken a lot of time already. So I'm gonna get you on your way here, but we have a few items to close out, of course, is\r \r the R weekly project is a community driven project. We do not have sponsors. We we do this all for you\r \r in the R community and the data science community.\r \r\n\nAll we ask is for your help to make sure this is up and running quick, you know, sustainably,\r \r and that's via your contribution. So if you see wherever you authored it or someone else authored it, a great resource that should be featured in next week's issue, you just go to rweka.org.\r \r That should be in your bookmarks. If it's not, I dare say, hot take. You should have rweekly in your bookmarks.\r \r Hit that little, ribbon at the top where it'll take you to our draft of the upcoming issue and a way to do a poll request right there in GitHub's web UI.\r \r You just need to do a little markdown, folks.\r \r\n\nI'll markdown all the time just like with quarto,\r \r and you can give us that great resource. And the the next issue's curator will be glad to review that and merge it in. So we're really,\r \r really eager to have your contributions on this very, very important project.\r \r We also like to hear from you in terms of this show itself. We have a little contact page linked in the show notes. You can find this\r \r hand you a web form to fill out.\r \r You can also with a modern podcast app, I really like Podverse and Fountain\r \r these days, but many others in the ecosystem,\r \r you can send us a fun little boost along the way. They give us feedback directly without anybody in the middle, without any\r \r corporate overload trying to say, oh, nope. You can't say that. You can be as as unfiltered to us as you like.\r \r\n\nLuckily, all the feedback we get is usually positive. But if I make any fumbles, I always like to hear about that\r \r too. And, also, you can hear you can get in touch with me on social media these days.\r \r I'm mostly on Mastodon with my\r \r [email protected].\r \r Also on LinkedIn, you can search my name and you'll find me there saying something usually or responding to other people.\r \r I am contemplating\r \r getting a blue sky account because I am seeing a lot of traction in the art community\r \r going to this. But honestly,\r \r Mastodon's been pretty nice to me. And I know there's some people wondering, oh, is this replacing Mastodon? No. I don't think so.\r \r\n\nI think they both can exist, but I think Mastodon has been extremely helpful for me for both my R and data science, you know, friends getting keeping in touch with them and meeting new friends along the way, as well as my podcasting adventures. So Mastodon is not broken at all. In fact, I'm gonna keep going with that as long as I can.\r \r And, big shout out to Dan Wilson speaking\r \r of Mastodon. He's the one that maintains the r stats dot me server for Mastodon. That's been a great one to follow\r \r and he he's been, you know, doing a lot of work to keep that up and running. So, Dan, your your your efforts are not going unnoticed for sure. I I greatly appreciate what you do for us.\r \r Nonetheless, that's gonna close-up shop here for this episode of our weekly highlights.\r \r\n\nWe hope to have Mike back next week, so you don't have to hear me babble all the time.\r \r Nonetheless, I hope you have a wonderful week for wherever you are.\r \r Again, have fun with your journeys of R and data science, and we will be back with another episode of R Weekly Highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_45_highlights",
        "chap_timestamp": 30,
        "chap_text": "posit::conf(2024) recordings",
        "chap_href": "https://posit.co/blog/talks-and-workshops-from-posit-conf-2024/"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "chap_timestamp": 51,
        "chap_text": "Automating with GitHub Actions",
        "chap_href": "https://3mw.albert-rapp.de/p/automate-anything-with-r-github-actions"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "chap_timestamp": 47,
        "chap_text": "Paramaterized reports with Quarto",
        "chap_href": "https://nrennie.rbind.io/blog/parameterized-plots-reports-r-quarto/"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "chap_timestamp": 14,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_45_highlights",
        "chap_timestamp": 38,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_43_highlights",
        "ep_date": "2024-10-23",
        "ep_duration": 59,
        "ep_description_short": "Bringing tidy principles to a fundamental visualization for gene expressions, being on your best \"behavior\" for organizing your tests, and how data.table stacks up to DuckDB and polars for reshaping your data layouts. Episode Links This week's curator: Jon Carroll - @[email protected] (Mastodon) & @carroll_jono (X/Twitter) Exploring the…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_43_highlights",
        "description_long": "\r \r Bringing tidy principles to a fundamental visualization for gene expressions, being on your best \"behavior\" for organizing your tests, and how data.table stacks up to DuckDB and polars for reshaping your data layouts.\nEpisode Links\n\nThis week's curator: Jon Carroll - @[email protected] (Mastodon) & @carroll_jono (X/Twitter)\nExploring the tidyHeatmap R package\nDon't Expect That \"Function Works Correctly\", Do This Instead\nComparing data.table reshape to duckdb and polars\nEntire issue available at rweekly.org/2024-W43\nSupplement Resources\n\ntidyHeatmap: Draw heatmap simply using a tidy data frame https://stemangiola.github.io/tidyHeatmap/\nNovel App knock-in mouse model shows key features of amyloid pathology and reveals profound metabolic dysregulation of microglia https://molecularneurodegeneration.biomedcentral.com/articles/10.1186/s13024-022-00547-7\nShiny App-Packages chapter on writing tests and specifications https://mjfrigaard.github.io/shiny-app-pkgs/test_specs.html\nWANT CLEANER UNIT TESTS? TRY ARRANGE, ACT, ASSERT COMMENTS https://jakubsob.github.io/blog/want-cleaner-test-try-arrange-act-assert/\nSuper Data Science Podcast 827: Polars: Past, Present and Future, with Polars Creator Ritchie Vink https://www.superdatascience.com/podcast/827\nduckplyr: A DuckDB-backed version for dplyr https://duckplyr.tidyverse.org/\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @[email protected] (Mastodon) and @mike_ketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nBlack Feathers in the Sky - Kid Icarus: Uprising - MkVaff - https://ocremix.org/remix/OCR04200\nCross-Examination - Phoenix Wright: Ace Attorney - PrototypeRaptor - https://ocremix.org/remix/OCR01846"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://fosstodon.org/@jonocarroll"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://tomsing1.github.io/blog/posts/tidyHeatmap/"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://jakubsob.github.io/blog/how-to-improve-your-unit-test-titles/"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://rdatatable-community.github.io/The-Raft/posts/2024-10-17-duckdb_polars_reshape-toby_hocking/"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://rweekly.org/2024-W43.html"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://stemangiola.github.io/tidyHeatmap/"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://molecularneurodegeneration.biomedcentral.com/articles/10.1186/s13024-022-00547-7"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://mjfrigaard.github.io/shiny-app-pkgs/test_specs.html"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://jakubsob.github.io/blog/want-cleaner-test-try-arrange-act-assert/"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://www.superdatascience.com/podcast/827"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://duckplyr.tidyverse.org/"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://ocremix.org/remix/OCR04200"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "links": "https://ocremix.org/remix/OCR01846"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with a 183 of the R Weekly Highlights podcast.\r \r This is your weekly podcast. We're gonna talk about the great resources that are shared every single week on this week's Our Weekly Issue.\r \r My name is Eric Nantz, and I'm delighted you're joining us from wherever you are around the world.\r \r Already near the end of October, it's hard to believe the time is flying by. The air is crisp\r \r in the mornings as I ride my bike to my kid at school. You can feel the the chill in the air, but, nonetheless, we're heating things up here in more ways than one with this episode. I can't do that alone, of course. My, next, generator of our heat, if you will, is right here next to me virtually, Mike Thomas. Mike, how are you doing today?\r \r\n\n[00:00:52] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'm doing pretty well, Eric. This is the first I guess I'm spoiling it a little bit, but this is the first our weekly I've seen in a couple weeks, we where we are not discussing\r \r AI in any of the three highlights.\r \r I don't know if that means that\r \r the AI buzz has has cooled off maybe.\r \r\n\n[00:01:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Or they know that we need a break from it either way. Probably both. It could be both. It could be both. But, yes, it's good to have variety in life as we say in this very show, and we got a good variety of content to talk about with you today. And our weekly, if you're new to the project,\r \r this is a terrific resource. We\r \r aggregate all the awesome use cases of R across data science\r \r and industry, academia,\r \r and new packages and updated packages and great tutorials. And we got a mix of all of the above on this one.\r \r And it has been curated this week by our good friend, Jonathan Carroll, who is also gonna be involved with helping\r \r chair for the first time ever\r \r the R pharma conference. It's not just having a, you know, US or western hemisphere based track. He is helping chair the APAC track for the Asia Pacific region. So we're very happy to, John, to have you involved with our team. He's already been hard at work preparing for that conference. But as always, with our weekly, he had tremendous help from our fellow, our weekly team members, and contributors like you all around the world of your poll request and other great suggestions.\r \r\n\nAnd like I said, we're gonna heat things up initially on this very podcast, and we're gonna talk about a fundamental pillar of visualization\r \r across multiple disciplines,\r \r and that is the venerable heat map.\r \r And if you you know, as usual on a podcast, it's hard to describe everything in audio fashion. But a heat map, if you haven't seen that before,\r \r is a 2 dimensional, you might say, grid where each cell\r \r is kind of the, you know, the expression, if you will,\r \r of how large or small a quantity is.\r \r And we see this a lot in, for example,\r \r correlation analyses where you might look at all the pairwise correlations across a group of variables,\r \r and each of those combinations is a cell in the heat map with a higher correlation,\r \r which is, of course, between 01,\r \r might get either a brighter color or darker color depending on how you invert the palette\r \r and whatnot.\r \r\n\nAnd there is another domain where heat maps are\r \r very much in play and very much a fundamental,\r \r you might say, pillar of data exploration,\r \r and that is the world of genomics and biomarker analyses.\r \r From my days many years ago dealing with the Bioconductor\r \r project, I create a lot of these heat maps often using the core set of Bioconductor\r \r packages that\r \r would have nice wrappers around the typical object types that you get in Bioconductor,\r \r which is typically the matrix.\r \r A matrix is a fundamental\r \r data input in many of the classical heat map functions.\r \r Maybe you're getting data that already isn't quite in the Bioconductor like layout, but you want to take advantage of some of these great visualization\r \r techniques\r \r like heat maps. And that's where our first highlight comes into play.\r \r\n\nIt is a blog post author by Thomas Sandman, who is a\r \r scientist at Denali Therapeutics, and I can tell who has vast experience\r \r in the world of genetic and biomarker and PKPD\r \r analyses\r \r because he is actually attempting in this blog post to recreate\r \r some very nice heat map visualizations\r \r from a recent manuscript\r \r looking\r \r at the that the effect of a specific mutation of a gene\r \r for\r \r understanding\r \r more of the pathology\r \r behind\r \r what turns out to be neurodegeneration,\r \r which many people are familiar with the Alzheimer's disease as one of the manifests of that.\r \r But there has been research in many, and I do mean many decades,\r \r on trying to find the best\r \r genes and other biomarkers to target\r \r to try and hopefully minimize the impact of this, you know, debilitating disease and hopefully even cure it altogether.\r \r\n\nIt's been a lot of research. There's been a lot of misses along the way, but there are some promising\r \r avenues in this manuscript of a few lipids\r \r and also other additional biomarkers\r \r that they did an experiment with mice to see what the gene expression would be in certain parts of their brains\r \r on this regulation of these of these genetic markers.\r \r And the heat map is, like I said, a classic way to visualize\r \r the impact, in this case, of some linear models\r \r looking at the different, you know, characteristics\r \r of these lipids\r \r after this experiment.\r \r\n\nAnd so the post starts off with giving us, of course, a nice link to this manuscript, which we'll link to in the show notes as well.\r \r But this manuscript, if you do dig through it,\r \r has a little bit of a description\r \r on the methods used and some of the r packages that were used mostly from Bioconductor\r \r and, thankfully,\r \r example\r \r Excel files with\r \r the results of the stat analysis.\r \r However, there was no article shared with this, which, again,\r \r unfortunately, is kind of common in these areas. Right? You may get snippets of this for reproducibility, but you don't quite get the full picture.\r \r So with that said,\r \r the the journey begins with trying to figure out, okay, how do we get this data\r \r ready to go for a statistical analysis or a visualization, I should say, with heat maps.\r \r\n\nThe first step is to import this data from Excel, and there's some nice, I can tell this blog is written record, also got some nice call out blocks that you can expand to look at the different functions that Thomas has outlined here.\r \r Really nice use of ReadExcel\r \r and TidyR to get the data into the right shape for the eventual,\r \r heat map visualizations.\r \r Also, there was a\r \r additional spreadsheet\r \r that the researchers shared with the statistical analysis, so he's got,\r \r CSV import of that particular file as well if you just want to get the finished product of that.\r \r And to make generating heat maps easier,\r \r Thomas is spotlighting\r \r the package\r \r tidy heatmap,\r \r which is a nice front end to another package called complex heatmap,\r \r which again would expect the data going into it to be in matrix form.\r \r\n\nBut tidy heat map lets you have a more, you know, tidy ish type data where you've got your rows as observations,\r \r columns as\r \r the variables.\r \r And he's got a nice way, once you do a little filtering\r \r and a little pre processing to match kind of the groupings that went into this original manuscript's heat map\r \r visualization.\r \r It literally is a function called heat map feeding in the data frame,\r \r which variable corresponds to your rows,\r \r which variable corresponds to your column, which in this case is the sample IDs\r \r of these different mice because there are different samples taken for each for each specimen.\r \r\n\nAnd then what is the value going into it? In this case, it's called an abundance measure, which is the\r \r fold change\r \r log transform of the gene expression of these markers.\r \r And right away, you got a pretty nice looking heat map along the way that looks like straight out of ggplot2. I believe it's using that under the hood,\r \r but you can do a lot more to this. And that's what the rest of the post talks about. How do we go from that very\r \r quick starting point\r \r to a heat map that more matches what the manuscript\r \r outline? So there's a few steps here involved,\r \r one of which is to change the color palette a little bit.\r \r\n\nAnd there is, a set of packages that are being used here. 1 is called circlewise,\r \r which I haven't seen before,\r \r which has its color ramp 2 function\r \r to basically say, okay. For this amount of breaks in your numeric axis,\r \r use\r \r these set of colors going from navy to firebrick\r \r with the different ranges, and then you can now feed that into\r \r that original heat map call. So now you've got a heat map that definitely looks a little more like you would see in many of these manuscripts already\r \r colorized differently.\r \r And then also there is additional ways that you can put grouping\r \r annotations\r \r on top of those columns, which in this case were depicting\r \r the sample IDs.\r \r\n\nThey have an inherent grouping between those,\r \r so this is going to let you do, like, a visual split, kind of like a little bar with an annotation in the middle\r \r over each of these groups. So you can quickly see then the different types of samples\r \r based on the different type of genetic marker it was targeting.\r \r So that's already very familiar in the ggplot2 side of things with fascinating.\r \r But that's not all. You can also add\r \r custom annotations\r \r as well where there is a handy function called annotation\r \r or annotation_tile,\r \r which now under those headings that you saw\r \r above each column,\r \r you can then do like a in essence a color like legend\r \r that depicts different groups within each of these overall groups. In this case, the batch,\r \r which is these samples usually goes in a different batch for the experiment,\r \r and then also the gender of these mice. So those can be neatly colored so your eyes can quickly see then\r \r on top of this one genetic marker\r \r what were the batch the batch ID in terms of color\r \r and then also the gender associated with that. So it's a really,\r \r really handy way\r \r to visualize that grouping in a categorical fashion but with colors instead.\r \r\n\nLastly, but certainly not least, we got some additional processing to do,\r \r and that's where we start to look at how do you annotate additional\r \r quantitative\r \r information\r \r underneath\r \r these these additional group grouping of colors\r \r based on the cell number that these markers are coming from. So that's another handy function\r \r waiting to happen\r \r with an additional use of annotation tile and annotation\r \r point.\r \r So, again, audio won't do this much justice, but\r \r underneath those color regions, he's got little dots that that depict the cell number with a little y axis right at the left. So\r \r already done about 3 or 4 different\r \r types of variables above the columns.\r \r\n\nAnd then\r \r the last part is about how the rows are organized, and this is gonna take a little more dplyr\r \r data munging magic\r \r to make sure that the groups match kind of the grouping order based on a) the expression level\r \r and then also\r \r doing a more manual grouping fashion to match kind of different overall\r \r groups that we saw\r \r in the heat map earlier\r \r in the manuscript.\r \r So all the code is reproducible.\r \r Again, this heat map function has got a lot of parameters inside.\r \r But depending on how in-depth you want to make your customizations,\r \r there's typically a parameter for it. Like I mentioned, this column\r \r grouping, the way you can organize the different rows, the way you can put these annotations together.\r \r\n\nI never knew how much power was exposed to us with these heatmap functionality. So next time\r \r I whether I do a biomarker analysis in the future or even go to my tried and true correlation analysis,\r \r I'm gonna have to give tidy heat map a try. This looks really fun.\r \r\n\n[00:12:53] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. This is pretty incredible.\r \r If it is ggplot under the hood, it's insane, you know, how far we can push it to customize\r \r all sorts of stuff here.\r \r I I really like sort of the approach\r \r that has been taken to to tidy up, if you will, by Thomas, the complex\r \r heat map package.\r \r If you're somebody who's more familiar with the tidyverse, I think you're gonna find the API here to be a lot more friendly. I took a look at the complex heat map, our package, and it actually has some fantastic documentation. There's, like, a whole book\r \r on using the complex heat map package. But as you mentioned earlier, Eric, sort of the the root unit that you're gonna pass to this this heat map function that starts with a capital h, we can talk about that later, as opposed to a lowercase h, is a matrix as opposed to a data frame.\r \r\n\nAnd I think, you know, this complex heatmap\r \r package tries to\r \r maybe reduce the number of parameters passed to the heat map function and abstract away, some of the heavy lifting for you. But I it seems to me when it goes about doing that, that it it makes probably a lot of assumptions\r \r off the bat about how it's going to, display that data, sort of what column should be named as,\r \r things like that, how the data should be structured. And I think you just have a little bit more control with the API,\r \r at least in terms of getting started for those who are coming from a more, you know, tidyverse,\r \r background\r \r with this, new package that that Thomas has put together. So we have some clients that do some, you know, bioinformatics,\r \r biomarker type of work, and the heat map is, like, the most important tool, data visualization tool, for them to be able to use. And oftentimes,\r \r they wanna push those heat maps, as far as they can go with multiple\r \r different legends,\r \r dendograms\r \r on the side. Right? We have, also on, you know, sort of the other vertical axis of the dendogram's on the left side of the heat map, on the right side, in this example here that Thomas has. We have, for every single sort of row on the heat map, a particular\r \r label.\r \r\n\nAnd those can be very, very small, difficult to see if you're not\r \r providing arguments in your API to be able to adjust all these things to try to make these heat maps,\r \r which are very complex by nature,\r \r as digestible as possible to those who are going to be making the decisions based upon the data that they're seeing in in a way that they're interpreting\r \r interpreting the heat maps that you're putting together.\r \r So I I think it's incredibly powerful that we have sort of this much control over how to develop these heat maps. I really, you know, like the the syntax\r \r that, this API has in Thomas's new package. And I think folks who are\r \r looking to take their heat maps to the next step\r \r and certainly all the folks that we work with in the the biomarker and bioinformatics\r \r space, I'm going to pass this blog post along to them because I think this is going to to save them time and be able to help them accomplish\r \r all of the little nuances that they wanna introduce into their visualizations.\r \r\n\n\n\n[00:16:06] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And I do stand corrected, my friend. Real time correction here. I did check\r \r the packages that it depends on. It actually does not depend on ggplot2. It's it's depending on the grid system, of course, which is a fundamental\r \r foundation of ggplot2. But interestingly enough,\r \r we'll have a link to the tidy heatmap, package down site in the show notes.\r \r They also integrate with Patchwork, which is what we've talked about previously to stitch multiple grid based plots together, which now it all comes together in real time, doesn't it? Those nice, you know, annotations that we talked about, you know, going between the column labels and the actual content of the heat map itself,\r \r that seems like patchwork under the hood if I had to guess with those custom visualization\r \r types above the above the main the main area. So\r \r really, really interesting use case. I had no idea the kind of directions that that could take, but I and the yeah. Definitely check out check out the heat the tiny heat map site. There's lots of great examples on top of what Thomas has done in this blog, which is, of course, focused on the more genetic, you know, biomarker suite of things, which I'm sure many of you will be very appreciative of. But, yeah, there's lots of great examples\r \r in the vignettes that I'm looking at already,\r \r in the overview. Lots lots of things to to\r \r to digest, if\r \r you will, in your heat map exploration.\r \r\n\nSo this is going to my\r \r massive set of visualization bookmarks for future reference.\r \r Mike, we always love our continuity on our weekly hallways podcast. And last week, we were talking about a novel way\r \r to help organize maybe a many, many sets of tests that have some relationships amongst each other\r \r with a nesting approach.\r \r And if you're not familiar with that, go listen back to our previous episode\r \r 182\r \r where we had talked about Roman Paul's announced or blog post on organizing tests with a nesting approach.\r \r There are always more than one way to do things in the r ecosystem, and our next highlight here comes us from Jacob Sobolowski,\r \r who is a r and shining developer at Appsilon,\r \r who if you haven't been following his blog, he has been all over the different ways of how he thinks about testing complex shiny applications,\r \r many thought provoking posts that he has on his blog. But in particular, this one here is talking about\r \r another approach\r \r to organize and really notes for future use, so to speak,\r \r on the different tests that you can organize that have some relationship with each other.\r \r\n\nSo to motivate this, he has a simple example,\r \r again very trivial but hopefully you can generalize it,\r \r of a simple set of expectations\r \r to test that the median function\r \r in base r is performing as expected.\r \r So in the test that call, which, again, test that is the package that's helping,\r \r you know, drive the engine behind many of the automated testing,\r \r paradigms in r that you see in package development, Shiny apps, and whatnot,\r \r It has a simple call to test underscore that, and the description\r \r reads, does median\r \r works correctly.\r \r\n\nAnd so within that, there's a set of 6 expect equals in this case\r \r of the different, you know, numbers that he feeds in and does it get the actual number in the answer. Again,\r \r very very straightforward,\r \r but\r \r you are seeing that the median should, when you look at these functions,\r \r handle a few different use cases.\r \r Whereas,\r \r if it's only one element, should give you the same value back. Or if it's 2 elements,\r \r should be the average.\r \r If it's an odd number of elements, should be the middle number in sequential order. Blah blah. You you understand that.\r \r Now imagine that had been a more complex function.\r \r\n\nImagine\r \r that the expectations\r \r may not be as obvious at first glance when it's really trying\r \r to infer here.\r \r So\r \r his next,\r \r snippet of code is now\r \r going to write\r \r test that,\r \r but each of the tests is corresponding to those individual expectations.\r \r So\r \r like I just mentioned earlier, he's got, in this case, 4 different tests\r \r that are, you know, verifying the different behaviors based on either how many numbers are going in or,\r \r you know, in fact, that is basically it. And Revver, does the same thing for order and unordered\r \r elements.\r \r\n\nNow that's, again, a perfectly valid approach.\r \r It is illustrating that test that when you put these descriptions inside,\r \r that test that function is named that for a reason. You kind of read it as test that and then something. However, in this case, it's like the median should return the same value if the vector only has one element.\r \r You you get the idea there.\r \r But here comes the kicker.\r \r In TestDaT, there are additional functions to organize your tests even further.\r \r And this is getting into a paradigm that admittedly\r \r is not quite comfortable to me just yet called behavior\r \r driven development\r \r or BDD syntax\r \r and test that for I'm not sure how many releases up to this point has spurred the use of a function called a set of functions called describe\r \r and it.\r \r\n\nSo in this last snippet of code,\r \r Jacob has an overall describe call that just simply says median.\r \r And then within it are a series of it calls\r \r and then the description in these it function calls is kind of the behavior itself that he's trying to test,\r \r where we have about the same value if it's only one element, the average of 2 values if it has an even number,\r \r the middle value in sequential order if it's an odd number of elements,\r \r and that it's the same value for ordered and unordered elements.\r \r I've seen this once before\r \r when I in Pasa Comps in recent years, I've had some interesting conversation with Martin Frigard,\r \r who has written a book\r \r called Shiny app as packages or something to that effect. But he has a specific chapter on behavior driven development in in light of specifications\r \r and requirements and how your test that test can kinda mirror that approach.\r \r\n\nAdmittedly, I have not had enough practice of describing it, no pun intended,\r \r in this workflow,\r \r but maybe it is quite helpful in your use case\r \r to have, again, another\r \r approach\r \r to how you organize related\r \r expectations\r \r into an overall testing block. So it is kind of a paradigm shift. Right?\r \r We could have either the nesting approach that we saw last week with the test that and multiple test that calls inside\r \r or the describe,\r \r and then these it functions\r \r are gonna have the expectations\r \r directly.\r \r Which is right for you?\r \r I don't know. Mike,\r \r what's your take on this?\r \r\n\n\n\n[00:23:34] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Mike Thomas",
        "trans_text": "This is the 2nd week in a row, I think, maybe 2 out of 3 weeks where\r \r I have found\r \r things in the test that package that I had no idea.\r \r Literally no idea existed.\r \r And,\r \r Eric, as\r \r I am, I know you are,\r \r we're very organized\r \r people and probably fairly opinionated about how we organize our code as well.\r \r I am open to this.\r \r I think if you were looking for a hot take on\r \r why we shouldn't consider this and and why the old way is the best, I'm not sure you're gonna get it from me right now. And it might be still because I'm I'm reeling from,\r \r learning about\r \r this new describe it paradigm.\r \r\n\nBut\r \r just like I was sort of blown away by\r \r the organization\r \r in the in the blog post around,\r \r nesting your tests\r \r last week or the week before.\r \r I'm similarly\r \r kinda blown away by this additional functionality here where we can leverage this describe it\r \r paradigm.\r \r I'm actually even more\r \r sort of\r \r not necessarily blown away, but but more keen\r \r on the the final sentence of this blog post.\r \r It says, if you wanna push test readability even further, check out how we can use the arrange, act, assert pattern to achieve that. And if you take a look at that link it's another nice short blog post as well by by Jacob. And,\r \r I I really like sort of the concept around how he he specifies\r \r arranging,\r \r the inputs sort of acting and and evaluating those inputs, and then passing those evaluated\r \r values to a set of test assertions\r \r after the fact. And, again, in that blog post, he's usually I know this this one isn't part of the the rweekly, but it's it's a cousin. It's close enough.\r \r\n\nAgain,\r \r he's leveraging that describe\r \r it paradigm.\r \r I think it's sort of I don't know. The more I look at it, it looks like it's it's sort of, you know, 6 in 1, half dozen in the other. I'm not sure how much of a difference\r \r it it makes. I I think it's just a matter of of preference, you know, if somebody on my team decided that they wanted to use describe it versus, you know, the traditional test that,\r \r verb from the test that package.\r \r I don't think I would I would care too much either way because I think it's it's legible both ways. I think it's fairly similar,\r \r in approach. It's it's sort of just different verbiage, if you will.\r \r\n\nBut it's very interesting for me, you know, to to know that this\r \r exists,\r \r and see that potentially maybe there there might be a use case for me in the future to try to adopt them. I'm just gonna stick one toe in the water, I think, for now. You know, I was taking a look\r \r at\r \r the some of the most recent packages that Hadley Wickham has put together,\r \r Elmer being one of them. And I wanted to take a look at the unit tests in there to see if Hadley was leveraging, you know, the older type of framework that traditional test that framework or or leveraging this describe\r \r and it paradigm.\r \r\n\nAnd it looks like Hadley is still utilizing\r \r the old ways,\r \r if you will.\r \r So not necessarily adopted the describe it functionality,\r \r but I believe he has or had at one point in time a large hand in,\r \r authoring and making these decisions around the the test that package. Don't quote me on that. So I imagine\r \r perhaps, he was involved in maybe a pull request or 2 that that included this describe it\r \r functionality. So I was interested to see, you know, if the if he was going to be one of the folks who had also adopted sort of this new paradigm for code organization purposes purposes because I know that Hadley preaches,\r \r you know, good software development practices and and trying to articulate your code as as best as possible.\r \r\n\nSo I guess at the end of the day here, interested to see that we have these two new functions that I did not know about in the test that package.\r \r Am I all in on it? No. But I'm not all out on it either.\r \r\n\n[00:27:38] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And I've I'm giving this the old college try as they say with this, app at work that I've just put in the production now.\r \r I took this behavior driven approach, describe its syntax for the the test. I will admit it it felt more cumbersome than right initially,\r \r but I'm thinking the payoff is not so much for me personally\r \r in the short term. The payoff hopefully is if I get additional developers to help me with this app as a, quote, unquote,\r \r scales,\r \r buzzword for all you industry folks out there, where I might need some help to orient somebody relatively\r \r quickly over. It's a dedicated member of my team or if it's contracting resource and whatnot.\r \r\n\nAnd so being able to read that more verbose, but yet under you know, might say legible,\r \r might say more digestible way of organizing the test,\r \r then, hopefully, it makes it easier for them\r \r to write tests in that similar framework.\r \r And then we all can kinda have a common, you might say, style\r \r that we can gravitate towards for that particular project.\r \r Not too dissimilar to the whole paradigm of a given project having the same code style for all of its, you know, coding files, which,\r \r again, I can speak from experience when teams don't adhere to that.\r \r There'd be dragons when you do code reviews, and I won't say that for another time. That's my hot tech.\r \r\n\nBut I I think this is I think for future proofing things, I could see this being\r \r quite valuable,\r \r especially in the other context that I was dealing with. Right? I tried to\r \r I tried to have an attempt\r \r back to Martin's book that I'm gonna put in the show notes here\r \r of really articulating those user stories if you wanna use the agile methodology\r \r into\r \r what I'm actually trying to accomplish in that test. So if there's a, quote, unquote, project manager that wants to see how I how I assess all those different user stories even though the basically, that project manager is me for this particular project. But let's say, hypothetically, it was a more larger scale project. It was a good practice to see how it goes. So, again, it didn't feel comfortable yet, but maybe the proof is a year from now. So ask me a year from now, Mike. We'll see if I take changes.\r \r\n\n[00:29:52] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Put it on my calendar. Oh,\r \r I don't think so.\r \r\n\n[00:30:09] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And over the course of the last, you know, might say year or or so,\r \r we have seen an influx of really top notch resources\r \r and discussions in the in the r community as a whole\r \r with respect to the\r \r data dot table package. It's been around for many years. But thanks to recent NSF grant, they have had some real robust efforts\r \r to get the word out and also putting in the different situations and different context so that users that are new to the package\r \r can really understand what are the benefits of data dot table in their daily workflows.\r \r And so our last highlight is coming\r \r from the\r \r our data table community blog, which we've talked about in previous highlights.\r \r\n\nIn this case, the post is coming from Toby Dylan Hocking,\r \r who is a statistical researcher\r \r and the director of the LASSO lab at the University of Sherbrooke, which I believe is in Canada.\r \r And he has a very comprehensive post here\r \r about\r \r the comparison of data dot table functions for\r \r reshaping your data\r \r as compared to 2 other additional\r \r packages in your ecosystem. We're gaining a lot of momentum lately,\r \r which are DuckDV\r \r and Polars.\r \r So first, let's set the stage a little bit here\r \r because especially if you're very familiar with with database operations\r \r or if you're not so much like I was before,\r \r say, a few years ago,\r \r there is somewhat different terminology between what we use and, like, the tidyverse\r \r type of explanations\r \r of reshaping\r \r or in general data manipulation\r \r and\r \r the database equivalence of this. So\r \r when we talk about a long format, we are talking about\r \r not many columns\r \r but many rows in your dataset.\r \r\n\nAnd often, there are groups of these rows based on, say, a variable type or a feature or whatnot.\r \r In SQL\r \r lingo, that's called unpivoted.\r \r That was new to me\r \r a while ago.\r \r Versus the wide format when you have one record, but then the columns are representing maybe different variables,\r \r and they are literally specific to that variable.\r \r You have, again, many columns, potentially fewer rows.\r \r That is called pivoted in the SQL\r \r lingo. Again, new to me, but that's where we're we're operating on where\r \r a lot of times, you would see in the community blog posts about benchmarks talking about the classical\r \r SQL like operations,\r \r like filtering,\r \r adding new variables,\r \r group summaries, or whatnot. But now we're literally turning it on its head, so to speak, by looking at the different ways we can change our data layout.\r \r\n\nSo the first part of the post is talking about just how data dot table accomplishes this,\r \r and this terminology is actually familiar from,\r \r I would say, previous language and dplyr for some of these other operations.\r \r But first, we will talk about\r \r going from a wide format\r \r to a long format\r \r and that unpivoting operation, if you will. And in data dot table, there's a function called melt for that, which if you're familiar with tidr back in the day, there was functions called melt\r \r and cast, I believe, which has now been changed to pivot longer and pivot wider, but that may be familiar for the tidr veterans out there.\r \r What was interesting about data dot table's take on this on this melt function\r \r is, in this example based on the iris dataset,\r \r when you deter when you want to say what are your variable\r \r that are variable or variables determining\r \r kind of the grouping of these observations,\r \r you can actually have\r \r multiple columns generated at once.\r \r\n\nSo in this example here, going from the the iris dataset, which has in wide format\r \r columns like sepal. Width,\r \r length sepal. Width, petal. Length, petal. Width,\r \r this melt function is taking a measure. Vars argument\r \r where you can feed in this measure function\r \r the names of 1 or more variables that are defined in these groupings\r \r and either a separator\r \r in the original name of the column\r \r or,\r \r down later in the example,\r \r regex\r \r to get to those column names.\r \r That,\r \r I must say, is quite handy and eliminates a post processing step,\r \r which,\r \r as Toby talks about later on,\r \r you need additional post processing to accomplish that that same step\r \r in both polars\r \r and DuckDV.\r \r\n\nSo there's already kind of a nice concise syntax,\r \r you might say, advantage\r \r at least at first glance\r \r with data dot table going from wide to long. And it's got some example visuals of what you might do with that data.\r \r But\r \r next, how do we accomplish this in Polars? And if you haven't heard of Polars before,\r \r this is a new binding\r \r to Rust\r \r for very efficient database\r \r data like operation and tidying operations.\r \r And yes, they do support reshaping\r \r or\r \r re pivoting these data sets as well.\r \r And that is a function called unpivot going back to that SQL language.\r \r But in the example snippet, you will see that\r \r at that the first attempt you cannot do more than one variable for that grouping\r \r of the observation.\r \r\n\nSo you would have to do that in post processing afterwards, which is not difficult.\r \r But, again, it's just an extra step. But, of course, it can be done.\r \r Lastly, for DuckDV\r \r via SQL queries,\r \r you can use the unpivot\r \r SQL keyword\r \r and then feeding into what are the variables that are going in,\r \r what are what's the name of the variable that's going to define that grouping of the long observations,\r \r what's the value the column name that you wanna use as, like, the numeric result.\r \r Once again, in this case, DuckDb cannot do\r \r that\r \r that nice convenience\r \r of 2 variables at once.\r \r\n\nYou have to do that in post processing as well. So there's example\r \r snippets and and Toby's code of the blog post here to talk about that additional post processing.\r \r That that is, again, all achievable.\r \r There is another\r \r example where you can reshape into multiple columns, and that might be helpful for different types of visualizations\r \r you want to conduct. And in this case,\r \r doing an additional column for or additional columns both for sepal and petal, but then there's a grouping variable called dim, which determines if it's the length or width. So\r \r data dot table has another\r \r way of doing that as well.\r \r\n\nAgain, the measure function comes into play there. You can see the example in the in the blog post.\r \r And then comes the comparisons\r \r for this operation.\r \r This is where my eyes open a little bit. So Toby does,\r \r a call to a an interesting func a package called a time.\r \r I'm not as familiar with this as I am with, like, the benchmark\r \r or a bench package,\r \r but he is taking\r \r a set of n values representing\r \r the number of rows in this, like, fictitious\r \r high dimensional\r \r Iris data set doing just some resampling\r \r and runs 3 different functions: 1 with the DuckDb\r \r on pivot,\r \r 2nd with the polars on unpivot, and lastly with data dot table and melt.\r \r\n\nAnd across these cases,\r \r the ggplot that's put in the blog post clearly illustrates\r \r that the data dot table approach\r \r is definitely\r \r faster\r \r in this initial benchmark here than either of the other ones, especially as the end values get large.\r \r In particular, this was surprising to me,\r \r DuckDb had the worst performance\r \r by a pretty healthy margin when the end values got to, like, a 1000 rows and above.\r \r Now, again,\r \r maybe this isn't so surprising\r \r if DuckDb,\r \r of course, is based on the column type representation\r \r of data. Maybe it just isn't as optimized for these transposing operations. That very well could be a play. I'm still\r \r learning the ropes on the internals of it.\r \r\n\nBut that was interesting on top of the convenience function\r \r that data dot table has with MELT to get those multiple variables at once.\r \r It is showing, at least in this benchmark,\r \r a speedier process, especially as the number of rows increase.\r \r Now,\r \r again, maybe practically speaking, that won't be a huge impact to your workflows,\r \r but it was thought provoking nonetheless.\r \r But he does acknowledge that there's a lot of confounding\r \r in these comparisons, so it may not be quite apples to apples\r \r because of the different post processing that comes into play.\r \r And then when that is taking place, there are some additional\r \r visualizations when he kind of teases that out a bit that show the differences in even more,\r \r more fashion than what you saw in the previous plot. So\r \r interesting\r \r thought provoking exercise,\r \r but that's not the only operation, Mike, because we can also go the other way around. We can go from long to wide. So why don't you take us through that journey here? Exactly. If you are,\r \r\n\n[00:39:50] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Mike Thomas",
        "trans_text": "for some strange nonanalytics\r \r reason, looking to take your nice long data and reshape it into to wider data. And I shouldn't say that. There are some R packages that maybe it makes more sense to have each,\r \r you know, sort of sort of, a wider\r \r dataset, you know, representing\r \r your categorical data in\r \r multiple columns instead of a single column.\r \r But for\r \r me, this is a\r \r use case, that I face less often than going from from wide to long. But for those particular use cases where you do need to go long to wide,\r \r the function that you're gonna be using from data dot table\r \r is called dcast,\r \r and they provide some great examples here, Toby does, of how exactly to do that. Again,\r \r you can leverage a separator,\r \r if you would like to do that.\r \r\n\nIn this case, they're using that that period separator again, and the code is is fairly similar, to what you saw in the Melt code and allows you to pivot that that long column into a wider\r \r data frame, with multiple columns in it.\r \r If you are using polars,\r \r the method that you're going to be using there is literally called pivot.\r \r And, again, you know, the syntax is is pretty similar. You're sort of doing the opposite of what you did, when you were going from wide to long\r \r format.\r \r And then lastly, if you are using DuckDb,\r \r you're going to again use,\r \r the same\r \r named\r \r function as in Polaris. It's it's called pivot, the pivot command,\r \r which can be used to, as they say, recover the original iris data,\r \r the way that it is in wider format as opposed to long format.\r \r\n\nAnd the SQL there is is pretty straightforward to look at especially compared to what we just walked through on the unpivot side of the equation.\r \r So\r \r drum roll, what everybody cares about here, right, is the benchmark comparison analysis.\r \r And this one goes a little bit inverse\r \r of the,\r \r wide to long approach\r \r such\r \r that,\r \r the engine, if you will, that has the best performance\r \r appears to be DuckDb,\r \r then closely followed by polars and then followed thereafter by data dot table.\r \r These\r \r benchmark lines that they have here are all pretty tight. I I wanna mention that that there's probably, you know, a much tighter a much tighter gaps between the 3 benchmarks here, across the 3 different engines,\r \r compared to what we saw in the wide to long approach.\r \r\n\nSo your experience is probably gonna be minimal,\r \r up until you start really scaling up to to datasets larger than, it looks like, you know, 24,000,000\r \r rows roughly is is what DuckDV was able to handle in 0.1,\r \r seconds\r \r or or 10 milliseconds, if you will. So that was, you know, interesting to see sort of the benchmark there flip.\r \r One of the things that, Eric, I wanted to\r \r talk about here that I was curious about\r \r is I know and this is from listening to,\r \r especially, a recent podcast, not in the super data science podcast,\r \r with the author of the Polars Library,\r \r and I know DuckDV has some of this too,\r \r is\r \r both Polars and I think DuckDV\r \r have an option\r \r to do sort of a what's called a query plan and maybe lazy execution\r \r of, you know, chained functions that you might have together. Right? So we were talking about before where you can't do, you know, both in an unpivot\r \r and, you know, use a a separator in a value to split out additional columns all in a single function. You would have to chain that together in a couple different functions,\r \r in polars.\r \r\n\nAnd I believe, you know, the way that polars works is depending on\r \r the default, and don't quote me on this, you know, it may default to what's called, like, eager evaluation,\r \r which is, you know,\r \r actually running\r \r those functions sort of in the order that they are written.\r \r But it provides you the option through some sort of binary flag to evaluate,\r \r your your query, if you will, or the code that you've written lazily,\r \r which means that behind the scenes, polars will put together a an optimal query plan that it believes will execute your code in the the most efficient and and fastest, if you will, way possible.\r \r And I imagine that DuckDb does some of this too.\r \r\n\nAnd I also imagine that that query plan may take some time, right, under the hood to execute. So if we're only looking at these benchmarks up to 0.1\r \r seconds,\r \r you know, I'd be interested in taking a look at datasets that are are maybe even larger, right, in the order of, like, a 100000000 rows,\r \r something like that or or larger.\r \r And\r \r seeing, you know, how these benchmarks\r \r compare\r \r after that at 0.1 second threshold to see if things change after the query planning,\r \r you know, algorithm is essentially\r \r run and the the time that it takes to do that has finished. And then we're really, you know, sort of just\r \r running,\r \r the actual code to or the actual query to do some of this data reshaping. So I'd be interested to see these benchmarks, I guess, you know, a little bit further out, extrapolate it a little bit further out in both time and magnitude of the dataset.\r \r\n\nBut, just an interesting thought that I had upon reading this blog post and it's it's super interesting to me,\r \r you know, where\r \r these,\r \r different engines\r \r sort of beat one another, if you will.\r \r You know, at the end of the day, if if you can't wait the extra\r \r 0.1\r \r seconds or or or whatever it is, you know, half a second,\r \r just because you wanna use your your favorite engine. I guess it depends on your use case if you're standing up an API or something like that and you need response times as quick as possible and the data needs to be pivoted or or unpivoted, this is a great blog post to check out. But in sort of a general analytics,\r \r you know, approach here to to your day to day analysis.\r \r\n\nThe really cool thing I think about the ecosystem right now is\r \r is benchmarks are are getting to be fairly negligible,\r \r across most normal sized datasets.\r \r\n\n[00:46:04] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That's a very, very fair assessment.\r \r And also with the advent of our computing technology\r \r with the processes processor cores going up and everything like that, we are seeing\r \r that for a data science workflow\r \r where let let's be real here. As much as the advancements in cloud happen, we know a lot of data science happens on people's laptops as well that with these compiled,\r \r you know, you know, I say back ends, wherever going with data dot table really based in c,\r \r and then you got polars based in Rust, the number, you know, getting a lot of attention in terms of performance. And, of course, DuckDb with its bindings. You are seeing this experience of these type of datasets. You you've got great choices here. And on that topic, like, query planning, if you want a way in especially in the DuckDV landscape, kind of get to what that query\r \r language actually looks like, I'll put a plug in the show notes for the Duckplier package, which had a CRAN release a few months ago because they have a handy function\r \r called explain\r \r that literally shows in kind of a plain text\r \r printout\r \r all the different operations that are about to be conducted. But it's doing it in an optimized order, I believe,\r \r to get the best performance as DuckDBC's\r \r fit for that particular operation, which then you can use with your familiar dplyr verbs of, like, mutate\r \r and summarize and whatnot. Again, those kind of classical operations\r \r that we've seen, you know, for for those type of work. So that was an interesting learning for me.\r \r\n\nI do think the concept of the different data layouts is\r \r a frontier that I haven't seen as much attention on. So I'm certainly appreciative of Toby's post here to highlight, you know, the different ways that this can be accomplished.\r \r And I think, again, your use case may determine different things.\r \r I want, you know, for my back ends to have very minimal dependencies.\r \r And with that,\r \r to be able to fold into potentially a Shiny app for very quick operations about hogging the user's memory,\r \r for that particular app session. Those are my biggest,\r \r might say, criteria, if you will, as I'm looking at these.\r \r\n\nAnd so I may have a use case where DuckDV does exactly what I need. There may be another use case for data dot table is king based on existing workflows. So, again, choice is gray here. Like you, Mike, I would love to see this expand in some of the different benchmarks and different scenarios\r \r to see where that plays out. But you can experiment with all these and kinda see what best fits for you. But, again, really comprehensive post by Toby here. And, again, it really shows that this funding that they're getting from this NSF grant is being put to great use to spread the word out about these different the different ways that we can accomplish these\r \r very common tasks in data science.\r \r\n\nWell, we're we're running a bit well on time here on this episode. So we're gonna wrap things up after that great discussion of the highlights. But if you wanna get in touch with us further, we have multiple ways of doing that.\r \r You can send us a quick note in a contact page in our episode show notes. You can also\r \r send us a fun little boost along the way if you have a modern podcast app, or you can get in touch with us on social media. I am mostly on Mastodon these days, Yvette R podcast at podcastindex.social.\r \r Also find me on LinkedIn. Search my name and find me there. And, Mike, working on wisdom has got a hold of you.\r \r\n\n\n\n[00:49:35] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 35,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yep. You can find me on Mastodon at [email protected],\r \r or you can find me on LinkedIn by searching Catchbrook Analytics,\r \r k e t c h b r o o k, to see what I'm up to lately.\r \r\n\n[00:49:48] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome stuff, my friend. Thanks again for a great episode, and thanks again for all of you tuning in from wherever you are. Have a great day, everybody, and we'll hopefully see you back here next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_43_highlights",
        "chap_timestamp": 12,
        "chap_text": "tidyHeatmap",
        "chap_href": "https://tomsing1.github.io/blog/posts/tidyHeatmap/"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "chap_timestamp": 52,
        "chap_text": "Great (testing) expectations",
        "chap_href": "https://jakubsob.github.io/blog/how-to-improve-your-unit-test-titles/"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "chap_timestamp": 9,
        "chap_text": "data.table reshaping",
        "chap_href": "https://rdatatable-community.github.io/The-Raft/posts/2024-10-17-duckdb_polars_reshape-toby_hocking/"
      },
      {
        "ep_name": "issue_2024_w_43_highlights",
        "chap_timestamp": 1,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_42_highlights",
        "ep_date": "2024-10-16",
        "ep_duration": 30,
        "ep_description_short": "A helpful way to organizing your growing collection of unit tests, how interfacing with LLMs just got easier in the R ecosystem, and a clever use of AI to summarize a large collection of blog posts. Episode Links This week's curator: Eric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter) Nested unit tests with…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_42_highlights",
        "description_long": "\r \r A helpful way to organizing your growing collection of unit tests, how interfacing with LLMs just got easier in the R ecosystem, and a clever use of AI to summarize a large collection of blog posts.\n\nEpisode Links\n\nThis week's curator: Eric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nNested unit tests with testthat\nshinychat: Chat UI component for Shiny for R\nCreating post summary with AI from Hugging Face\nEntire issue available at rweekly.org/2024-W42\nSupplement Resources\n\nelmer: Call LLM APIs from R https://hadley.github.io/elmer/\nJoe Cheng's sidebot app (R edition) https://github.com/jcheng5/r-sidebot\nEDA Reimagined in R: GWalkR + DuckDB for Lightning-Fast Visualizations https://medium.com/@bruceyu0416/eda-reimagined-in-r-gwalkr-duckdb-for-lightning-fast-visualizations-05b011e8ae39\nApache superset https://superset.apache.org/\nPostprocessing is coming to tidymodels https://www.tidyverse.org/blog/2024/10/postprocessing-preview/\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @[email protected] (Mastodon) and @mike_ketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nPachelbel's Ganon - The Legend of Zelda: Ocarina of Time - djpretzel - https://ocremix.org/remix/OCR00753\nVoodoo, Roots 'n Grog - The Secret of Monkey Island - Alex Jones, Diggi Dis - https://ocremix.org/remix/OCR02180"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://rpahl.github.io/r-some-blog/posts/2024-10-07-nested-unit-tests-with-testthat"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://github.com/jcheng5/shinychat"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://drmowinckels.io/blog/2024/ai-blog-summary/"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://rweekly.org/2024-W42.html"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://hadley.github.io/elmer/"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://github.com/jcheng5/r-sidebot"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://medium.com/@bruceyu0416/eda-reimagined-in-r-gwalkr-duckdb-for-lightning-fast-visualizations-05b011e8ae39"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://superset.apache.org/"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://www.tidyverse.org/blog/2024/10/postprocessing-preview/"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://ocremix.org/remix/OCR00753"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "links": "https://ocremix.org/remix/OCR02180"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back up so 182 of the R Weekly Highlights podcast.\r \r This is the usually weekly show where we talk about the latest happenings that are highlighted in every single week's, our weekly issue. Now we were off last week because yours truly did have a a bit of a vacation he forgot about until after recording last week with my kids being off for fall break. But nonetheless, I am back here. My name is Eric Nanson, and as always, I am delighted that you join us wherever you are around the world.\r \r And, yeah, fall is in the air as, my co host can see I'm wearing my one of my our hoodies here because it is a little chilly here in Midwest. But, of course, I gotta bring him in now. I also my host, Mike Thomas. Mike, are you, experiencing the chill there too? It is a little bit chilly here, Eric. Not gonna lie. My office, for whatever reason, seems to be the coldest\r \r\n\n[00:00:52] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Mike Thomas",
        "trans_text": "room in the house.\r \r I don't have great zoneage set up here. So been trying to, put the sweatshirts on and off in between teams calls and get the space heater out, but it's 'tis the season.\r \r\n\n[00:01:05] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 5,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. You know what's a great space heater? A really beefy server like the one right next to me. No. That's a good idea.\r \r Yeah. This one's not too bad, but if you go behind it, yeah, you can more up your hands hands a little bit. But,\r \r I I will mention in our week off, probably one of the funniest things I did was\r \r we had gone to a place here in Indiana about a bit south of where I met\r \r called Blue Spring Caverns, where basically you can go about 200 feet below the surface into literally this\r \r set of caves\r \r with a waterfall, and we had this fun little boat tour.\r \r\n\nAnd as you get deeper in this,\r \r with the tour guy turning his his fancy light off,\r \r pitch black, like, you can't see anything.\r \r And then if you are completely silent,\r \r it is completely silent. Like, it is the closest I've ever gone to a place where I'm literally away from every single thing imaginable.\r \r But it it was a good time. You don't wanna be stuck there because you could you know, hypothermia\r \r could happen. Luckily, it was only about\r \r 40 minute tour, but, yeah, that was,\r \r that was kind of like a meditative type experience. So that that was a highlight for me. Very cool. Yep. So I made it back in one piece, and luckily, my kids didn't cause too much trouble or try to tip over boats or anything. So that was a win too.\r \r They they were not alone. There were other kids on that, but, of course and when the tour guide said, okay. Let's try this whole silence thing. In about 10 seconds, one of my kids just blurts out laughing. I'm like, gosh. Naturally. Yeah.\r \r\n\n\n\n[00:02:38] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Surprised it lasted 10 seconds.\r \r\n\n[00:02:41] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Yeah. Me too. Yeah. Because I I could've been a lot worse. But, nonetheless, yeah, we had a lot of fun. Good time on the on the fall break, but I'm happy to be back with you. Tell him about the latest r w two issue. And,\r \r yeah, guess what? Just serendipitously,\r \r the timing worked out that I was a curator for this past issue. So that was a late night, Friday Saturday session to get this together. But, luckily, I think we got a awesome issue to talk about here, but I can never do this without the tremendous help from our fellow Rwicky team members and contributors like all of you around the role of your awesome poll requests and suggestions, which I was always very happy to merge into this week's issue.\r \r So first up in our highlights roundup today, we are talking about a pattern that as a package developer or an application developer,\r \r you definitely wanna get into the pattern of building unit tests in your package and and application\r \r because\r \r future you will thank you immensely\r \r for building that test to figure out any regressions in your code base,\r \r figuring out that new feature, making sure that you've got a good set of rules to follow for\r \r assessing its fluidity and quality and whatnot.\r \r\n\nWell, as you can imagine, Mike, you can speak from experience on this too.\r \r As your package or application gets larger,\r \r start building more tests,\r \r more tests.\r \r Yes. Even more tests. This could be spread into, like, massive set of r scripts\r \r in your test that folder or whatnot.\r \r And you may be wondering,\r \r yeah, what's,\r \r what are some best practices for just keeping track of everything or keeping things organized?\r \r Well, I was delighted to see that, in our first highlight here, we have this terrific post\r \r by Roman Paul, who is a statistical software developer in the GSK vaccines division.\r \r On his blog, he talks about a neat concept\r \r called nested unit test with test that.\r \r\n\nAnd this\r \r was something that\r \r I probably thought was possible. I never really tried it out. So let's break this down a little bit here. So\r \r as usual, he starts off with a nice example here with, in this case, a simple function for adding two numbers. Of course, that's one of the most basic ones, but that's not the point here.\r \r But as you develop, you know, thinking about what are the best tests for a function like this, you might come up with more than 1, like in the first part of the example here where he has a testing of whether the addition of 21+2\r \r is indeed equal to 3.\r \r\n\nBut you may also want to build in tests for, like, error checking,\r \r such as\r \r detecting if an error occurs if one of the\r \r inputs like a and b are not numerics. And now you've built 2 tests back to back in your script.\r \r Now they they, in essence,\r \r even though they're separate script they're separate test that calls,\r \r they're still using the same function under the hood that they're actually testing.\r \r So naturally, what he goes do next\r \r is that you can actually\r \r bundle both of these tests inside an overall test,\r \r might call a wrapper test. He simply calls it ad. But within this,\r \r there is, a little trick that we'll get to in a little bit, but he's basically nested in those 2 separate test that calls\r \r for the baseline functionality\r \r and then testing those input values\r \r inside this overall test. Now\r \r there is a trick to do if you've tried this before and maybe gotten some, you know, warnings from test stat about,\r \r you know, a a,\r \r testing or an empty test.\r \r\n\nHe has, at the beginning of this overall block,\r \r a call to expect true\r \r whether a function\r \r exists,\r \r called add.\r \r And that that apparently will suppress any warnings about\r \r an empty test. That was new to me as a little trick there.\r \r So\r \r this this paradigm works great for, again, this 2 test case.\r \r But now in the rest of the posties talks about why would you wanna invest in this instead of just having all these\r \r as separate on top of just in the more cleaner\r \r organization.\r \r But there may be cases whereas you're building a larger code base of tests,\r \r you might want an easy way\r \r to skip your tests occasionally as you're iterating through development.\r \r\n\nSo in the next example, always added as a line after the expect true\r \r of skipping\r \r all the remaining tests below it with a a simple call to skip.\r \r So in that way, if you know you're breaking stuff and you don't wanna quite test again, and you just throw that skip in there, keep iterating, and take that skip out, and then it'll just go ahead and run those tests again just like it would before.\r \r And then there are some additional benefits you can have there but takes advantage of a couple different concepts that are familiar to an R developer.\r \r One of those is having a little shortcut, if you will,\r \r for that function that you're testing.\r \r\n\nMaybe it has a long function name and you just wanna do a simple letter for it for the purposes of your test. So he gives this add function\r \r an assignment to the letter f, and then simply he's able to use that in all the expect equal or the expect error calls going forward. Again, that might be helpful if you have a pretty verbose\r \r function name. And then another one is taking advantage of\r \r much like in functions themselves, they have their own scoping rules\r \r where you might have\r \r then we might wanna reuse\r \r different parts of this test scope\r \r that may be more self contained for this group of tests, maybe not for remaining tests that are outside of this\r \r block, you can take advantage of having function having objects\r \r inside this overall\r \r wrapper, you know, test that that's going that's the outer layer. And then those can feed directly into those sub test stack calls\r \r much like you would with nested functions. That's another interesting approach if you wanna cleanly organize things about duplicating these objects\r \r in each test stack call of of objects that are related to each other.\r \r\n\nAgain, it will depend on your complexity to see just how far you you take this. But, yeah, the possibilities\r \r you you can go many different\r \r additional directions with this.\r \r And in the last example, he talks about\r \r how you can group the unit tests by maybe some additional criteria. Perhaps it's based on the type of input data. Maybe it's based on another factor.\r \r In this case, he's got ways of grouping it based on whatever he's testing for positive\r \r or negative numbers.\r \r Interesting\r \r functionality there that you can build and play.\r \r But in the end, the key part I take away from this is that the test that function\r \r is pretty open ended after all. Once you know kind of the the quirks to get around that empty\r \r warning,\r \r you could do some pretty interesting organization\r \r in terms of nesting related tests together,\r \r sharing objects between them,\r \r and overall having a slightly cleaner code base\r \r for your your what could be a massive amount of tests, which is I'm just releasing an app in production this week. I have a lot of business logic tests, so this may be something I have to look into for the future as well. So very night fit nice, fit for purpose post here, and I'll definitely take some learnings from this in my next, business logic testing adventures.\r \r\n\n\n\n[00:10:27] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Me as well, Eric. This is really interesting, and like you, it's not something that I had tried before.\r \r You know, what we're talking about here is a test that call\r \r inside another test that call. You know, not just having multiple expect\r \r type calls in the same test that block, which I'm I'm sure folks who have written unit tests before\r \r are familiar with, hopefully. Otherwise, your your, your code would be quite lengthy.\r \r And and one of the ways that I learned to to write unit tests was to look at the source code of some of my favorite r package developers,\r \r primarily Max Kuhn and Julia Silgy.\r \r\n\nBecause\r \r unit tests are are kind of interesting, you know, they're they're very different than a lot of the other R code that you'll write. And, they sort of execute in their own environment as well, which makes some of this stuff a little tricky.\r \r I learned this the hard way, you know, trying to download a file inside my testing script and handling, you know, the creation of a variable within a test that block that maybe doesn't exist in the next test that block.\r \r And as an r package developer, and I I know, Eric, you share a lot of these same sentiments,\r \r you can quickly\r \r become\r \r sort of obsessed with organization\r \r of your code, and I think testing is another place that that applies to.\r \r\n\nAnd these concepts,\r \r I think, are\r \r really useful from an organization\r \r standpoint.\r \r I\r \r feel like I need to go go right back to some of the r packages that we have right now and take a look because I know that there are opportunities to improve,\r \r you know, leveraging what Roman's written about here, you know, particularly\r \r in some of the the lower code code blocks in this blog post,\r \r underneath local scoping where you're developing some variables\r \r within this outer test that call, that you're going to use in some of these inner test that calls that I believe will really just make, you know, some of the the code, run quicker and more lightweight instead of defining, like, global variables at the top of your script that are going to stay there for the remainder\r \r of all of the tests being executed.\r \r\n\nThese can kind of be local to just this particular outer test that chunk. So really interesting. I feel like it's kind of a tough blog post to do justice without actually taking a look at the code and reading through it, but it should click really quickly if you take the time.\r \r And it's a pretty short and sweet concise blog post here, to read through it. But, another takeaway for me was that I did not know about the skip function from test that, which skips all of the tests below the skip call in that same test that block. So it'll execute the ones above it, but, you know, the all of the ones below it within that same test that block,\r \r as far as I understand, will be skipped, which is is really interesting if you are in the the middle of development,\r \r you know, if something's failing and you you need to just sort of, make sure that you're able to lock down, what you understand\r \r and then, you know, re execute the the tests that are firing so that you can, you know, work on the bug fixes in a safe and efficient environment. So really, really helpful blog post here, some concepts that I had never honestly seen talked about before or used, that I think are really, really applicable to anybody who's developing in our package or maintaining in our package out there.\r \r\n\n\n\n[00:13:51] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 51,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. That skip function was, underrated gem that I dived into a little bit before this only because\r \r of necessity.\r \r You may find yourself in a situation, we're gonna get in the weeds on this one, where for my app I'm releasing to production,\r \r I had a different set of tests that were more akin\r \r to operating in our internal environment and our Linux environment versus\r \r when I would run it in GitHub actions, that was technically a different environment.\r \r And so I had to skip certain things if it was running on GitHub actions that were more,\r \r I'm gonna be blunt here, very crude hacks\r \r to get around issues with our current infrastructure for the tests that were appropriate for internal use. So, yeah, the skip there are variants of the skip function as well. There's like a skip if CRAN type function, which is a wrapper that detects if this is running on the CRAN server or not. So it won't run those tests where maybe you wanna run them in development, but you don't care as much for the actual CRAN release of a package. Again, there would be different\r \r use cases for these. So, yeah, you're invited to check out the the test that vignettes. There's a lot of great documentation there. But this concept that's been covered here,\r \r has not been mentioned in the vignettes of test that before. So I'm really thankful to Roman for putting this together for us because I'm gonna bookmark it and test that related resources to use going forward.\r \r\n\nDoesn't it seem like yesterday, Mike, when we were sitting near each other at deposit conf, listening to Joe Cheng's,\r \r very enlightening talk about\r \r\n\n[00:15:40] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Mike Thomas",
        "trans_text": "using AI chatbots and Shiny. Don't you remember, my friend? Oh, I remember it like it was yesterday, Eric. I was gripping onto the edge of my seat.\r \r\n\n[00:15:49] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. And I I teased you a little bit before that because I had an inside preview. But, nonetheless, I was still blown away when you actually see it in action. And\r \r while I hope the recordings will be out fairly soon, once they are out there, you'll wanna check it out, for you and the audience because\r \r Joe Chang\r \r demonstrated\r \r a very interesting Shiny application.\r \r At that time, he was using Shiny for Python\r \r that had a, in essence, a chat like interface on the left hand margin,\r \r and then it was visualizing\r \r through a few different, like, summary tables and visualizations,\r \r a restaurant,\r \r tipping dataset.\r \r\n\nBut when Joe would write an intelligent kind of question in the prompt\r \r saying,\r \r show me the the tip summaries for those\r \r that are males,\r \r Instead of being a shiny app developer trying to prospectively build all these filters in yourself,\r \r the the chatbot was smart enough to do the querying itself,\r \r and it rerendered the app on the fly. It was\r \r amazing.\r \r Many in the audience were amazed. Mike and I, of course, are looking at each other. It's like, yep. We wanna use this.\r \r\n\n[00:16:59] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yep. We've been skeptical about AI.\r \r Have some harsh feelings for it,\r \r at some points in time, but, yeah, we wanna use this. I agree.\r \r\n\n[00:17:09] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Eric Nantz",
        "trans_text": "So as I mentioned, that was using Shiny for Python, and he had mentioned that the R support was coming soon.\r \r Well,\r \r that soon is now, and you might call this an inside scoop, so to speak, because while we're talking about is public, it hasn't really been publicly\r \r announced yet by time deposit team, so you get to hear it here first.\r \r But there is a new package out there, by Joe Chang himself called shiny chat.\r \r This\r \r is basically giving you as a Shiny developer a way to build in\r \r in a module like fashion\r \r the chat user interface component\r \r inside your Shiny apps. And it indeed on the tin works as advertised where you can call a simple function to render this chat\r \r interface in very similar to, like, a chat UI call.\r \r\n\nWe have a little server size stuff we'll talk about shortly, and then your app will have a very familiar looking chat interface\r \r that you can type queries in and get results back. There are some interesting things under the hood here that respect the Shiny itself\r \r and giving you that that chat like experience that you see in the external services\r \r with some clever uses of synchronous and asynchronous\r \r processing\r \r under the hood. There is example in the in the GitHub for the package that you can take a look at as well.\r \r But there is\r \r there is another component to this, Mike, that ShinyChat on its own doesn't do all the heavy lifting much like, you know, robust Shiny development. We always say that for heavy lifting of, like, server processing or business logic,\r \r you wanna put that into its own dedicated set of functions or packages.\r \r\n\nSo hand in hand with shiny chat, we will put a link to this in the show notes,\r \r is a new package that's being authored by Hadley Wickham\r \r called Elmer.\r \r Elmer is in our package to interface directly with\r \r many of the external\r \r AI services that we've been using,\r \r for a while now, such as, of course, OpenAI.\r \r There's been now support for Google Gemini.\r \r There's support for Claude\r \r and support for all WAVA models if you've had those deployed on an API like service.\r \r So Elmer is actually the way that Shiny chat from the server side\r \r is going to communicate directly with this AI service,\r \r and this is where you feed in\r \r any customizations\r \r to the prompt\r \r before the interface is loaded,\r \r which is something I've been learning about, recently, prompt engineering.\r \r\n\nSo Elmer will give you a way to feed that in directly,\r \r And\r \r then you can also\r \r take advantage of, of course, the responses being returned\r \r to you, and you can do whatever you want with those.\r \r But the real nugget here, and, again, this is actually how that restaurant tipping app works under the hood, is in addition to the prompt being sent to this chat interface,\r \r you are able to select what are called\r \r tools for this.\r \r Now what is a tool in this case? We're not talking about, like, a, you know, tool in the traditional sense.\r \r You are letting the AI\r \r take advantage of, say, a function or maybe functions from another package\r \r to help assist you\r \r with taking the result from that initial query or or that message you send to the chatbot\r \r and maybe calling something on your behalf to help finish off the process.\r \r\n\nSo an example I can illustrate here is if you\r \r ask a chatbot,\r \r hey,\r \r how long ago was, say, the declaration of independence written?\r \r Guess what? Due to the stateless nature of these chatbots, it doesn't really know\r \r what time it is for you right now when you call that. It may try to guess that you're calling it in October or whatnot, but it's not gonna really know that answer.\r \r So how to get around this is you can help feed in via this tool argument in Elmer when you set up the chat interface,\r \r a function that it can call\r \r to help answer these kind of questions.\r \r\n\nThis opens up the possibilities\r \r to help the AI bot\r \r get answers to things that through its, you know, training that it's done externally or internally, depending on how you're using it, would not be able to answer on its own.\r \r This took this taken me a little bit to get used to, but that time example was one thing that kinda clicked. But that, in theory, is what's happening with this restaurant tipping app that we saw at Pazitconf\r \r where Joe built in a tool, I. E. A function\r \r to basically execute that what became a SQL query as a result from that question that we asked it. And then it would execute it on the source data that was fed into the app. It was set as a reactive\r \r doom. Every output is refreshed in real time after that query is executed.\r \r\n\nAnd that is something that is amazing to me that now we can give the chatbot\r \r a little more flexibility.\r \r But just like if I was training, like, a a new colleague\r \r to get used to one of my tools or one of my packages,\r \r You've gotta be pretty smart with it or or I should say be helpful with it.\r \r We have a function. What do we talk about? Have good documentation.\r \r Have good documentation of the parameters,\r \r the expected outputs.\r \r That is going to be necessary\r \r for Elmer to take that that source of that function or that function call\r \r and then help assist you with the syntax you need to feed this in as a tool\r \r to the AI to the AI service.\r \r\n\nSo there is a lot to get used to here, but we'll put a link in the show notes to, again, the the restaurant tipping examples. You can see this in action. But now the combination of Shiny chat and Elmer,\r \r we can start building these functionalities\r \r into our Shiny apps that are written in r,\r \r and we are always scratching the surface here. This stuff I wanna stress is an active development.\r \r These are not on CRAN yet, so there could be features that are breaking changes or whatnot. So be wary of that. But they are very actively working on this as we speak, and I'm excited to see\r \r what the future holds. And my my creative wheels have already been turning\r \r about ways that I can leverage this at my in my day job as this gets\r \r\n\n[00:23:47] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Mike Thomas",
        "trans_text": "gets more mature. Yeah. Eric, I mean, you you summarized\r \r it very well. I think\r \r that presentation by Joe really\r \r blew a lot of us away. I think it,\r \r created a lot of\r \r opportunity, probably a lot of of work for us, right, to to be able to try to integrate these things, especially if any of our bosses saw that presentation,\r \r to try to integrate this type of functionality and user interface and, you know,\r \r capabilities into our\r \r Shiny apps to,\r \r you know, I I think not only reduce the number of filters maybe that we need to create,\r \r but also sort of allow this sandbox environment for users to play around with the data that we're displaying\r \r in our apps such that we don't necessarily have to worry about boiling the ocean for them anymore and, you know, being able to to handle every possible little edge case that anybody could ever want to see,\r \r before we just yell at them and tell them to learn how to write SQL against the database. Right? Not that I've ever been there before. Oh, never.\r \r\n\nBut it it it's very interesting how\r \r a lot of this tooling by posit\r \r seems to be, you know, sort of quietly taking place behind the scenes. But, obviously, you know, I think this Elmer package\r \r is doing a lot of the heavy lifting, and it has a great package down site if you haven't taken a look at it yet. And this tool calling Vignette is is a fantastic introduction to to sort of how\r \r that works and how we'll be able to I don't know if customize is is the right word,\r \r but really be able to\r \r nicely\r \r integrate these large language model capabilities\r \r into our our\r \r workflows,\r \r right, and not have as much of a disconnect as I would have imagined\r \r there to be at the beginning. So it it's pretty incredible that we we do have this tooling. You know, I think as as Joe said,\r \r there are a lot of considerations\r \r that you need to take around, you know, potential safety\r \r to ensure that these large language models aren't actually getting direct access to the data in your app and ideally\r \r just executing\r \r a a or the models are returning a a query maybe based on the schema\r \r of your data without ever actually seeing,\r \r you know, your data\r \r itself in the case of, you know, that tipping example where\r \r the the model is really mostly returning a SQL query, essentially, that you can leverage to execute against,\r \r you know, your underlying data source, which,\r \r in my opinion, you know, those are the situations\r \r unlike this, you know, this this time example is interesting.\r \r\n\nBut I think, you know, the the former that I was talking about are are probably the most useful,\r \r as in terms of low hanging fruit that I can see applications of these large language models into Shiny apps. So\r \r it's really interesting to see all of this start to come together. Obviously, we saw some of this on the Python side first and and really excited that, the ecosystem on the the R side is\r \r expanding,\r \r just as well. So lots to\r \r see here already. I can imagine only more to come.\r \r And you, I I believe, Eric, had the opportunity to participate in a little hackathon around this stuff. I haven't gotten my hands quite as dirty\r \r yet, but that is\r \r really, really, on the forefront of what we're we're trying to do,\r \r\n\n[00:27:16] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Eric Nantz",
        "trans_text": "at the day job here. So, hopefully, I'll be able to report back on on some of our findings pretty soon. Yeah. That was, very, very fortunate that I I got the invitation to see some of the preview versions of these interfaces,\r \r and, you know, I wouldn't turn that down for anything. And,\r \r Mike, though, as we talked in the outset, I have been\r \r resistant is kind of a strong word, but it has been very\r \r not not very tempting for me to adopt a lot of this yet in my daily work. But\r \r I think with the right\r \r right frame of mind in this and the right use cases,\r \r this can be a massive help. I think as long as we have a way, especially in my industry,\r \r to only let it access what it needs to access, but yet this tooling functionality\r \r gives us a way to then\r \r act as if maybe the AI did get us 80% of the way there, and then we would have to manually do the rest of the 20%.\r \r\n\nWe're basically giving them a way to get to that 20%,\r \r but still run it in our local environment to do it. It's not going back to them\r \r to run it. That that is or to get the results back itself, so to speak. It's acting on my behalf.\r \r That's a nuance I'm still kinda wrestling with. It's still something that seems a little magical to me, but I think what we'll have a link to is the r version of this side restaurant app example\r \r in the show notes as well. The key another key part of this along with the tools\r \r supplying the tool function\r \r is the prompt itself. So in the example we'll link to, Joe has put together a markdown document\r \r that is the prompt that's being sent to it. Basically, it's reading the entire line this markdown file where it's very verbose with the AI, you know, the AI bot about what it has access to, what is expected to do, what it should not do, and then making sure that it doesn't go outside those confines.\r \r\n\nIt's interesting to see just what the nuances would be when you try this on different back ends, so to speak. Because I have heard that, yeah, things like OpenAI, this works really great almost a 100% of the time. There may be other cases where a self hosted model isn't quite there yet,\r \r but that's just the nature of this business. Right? Some of these models are gonna be more advanced than others because of the how many billings of parameters\r \r that are used to train the things. So there's a lot of experimentation,\r \r I think, is necessary to figure out what is best for your\r \r particular use case, but you get the choice here. That was one of the things I was harping on when I first heard about this is I don't wanna be confined to just one model type. I wanna or one service. I wanna be able to supply that\r \r as the open source versions do get more advanced. So\r \r there's the responsibility\r \r aspect is still very much at play for what I'm looking at.\r \r\n\nBut the fact that now this is our disposal about me having\r \r to tap into and again, no\r \r no shade to our friends in Python, but I've heard that the langchain framework can be a bit hairy to get into, and Elmer is really trying to be that\r \r very friendly interface\r \r on top of all this about me having to engineer it all myself. So\r \r I'm super impressed that with about 4 hours of work I did in this hackathon\r \r to build an extension of this restaurant type example with podcast data,\r \r I was able to get to even about, like, 85%\r \r of the way there in that amount of time.\r \r\n\nI'm telling you, when I picked up Shiny, it took me well more than 4 hours to get to where I wanted to get to initially. So I I'm very intrigued by what we can accomplish here.\r \r Well, we're going to stay on the AI train for a little bit here, Mike, in our last highlight here, because one of the things that has been one of the more,\r \r I might say, low hanging fruit for many use cases across different industries and different sectors\r \r is being able to ingest maybe more verbose documentation\r \r or more verbose,\r \r sources online\r \r and generate a quick summary of that.\r \r\n\nWe're seeing this in action even with some, you know, external vendors.\r \r Those of you that live in the Microsoft Teams ecosystem probably know that there are things like\r \r a chat copilot for meeting summaries, which in Middle East can sometimes be a bit odd when their results come through, but that's that's that's all happening. That's all happening here.\r \r Well, imagine you have\r \r a lot of resources at your disposal, and\r \r maybe you could take the time to go through each of these. Maybe they're a blog,\r \r and you just summarize them quickly for maybe sharing on social media or sharing with your colleagues.\r \r But is there a better way? Well, better or not, no. It's up to you to decide. But our last highlight here, we've got a great interesting use case from Athanasia Mowinkle, who has been on the highlights quite a bit in the past, talking about her adventures of creating\r \r summaries of posts from her blog\r \r with artificial\r \r intelligence surfaced via Hugging Face.\r \r\n\nSo as I mentioned, her her, motivation here was\r \r she's got a lot of posts on her blog, and it's a terrific blog. You should definitely subscribe to that if you haven't already.\r \r And she wanted to see what she could do to help get these summaries for additional metadata\r \r to be supplied in,\r \r and he she saw a colleague of hers\r \r that was using OpenAI's\r \r API to create summaries of his blog,\r \r and she wanted to, you know, again get away from the confines of Python on this.\r \r She wanted to give Hugging Face a try by calling it with directly an R.\r \r The rest of the post talks about,\r \r okay, first getting set up with a hugging face API, which again, you know, pretty straightforward.\r \r\n\nHaving getting an API key, which is pretty familiar to any of you that have called web services from r in the past.\r \r And then she is going to leverage a very powerful\r \r ACTR 2 package\r \r to build in a request\r \r to Hugging Face\r \r to speed a set of inputs\r \r and then doing the request, you know, the request,\r \r summarization\r \r or the request parameters.\r \r It's a lot of a lot of, like, low level stuff, but once you get the hang of it, it works, which by the way, that Elmer package we were just talking about is wrapping HTTR 2 under the hood to help with these requests of these different API services. So maybe in the future,\r \r that will get Hugging Face support. But nonetheless,\r \r she has a nice tidy example here of using you know, making a request\r \r to,\r \r feed in, I believe,\r \r some summary text\r \r and then preparing that for a summarization\r \r afterwards\r \r where she's got a a custom function\r \r to grab the front matter of her post,\r \r determining if it needs a summary or not, and if it does need it\r \r to basically\r \r now call to this\r \r custom function\r \r for the API\r \r to grab that content back and then to summarize that\r \r into\r \r a file\r \r so that it can go back into the markdown front matter of her post.\r \r\n\nWe've actually covered her explorations\r \r of adapting front matter to her post in a previous highlight, I wanna say, about a month ago. So this is very much using those similar techniques. So go check that episode out if you want more context\r \r to what's happening in these functions, but she's reusing\r \r a function that add the con the post summary to the front matter\r \r and then being able to write that out\r \r as a pretty nice nice and tidy process.\r \r So in the end, she links to the entire\r \r the entire collection of functions. It's about 7 or 8 functions here. Not not too shabby. It's a great way to learn\r \r under the hood of what it's like to get results\r \r from these API services like Hugging Face, and you could use the same technique\r \r with OpenAI as well from the r side if you wanted to.\r \r\n\nBut this is this is really going under the hood of what now I believe the Elmer package is gonna try and wrap for you in a nice concise way. But for me, sometimes the best way to learn is to sometimes brute force this myself and then be able to take advantage of the convenience, but knowing\r \r what that abstraction that, in this case, Elmer would bring you is really doing under the hood. So it's a really great learning journey that she's she's authored here and then she seems pretty satisfied\r \r with the summarizations\r \r that she's able to get here. But Hugging Face does give you an interesting approach to feed in a model of your choosing to that to your account and then be able to call that via an API.\r \r\n\nSo I believe you can feed in things like llama models and other ones there as well. I haven't played with it\r \r myself yet, but it's another intriguing\r \r way to take a set of, in this case, publicly available content via her blog post,\r \r grab some interesting summaries,\r \r feed that back into her post,\r \r front matter so that her blog can show these summaries\r \r very quickly without her having to manually craft this every step of the way. So again,\r \r great examples of h t t r two in action\r \r and Waze and her examples talking about the custom functions\r \r that she's done to grab these posts, grab the content,\r \r put in the summary from the API service from hugging face back into the front matter, and then rerender the site. So there's a lot of a lot of interesting nuggets at play here. And, again, great use of engineering with the new tools available to us\r \r to make your, crafting of these summaries a lot easier,\r \r which I might have to do for our very podcast here, may Mike, maybe I don't have to write my summaries anymore. Hey. That's not the worst idea. And you know what?\r \r\n\n\n\n[00:37:22] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 22,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I don't, you know, I don't know if this is sad or a good thing, but I feel like large language models because they're trained on the Internet in terms of, like, SEO\r \r or or and and summarizing some text, you know, so that it's going to look the best\r \r online.\r \r I gotta hand it to them. They're probably better at that than I am in terms of trying to boost the SEO for for my own website.\r \r So I should probably\r \r take a page out of Athanasios\r \r blog post here\r \r and, try that myself.\r \r You know, one of the the things that just always, you know, makes me\r \r happy, I guess, is looking at h t t r two\r \r code for building these,\r \r API\r \r requests. You know, we don't have to write 4 loops anymore for retrying an API if it if it fails the first time. We have our request underscore retry\r \r function. There's this request cache function,\r \r to be able to build a cache within, your your API\r \r request, which is\r \r really fantastic,\r \r and it's just this really nice pipe syntax to build this up. It looks so clean, compared to some of the crazy stuff that I used to do to try to call, APIs in a a neat manner.\r \r\n\nAnd\r \r it looks like, you you know, again, the Hugging Face ecosystem is one that I should\r \r know more about. I don't,\r \r unfortunately,\r \r but\r \r upon some research here, it looks like there's there's probably a lot of different text summarization\r \r models\r \r that, Athanasia\r \r could have chosen\r \r from. The one, it looks like that,\r \r she leveraged here is called Distilbart\r \r CNN, assuming that's for convolutional neural network 126.\r \r I think there's a lot of different trade offs in terms of, you know, the the size of these models that you can use. I don't know what the pricing looks like for Hugging Face,\r \r in terms of, you know, how many requests you can make to a particular,\r \r you know, model endpoint,\r \r before you start getting charged or how much it costs, you know. And I imagine that the the larger size models, which are the better performing ones, probably cost more than the smaller size models, but that's just something to watch out for if you are, you know, taking the time to try to recreate Athanasi's\r \r blog post\r \r or leverage, her work here to be able to do this for your own purposes.\r \r\n\nBut, you know, as you mentioned, Eric, the ability to\r \r integrate your\r \r model of your own choosing,\r \r into this function, I think, is a really nice feature in the way that she's laid out this ad summary,\r \r function here at the end of the blog post that sort of, encompasses\r \r everything, you know, that we're doing in this workflow\r \r and being able to choose between some of these more closed source models versus some of the more open source\r \r models, like, llama, I think is is really\r \r a neat thing that we have at our fingertips. So fantastic,\r \r blog posts here that she's put together. You know, love the code. Love the way that she formats her code. I think it's really legible.\r \r\n\nAnd I\r \r guarantee that I will have a use case where I'll need to probably ask you, hey. What was that blog post that,\r \r was on the highlights, you know, a few months ago, when it comes time for me to try out this exact same type of thing for my own purposes?\r \r\n\n[00:40:40] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And there's there's other nuances here, again, tying back to what we talked about recently here.\r \r What I noticed as she mentions as she was preparing\r \r the the the post content\r \r to go to the the AI service on Hugging Face is as she mentioned that she had a little gotcha when she kept it in the YAML structure that the results weren't quite making sense coming back. And this is one thing that it's taking my old timer brain a bit much getting used to. When you feed in this information for it to digest,\r \r it can be as if you just wrote it in plain text, basically. Like, you can treat it. Like, even with a prompt example from the restaurant app, that's as if, like, you and me just took, like, a half hour to\r \r write maybe to a colleague what we wanted them to do. It's kinda like instructions for a task.\r \r\n\nLike, it it's I'm just so I don't know. I have this, like, muscle memory of, like, I have to do things so structured or it's gotta be in this syntax of YAML or JSON and whatnot.\r \r These prompts are just like plain text stuff. It's like it doesn't make sense how it can parse it all out. But, again, I'm just not giving it enough maybe credit under the hood to ingest, like you said, these online resources\r \r and to be able to do what it needs to do even just with somebody banging at a keyboard to write this out for a half hour or so. So she's got, again, a convenience function to strip all that YAML stuff\r \r out of the post content so that it can just go directly in. It's it's just amazing just what they're capable\r \r of. And, yeah, I I realize that sometimes I can sound too optimistic on this show sometimes, so I'm gonna have to play with this myself with some of the sources I make. But,\r \r spoiler alert,\r \r the podcast service that we do use\r \r does give me a plug in to execute to generate summaries for me. So maybe I just have to switch that bit on, but I imagine it's doing something like this under the hood. Very interesting. No. I'd like to see how it does that.\r \r\n\nIn this,\r \r for for the rest of this issue. So we'll take a couple of minutes for our additional finds here.\r \r And certainly,\r \r in the world of exploratory data analysis,\r \r especially if you've been in industry as long as Mike and I have or even if you're new to it, you know that in terms of business intelligence\r \r and, you know, looking at data,\r \r there are some established players in this space, IE Tableau and Power BI,\r \r which give you that\r \r yeah. Yeah. And we're we're doing the, the thumbs down from us on the video here. But,\r \r it can be hard to crack that nugget if you're an R user\r \r and you still want a way to quickly build these, you know, great shiny dashboards,\r \r but, a way to get started.\r \r\n\nWell, I am I'm intrigued by this this one I'm gonna mention here by Bruce Yu in his post called\r \r EDA reimagine in r with the gwalker\r \r package\r \r plus duckdb\r \r for lightning fast visualizations.\r \r And so, basically, what gwalker does, which I'm gonna have to dig into some more, is it takes a data frame\r \r or a data or a database,\r \r and it's able to translate\r \r into a drag and drop type UI interface\r \r that will look very familiar to those in the Tableau and Power BI ecosystem.\r \r But then the user that's consuming this can simply use their mouse to explore the data with drill downs, with nice little histograms\r \r above like column names.\r \r\n\nIt looks really\r \r intriguing\r \r even to let you look at kind of quality metrics of your data\r \r and, again,\r \r be able to have this interface built right away\r \r to do this. It's pretty fascinating.\r \r So apparently, there's also a Python package that accompany this called pygwalker\r \r that if you're on the Python side, you might want to look at as well,\r \r but that could, lower the barrier of entry quite a bit for those\r \r maybe at your respective organization. If you get some pushback from certain people,\r \r say, yeah. Shiny's cool, but it's just so hard to get something up and running quickly.\r \r Maybe g Walker could get you halfway there, especially for an EDA context. So I'll be paying attention to this more closely.\r \r\n\n\n\n[00:45:14] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 14,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That's pretty interesting, Eric. Another one that I would check out that I think is kind of in that same vein is the Apache Superset project. Have you seen that?\r \r I have not. So it's open source,\r \r modern data exploration and visualization\r \r platform. It's like a dashboarding tool, kinda looks like Tableauy, allows you to write custom SQL\r \r if you want to as well.\r \r Pretty pretty incredible\r \r under, I think, that whole sort of Apache\r \r umbrella.\r \r But this GRarker package reminds me quite a bit of that. So this is this is very interesting as well.\r \r One thing that I found that I was really interested in\r \r is,\r \r this blog post titled post processing is coming to tidy models. It's a blog post from the tidy models team, Simon Couch, Hannah Frick, and Max Kuhn,\r \r essentially\r \r about sort of this new\r \r I think it's our package or function. Yes. It is in our package, called Taylor.\r \r\n\nThat is sort of like\r \r recipes\r \r except for\r \r at the end of your model in terms of developing the workflow at the beginning of your model. And what it does is it takes the results of your model and does some tuning,\r \r tailoring, if you will,\r \r post processing\r \r of those results\r \r to, you know, one example\r \r here that they use is,\r \r a situation where your model\r \r is predicting, you know, your your class probabilities\r \r of\r \r of 0.5\r \r are going to 1 class, and and the ones that are less than 0.5 are going to the other binary class in your dependent variable. And if you look at maybe your model results, you know, most of the data is coming in on one side or the other. It's not sort of evenly\r \r distributed,\r \r on either side of that 0.5 threshold.\r \r\n\nYou know, a lot of times,\r \r we see this in situations where there's class imbalance\r \r in the dependent variable.\r \r And let's be honest. I mean, if you are out there working on machine learning problems all the time where you have great class balance,\r \r in your dependent variable, I think that you're in the minority\r \r because the rest of us\r \r in the real world,\r \r face this issue\r \r constantly,\r \r unfortunately,\r \r where it's it's hard to find, you know, that that one case where where things are going,\r \r bad, if you will.\r \r And I think probably that stems from hopefully, if you're running a business, you know, things are going well more often than they're going bad. So you probably have less observations in your data of things going poorly.\r \r But I'll save that tangent for another day. But one place I think that we've struggled a lot in machine learning in the past is trying to find the right approach to dealing with class\r \r imbalance.\r \r\n\nYou know, resampling\r \r can kind of conflate results,\r \r different ways. And I I think this post processing\r \r technique that might allow us to be able to better\r \r handle those types of situations. So there's great examples in here for both,\r \r you know, binary,\r \r dependent variables as well as,\r \r continuous\r \r dependent variables\r \r to be able to adjust,\r \r you know, sort of your your output and improve your root mean mean squared error and things like that.\r \r It's a fantastic blog post. I'm really excited about it. There's more to come here, but all of this this code looks like a really nice complement to what already exists in the tidy models ecosystem. It should feel pretty natural to folks who are comfortable\r \r with the recipes, our package,\r \r leveraging, you know, similarly named functions, if you will, just within this tailor\r \r package on the back end of your model. So something I'm I'm really, really excited about,\r \r and and really,\r \r thrilled to be able to to try to kick the tires on this as soon as possible.\r \r\n\n\n\n[00:49:13] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I I know post processing in general has been especially, like you said, class imbalance. I've never met a dataset with perfect balance in my wife yet, especially in my day job. So having a way to to interrogate this more carefully and getting these these summary metrics and visualizations. Yeah. This\r \r is this is very, very important, and I can I can tell that it looks like the team has taken their\r \r their their due diligence, so to speak, to build this in with a nice unified interface? So like the rest of the tiny models ecosystem,\r \r there should be something that's very, you know, quick to adopt in your workflows, and I'm really excited to see to put this in action. And so if our messy, predictions\r \r\n\n[00:49:52] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Mike Thomas",
        "trans_text": "that we've done in the past, for sure. We got survival modeling. Now we got post processing. I don't know what's next.\r \r\n\n[00:49:59] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I don't know, man. That that Max over there and Julia, they they know how to crank them out every every year. There's always something new. So credit to them for, you know, blowing our minds almost every on a yearly basis. But,\r \r yeah. And we hopefully the rest of the our weekly content will give you some mind blowing moments as well. There's a lot more that we couldn't get into today, but definitely check out our sections on the new packages out there. I saw some great stuff related to life sciences that has landed as well as some other great tutorials out there, from familiar faces and new faces\r \r in the r community.\r \r\n\nAnd how do we keep this project going? Well, a lot of it relies on all of you out there to send us your suggestions\r \r for great new content. The best way to do that, head to rweekly.org.\r \r Hit that little top right ribbon in the upper right corner to send us a poll request to the upcoming issue draft where our curator will be able to get that great new blog post, new package, tutorial, package update\r \r into our next issue. And, again, huge thanks to those in community that sent your poll request. They are much appreciated. It makes our our job a lot easier on the curator side to have that given to us.\r \r And, also, we love to have you involved as well in terms of listening to this show.\r \r\n\nYou can send us a fun little boost if you're listening to one of those modern podcast apps like Podverse\r \r Fountain or Cast O Matic. They're all great options to get you up and running with that functionality.\r \r And we have a nice little contact page directly in the show notes. I mean, it should be in the show notes if the AI bots don't remove it. We'll find out. But nonetheless,\r \r we also like to hear from you on social media as well. I am on Macedon these days with at our podcast at podcast index.social.\r \r I'm also on LinkedIn. Just search your search my name, so to speak, and you'll find me there. And occasionally on the Weapon X thing, I may not post very much, but I'll definitely reply to you if you shout at me. So, Mike, where can listeners get a hold of you? You can find me on mastodon@[email protected],\r \r\n\n[00:51:57] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 57,
        "trans_speaker": "Mike Thomas",
        "trans_text": "or you can find me on LinkedIn by searching Ketchbrook Analytics,\r \r ketchbrook,\r \r to see what I'm up to lately.\r \r\n\n[00:52:05] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "trans_timestamp": 5,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Very good stuff. And, Mike's posts are authentic so this week. Sometimes on LinkedIn, you can see some of those, you might call,\r \r should've rated posts, but Mike's always Mike always keeps it real. Try to. Absolutely.\r \r So we're gonna close-up shop here for this edition of our weekly highlights, and we'll be back with another episode, at least I hope we will, of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_42_highlights",
        "chap_timestamp": 18,
        "chap_text": "Exploring caves!",
        "chap_href": "https://rpahl.github.io/r-some-blog/posts/2024-10-07-nested-unit-tests-with-testthat"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "chap_timestamp": 19,
        "chap_text": "Nested tests",
        "chap_href": "https://github.com/jcheng5/shinychat"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "chap_timestamp": 30,
        "chap_text": "shinychat for R",
        "chap_href": "https://drmowinckels.io/blog/2024/ai-blog-summary/"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "chap_timestamp": 10,
        "chap_text": "Post Summaries with AI",
        "chap_href": "https://medium.com/@bruceyu0416/eda-reimagined-in-r-gwalkr-duckdb-for-lightning-fast-visualizations-05b011e8ae39"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "chap_timestamp": 2,
        "chap_text": "gWalkr for EDA",
        "chap_href": "https://www.tidyverse.org/blog/2024/10/postprocessing-preview/"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "chap_timestamp": 52,
        "chap_text": "Tidymodels postprocessing"
      },
      {
        "ep_name": "issue_2024_w_42_highlights",
        "chap_timestamp": 12,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_40_highlights",
        "ep_date": "2024-10-02",
        "ep_duration": 19,
        "ep_description_short": "A monumental achievement for bringing the Nix package manager to reproducible data science, travelling deep through the in-place modification rabbit hole across multiple languages, and a sampling of sage advice from the Data Science Hangout. Episode Links This week's curator: Tony Elhabr - @[email protected] (Mastodon) & @TonyElHabr…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_40_highlights",
        "description_long": "\r \r A monumental achievement for bringing the Nix package manager to reproducible data science, travelling deep through the in-place modification rabbit hole across multiple languages, and a sampling of sage advice from the Data Science Hangout.\nEpisode Links\n\nThis week's curator: Tony Elhabr - @[email protected] (Mastodon) & @TonyElHabr (X/Twitter)\nReproducible data science with Nix, part 13 -- {rix} is on CRAN!\nIn-Place Modifications\nData Career Insights: Lessons from four senior leaders in the data space\nEntire issue available at rweekly.org/2024-W40\nSupplement Resources\n\nrix rOpenSci review: https://github.com/ropensci/software-review/issues/625\nDeterminate Systems Zero to Nix guide https://zero-to-nix.com/ \nvec - A new vector class with added functionality https://jonocarroll.github.io/vec/\nrray - Simple arrays https://rray.r-lib.org/\nLibby Heeren's podcast Data Humans https://libbyheeren.com/podcast.html or https://datahumans.libsyn.com/site\nA Bayesian Plackett-Luce model in Stan applied to pinball championship data https://sumsar.net/blog/bayesian-plackett-luce-model-pinball-competition/\n Cover and modify, some tips for R package development https://masalmon.eu/2024/09/24/cover-modify-r-packages/\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nTorvus Clockwork - Metroid Prime 2: Echoes - DarkeSword - https://ocremix.org/remix/OCR01507\nHome is Where You Belong - Final Fantasy IX - Reuben Spears, Earth Kid - https://ocremix.org/remix/OCR04135"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://mastodon.skrimmage.com/@tonyelhabr"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://www.brodrigues.co/blog/2024-09-27-nix_part_13/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://jcarroll.com.au/2024/09/25/in-place-modifications/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://posit.co/blog/lessons-from-four-senior-leaders-in-the-data-space/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://rweekly.org/2024-W40.html"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://github.com/ropensci/software-review/issues/625"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://zero-to-nix.com/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://jonocarroll.github.io/vec/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://rray.r-lib.org/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://libbyheeren.com/podcast.html"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://datahumans.libsyn.com/site"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://sumsar.net/blog/bayesian-plackett-luce-model-pinball-competition/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://masalmon.eu/2024/09/24/cover-modify-r-packages/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://ocremix.org/remix/OCR01507"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "links": "https://ocremix.org/remix/OCR04135"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with episode a 181 of the Our Weekly Highlights podcast.\r \r If you're new to the show, this is the weekly podcast where we talk about the latest happenings that we see in our highlights and additional resources every single week at rweekly.org,\r \r your weekly curated content\r \r for all things\r \r news and other awesome events in the art community.\r \r My name is Eric Nantz, and I'm delighted you join us wherever you are around the world.\r \r And joining me as always,\r \r it seems like October is already here. Where did the time go, my friend? But\r \r join my my awesome co host, Mike Thomas. Mike, yeah, where did the time go? I can't believe it. Can't believe it either. The 2024 is almost wrapping up,\r \r\n\n[00:00:44] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Mike Thomas",
        "trans_text": "coming to a close here, but we're gonna try to enjoy what we have left of it. I'm looking forward to 2025 coming soon.\r \r\n\n[00:00:52] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Absolutely. So many of us are probably in the midst of these year end activity wrap ups, getting\r \r releases out the door, getting other things documented. I'm definitely in that\r \r in that mode right now, but this is always the the highlight of my day, no pun intended, for what we do here today. So I'm happy to, record this awesome episode with you as always, Mike. And our issue\r \r this week has been curated by Tony Elharbar, who didn't have a a big break between his last curation, but he's helping with our he's kinda scheduling switches here and there. But if you're not familiar with the our weekly effort, we have a rotating list of curators\r \r that step in every single week so we kinda spread the spread the work around, but it's all community effort driven. But as always, yeah, tremendous help from our fellow ROCE team members and contributors like you all around the world with your poll requests and other suggestions.\r \r\n\nAs I saw the the highlights come through in our little voting at the end of the weekend,\r \r it was very obvious to me what I was gonna lead off with on this episode because I am delighted,\r \r super excited\r \r to share the news\r \r that an effort that we have been covering on this show, whether in the highlights section or in our additional finds for over a year,\r \r has officially\r \r hit CRAN, and we are talking about the ricks package\r \r authored by Bruno Rodriguez\r \r to help facilitate the use of the NICS package manager\r \r for reproducible\r \r data science workflows\r \r entirely in r.\r \r\n\nI am, again, super excited and huge congratulations\r \r to Bruno on getting this release out. It is absolutely\r \r monumental\r \r to see this happen.\r \r And as he alludes to in the blog post, and we'll have Wing 2 as always,\r \r there has been over 15 months of rigs being in development,\r \r over\r \r 1300 commits,\r \r a 143 closed issues,\r \r 175\r \r closed poll requests,\r \r and not only that\r \r not only is ricks on CRAN itself as of earlier last week,\r \r It is also\r \r under the rOpenSci\r \r umbrella.\r \r Another\r \r major achievement.\r \r And frankly,\r \r when you think about it, it makes total sense.\r \r We are talking about a huge,\r \r huge boost\r \r in making reproducible data science workflows. And rOpenSci is one of its biggest core principles\r \r is the idea of reproducible data science. So it does seem like a match made in heaven to me, so I'm very excited to see where this goes.\r \r\n\nAnd as a result of being under the Arkansas umbrella,\r \r one of the ways that a package or an effort gets onboarded\r \r is a very robust and a very transparent peer review process to get the package into our OpenSci,\r \r which we can actually look at\r \r in real time, but also I have the link to in the show notes the very, poll request or the issue\r \r with all of the review feedback and all the review steps that Bruno has done to to address feedback. It's all there, all transparent. It was a very looks like a relatively smooth process.\r \r Lots of great documentation\r \r there. It's another showcase just how robust the opens side,\r \r effort is for getting high quality software\r \r under their umbrella.\r \r\n\nSo with those,\r \r notes out of the way,\r \r you may be new to this effort and wondering just what the heck Nix actually is. We're not talking about Linux. We're not talking about Unix.\r \r We're talking about Nix, and Nix is a package manager\r \r under the hood, not too dissimilar to what some Linux distributions\r \r do for distributing software in their respective systems.\r \r Distributions such as Ubuntu and Debian use the apt package manager.\r \r Red Hat, Fedora\r \r use an RPM based distribution system.\r \r Arch is definitely the host not for the faint of heart, has their own custom repository.\r \r Nix, however,\r \r you don't have to use Nix on Linux. You can actually use it on macOS\r \r as well as Windows itself, thanks to WSL or the Windows subsystem for Linux.\r \r\n\nSo no matter which OS you're on, chances are you could get Nix up and running.\r \r And one of the ways that we recommend, I know Bruno recommends this as well, to get started with Nix in a very smooth way is using what's called the determinant systems\r \r installer of Nix. That's a vendor that's trying to bring Nix,\r \r to a first class way to enterprises\r \r and in open source and the like.\r \r And I have I have a good friend on on that team named Martin Wimpress, who\r \r is helping a lot of their documentation\r \r and and other advocacy.\r \r So getting getting NICS on your system, I highly recommend checking out the determinant\r \r NICS installer.\r \r\n\nWe're also gonna have linked in the show notes a guide called 02 NICS. If you wanna get more familiar with what's happening with Nix and trying out a few different ways in your set of development environments.\r \r But as an R user,\r \r Rix is going to handle a lot of this integration with Nix for you in the sense that you can bootstrap\r \r the necessary\r \r manifest files\r \r to tell the Nix package manager\r \r not only in the version of r to install in this isolated development environment,\r \r but pull down the packages based on a snapshot in time.\r \r In total, Nix has over 80,000\r \r packages\r \r across the entire spectrum of software, and R is a first class citizen\r \r in Nix along with other languages like Python and Julia and many others.\r \r\n\nSo what Rakes is gonna do is help you, you know, bootstrap these environments\r \r and then to be able to say on my host machine, which may or may not even have R installed,\r \r you can have this, again, self contained\r \r development environment\r \r ready to go,\r \r reproducible.\r \r You could commit these files that are generated, which are called default dot nix, as well as a dot R profile file that's going to help the R session specifics.\r \r That could be on your GitHub repo. And if you have a collaborator that's also running next, they can pull down that exact same environment.\r \r That is huge. And if that doesn't sound familiar,\r \r you might say that does sound kind of similar to what Docker would give you and sounds similar to what RM would do from a package management perspective.\r \r\n\nYou're not wrong. They're they are somewhat similar in that sense of the overall goal,\r \r but the way they achieve it is a bit different.\r \r Docker is a core space and container technology, and that can be a heavy footprint depending on your perspective.\r \r But it also, admittedly,\r \r has a lot more mindshare in most of the dev ops sector\r \r and even in in sectors of data science\r \r with things like the rocker project that we speak highly about.\r \r So Nix may not always be right for your use case, but I am very intrigued by the promise it brings you. And full disclosure, I've been using Nix on a brand new server I have here in this basement a few feet behind me, which has been a great learning experience in and of itself\r \r to have more reproducible software stack for my infrastructure.\r \r\n\nBut I have been putting Nix through a couple tests in my open source work.\r \r And what's even more intriguing is that on top of the R environment that I can bootstrap for Rix,\r \r I can also easily add in other utilities\r \r such as a custom instance of what's called vscodium\r \r to have its own IDE\r \r in that same environment and bring it up as a GUI and have it ready to go. It's completely segregated from the rest of my host system, but I can tailor it to my liking. I could put extensions in there. I can have a pretty neat experience\r \r with r\r \r on Nix\r \r in a custom\r \r IDE to boot. Like, the possibilities are almost endless with this, and that's why I'm still\r \r I'm still learning the ropes on this, quite a bit.\r \r\n\nI will say I haven't had a perfect experience of it just yet.\r \r There was an instance, which if you're using R on a Linux system, you're probably all too accustomed to this,\r \r where I was installing a package, I believe it was called rag or something like that, where it needed an image library development libraries to help compile.\r \r And for whatever reason, when Rix was bootstrapping this, this development environment,\r \r it didn't pick up that I needed that extra library. So I had to manually add that in. So there's gonna be, I think, some cases that are still\r \r still getting worked out, but the the future is certainly bright here.\r \r\n\nMy\r \r other picky wish that I know has been mentioned in the Rick's issue tracker,\r \r for those of us that are coming from an RM mindset\r \r where we have projects that have an RM lock file,\r \r Oh my goodness. I sure would be nice to import that directly into Rix and then magically get the package installation.\r \r There's a lot of engineering required to do that. So I'm not surprised that it hasn't landed in just yet. But I am\r \r I am getting a bit more,\r \r you know, to say I I want this feature more and more because I have\r \r I I I'm I'm not I'm not gonna exaggerate here, Mike.\r \r\n\nI probably have in my day job over 90 projects that use RM in some way.\r \r And if I wanna convert all those to Nicks, that's a lot of manual Mhmm. Manual effort to do. So having some kind of automated way to take a lock file,\r \r magically, you know, transform that into the necessary default dot nix\r \r and getting the right package hashes,\r \r that would be massive.\r \r I have seen\r \r Python\r \r having these custom utilities\r \r that tie\r \r that poetry framework for their package management\r \r with nix. I think they call it poetry to nix,\r \r where they can somehow do this magical inference of a poetry lock file,\r \r which looks a lot similar to an rmlock file, if you're familiar with that. And they can somehow parse out then from the next package manager which Python packages to install and what hashes that correspond to that particular version.\r \r\n\nSo I have been spoiled by seeing that on, like, the Python ecosystem. I believe they have a similar thing for Rust, maybe for Julia as well. So maybe it's a matter of time. I don't know. But once that comes in, yeah, that's gonna really ease the onboarding even further for those that are coming from a different framework such as RF\r \r to Rix. But nonetheless, I don't want that to discount my huge excitement for this. I think it's a huge step to seeing Nix really\r \r taking a a solid footing in in the realm of reproducible data science.\r \r And also in the post that we're gonna link to, Bruno has a short little 5 minute tutorial video. They get you up and running with Rick's quite quickly.\r \r\n\nBut we invite you to check out the rest of his blog because\r \r there are literally about 14 or 13 of these other posts\r \r that chronicle this entire journey,\r \r which you can tell is interspersed\r \r with his learning journey of Nick's along the way. It's great to kinda see that evolution\r \r happen, and it's all been open, so to speak, for us to watch. So,\r \r yes, am I excited? Oh, heck yes. I am because the the future does look pretty bright here. I'm interested to see whatever's in the art community do with next.\r \r I've had some brief conversation with George Stagg about it. He's intrigued by the possibilities as well.\r \r\n\n[00:12:46] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 46,
        "trans_speaker": "Mike Thomas",
        "trans_text": "But, yeah, the future's looking pretty bright. So I'll be honest with you, Eric. Before\r \r the Rix package came out, Nix was sort of intimidating to me. I had built up a lot of, you know, personal education around\r \r Docker,\r \r and containerized environments.\r \r And when Nix came along, I don't know, it just felt like too big for me to,\r \r you know, wrap my brain around at the time.\r \r I've switched since then because\r \r this Rix package\r \r makes me feel,\r \r and the 5 minute tutorial\r \r video that Bruno has put together,\r \r showcasing, you know, how to get up and running with this package,\r \r makes me feel like it's so much more accessible.\r \r\n\nAnd I think that sort of the our functions, which I think there's only 6 or 7 in this package right now that help you get up and running, with a Nix environment for your art project.\r \r Take care of a lot of the things that may have intimidated me in the first place about Nix,\r \r and and sort of make it much easier to to get started\r \r with. And if you watch this 5 minute video,\r \r you you start to realize that maybe it's not maybe it's not all that intimidating,\r \r after all. And I think, you know, one of the potential benefits, as you alluded to, Eric,\r \r of having Nix as compared to maybe the Docker and and our end environments is that your\r \r Docker images that you create can get fairly heavy fairly quickly.\r \r\n\nAnd I think that there may be use cases out there\r \r where Nix would do the same thing, but the end product would be a lot more lightweight. That end environment might be a lot more lightweight. And that might be really important,\r \r depending on the the type of project that you're working on, depending on where you're trying to deploy to,\r \r you know, on the edge or something like that, a a system that doesn't have a lot of space to store, you know, large\r \r Docker images.\r \r So I I I'm really intrigued by the next project. I think this Rix package makes it a lot more accessible. I think the,\r \r fact that this package is now part of the rOpenSci\r \r project\r \r says a lot about the amount of work that Bruno and the others who've contributed to this package have put into it, and its potential importance in data science as a whole. So, very excited to see it hit crayon,\r \r and very excited to to start playing around with it because right now, at this point, there's there's no excuse. I think Bruno has done all of the work to make this as easy as possible to get started with for our developers like us.\r \r\n\n\n\n[00:15:23] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 23,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And and and speaking of the ways of making it easier, when you look at what the Rick's package offers you, there are 2 other additional nuggets that even go above and beyond,\r \r in my opinion. One of which is being able to leverage an another service out there for next package\r \r binary is called cachex\r \r to be able to help build an an environment and have it cached there on their infrastructure.\r \r That way when somebody pulls it down,\r \r is not having to recompile a package of some source. It'll get binary versions\r \r of the packages and other dependencies of that particular project,\r \r which, again, if you're familiar of running R on Linux,\r \r you love having at your disposal binary\r \r installations because that cuts the installation time from sometimes hours to minutes, if not seconds. So you you'll definitely wanna\r \r you'll appreciate that when you find yourself in those situations.\r \r\n\nBut he's also put this additional nugget here. Bruno has also been one of the bigger proponents of the targets package by my good friend, Will Landau. And there is a function in here called TAR nix GA,\r \r which will help you run a Targus pipeline,\r \r bootstrap by nix\r \r on GitHub actions. Oh my goodness. Like, that's almost sensory overload of all the integrations there. But what a great fit for having an automated data science\r \r pipeline,\r \r but then next having the full control on your installation of your dependencies.\r \r That that's massive. I I I can't wait to play with that myself. Yeah. No. It's incredible, and I think that\r \r\n\n[00:16:59] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Bruno has focused on\r \r those types of applications where I think Nix can be the most powerful,\r \r you know, in terms of GitHub's actions. We have functions here that are wrappers, as you said, around,\r \r you know, building an environment on GitHub actions and making sure that, you know, after it's run the first time, everything is cached on that cache server, so it's gonna run a lot faster.\r \r The second time sort of makes me,\r \r think of, you know, Docker Hub. Maybe you could sort of,\r \r equate cachex to that, but I think there's some differences\r \r there. But I think the idea is is fairly the same. Right?\r \r\n\nSo, yeah, I I I think just the applicability\r \r and the the usefulness and new utility that Bruno has built in to,\r \r sort of the concepts behind this package are are pretty incredible.\r \r\n\n[00:17:47] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. So I invite you to not only go to his post, but also the Rick's package site. Again, very well documented. There are a lot of vignettes, and they're ordered in a logical way to kinda start when you're brand new to Rix up until some of the very advanced use cases. So the the website\r \r looks absolutely fantastic.\r \r Again, a great fit for our OpenSci in general. So, again, it's always a team effort when these packages come up. So I wanna make sure I give kudos not just to Bruno, but also Philip Bowman, who is one of the coauthors\r \r of the package. I've seen their their work on the GitHub repo. There's been a lot of commits, as I mentioned earlier. And, this is only the beginning. Like, I can see lots of improvements coming along to Rick's end, especially as adoption grows.\r \r\n\nHeck, I I if I get more time, I wanna help contribute to this r and piece of it. Because, again, that is somewhat scratching my own niche, but I can't be the only one that wants to transfer some legacy projects that maybe\r \r to to have a more robust workflow with Nix, down the road. So we'll be watching this quite closely.\r \r And one other mind blowing thing that, again, when you have the next package that kind of blew me away when I first did this\r \r is that with Rix itself,\r \r if you want to get one of these files, you know, boostramp or the set of files boostramp for a particular project,\r \r you don't even need R on your host system to even get Rix running at first. Because with the next package manager,\r \r you can have a special command that basically shells out\r \r to compo to grabbing the the the R environment\r \r that Bruno has baked into the the package\r \r on GitHub\r \r and then pull that down interactively in what I call an interactive shell.\r \r\n\nYou can then run RICs on that directory and get the the necessary files\r \r in that temporary environment and then exit out. I guess it's similar to what Docker gives you, but it's still it just can't I can't believe that's even possible. So on this new laptop that I just got, I don't have r on it. It's all RICs. RICs or Docker. There's no r trace of it because each of the project has its own environment, and I didn't even need r to get RICs up and running. That how what magic\r \r time are we in, Mike? I just can't believe it. Gotta love it.\r \r Well, we're going to exercise a little bit different part of our brain on this next highlight, Mike. We got a fun little programming adventure for one of our fellow rweekly curators\r \r this week. And this blog post, this highlight, has been authored by Jonathan Caroll,\r \r and he is continually pushing the envelope and trying to solve what seems like almost all the programming problems that he can come across over the next year or so that he's been doing this series.\r \r\n\nAnd he comes to us this week to talk about\r \r in place modifications\r \r in R and other languages.\r \r And this all stemmed from a recent post or a video that he saw\r \r based on a problem, which in a nutshell\r \r involved having\r \r an array of of integers,\r \r and then you define some integer k and then another integer he's calling multiplier,\r \r where the task is you've got\r \r k operations\r \r to perform on this vector of numbers.\r \r And in each of these operations or iterations,\r \r you've got to find the minimum value\r \r of this vector. And, of course, if there are multiple, you know, ties in this, you just take whatever appears first. Then you replace that number you found\r \r with that number times the multiplier,\r \r and then rinse and repeat until you've exhaustively\r \r gone through all these k iterations.\r \r\n\nSo when the video he saw that there was a pretty elegant way in Python to do this,\r \r And in particular, this Python solution\r \r is taking advantage\r \r of what it has built in\r \r a\r \r compound assignment type operator, the star\r \r equal\r \r to that to that result.\r \r That is, again, calling it an in place modification.\r \r Well, r itself doesn't quite have that built in operator. He does have a solution, but that solution is technically speaking\r \r making a copy of that updated number every time. You can inspect this when you look at the memory kind of hash of an object in r, and you would see that after that operation, which looks like it's in place overriding.\r \r No. It's not. It's actually making a copy of that object\r \r updated copy of it.\r \r\n\nAnd this is another case wherein in John's r solution,\r \r he has to use a for loop. He's not able to use the map function because the iterations actually depend on what happened before it. So Markov chain. Markov chain. Oh, give me flashbacks to grad school, my friend. That's,\r \r that's some frightening stuff. But, yes,\r \r Markov chain's for the win here.\r \r So as he's going through this, he realizes that the closest thing that he's seen\r \r in the R\r \r ecosystem to this in place modifier\r \r is is from the Magritter package.\r \r If you've used this before,\r \r it's the percent sign, less than sign, greater than sign, and another percent sign.\r \r\n\nI just short aside here, this operator\r \r has given me fits for debugging, so I stopped using it many years ago. Did you have those same issues as well? I've heard the same. Yeah. In stories. Never used it.\r \r\n\n[00:23:31] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 31,
        "trans_speaker": "Mike Thomas",
        "trans_text": "It scared me just just\r \r visually to look at, but I had heard similar things.\r \r\n\n[00:23:38] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I I lost, I lost a few hours one time. I was trying to be too cute with a deep fire pipeline, and I I wrecked havoc on myself. And I was like, nope. Not gonna do that again.\r \r None\r \r nonetheless, as,\r \r John's exploring,\r \r what possible ways\r \r could he kind of replicate this in place modifier\r \r in r itself?\r \r Because his motivation is,\r \r yeah, when you have a small variable name, it's kinda easy to take a reference that variable that's probably as a vector or some numbers. And then in the square brackets,\r \r call a function on that vector\r \r to grab the right element, but then reassign that a new value.\r \r\n\nHe says them says in this, well, what if that variable name is long? We don't have to keep typing that over and over again.\r \r Is there a more convenient way to do this?\r \r Turns out\r \r not really\r \r easily unless you take\r \r some,\r \r rather risky shortcuts, and that's where I'm kind of gutting to this meat of of the solution here.\r \r Again, this is giving me flashbacks to some bad practices\r \r I did in my earlier days\r \r where you're looking at the parent environment\r \r of the function, you know, that's being called in\r \r and then using a combination of the assign operator\r \r and then the deparse\r \r substitute\r \r for that variable\r \r and injecting into a basically a copy of that, a hidden copy of it.\r \r\n\nOh, you tell about the bugging nightmares.\r \r A lot of times in my early days, I would either get code from my old projects or a collaborator that did this,\r \r and it was so difficult to make heads or tails on what was happening there. But that is kind of the closest John\r \r was able to achieve with this solution,\r \r but he acknowledges he would not really wanna do that in production,\r \r that kind of solution.\r \r So he started to look at other languages and what they offer. And sure enough,\r \r in the Julia language,\r \r there are ways to have this in place operator\r \r with a slightly different syntax that or they call mutating,\r \r where they give the name of a function but then an explanation\r \r point afterwards\r \r and feeding in the name of the object that you want to modify in place.\r \r\n\nAnd sure enough, he shows her this example of, like, reversing the order\r \r of numbers\r \r that you can, in Julia,\r \r get that in place modification of a simple vector without having to call the name more than once. So that\r \r that's pretty slick that Julia has that.\r \r And he experimented with that a little bit more, started to look at, you know, how could he do more elegant solutions to this, kind of do a little hacking around it.\r \r And so he's got at the end of the post a little\r \r modified\r \r version of this as based on, like, vector operations. He's calls that set underscore if.\r \r And sure enough, it kind of does the job.\r \r\n\nBut he's wondering\r \r if he could avoid if he can make that even easier and if maybe there's an r solution\r \r after all.\r \r So another update at the end of this post. Turns out John did end up writing a solution to this in r after all. He's got a package called Vec. It's available on GitHub. I'll link to it in the show notes with some of these features kind of baked in. And he said that there are some suggestions already from members of the community\r \r that in the base of what Vec is going to do is give you a new vector class\r \r that is gonna help with some of these in place modifying another\r \r optimized\r \r operations of vectors. So, again, great to see this. I haven't actually\r \r seen this yet.\r \r\n\nAnd then\r \r yeah. So it was a great a great exploration into what's possible with these in place operators and gotten the learning journey\r \r of seeing r not quite having enough. And then in the end, like anything,\r \r you don't know if it you don't see any something there? Write a package for it.\r \r So fun journey nonetheless and a good little brain teaser once again that enters the highlights here.\r \r\n\n[00:27:52] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Absolutely. It was fun to, I guess, just see how a a leak code problem,\r \r could\r \r be, you know, as Jonathan, I feel like often does,\r \r push to its limits in a lot of different ways and then turned into an r package that potentially\r \r may have some practical applications for folks looking\r \r to to do this type of, you know, in place\r \r replacement, if you will, without consuming,\r \r more memory\r \r than necessary, you know, as we have typically had to do in r. And this new Vec package that he's created is is pretty interesting right now. It looks like it's fairly early on in its life. There are a couple of issues out there,\r \r looking for folks to help implement,\r \r some generics\r \r for,\r \r these these Vec objects, which are\r \r this new class of of vectors that hopefully will be able to to do some of the things that John mentions in the in the blog post, but have a lot more extensibility\r \r than what we get out of the box in in base r with, vectors. So that's pretty interesting as well.\r \r\n\nIt looks like in the GitHub issues, there's some discussions\r \r around this concept of of broadcasting,\r \r which wasn't a term, I believe, that I I saw in the the blog post, but, I think it intersects with maybe some work that Davis Phan has done as well on a an R package called R Ray,\r \r which I'm taking a look at at now.\r \r So it'd be I guess, this is all, you know, pretty interesting stuff as we're we're fairly in the weeds here as Jonathan often does in terms of taking a look at at really the internals of r, and I I really love the comparisons to Python and and Julia,\r \r and and taking a look at, you know, what's available over there\r \r and bringing it potentially into the r ecosystem. I feel like that's a concept that we see\r \r more and more of nowadays.\r \r\n\nI've seen a lot of conversation lately about the the polars package in Python and and its potential,\r \r inspiration\r \r from the tidyverse.\r \r Right? So we have, I feel like, a lot of cross pollination going on to try to build the best products\r \r possible and and take a look at, you know, what are the best concepts\r \r across all programming languages, such that when we do create something new, we're trying to to create the best version of it. So very interesting blog post, by John. Cool thing about open source is that we can, you know, develop something that that somebody else can use pretty quickly here when we come up with an idea. So I highly recommend checking out the vecvecpackage\r \r if, this is a topic that is of interest to you.\r \r\n\n\n\n[00:30:29] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Absolutely. We got that linked in the show notes as well. And, certainly,\r \r if not only is John's, you know, post insightful about his current take on these solutions,\r \r There's always, like, I wanna call history lesson per se, but he was venturing into\r \r some of the ideas of other programming languages. Some of them definitely have a a long history, you might say. Even this language that he references called\r \r APL,\r \r which at first I thought was a license\r \r abbreviation, but, no, that literally stands for a programming language, which has a book itself dedicated to it. So he's he's I love the way he intersperses kind of the lessons he's learned from these programming, you know, brain teasers, these exercises,\r \r but seeing the mindset across whatever languages are doing. So, certainly,\r \r if you wanna sharpen your dev toolbox, John's blog is a is a great place to go.\r \r\n\nAnd rounding out, we're gonna get a bit, you know, back to the practical side of data science in our last highlight here because we have a very\r \r great showcase of some of the valuable insights that we've seen\r \r from recent sessions of the data science hangout, which is,\r \r hosted by Rachel Dempsey. And\r \r as of recently,\r \r her new co host is also the author of our last highlight today,\r \r Libby Heron, who has just joined POSIT as a contractor for helping with the data science hangout and also POSIT Academy.\r \r She authors this terrific post on the POSIT blog\r \r called Data Career Insights:\r \r Lessons from 4 Senior Leaders in the Data Space.\r \r\n\nSo we're gonna walk through 4 of these examples here in our in our roundup here. But first, I just want to mention that hangout is a great place, a great venue for those that are looking at learning from others in the community\r \r on their data science\r \r journey. If you're not familiar with the effort,\r \r there is what we call a featured leader or featured, you know, maybe co leaders\r \r that Rachel talks with and Libby talks of as well in the session,\r \r but it's a welcoming environment.\r \r Anyone at all are welcome to join no matter which industry, no matter which spectrum of data science you fall under.\r \r I had the pleasure of being on that about a year or so ago. It was it was a a a great time.\r \r\n\nWe've we've learned a lot even just through the questions that we would get from the audience,\r \r and the chat is always on fire, as I say, whenever\r \r whenever those sessions are on. There's lots of awesome insights on there. So she has links to all that in the blog post that we're mentioning here, but we're gonna give our take on some of the lessons that are highlighted\r \r in this post here. So the first,\r \r insight here\r \r is focusing\r \r on learning\r \r how things work\r \r and not being afraid\r \r of this feeling\r \r that you should already know how things work. I boy, does this resonate a lot? So this came from a conversation with Jamie Warner who is a managing director at Plymouth Rock Assurance,\r \r where\r \r she was talking about, yeah, you may have heard some advice before,\r \r but in the data science world,\r \r but there may be a legacy process, a legacy model\r \r that\r \r some it may be explained to you, but then\r \r there may be other situations\r \r where you may not know exactly how something works.\r \r\n\nBut when you are insight you're inquisitive,\r \r I should say,\r \r and you talk to a subject matter expert about, you know, what what is the mechanics behind this, getting around their thought process,\r \r Yeah.\r \r That is amazingly helpful. People end up being a wonderful resource.\r \r You can only do so much on Internet searches in your company's Internet or whatnot.\r \r Getting to the source of an effort or an author of a tool and getting to know their mindset on how things work. This is gonna help resonate or help illuminate a lot of ideas for you.\r \r There are times where I, again, will have impostor syndrome about some of the Bayesian methods that we use in our team on various tools.\r \r\n\nAnd in\r \r in in past, I would say,\r \r oh my goodness, Eric, you got a PhD. You should know how Bayesian works. No. I don't know how long the Bayesian algorithms work, and that's okay\r \r because I can talk to the some of the my brilliant teammates who have authored these solutions. And lo and behold, we had a great project that we're about to release in production that incorporates some, you know, fairly standard with a little sugar on top Bayesian models for clinical designs,\r \r but I was not shy about learning about why they chose certain approaches for, like, a binomial approximation\r \r versus a normal approximation and things like that. So\r \r I still have to catch myself sometimes. I'm thinking, oh, Eric, you've been in that company for 15 years. You should know about that process. No. It's okay. It's okay. It's better to ask than to not ask at all. That's my biggest takeaway from that.\r \r\n\nSo moving on to another great advice and this one coming from JJ Allaire who,\r \r is the founder of Posit.\r \r He this this part is titled getting clear about what you like doing\r \r and then finding teammates\r \r that are excited by the stuff that you don't really like doing.\r \r So in JJ's example, he mentions\r \r that he enjoyed, you know, bootstrapping these companies or founding these companies such as Rstudio, which became POSIT.\r \r But he's not exactly one that likes a lot of the managing kind of stuff that goes with, you know, running your own company. And I'd imagine,\r \r Mike, you you deal with this quite a bit in your your daily work as well. So one of the in JJ's opinion, one of the best decisions he made was helping expand his team to help those\r \r managerial\r \r administrative\r \r type tasks of running a company\r \r so that he could focus on what he's interested in is product development\r \r and really getting into the technical weeds\r \r of these solutions,\r \r which if you follow JJ's\r \r path of Rstudio and now posit,\r \r you have seen how active JJ has been\r \r in ecosystems\r \r like Rmarkdown,\r \r now Quartle,\r \r and other efforts as well. It's not just that he's the founder of Pozid. He is one of their top engineers\r \r in getting these efforts off the ground. So all you have to do is check the GitHub repo, and you can see him on top of many issues, on top of many poll requests. He is really\r \r in that. But he surrounded himself with people like Tariff and others\r \r at Pasa that are helping running, you know, the the enterprise\r \r aspects of a company\r \r while he gets to really do what he is passionate about. Again, that product development\r \r and getting into the technical bits of these products that he's working on.\r \r\n\nSo really great insights there. And and each of these, you know, kind of summaries here, there are direct links to the recordings of these actual Hangouts\r \r on YouTube, the archived Zoom, you know, Hangout sessions. So if you wanna hear it again, you know, from the source, you you're able to do that. But there's some more nuggets. Mike, why don't you take us through those? No. That's some great advice from from JJ, especially as a as somebody running a business that I can\r \r\n\n[00:38:06] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Mike Thomas",
        "trans_text": "definitely appreciate and probably need to to listen to a little bit more about delegating and making sure that you're you're focusing specifically on the the the most important parts of your\r \r job function.\r \r 2 more that we have in this blog post are from Emily Riederer and Ben Aransabia.\r \r Emily's\r \r is all about essentially\r \r making sure or or understanding\r \r that, you know, sometimes the the less flashy parts of data science, maybe not building the the fanciest machine learning or now it's AI, right, model,\r \r maybe the more gratifying\r \r parts of your data science job and your data science journey\r \r as well. And that it's important to even as we see, you know, in all the marketing hype that the the machine learning and the AI and the the ML stuff,\r \r is is, you know, maybe the stuff that gets the the most press out there,\r \r taking the the time to to learn the maybe less sexy parts of data science,\r \r is is really important to not only building your foundation, but you might find that, you know, sometimes those are the the most interesting\r \r parts of of your day to day work and being open to all of the different, you know,\r \r facets of data science and understanding that that maybe there are some of these facets that are underappreciated,\r \r but,\r \r might essentially\r \r provide you with with the most gratitude in your your job on a day to day basis. One that I can think of is is our package\r \r development and our package management, something that I absolutely love to do. I love to be able to build in our package that somebody else can install,\r \r and and and run on their their own machine and all of the different less glamorous things, right, that go into maintaining that package,\r \r ensuring that all of the different,\r \r components of that fact that package and the different requirements that that go into in terms of of files and things like that that go into ensuring that your R package is is robust and, you know,\r \r less as as less prone to to troubleshooting or or errors for somebody else as possible,\r \r is something that I actually get a lot of gratification\r \r from. And it's it's why we build our a lot of our packages,\r \r both open source and and proprietary at Catchbook for others\r \r to use. So I really appreciated,\r \r that advice there. Emily always comes with really, really practical advice. Her,\r \r talk at positconf this past year on Python ergonomics was super practical.\r \r\n\nAnd, yeah, anything that that she puts out there into the world is something that I enjoy\r \r consuming.\r \r And as I said, Ben, who's the director of data science at GSK,\r \r I think had some some great advice that's probably\r \r more general than just even if you're in data science, and it's the importance of saying no.\r \r Once in a while, Eric, I have to say I have to say no to you or or no to this podcast. And and as much as we absolutely hate\r \r to do it,\r \r sometimes we have to ensure that we're keeping the correct balance\r \r in our life. And by by saying no, you know, it can\r \r be a powerful word, but it can bring peace, I think, in your day to day\r \r life, not only, you know, professionally, but but also personally because we we can't do it all as much as we often try to and as much as I know you often try to, especially. So this is was a great reminder as well.\r \r\n\n\n\n[00:41:42] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I I find myself living that a lot lot these days. Yeah.\r \r I I'm okay with the nose from you. Sometimes my kids on your overhand, sometimes they say no a little bit too much, but that's a different story altogether.\r \r Oh, gosh. Oh, mighty. Yeah. In any event, yeah, I\r \r another example that I thought of where it's a combination of saying no to something, but then also finding a better way to do it was\r \r I had, joked with some colleagues at the day job where I made a shiny app a few years ago that was in essence a glorified PowerPoint slide generator\r \r based on dynamic data coming in with some ggplot2\r \r based vector graphics\r \r going into,\r \r a PowerPoint via the officer package. Again, awesome tooling. Trust me. I\r \r I really love the officer package for when I need to do this stuff. But then the time came where I was kinda asked to do this again in a more, I guess, a more simplified way, albeit trying to use the same machinery.\r \r\n\nAnd I did try. Like, I really tried,\r \r but this template just was not gonna cut it. It just was not gonna cut it. And I could have brute forced my way. I could have tried to find some clever algorithm to modify the text size based on number of characters going into these\r \r cells or these areas of a PowerPoint site, but I thought,\r \r no.\r \r You know what? There's a chance to do it a better way.\r \r Quartle\r \r came to the rescue. But quartle dashboards,\r \r a responsive layout for this template where it didn't matter how much text was in it, they could expand that little, you know, expander button in each of the boxes and then get a full screen view of that particular area and then wrap it back down and just zoom in, zoom out as needed. That team loved it. But I\r \r I I I probably did too much time trying to retrofit the old approach, but\r \r trying to know when to say no,\r \r even if it's just to yourself when you're trying to come up with a solution,\r \r is is a is a is a skill that I've had to learn from experience. I'm not great at it, but that was an interesting example this year. I could have said I could have said no sooner and done the portal thing right away,\r \r but it did. Sometimes you do have to struggle a little bit in these experiences\r \r to make it happen. But, yeah, I I really resonate with everyone in those posts, and there are all sorts of those nuggets\r \r on each of those hangout sessions. So if you've never been there before, again, Libby's got all the links in in this post to those previous recordings,\r \r but it's super easy to get that on your calendar and join every Thursday\r \r at noon PM EST for those wonderful hangout sessions.\r \r\n\nAnd so, yeah, I came away, you know, really excited after I had my little session last year. So, yeah, lots and lots of fun stuff there.\r \r Alright. And there's a lot more fun to be had when you look at this,\r \r some entire issue of our weekly that we have curated by Tony this week. And as much as we love to geek out and talk about the rest of the afternoon, we're gonna leave you a couple\r \r additional finds before we close-up shop here.\r \r And I told you earlier in this episode, not too long ago, that sometimes I feel a little impostor syndrome of Bayesian modeling because I did not have a lot of training of that in grad school, and I have some really brilliant teammates. I can do wizardry with it.\r \r Well, sometimes I just like to see, like, relatable examples\r \r to help connect some dots, if you will. And this this post here from Rasmuch Bath\r \r is titled a Bayesian\r \r Placket Loose Model in Stan\r \r that's applied to, of all things,\r \r pinball championship\r \r data.\r \r\n\nSo if\r \r I I love me some pinball, man. I have lots of lots of quarters ways on that in the arcade when I was younger.\r \r But what a great way to illustrate\r \r these great concept of taking, what in essence, our pairwise\r \r comparisons\r \r between different items of something such as when you have, you know, 2 teams or 2 players head to head and be able to predict them what is the likelihood\r \r of winning\r \r those particular matches\r \r based on this custom Bayesian Placket Luce model.\r \r So, they got they got the great, you know, you know, set of formulas here with the r codes of reproduce\r \r the visuals and then how to turn that into a stand model,\r \r which is, you know, a very robust way to fit Bayesian modeling,\r \r looking at all the trace spots for kind of the best fit. And then in the end, a nice little visualization,\r \r kind of hybrid line chart with the dots and the and the skill\r \r the skill of each player to see just who is kind of ranking above the rest in a somewhat\r \r forest plot like diagram. So\r \r lots lots of interesting nuggets here for a Bayesian novice like me with a domain that makes you wanna turn back time 20 years and go back to the arcade in my hometown.\r \r\n\n\n\n[00:46:45] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 45,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Mike, what did you find? I found a great blog post from,\r \r Ma'el\r \r on it's called cover and modify some tips for our package development.\r \r A lot of it is about,\r \r maybe the workflow and and types of tests\r \r unit tests that you may want to incorporate\r \r when you are developing a test for a function that already exists.\r \r So some great, you know, little pieces of advice here,\r \r include, you know, take a look and see in the roxigen\r \r documentation\r \r above that function if there is any example code that you can leverage,\r \r to within the unit tests that you need to write for that.\r \r These are 2 types of tests that I I commonly write. It's,\r \r tests that expect type, and and, you know, you're setting maybe double or character or or or,\r \r maybe a table or something like that, a data frame, to make sure that the function is returning the type of object that you are expecting,\r \r as well as, you know, testing expect equal and actually maybe running some data through that function and ensuring that it is spinning out the the number or the value,\r \r or the character string that you would expect it to return.\r \r\n\nAnd as Ma'el points out, it turns out that those two types of tests have a name,\r \r and they are called characterization\r \r tests,\r \r that lend themselves to this concept of cover\r \r and modify. So some really interesting little nuggets in here. Again, you know, anything that Mel authors is is kind of required reading for me. And I as I just mentioned in the in the last highlight that one of my,\r \r passions, if you will, is our package development and management.\r \r This is really applicable to that.\r \r\n\n[00:48:27] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I feel like you and I need to be accountability\r \r buddies to put these principles in practice because Yep. My, test driven development skills are not quite up to snuff yet.\r \r\n\n[00:48:38] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Mike Thomas",
        "trans_text": "You and me both.\r \r\n\n[00:48:40] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. Yep. Well, we'll keep each other honest on this. But, yeah, it's amazing to see as my mentions in the early part of this post, how she's been working with the iGraph r package quite a bit, all these different lessons that she's learning and these different techniques.\r \r Isn't that the way, though, we find ourselves knee deep in a project that may not always be comfortable at first, but then we're adapting\r \r to, you know, finding new solutions.\r \r And then you can take those solutions and use them in the rest of your, you know, development workflows.\r \r So for me, that whole portal thing I just mentioned,\r \r I'm now a huge fan of chordal dashboards because of what I learned because of, you know, putting that for the paces. So, yeah, we there's always something new to learn. Only only one one brain in my head, but I feel like I wish I had 2 or 3 of them so I could keep this track for. If I could convince all my clients to accept\r \r\n\n[00:49:29] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Mike Thomas",
        "trans_text": "HTML output,\r \r I'd be right there with you, Eric.\r \r\n\n[00:49:33] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I don't say I have it all figured out yet, but at least in this one case, I was like, which one would you rather have? And everybody said, I like that web version. So we're we're on the way. It's much nicer. Yep. It is very much so.\r \r You know, the Rwicky project itself is nice for your r learning. And then again, it is a community based effort. We we thrive and we frankly depend on the contributions from the community as we go through your awesome resources that you're authoring\r \r on your blogs or authoring these great packages,\r \r perhaps even compile with Nix. Who knows? But if you wanna contribute to the r weekly project, there are a few ways to do so. First of which is if you find that terrific resource,\r \r put get it in touch with us because we can do that via a poll request on the main repo at rweekly.org.\r \r\n\nThere's a link in the upper right corner, that little octocat\r \r ribbon there. You can click that and get taken directly to the poll request template in markdown format,\r \r all markdown all the time. You get a very quick primer with that template of what the contribution should be, and you are on your way. And, also, we love hearing from you for this very show. We love,\r \r to hear have you give us a fun little boost if you're listening to one of those modern podcast apps.\r \r I just listened to a a fun webinar\r \r about the podcasting 2 point o landscape, really nice insights to some of the top developers.\r \r So I may put a link to that in the show notes if you wanna listen to the the post recording on that. But, also, you can get in contact with us through our contact page, which is linked in the show notes of this episode.\r \r\n\nAnd we are on social media sporadically sometimes, but I you can find me mostly on Mastodon.\r \r I am at our podcast at podcast index on social.\r \r I am also on LinkedIn as well. In fact, I will be sending a note probably in the next week or so when we put the recordings out from our recent\r \r Gen AI day for our pharma that took place a couple weeks ago. There'll be fun fun talks to to watch there. I'll put an announcement on that shortly.\r \r And then also you can find me sporackling on that weapon next thing with at the r cast. And, Mike, where can the listeners find a hold of you? Yep. You can find me on mastodon@[email protected],\r \r\n\n[00:51:47] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Mike Thomas",
        "trans_text": "or you can check out what I'm up to on LinkedIn by searching Catch Brook Analytics,\r \r\n\n[00:51:52] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Eric Nantz",
        "trans_text": "k e t c h b r o o k. Awesome stuff. Yep. Definitely a fun read as always whenever you put your post out there.\r \r But we can't have my fun much longer. Our day jobs are calling us back, so we're gonna close-up shop here,\r \r and wish you best of luck in your data science journeys for the rest of the week, and we will be back with another\r \r episode of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_40_highlights",
        "chap_timestamp": 46,
        "chap_text": "rix hits CRAN!",
        "chap_href": "https://www.brodrigues.co/blog/2024-09-27-nix_part_13/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "chap_timestamp": 22,
        "chap_text": "In-place Modifications",
        "chap_href": "https://jcarroll.com.au/2024/09/25/in-place-modifications/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "chap_timestamp": 33,
        "chap_text": "Data Career Insights",
        "chap_href": "https://posit.co/blog/lessons-from-four-senior-leaders-in-the-data-space/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "chap_timestamp": 50,
        "chap_text": "Bayesian models for pinball wins",
        "chap_href": "https://sumsar.net/blog/bayesian-plackett-luce-model-pinball-competition/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "chap_timestamp": 47,
        "chap_text": "Cover and modify",
        "chap_href": "https://masalmon.eu/2024/09/24/cover-modify-r-packages/"
      },
      {
        "ep_name": "issue_2024_w_40_highlights",
        "chap_timestamp": 46,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_39_highlights",
        "ep_date": "2024-09-25",
        "ep_duration": 37,
        "ep_description_short": "How the latest release of patchwork is saving a cozy space for gt tables, a new package in the ggplot2 ecosystem to lend a guide for your guides, and a prime way of using R to brute-force the answer to a mathematical brain-teaser. Episode Links This week's curator: Tony Elhabr - @[email protected] (Mastodon) & @TonyElHabr…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_39_highlights",
        "description_long": "\r \r How the latest release of patchwork is saving a cozy space for gt tables, a new package in the ggplot2 ecosystem to lend a guide for your guides, and a prime way of using R to brute-force the answer to a mathematical brain-teaser.\nEpisode Links\n\nThis week's curator: Tony Elhabr - @[email protected] (Mastodon) & @TonyElHabr (X/Twitter)\npatchwork 1.3.0\n{gguidance}: Extended guide options for 'ggplot2'\nPrime numbers as sums of three squares. by @ellis2013nz\nEntire issue available at rweekly.org/2024-W39\nSupplement Resources\n\ngt 0.11.0 release notes https://gt.rstudio.com/news/index.html#gt-0110\nBeing free from constraint https://www.data-imaginist.com/posts/2024-01-05-patchwork-1-2-0/#being-free-from-constraint\ngguidance: A guided tour vignette https://teunbrand.github.io/gguidance/articles/tour.html\nCreate a free Llama 3.1 405B-powered chatbot on an R package's GitHub repo in <1 min https://blog.stephenturner.us/p/create-a-free-llama-405b-llm-chatbot-github-repo-huggingface\nEase renv::restore() by updating your repository to Posit Public Package Manager https://www.pipinghotdata.com/posts/2024-09-16-ease-renvrestore-by-updating-your-repositories-to-p3m\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nSmoke & Marbles - Castlevania: Symphony of the Night - Emunator, ZackParrish, Lucas Guimaraes - https://ocremix.org/remix/OCR04714\nSee Me Again - Valis III - tibonev - https://ocremix.org/remix/OCR04610"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://mastodon.skrimmage.com/@tonyelhabr"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://www.tidyverse.org/blog/2024/09/patchwork-1-3-0/"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://github.com/teunbrand/gguidance/"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://freerangestats.info/blog/2024/09/21/primes-squares"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://rweekly.org/2024-W39.html"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://gt.rstudio.com/news/index.html#gt-0110"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://www.data-imaginist.com/posts/2024-01-05-patchwork-1-2-0/#being-free-from-constraint"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://teunbrand.github.io/gguidance/articles/tour.html"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://blog.stephenturner.us/p/create-a-free-llama-405b-llm-chatbot-github-repo-huggingface"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://www.pipinghotdata.com/posts/2024-09-16-ease-renvrestore-by-updating-your-repositories-to-p3m"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://ocremix.org/remix/OCR04714"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "links": "https://ocremix.org/remix/OCR04610"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back of episode a 180 of the Our Weekly Highlights podcast.\r \r You know what? That's a cool number. Maybe we should\r \r 180 and call this the SaaS Weekly Highlights podcast.\r \r Oh, oh, I get it. No. I'm just kidding. No. No. No. No. Buckle up, folks. We're we're still the rweeklyhighways. I couldn't resist. Anyway, this is the weekly podcast where we're talking about the awesome highlights and other resources I've shared every single week at rweekly.org.\r \r My name is Eric Nantz, and I'm delighted that you join us from wherever you are around the world. We're back at our usual recording time. But, of course, just like usual, I never do this alone, at least not unless I'm forced to because I still have my trust to cohost Mike Thomas with me. Mike, how are you doing this morning? Doing well, Eric.\r \r\n\n[00:00:47] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Had a look a tiny, tiny little time change. I appreciate you being accommodating here, but we're we're getting it in.\r \r\n\n[00:00:54] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 54,
        "trans_speaker": "Eric Nantz",
        "trans_text": "We're getting it in. One way, look like crook. No matter if we're moving or doing chaotic virtual events, we always find a way. Right? Exactly.\r \r Exactly. And just like finding a way, our weekly finds a way to release an issue practically every single week,\r \r and that is not possible without this being a community driven effort by our curator team.\r \r And our curator this week is Tony Elharbar.\r \r Of course, he was, made famous\r \r a few years ago with his participation in the slice competition. I saw a fond memories of watching that. But, of course, he had tremendous help from our fellow Arrowrocki team members and contributors like all of you around the world with your poll requests and other suggestions.\r \r And we're gonna actually, for our first two highlights, we're gonna definitely deep dive into some novel visualization\r \r upgrades for your toolbox.\r \r\n\nThe first of which is a package that has gotten a lot of positive attention since it was released a few years ago.\r \r If you've ever been in the situation where you had multiple\r \r plots that you wanted\r \r to put together in a seamless, like, multi figure, multi panel environment\r \r and may and have them be completely separate types of plots,\r \r Patchwork is your friend here. Patchwork is the r package that's been authored by Thomas Lynn Peterson, who is a software engineer on the tidyverse team over at Posit.\r \r And in particular,\r \r Patchwork just had a major new release,\r \r version 1 dot 3 dot o. And we're gonna cover a few of the major features landing this release.\r \r\n\nAnd to start off with,\r \r I have some good friends in another,\r \r industry, we'll call it, named Bubba Ray and D Von. And, boy, they sure like their tables. They were telling me, Eric, get the tables for Patchwork. Well, guess what? We're gonna get some tables for Patchwork because\r \r in this release,\r \r you are now able\r \r to not just put a ggplot2typeplot\r \r in patchwork.\r \r You now have first class support to put in a table created by GT.\r \r GT has made a lot of waves in the table\r \r generation ecosystem and r, which, of course, has been authored by Rich Yone, who did a wonderful presentation\r \r on the past and the future of GT at Positconf.\r \r\n\nBut a lot of this feature is possible\r \r because of yet more\r \r terrific contributions\r \r to the open source GT package.\r \r This one, authored by Toon Wendenbrand,\r \r who will be featured on another highlight later on, but he laid the foundation\r \r so that GT\r \r objects can now be composed or rendered\r \r as GROBs.\r \r Where if you're not familiar what a GROB is, that is the underpinning type of object\r \r that the system used by ggplot2\r \r is using to compose the plots together\r \r in the underpinnings.\r \r So with both now a gt object as a GROB\r \r and, of course, ggplot2 objects as GROBs, they now can fit seamlessly\r \r into patchwork.\r \r\n\nAnd we'll just, I'll cover a couple of the major things about this new feature. And, again, this is brand new,\r \r but already out of the box, you're gonna have terrific support\r \r to just literally just add this\r \r GT object in your patchwork call. Just literally adding the 2 objects together, and you're gonna get the patchwork rendered composition\r \r right away.\r \r And you get some niceties under the hood or as part of the functions with this\r \r because\r \r you will now have first class support for adding\r \r titles, subtitles,\r \r captions, just like you would in a normal GT,\r \r and they will show up just fine in a patchwork\r \r composition\r \r as well.\r \r\n\nBut if you wanna customize things further for how tables are wrapped into this,\r \r there is appropriate enough a function called wrap underscore tables\r \r that's gonna let you customize\r \r how the table utilizes,\r \r say, the space around it. So in Patchwork, each\r \r object gets put in what's called a panel.\r \r And with this wrap table,\r \r you can actually define\r \r which parts of the table are fitting into that panel.\r \r By default, it's every part of the table, which includes, like,\r \r row labels,\r \r titles, column headers, and whatnot.\r \r But you can actually customize\r \r which parts are actually going outside the panel area, such as maybe the top, the left margin, the right margin, and what have you. That's nice if you wanna line things up in a more custom way.\r \r\n\nAnd then also\r \r with that, there are some other enhancements as well to how you define\r \r the layouts. And what's cool is that it's even gonna be intelligent enough if you're doing, like, a top down\r \r composition\r \r and your table and your plot are sharing, say, the same variables\r \r in, say,\r \r rows or columns.\r \r They will automatically kinda line up next to each other. So your your eye can visually track\r \r maybe that plot at the top with that particular variable and then the table at the bottom and line those values up. It's really slick how they do that. I have no idea how they did it, but it's a lot of awesome engineering around it\r \r nonetheless.\r \r\n\nAnd the one the one caveat I wanna mention\r \r has to do with accessibility.\r \r Because under the hood, when these tables are rendered as GROBs and then put into a patchwork composition,\r \r the table is converted to an image PNG representation.\r \r Whereas by default in GT, if you're just creating the table, the default output format for that is HTML,\r \r which, of course, HTML. You can actually get the text that's representing that table\r \r and use that in accessibility\r \r type features.\r \r So if you are going to put a GT table in a patchwork setup,\r \r make sure to especially if it's going in, like, a report, publication, or whatnot,\r \r make sure to complete the alt text for that entire patchwork\r \r to include not just the text around the plot itself, but also the text around the table. It might take a little getting used to, but if you're already well versed in how accessibility features in GBOD 2 works, it should be a pretty seamless workflow for you. And it will also have a link to the the show notes for additional content\r \r with regards to the GT release notes where this, GROB feature landed if you want to learn more about how that worked.\r \r\n\nBut wait. There's more, as I say, in this Patchwork release.\r \r And if you've been looking for a little freedom\r \r in your Patchwork\r \r compositions,\r \r well, that has you covered with a lot of bells and whistles around that, doesn't it, Mike? Yes. It does. And I believe in\r \r\n\n[00:07:46] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 46,
        "trans_speaker": "Mike Thomas",
        "trans_text": "the previous version\r \r of Patchwork that was released,\r \r there was this new function called free,\r \r that was added to the API. And I know that Thomas Lynn Peterson, who I think is is one of the leads on the Patchwork project\r \r Yep. Not only talked about, you know, this function at at PasaComp last year, but was also really wanted to be really thoughtful\r \r about, you know, how this particular function called free was was going to work and and really careful because, you know, as you\r \r noted, Eric,\r \r Patchwork does some pretty incredible stuff for us,\r \r under the hood that, you know, you and I don't even understand necessarily\r \r how it works in terms of aligning axes and and things like that.\r \r\n\nSo so Thomas wanted to be really careful, and I think that the Patchwork team wanted to be really careful that, they made the correct decisions\r \r when it came to how this new free function was going to work. So there's there's some additional arguments,\r \r that are now introduced into this free function\r \r that allow you to better sort of, align, you know, multiple charts with each other.\r \r So one of those arguments is is called side,\r \r which allows you to supply either a a character t, r, b, or l. I think that's top, right, bottom, and left characters\r \r to indicate sort of which side you want to free up and not necessarily,\r \r you know, fix,\r \r axes and things like that.\r \r\n\nSo there's, you know again, we're doing\r \r podcasts on data visualization.\r \r You're gonna be best served if you take a look at the blog yourself, but he is a great example of, using the side equals l argument to to free up the left side of the plot, while the the right side of the plot sort of stays fixed, if you will,\r \r with the the plot below it.\r \r There is also,\r \r a type\r \r possible argument within the free function as well, which prior to, that type argument being introduced\r \r when you were putting 2 stacking, you know, for instance, vertically, 2 plots on top of each other,\r \r sometimes\r \r a\r \r plot that had a an axis label, that axis label would be pushed way out, if the other\r \r plot above it, if you will, in in this particular example, did not have an access title.\r \r\n\nSo that that access title in the the one plot that did have an access title was kinda floating way out in space in in situations\r \r where you had, long, sort of, access labels,\r \r on one plot. And, again, the the blog post does a great job of demonstrating an an example here. So now we have this type equals label,\r \r argument that we did not have previously\r \r that pushes\r \r that axis label on the the one plot that does have the axis title, excuse me,\r \r much closer to the axis labels themselves. So it's not that axis title is no longer, sort of, floating out in space,\r \r which is is really helpful. There is also a type equals space argument,\r \r that sort of just better condenses,\r \r from what I can tell, you know, your plots and the the white space in the margins between your plots, which is always something that I've had a tricky time doing, you know, especially when we are trying to in a lot of instances,\r \r you know, we might be saving this as some sort of an image file that we're then putting into a a quarto presentation or or something like that.\r \r\n\nAnd, you know, white space becomes very important when you were trying to fit a lot of content on a slide, for instance, or in a PDF.\r \r Right? So we have this new type equals space argument that allows us to to better manage that.\r \r And I think that there there might be a couple additional bug fixes in this highlight as well,\r \r but the new functionality,\r \r you know, is is really helpful. I've been doing a lot of work lately, unfortunately,\r \r in matplotlib.\r \r Some of this stuff is equivalent and possible, but some of it wrestling with with spacing and white space and what are called subplots\r \r in matplotlib,\r \r is is very, very tricky. And I wish that I had the patchwork,\r \r\n\n[00:11:52] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Eric Nantz",
        "trans_text": "package available over there. Yeah. So once you start using it, you don't know how you live without it. I mean, this has been an issue that I wrestle with so much back in my earlier days of helping do a lot of biomarker\r \r analysis and creating custom PDF reports so we wouldn't just have one type of plot. We would have\r \r multiple types and then trying to get into the grid system to do all the alignment manually. It was\r \r a major undertaking. Patchwork is just giving you such a elegant\r \r API on that fits so natively with the ggplot2,\r \r you know, layered philosophy of the grammar graphics. It it really is hard to replicate this across different different languages. So anytime I need these type of gg plots to be present, especially in a report, yeah, Patchwork is gonna be\r \r my go to for it. My greedy ass has been and I've been not the only one asking this, but if you recall, there was some work to\r \r create animated ggplot. So ggAnimate\r \r that, Thomas took over from David Robinson.\r \r\n\nOh, I'm so greedy. I would love that patchwork work with those, but that's okay. I I can I can wait for that because this is already\r \r spectacular\r \r in terms of the compositions we are have at our disposal? And now with GT, the possibilities are even more more endless in my opinion.\r \r And like many things in the r community, there's a lot of synergy in respect to this issue because our next highlight is coming from that same contributor I mentioned\r \r that helped build the foundation\r \r for getting GTE pack tables into patchwork.\r \r And this next highlight is a brand new art package that has hit the ecosystem\r \r authored by Ton Vandenbrand who is a PhD student at the Netherlands Cancer Institute. And, apparently,\r \r he's been working on a lot of ggplot2\r \r stuff in his previous open source efforts. But in particular, this new effort\r \r is a new r package called gguidance.\r \r\n\nI have to catch myself from saying ggguidance because of ggplot2, but, you know, hopefully, I got it right. But, nonetheless,\r \r if you've ever wanted or found yourself in a situation where,\r \r yeah, you get a lot of nice customizations\r \r already out of the box with respect to your guides\r \r and other aspects of how you, you know, customize your axes, labels, and your legend attributes\r \r in ggplot2,\r \r the vanilla version of it.\r \r G guidance is gonna give you kind of a more elegant way to bring some additional customization\r \r with some of its own versions of these guides.\r \r\n\nAnd the and this, vignette that we're gonna be highlighting here and that we'll put in the show notes as well as a nice summary of 2 kind of major categories\r \r of these features. I'm gonna lead off with these really great functions that are prefixed with guide underscore axis. So these are tailored\r \r towards bringing some additional formatting\r \r possibilities\r \r to the way your axis labels and tick marks are specified.\r \r The first of which is guide axis custom.\r \r And this is great for when you have, you know, your typical two dimensional plot with an x and y axis,\r \r and those axes are some kind of positional type metric,\r \r maybe a discrete scale or or a bin to continuous scale.\r \r\n\nAnd this is great when you want to\r \r add a little customization\r \r to it.\r \r Say one of the things that comes out of the box is on the tick marks.\r \r You can add what are called bidirectional\r \r tick marks where, again, as an audio podcast, it's gonna be hard to\r \r hard to say this, you know, very clearly, but it gives you kind of both the the line at the bottom of that\r \r or the axis\r \r line and above it as well. So in case you want that additional\r \r that visual cue of where the axis label tick actually starts,\r \r that's a it's a nice little visual cue around that. But the real selling point in tones of vignette here about this function\r \r comes when you decide in your plot to switch\r \r maybe the coordinate system\r \r going from, say, the typical scatterplot\r \r like x y, you know, 2 dimensional layout\r \r to a more radial, you know, type, you know, circle layout.\r \r\n\nIn the past, you would have to also modify the guide yet again in your usual route to call when you switch those coordinate systems.\r \r But with Guide Access Custom, it is intelligent enough to know when you switch that coordinate\r \r type of system, and you don't have to customize it any further. So there's a great example in the in the vignette here where he goes from, like, the scatterplot type visualization\r \r to a, to a radio plot, but he could keep the guide,\r \r access call\r \r exactly the same. That's pretty handy when you have to switch these, you know, on the fly with a lot of friction in between.\r \r And then another really neat feature,\r \r and I don't remember when this landed in Jigetwapattu\r \r proper,\r \r but now on your axes you can have nested axes where maybe\r \r you have in the case of the in the vignette here you've got a bar a stat a bar chart where you've got different\r \r flavors of a product of food maybe, you know, coffee, tea, apple, pear, or whatever.\r \r\n\nAnd then you've got a more overarching category for these. So you can put that overarching category\r \r underneath the appropriate labels,\r \r and you can do this with ggplot2\r \r proper.\r \r But what,\r \r is offered in this package\r \r is a way to customize\r \r how you're exactly doing that categorization,\r \r or maybe you have a leftover category\r \r in your nested top, you know, sublevel,\r \r and you don't care about putting that under any top level. So you just wanna leave that blank. You can do that by manually defining a key\r \r of these labels as a simple data frame\r \r like setup.\r \r\n\nBut then you can also customize\r \r instead of just having a horizontal line that separates\r \r these heading or these nested labels.\r \r You could have, like, a, like, a curly bracket, or you can have, in fact, up to 7 types of brackets that come out of the box for that separation between the sub labels and the top level labels.\r \r And, yes, if you're adventurous enough with creative enough,\r \r you can create your own bracket style by feeding in a simple kind of matrix of x and y coordinates.\r \r And in the example, he's got, like, a a jagged line instead, whatever you wanna do. That's beyond me. But the cool point is if you really\r \r want full control\r \r over the visual cues of these nested labels,\r \r you've got a lot of power exposed to you with this with this awesome function of guide access nested.\r \r\n\nSo I'm definitely gonna be checking that one out, but there is a lot more to this with respect to color customization.\r \r So, Mike, why don't you take us through what he offers you in this package? Yes. There is. There are these two functions,\r \r\n\n[00:19:18] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 18,
        "trans_speaker": "Mike Thomas",
        "trans_text": "guide call bar and guide call steps, which we'll talk about first, which are are pretty incredible that allow us to be able to either have, you know, sort of this continuous gradient gradient,\r \r in our legend, color gradient,\r \r or we can have,\r \r something that looks more like a discrete color gradient, where we have, you know, specific sort of bins,\r \r for the particular colors that we're going to show,\r \r in our legend that correspond\r \r to the colors that are shown on the plot as well. There's this, notion of caps as well, where you can sort of fix your color scale\r \r in your legend and have it bounded with a a lower limit and an upper limit. And then you can have a shape,\r \r that also has a corresponding, you know, perhaps different color. In this case, it's it's gray because,\r \r he's trying to show that, you know, these values would be out of bounds anything above 30 or below 10, and and he has a triangle\r \r on either side of the,\r \r the color guide here in the legend to represent, what are called these caps on the the legend or the guide, if you'll which are pretty cool.\r \r\n\nYou can also, you know, implement those caps as as shapes, and he uses triangles\r \r in the example here. But instead of, you know, having them be these out of bounds\r \r values,\r \r you could have them be, you know, these colors that, sort of, still correspond to your gradient that you're using in your chart. You can cap just one side, either the top or the bottom of the legend, which is pretty interesting\r \r as well. Just a lot of different flexibility\r \r to do things here. And then sort of similar, Eric, to what you were talking about in terms of brackets, you know, on the axes of the chart, you can also add brackets to the legend. So there's one example here where, he's he's sort of creating brackets on the legend that classify\r \r values,\r \r in a group a or, you know, if you're higher up in the gradient, then you would belong to to group b. And you can stick those brackets right against, the side of your legend, which is a really, really cool feature, something I had had never really thought about myself as well.\r \r\n\nHe he has an example here where the legend itself is is radial.\r \r It's it's a circle. It kinda looks like a donut chart or or a clock, if you will, where you have this this sort of polar coordinate system for your legend, which is really interesting.\r \r I can't think of a use case where\r \r I would necessarily\r \r employ that over a a legend that's, you know, just just rectangular.\r \r But it's it's wild that we have the ability\r \r to do that. So a lot of customization here, a lot of flexibility.\r \r I think, you know, one of my main takeaways in terms of the the most what I\r \r takeaways as some of the most useful functionality of this package is it's almost like chart annotation.\r \r\n\nRight? Here's one example in here where,\r \r you know, the the x axis is time. It's it's years,\r \r and it's some sort of a political,\r \r I think it's unemployment. Right? Right? And it's it's, you know, intended to be a political type of chart.\r \r And he has these horizontal brackets\r \r underneath the x axis values\r \r that show the administration, you know, the name of the president\r \r at the time,\r \r you know, and those those values are gonna change based upon whether they serve 4 years or or 8 years or or different, you know, the the horizontal width of those particular bars. And, you know, I think that annotation is is a really powerful addition to the chart, you know, in regards to the story\r \r that you may be trying to tell.\r \r\n\nObviously, the the subgroups as well in the bracketing and the boxes, that we talked about, I think, can be really, really helpful for, again, you know, doing the\r \r additional things and custom things that we need in our visualizations\r \r to ensure that we're getting our point across as effectively as possible.\r \r\n\n[00:23:14] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 14,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I wanna, you know, dive in on that as I've been digesting this more since I read about it. I feel like this is really still trying its best with these additional\r \r aesthetic kind of customizations\r \r to keep the the the viewer's attention\r \r on the main event, so to speak, of the plot itself, but then putting some nice annotations\r \r around that main area\r \r without you having to really switch context and maybe looking at a a paragraph above\r \r below the plot that talks about, like, categories of these color ranges\r \r or, like, these different, like, inherent groupings that are comprising these data points, like the time axis or whatnot.\r \r\n\nI think this is wonderful from, like, a best\r \r practices when you've gotta you've gotta nail that that initial look at these data.\r \r And there have been, you know, countless workshops about effective\r \r visualization with jigapod too, and those, you know, those great materials by Cedric Shearer and others are still must reads if you find yourself doing this routinely.\r \r I feel like this this package,\r \r g guidance, is giving\r \r us, our users, that don't really wanna dive into the realms of utilizing another program such as Adobe Illustrator or other software\r \r to do those, like, fancy customizations\r \r you often see in blog posts or whatnot.\r \r\n\nNow we can do a lot of that here\r \r and especially\r \r with making it\r \r the striking the balance between overwhelming the user but then not having enough information. I think this is hitting the sweet spot\r \r even in this early stage, which I am, you know, thoroughly impressed for. This isn't even on CRAN yet. This is its initial release, I believe,\r \r of this package. So I'm I'm I am, like I said, very impressed by this. I'm definitely gonna recommend this both to to future collaborators. I wanna\r \r level up their ggplot2\r \r visualizations\r \r with these nice annotations, and, of course, I may be using this in the future as well. So job well done,\r \r Tone, and, we can't wait to see what's next in this package.\r \r\n\nWell, let's, take a little break from our visualization\r \r round up there, and we're gonna go back to school a little bit, Mike. And I hope you're ready because you're gonna have to dust off some concepts, ironically,\r \r my, oldest son is starting to learn about,\r \r in this last highlight here. And this was spurred on by a LinkedIn post that was discovered by\r \r Peter Ellis, who actually was featured on the highlights of last episode with his blog post on the Australian Census.\r \r Well, he's back in a decidedly different topic this time around, whereas I mentioned,\r \r he saw on LinkedIn\r \r this post about how a particular number,\r \r 397,\r \r and this was conjecture to be the largest\r \r prime number\r \r that can be represented uniquely as the sum\r \r of 3 positive\r \r squares.\r \r\n\nSo let's step back a little bit because, you know, I'm gonna dust off my convoys here a little bit. If you're not familiar of what prime number is, this is the concept where there are no\r \r smaller numbers other than that number times one that you can use to derive the product of to get to that same number. So a classic example,\r \r the number 5. Right? You can't do, like, 2 times 2 or whatever. It's gotta be 1 times 5 or 5 times 1. That's the concept of a prime number. And, Mike, you're gonna keep me honest here. We're talking integers.\r \r Integers. Yes. Thank you. Integers. Yeah. Good caveats. Yeah. I knew I'd be rusty on this.\r \r\n\nBut, as as Peter read this, he wanted in his mind, he's going to change the wording a little bit to this, as being\r \r 3 97 is a conjectured\r \r largest prime number\r \r integer that can be represented as the sum of 3\r \r positive squares of integers in exactly one way.\r \r So\r \r had I been very much smarter, maybe there would be a way you could figure out a clever mix of linear algebra or other optimization\r \r to solve for this in a, you know, rigorous mathematical proof.\r \r I'm not one of those people.\r \r So, like like, what my approach might be, Peter decides to take matters in his own hands. He calls it a brute force approach,\r \r which, actually isn't too brute force, but you can kind of get the logic of this as we talk through it.\r \r\n\nHe decided\r \r to do a couple things\r \r for a given what we'll call max integer.\r \r He used 30 in this example.\r \r He first computes\r \r all the squares of those numbers, saves that as a vector.\r \r And then for a visualization\r \r later on, he's actually gonna leverage a package\r \r called primes,\r \r which I never heard about until this post, and I did some research on this.\r \r This is a package that's authored by,\r \r that's authored by Oz Keys, who I have a link to in the show notes, for all sorts of\r \r derivations and testing with respect to prime numbers and r. So he's going to have that kind of on the on the back burner,\r \r but he's going to leverage the tried and true\r \r expand dot grid to take\r \r basically\r \r all those squares, that vector of squared numbers,\r \r and do 3 columns of them that represent the three numbers that have to be added to get to this, you know, magical prime number.\r \r\n\nHe's gonna expand grid all the combinations\r \r of those\r \r and then filter\r \r for when\r \r those\r \r are uniquely\r \r different from each other\r \r and that the the sum of that is 397.\r \r And sure enough, when he does that filtering in the blog post, you can see that it's numbers\r \r 964324\r \r that get you to that final result.\r \r Now that's great for, you know, the smaller cases.\r \r Certainly,\r \r if you want to beef this up further, yeah, you're going to start needing some processing time. If you go above 30 for the possible\r \r other answers,\r \r you could derive here.\r \r But it's just he does some additional\r \r customization\r \r to count how frequently some of these other results might happen\r \r with these different combinations.\r \r\n\nAnd, say, they're like for the number 54,\r \r he found that there were 3 instances where you can satisfy\r \r this requirement.\r \r But as you think about all the ways to explore this, this could balloon up pretty quick.\r \r So\r \r to wrap it all up, he's got this nice visual set of visual charts of ggplot2\r \r to look at all the possible prime numbers,\r \r with a given range on the x axis\r \r and the number of times that these are these are occurring\r \r on the y axis or the number of ways that you can derive\r \r to that to that particular prime number.\r \r And as as you can see, he does a nice annotation on the first one to show where 3 97\r \r wise. And then as you bump up that number from 30 to a much higher,\r \r such as 10,000\r \r and then ballooning it up even more, yeah, it's it's gonna it's gonna eat up some horsepower\r \r on your machine because, of course, default r is memory based. Right? You're gonna be making this\r \r massive\r \r dataset\r \r of these different combinations. So he conjectures\r \r whether\r \r we could have, like, a way to fit this nicely into a, like, a database structure, which sounds like a a nice challenge for you readers out there if you wanna try that out. But a nice little exercise that once again with the power of r and its, you know, capacity under the hood, You don't always have to have that fancy mathematician mindset to figure out data driven approaches to these answers. So maybe I give this to my son as a homework assignment one day. I have no idea. There you go. No. It's a nice little brain teaser. I enjoyed it. I thought it was a really unique and interesting post and I I thought the data visualization aspect of it was interesting. I I'm not sure if that's\r \r\n\n[00:31:33] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Mike Thomas",
        "trans_text": "an approach that I would have thought of when, you know, trying to solve this problem and and come to this answer and I think it does a great job. We have a few different plots here essentially representing the same exact thing,\r \r that really demonstrate that,\r \r you know, this number 397\r \r is is the largest\r \r number,\r \r that is uniquely able to to be,\r \r the sum of 3 positive squares\r \r of integers and that's that's the the highest prime number, if you will.\r \r Like the like the ggplot annotation, the little red circle, around the dot across the three 3 plots, which is really nice. I believe it's just all base ggplot,\r \r that we have here and some dplyr code. And it's incredible, you know, sort of simulation based analysis, you know, what we can do with really just 2 packages, dplyr and ggplot.\r \r\n\n\n\n[00:32:23] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 23,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And this gave me flashbacks to a a project at the day job where we had\r \r a situation for smaller sample sizes. We couldn't rely on the normal approximation\r \r to help derive some of our probabilities\r \r of success and and p value inferences.\r \r So we had to make kinda make our own exact type of solution,\r \r but we couldn't, like, be exact from a mathematical sense. We had the brute force\r \r what you might have had in your classical statistics or data science courses\r \r when you're learning about p values for the first time. And maybe this doesn't happen now because yours truly is a dinosaur in terms of the the world now. But we have lookup tables of the p values in the back of our textbooks where, like, the t distribution,\r \r the the normal distribution, the f distribution, or whatnot.\r \r\n\nAnd we had to do this kind of thing with our, situation where we made up this distribution, but we did, like, a preconfigured\r \r set of configurations\r \r of these\r \r p values, not too dissimilar to having, like, a configuration\r \r of ends in these p value lookup tables of yesteryear.\r \r And, yeah, we found out that if we did a bunch of these combinations,\r \r our resources,\r \r this data frame holding all that would blow up, and it will slow our app down immensely.\r \r So we've we fixed that quite a bit in this, upcoming release of this reenvisioning\r \r of this app. But I got flashbacks to, like, if you don't have the right answer, sometimes you gotta brute force it somehow, and sure enough, this is another\r \r interesting use case of that. And, of course, the real geeky side of me thinks,\r \r what if you could do all this in DuckDV and have, like, a huge massive table out of all this that you could explore with, like, a shiny app. What am I thinking? I have no idea. Mike, you gotta watch me on this. I have no idea.\r \r\n\nThat'd be pretty cool, Eric. Sounds like a challenge. I may have just opted myself into by accident. Nonetheless,\r \r what's not an accident? The rest of this issue is no accident and how awesome it is. Right? This is all curated very handily and and very carefully\r \r by our curator every week. In this case, it is the aforementioned Tony Elhar Bar. And there's a lot more to this issue, but we're gonna take a couple of minutes for\r \r our additional finds that we talk that we, that caught our attention.\r \r And for me, it's,\r \r as I'm starting to learn more about leveraging\r \r AI modeling\r \r into my workflows, I'm still\r \r very much in my baby steps of this journey.\r \r\n\nOne thing I have been pretty, you know, passionate about\r \r is where we can leverage the open source model tooling and creative ways of utilizing that. So Stephen Turner's recent post on his blog we we featured Stephen in a few highlights ago.\r \r He has a great blog post about how you how he was able to create\r \r the route the newly released\r \r olama3.one.four\r \r zero five b, which basically is the way they denote\r \r how many parameters, in this case, 405,000,000\r \r parameters.\r \r And now he was able to set that up on a GitHub repository\r \r to incorporate into Hugging Face to expose as a custom\r \r model deployment.\r \r\n\nNot something I've ever tried before, and he does warn in the post that with this amount of parameters, the responsiveness\r \r is not always great\r \r and that there might be alternatives if you really need speed\r \r such as using the 70,000,000,000\r \r parameter model instead.\r \r But it's another kind of showcase to me,\r \r some of the flexibility that we get with these open source models,\r \r which in my industry is gonna be something we have to pay a lot of attention to. So I thought that was a pretty clever use of at least one existing platform, but opening the possibilities of what we can do,\r \r with these model choices.\r \r\n\n\n\n[00:36:07] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 7,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That's super interesting, Eric. It's something that we've been toying around with. So I'm gonna have to take a look at that that blog post as well. I found a great blog, from Shannon Pileggi on her blog called Piping Hot Data.\r \r Shout out Shannon. I had the opportunity to meet her in real life at PositeConference\r \r this year, which was pretty cool.\r \r And she has a very applicable blog post, something that we've wrestled with quite a bit, which is our end\r \r and, the sort of repository that you're going to use, CRAN versus POSIT package manager.\r \r And if you are not already,\r \r using\r \r POSIT package manager\r \r or, I guess some other\r \r service that, you know, maybe our universe that provides binaries,\r \r you definitely should with your r n projects. And a lot of times,\r \r by default,\r \r r n in the lock file,\r \r specified is crayon, which isn't always going to install,\r \r install binaries of the packages that you need when you run rnd\r \r restore.\r \r\n\nSo Shannon points out this handy file in the rnd this handy function in the rnd package called lock file modify,\r \r which allows you to, change your repository,\r \r for example, from CRAN to posit package manager.\r \r And then there is a second file a second function in r end called lock file write that would allow you to overwrite your lock file with that change, which is pretty cool.\r \r One of the questions that I have here, something that I'm gonna have to dive into myself,\r \r is\r \r to ensure that this would also update,\r \r the\r \r specified repository\r \r in your r n block file that is there for every package as well. So your first entry in your lock file is is typically the repository or repositories\r \r that you're going to use. And then and every individual package in your lock file as well also, you know, links to the particular repository,\r \r that was specified in that header that you want to use to install that particular package.\r \r\n\nAs a sort of a cheat, sometimes when we're switching from CRAN deposit package manager, I'll leave the the name or the label of the repository as CRAN, but we'll change the URL from from CRAN to, package manager.posit.co\r \r instead,\r \r so that we don't have to change all of the package entries. But if there is a\r \r much better way than control f and replace all to do that,\r \r which it seems like, you know, these functions that Shannon's pointed out for us might be able to accomplish,\r \r I am absolutely all ears. So really appreciate, this blog post because I think it's an applicable\r \r use case for all users of the r env package.\r \r\n\n\n\n[00:38:47] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I've I've done that exact same hack or trick that you caught literally this week as,\r \r those of you that well, nobody listened to the pre show of this when Mike and I were exchanging.\r \r But the war stories of this with me and my recent shiny test 2 go on headless browser adventures with Docker, that's been a nightmare to deal with. But there was one point where I had to replicate my dev environment\r \r to a Docker container.\r \r And in my work setup, we have an internal repository that's, like, cram but in our firewall.\r \r Of course, that's not gonna play nicely with Docker, especially on GitHub Action. So, yeah, I switched that to positive package manager, but I'm gonna have to take the advice that Shannon has here and see if this is a a more elegant way to dynamically do this instead of being like a, you know, a a silly person and manually do that every time I pivot to a different\r \r architecture. So I the the creative juices are going after reading this post for sure.\r \r\n\nBut, yeah, if you wanna get creative, we invite you to check out the rest of the issue of of our of our weekly. There's a whole bunch of additional content with new packages,\r \r new resources,\r \r and upcoming events. And in fact, you mentioned Shannon earlier, Mike.\r \r She and I will be part of a team that's gonna we don't have the full details ironed out just yet in terms of the timing of it. But later in October, as part of the r pharma conference, we're having a\r \r diversity workshop\r \r with respect to getting started with version control. So Shannon will be one of the the leads on that. I'll be teaming up with my, fellow RUKI member, Sam Palmer,\r \r on a project.\r \r\n\nGet those that are new to Git that want a gentle introduction to that up and running. It's gonna be a lot of fun. We're putting all the finishing touches on that, so we'll be able to talk more about that later on. But, yeah, that that's just one of the things that you might find in that upcoming events section along with many other great resources.\r \r So how's the best keep the project going? Well, we can do this about you, the community. So\r \r any great blog post, resource,\r \r tutorial,\r \r anything that you think is useful to the r community, whether it's by yourself or by members of the community.\r \r We're just a pull request away on our GitHub page, but you can find all that atarwika.org.\r \r\n\nA little link to the pull request is in the upper right little ribbon there. It'll take you to the template. Very easy to fill out, all marked down all the time. Very easy to parse that through. And then our curator for the week will be able to get that merged in and be on your way.\r \r And, also, we love hearing from you in the audience. We've got a contact page\r \r in your podcast,\r \r player show notes for this episode. Directly link there. You can also send us a fun little boost with one of those modern podcast apps like Fountain Podverse, Cast O Matic. Lots of great happenings, especially in the fountain ecosystem these days. I'm paying attention to lots of great choices on that. And, also, you can get in touch with us on these social medias. I am on mastodon\r \r at our podcast at podcast index dot social.\r \r\n\nAlso on LinkedIn, just search my name, and you'll find me there. And sporadically on the Weapon X thing, although really not so much anymore. But if you must, I am at the r cast on there. Mike, where can listeners find you? You can find me on mastodon@[email protected].\r \r\n\n[00:42:07] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 7,
        "trans_speaker": "Mike Thomas",
        "trans_text": "You can find me on LinkedIn if you search Ketchbrook Analytics,\r \r ketchb\r \r r o o k. You can see what I'm up to lately.\r \r\n\n[00:42:15] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "trans_timestamp": 15,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Very good. Always a fun time when you see you see your post on there. But it's always been fun recording with you as always, but we're gonna close-up the docket here before more things get mangled and I respect the setup. So with that, we're gonna say goodbye to this edition of ROK Highlights, and we hope to see you back for another edition of ROK Highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_39_highlights",
        "chap_timestamp": 37,
        "chap_text": "patchwork gets the tables!",
        "chap_href": "https://www.tidyverse.org/blog/2024/09/patchwork-1-3-0/"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "chap_timestamp": 25,
        "chap_text": "gguidance",
        "chap_href": "https://teunbrand.github.io/gguidance/articles/tour.html"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "chap_timestamp": 34,
        "chap_text": "Prime numbers and squares",
        "chap_href": "https://freerangestats.info/blog/2024/09/21/primes-squares"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "chap_timestamp": 47,
        "chap_text": "llama chat bot",
        "chap_href": "https://blog.stephenturner.us/p/create-a-free-llama-405b-llm-chatbot-github-repo-huggingface"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "chap_timestamp": 7,
        "chap_text": "renv & Posit Package Manager",
        "chap_href": "https://www.pipinghotdata.com/posts/2024-09-16-ease-renvrestore-by-updating-your-repositories-to-p3m"
      },
      {
        "ep_name": "issue_2024_w_39_highlights",
        "chap_timestamp": 45,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_38_highlights",
        "ep_date": "2024-09-18",
        "ep_duration": 28,
        "ep_description_short": "Hide a picture of Homer Simpson in a residual plot of all places? Oh it's real, you could say \"surreal!\" Plus a data-driven approach to investigate recent changes to the Australian census, and a cautionary reminder to check just where those numbers are coming from the next time you build a prediction model. Plus the quest to make R the official…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_38_highlights",
        "description_long": "\r \r Hide a picture of Homer Simpson in a residual plot of all places? Oh it's real, you could say \"surreal!\" Plus a data-driven approach to investigate recent changes to the Australian census, and a cautionary reminder to check just where those numbers are coming from the next time you build a prediction model.\n\nPlus the quest to make R the official language for the Coder Radio program reaps a new reward!\n\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara - @Rby[email protected] (Mastodon) & @RbyRyo) (X/Twitter)\n{surreal} 0.0.1: Create Datasets with Hidden Images in Residual Plots\nGender and sexuality in Australian surveys and census\nPlease Version Data\nEntire issue available at rweekly.org/2024-W38\nSupplement Resources\n\nSurfing the WSL Wave - Coder Radio episode 587 https://www.jupiterbroadcasting.com/show/coder-radio/587/\nBrian (bhh32) on Nostr\nsurreal https://r-pkg.thecoatlessprofessor.com/surreal/\nResidual Plots and Data Sets (archived version) https://web.archive.org/web/20210927100125/https://www4.stat.ncsu.edu/~stefanski/NSFSupported/HiddenImages/statresplots.html\nLabels for Technical Writing Projects https://ropensci.org/blog/2024/09/12/labels-writing-projects/\nExpress to Impress: Leveraging IBCS Standards for Powerful Data Presentations https://medium.com/number-around-us/express-to-impress-leveraging-ibcs-standards-for-powerful-data-presentations-3c3a269f0ec0\n\n\n\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nMoonlight Vibin' - Mega Man X5 - DCT - https://ocremix.org/remix/OCR02053\nYou Are Not Confined - Final Fantasy IX - Sonicade - https://ocremix.org/remix/OCR01064"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://mstdn.social/@R_by_Ryo"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://cran.r-project.org/package=surreal"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://freerangestats.info/blog/2024/09/08/sex-gender"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://win-vector.com/2024/09/09/please-version-data/"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://rweekly.org/2024-W38.html"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://www.jupiterbroadcasting.com/show/coder-radio/587/"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://primal.net/p/npub1gw972dngerjd338n8gydyvh7ev28pgpl5ru0w9ru5dr3gcyxs9mqcn58gl"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://r-pkg.thecoatlessprofessor.com/surreal/"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://web.archive.org/web/20210927100125/https://www4.stat.ncsu.edu/~stefanski/NSFSupported/HiddenImages/statresplots.html"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://ropensci.org/blog/2024/09/12/labels-writing-projects/"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://medium.com/number-around-us/express-to-impress-leveraging-ibcs-standards-for-powerful-data-presentations-3c3a269f0ec0"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://ocremix.org/remix/OCR02053"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "links": "https://ocremix.org/remix/OCR01064"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with us on a 179 of the R Weekly Holidays podcast. We're a day late because yours truly was, busy with other, production stuff with a virtual conference that just happened yesterday, which you might touch on a little bit later. But, nonetheless, we are excited to have you here for this weekly show where we talk about the latest\r \r highlights and other resources\r \r that are shared on this week's Our Weekly Issue. My name is Eric Nantz, and I'm delighted you join us from wherever you are around the world.\r \r And, you know, never a dull moment in your in his life, but my awesome co host, Mike Thomas, is here with me. Mike, how are you doing? I'm doing well, Eric. Busy busy busy as as usual.\r \r\n\n\n\n[00:00:41] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Mike Thomas",
        "trans_text": "In the process, I think I said this last week of of selling a house, so I'm currently in a room that doesn't have much furniture. It's quite echoey.\r \r So hopefully that doesn't come through too bad for the listeners this week.\r \r\n\n[00:00:52] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Eric Nantz",
        "trans_text": "We, completely understand, and, yeah. We we hope\r \r that that gets more stable for you soon enough, but luckily, we can give you at least a few minutes here to live vicariously through these great resources we have shared for you, this this episode. And before I go on further, I wanna\r \r share a little up follow-up to what I teased last week with some of these other\r \r podcasts I've listened to and our quest\r \r to get the r language to dominate all the things in software development. Well, I'm happy to share that,\r \r our quest to get r as the default\r \r language for Decoder Radio Show is working very well,\r \r so much so\r \r that we earned the perk\r \r of having a custom\r \r song\r \r generated for the r language on the Dakota radio program,\r \r which I am going to play for you\r \r right now.\r \r\n\n\n\n[00:01:47] \r Unknown"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Unknown",
        "trans_text": "Down by the meadow\r \r under the banyan tree where old folks\r \r gather\r \r jabber\r \r and take their\r \r tea. Talking about numbers,\r \r trends to foresee\r \r in the world\r \r of digits,\r \r none purer than thee.\r \r And visions\r \r divine.\r \r Your cold unwrapped\r \r stories\r \r line by line.\r \r Oh,\r \r Oh, sweetheart,\r \r silent\r \r has the dew in the world of 1s and zeros.\r \r You're a lighthouse\r \r true.\r \r When umbers\r \r sing\r \r and scatter plots bloom through dire slapper and few lead us past gloom.\r \r\n\n[00:03:00] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 0,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And a huge shout out to Brian who goes by b h h for creating that song.\r \r And I'll have a link to his profile on Nastur in the show notes as well as the Coda Radio episode, where this came from, if you wanna learn more.\r \r Us and the r, you know, community and data science,\r \r we tend to we tend to be pretty chill about a few things. There aren't a lot of things that rattle us, and I think I think that suits us quite well. So job well done when\r \r we couldn't thank the program enough. And and, yeah. So that was awesome. Nonetheless, we're gonna move on here with the rest of the show here, and our issue this week\r \r was curated by\r \r Nariel Nakagura,\r \r another one of our longtime\r \r curators on the ROV team. And as always, he had tremendous help from our ROV team members and contributors like all of you around the world with your poll request and other suggestions.\r \r\n\nSo we're gonna start off with a visualization\r \r a visit to our visualization corner, you might say, in ways that you definitely would not expect.\r \r So this harkens back to my days when I was a TA in graduate school where most of the time I was helping in our computation lab, doing some cool\r \r at that time, building some innovative r stuff with,\r \r I still remember these days using, like, the LAMP stack and doing custom databases\r \r and randomly generated exams and whatnot. But there was a semester I had to teach the intro stats course. And, of course,\r \r it can be difficult to get the students engaged, especially when you get to, you know, some of the more harder concepts like regression model fitting,\r \r trying to make sure you're instilling in in the students\r \r the fact that, well, you can come up with the terms in the model, but you do want to check how those models are performing\r \r with some various mix of\r \r normality assumption tests and also\r \r tests about the quality of the model.\r \r\n\nOftentimes, we would use a classic type of visualization,\r \r plotting the residuals\r \r of your model against the fitted values and looking for\r \r any distinct patterns. Or, hopefully, you don't see a pattern, which means that your assumptions are are working well.\r \r Well, what if to motivate students to do that kind of checking,\r \r you give them a little, hidden Easter egg, if you will, throughout that process? And that's exactly\r \r what this first highlight is doing in the form of, you guessed it, an R package that has a lot more behind the scenes here. So we are talking about the latest package called\r \r Surreal,\r \r awesome name, by the way, authored by James Balamuta,\r \r who goes by the cultless professor on social media and LinkedIn. Always enjoy his work. He's also been\r \r hugely instrumental in incorporating\r \r Quirter and WebAssembly and WebR alongside George Stagg. So I always follow what James does, but this came kind of out of left field on my media feeds and, hence, in our our weekly issue.\r \r\n\nBut this is a package that gives you data sets that,\r \r on the surface,\r \r may not seem like very much. It's data sets in x and y coordinates. But\r \r when you fit a visualization\r \r about those or fit a model around those and you look at the observed, you know, or let's just say the predicted and the residual plot,\r \r you can embed\r \r basically\r \r a hidden image\r \r or even text\r \r in that actual plot. This is this is mind blowing, but let's let's give some more context here.\r \r This stems from research from back in 2007,\r \r approximately around that time,\r \r by a professor\r \r Leonard Stefanski.\r \r\n\nHe was at NCSU\r \r or North Carolina State University\r \r back at that time,\r \r and he wanted a way to motivate his students to learn about these different model assessment techniques. And one of those, like I said, is that visualization of the residuals versus predictive values.\r \r And he came up with a clever algorithm\r \r that I'll try to describe, but in essence,\r \r you want you know what kind of image or text you want the student to see in this plot. So you start with that,\r \r and then you use a a mix of image processing\r \r and and some other extraction\r \r processing.\r \r\n\nSo you get, like, a black and white version of that image. You feed that into\r \r programs such as ImageMagick or whatever. So you can get on a two dimensional plane kind of like the x and y coordinates\r \r of what maybe the black dots are that comprise that image or text as compared to the white, like, the the background, if you will.\r \r So then if you also, depending\r \r on the image itself or the text,\r \r you are he's and his algorithm goes by assuming\r \r that the product of the residual\r \r vector,\r \r if you transpose that and multiply that with the fitted or predicted\r \r value,\r \r vector in matrix multiplication,\r \r that that product is 0,\r \r meaning that the residual and the predictive value\r \r vectors are orthogonal.\r \r\n\nThat's another assumption we see in things like principal component analysis\r \r and whatnot. But when you go by that, you can come up with an iteration algorithm\r \r to introduce new data\r \r that meets that requirement that may have 1, 2, 3, or more\r \r of these explanatory\r \r variables or predicted variables\r \r against an outcome variable.\r \r So if you do, like, a plot that looks at all these variables together and, like, those pairs plots that we like to do when we have multiple variables,\r \r you're not gonna really see much of a pattern to that new data. But then when you do that, that aforementioned\r \r visual look at the residuals and predictive value, you're gonna get that original image back. So\r \r this, package got a few datasets that correspond to some of these different images that you could that you could use. But I'm also gonna throw\r \r in the show notes well, actually, in the in the package site itself, he's got the r logo, the original r logo in this kind of black and white, you know, 2 d dimensional plane. But then when you look at after the transformation that I mentioned, it just looks like a scatterplot\r \r of 5 variables against the y,\r \r but looks like kind of random blobs really. Nothing nothing discernible here, but it's a hidden image of looking at the quality of the model where you start to see that actual, you know, Easter egg type image.\r \r\n\nSo there are other datasets here too. He even shows how to do a custom message\r \r saying r is awesome. We always agree with that. But then the one I'm gonna throw in the show notes is\r \r an archived version\r \r of Leonard's,\r \r I guess, original site that had more datasets\r \r that were fed into this, including some fun,\r \r Homer Simpson images\r \r and many others that you would not expect in a scatterplot that ends up being there. So if you want more background\r \r on just how this all came to be, check out that archive site. And I believe through that, you'll also be able to dig into finding the manuscript\r \r and a presentation that this professor did way back in the day.\r \r\n\nSo if you're looking for ways to engage your students on teaching regression principles,\r \r you wanna give them a little fun along the way, like, I wish I'd done back in\r \r 2,005 ish when I was doing a TA work on this. I would have loved to have had this to be a way to motivate the students, but real fun package. I can't wait to put some hidden things maybe to do, some pranks on my colleagues at work. I don't know. Could be fun nonetheless. But, Mike, you're gonna do some new residual plots out of this.\r \r\n\n[00:10:49] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Oh, for sure. We'll stick this in all of our model validation reports at the end. Just some nice Easter eggs for our clients. And just when I think just when I think the art community, you know, can't come up with anything more creative than the last thing that we came up with, a package like surreal\r \r drops. And the project I I had never heard about, you know, Stefanski's work back in 2007.\r \r And it sounds like there are some earlier art implementations as well, by a few folks, John Stoudenmeyer, Peter Wolf, and Yul Ricky Gromping,\r \r who maybe attempted to to try to do the same thing. And the fact that you can stick, you know, images or messages here in your residual plots is pretty cool. And I I agree, Eric. I think, you know, a a really fun\r \r utilization of this package\r \r and a real good application for it would be in the classroom for, you know, statistics professors trying to teach,\r \r how to analyze, you know, model fits and to look at residuals.\r \r\n\nI think that would be a pretty fun thing for your students to be able to to see. So this might be, you know, applicable for them and and interesting to them, and it's just, you know, another\r \r sort of\r \r example in the art ecosystem of all of the different crazy things that we can do with the art language.\r \r\n\n[00:12:04] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah.\r \r Like I said, this this came completely out out of the blue, but,\r \r oh, it's just amazing with a little math knowledge what you can accomplish in these in these, assessments. So I I got I told Mike in the pre show, I went down a little rabbit hole last night looking at all these different images that have been generated. There's some real comical ones there, even some nice messages\r \r about, you know, George, Box is famous, all models are wrong quote, and many other little things that, again, may get the students thinking not just about how did how is this actually accomplished, which, again, if you look at the manuscript in your spare time, you'll see there is a lot of clever\r \r matrix multiplication and iteration here. Like, the this this would have been a fun way in my linear algebra class to learn some of these concepts. But, again, I I I'm I'm in dinosaur age, so to speak. So this even predates that research when I was learning that stuff. But, yeah, this I think this could be great for\r \r especially in this day and age where I'm sure there's gonna be more\r \r models that are thrown to us may or may not even be generated by humans these days that\r \r looking at the integrity of these models, no matter machine learning or in the classical\r \r regression sense, is hugely important. So whatever we can do to to spark that light bulb in in students' minds and even those in in the field that are working daily, I'm all for it. So credit to James for putting this through. And, again, I'm I I can't wait to play this more. Yeah. This is like Anscombe's\r \r\n\n[00:13:31] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 31,
        "trans_speaker": "Mike Thomas",
        "trans_text": "quartet on steroids, sort of. And for the folks who are feeling festive or may celebrate Halloween,\r \r there is a function in the surreal package called jack o'-lantern surreal data. That's a built in dataset that you can use such that your residuals, when plotted,\r \r show a nice jack o'-lantern right in the middle of it.\r \r\n\n[00:13:50] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That is awesome. Yeah. I think\r \r that'll be a good thing for my kids to say, oh, hey. Guess what I can do with r? And they'll be like, no. We want the real pumpkin. But you know what? But\r \r\n\n[00:14:13] \r Unknown"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Unknown",
        "trans_text": "whatever.\r \r\n\n[00:14:15] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 15,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And, in this next highlight, there's definitely been a lot of news that's been happening across the the pond, as I say, with our, friends at Australia\r \r with a recent update to the census that our next highlight\r \r is looking at a data driven way to look at the impact of additions\r \r in questions, really get a feel for\r \r how you can segment populations\r \r and looking at different differences amongst them. But, again, taking a data driven approach that I think we all can learn from.\r \r And this next highlight comes from Peter Ellis, who is the director\r \r of the statistics\r \r for development division at the Pacific Community.\r \r\n\nSo he's also based in Australia, but he in his latest blog post is looking\r \r at a recent addition,\r \r pushback and then readdition\r \r to certain questions in the 2021\r \r ABS standard, which is, I believe, the Australian Bureau of Statistics\r \r and their recent update to the census and some of the\r \r discourse that follow through with that with respect to\r \r sex and gender variations and characteristics\r \r that they were trying to\r \r measure in an updated census. There was some pushback,\r \r and then apparently they've been reintroducing\r \r some of these questions\r \r dealing with, you know, what is a person's gender,\r \r how does that person describe their sexual orientation,\r \r and has that person been told that they were born with a variation of sex characteristics.\r \r\n\nSo certainly\r \r a a major topic around the world.\r \r But he wanted to not just, you know, react to the discourse that's online. He wanted to really dive deeper into\r \r with what we currently have, what is a way to convey\r \r the impact\r \r of trying to\r \r accurately distinguish some of these populations\r \r and seeing what that relates to other questions\r \r in the census itself.\r \r So,\r \r Peter does a great job in background, which, again, we'll invite you to check the preview or check the link yourself if you wanna read more background. We're gonna dive into more of the data\r \r analysis side of it where\r \r this is a very much a tidyverse inspired workflow\r \r with a real world use case of\r \r importing spreadsheet data from the from the ABS\r \r in a spreadsheet. So again, that's very common in the in this part of the world of of data analysis. So he's using the read excel package, one I've used great with great success\r \r in importing this type of data\r \r with a bit of,\r \r tidyverse cleaning up with a little bit of filtering for\r \r making sure they're getting non missing values and as well as different derivations of variables,\r \r a little bit of grouping. So again, pretty, pretty logical. We get to a dataset,\r \r eventually leads to a visualization\r \r that when you read the blog post, you're gonna have to zoom in on this a little bit. But\r \r Peter is trying to illustrate\r \r some of the key differences as measured by the data\r \r between the LGB plus and the heterosexual\r \r Australian\r \r responses\r \r on this survey from back in 2020\r \r and then seeing what\r \r what impact that would be in various questions. And you do expect\r \r there will be some differences not just in the in the age categories but also responses\r \r such as, like, family composition in their household,\r \r income questions, and the like. But he's using a pretty nice kind of, I think, pseudo lines, you know, dot chart but showing the the difference in in arrows\r \r pointing at the the shift from\r \r the heterosexual\r \r side to the LGB plus side of it. So you can kind of see where the wider\r \r differences are.\r \r\n\nBut he says he struggled with how to put this plot more accurately,\r \r and he went through quite a few iterations on that. So at the end of the post, he's got kind of what led to that final visualization,\r \r a set of faceted bar charts\r \r that are basically looking at each of those questions individually\r \r in different categories\r \r as well as the facets. So you can get a good read on that as well. But he was trying to distill some of the findings from this side by side bar chart\r \r analysis\r \r into this line plot as well. So as as I said, you can kind of see\r \r different types of domains are showing a wider differential\r \r in terms of percentages,\r \r which again may or may not be expected. But I'm always up for letting the data tell the story\r \r and and certainly, hopefully, that in the future,\r \r the the census from anywhere in the world is able to accurately portray these different populations\r \r that, again, deserve their voices to be heard. So\r \r really, really great summary here by Peter. Definitely a lot to digest if you're looking into the space of census analytics.\r \r\n\nI think a lot of good ideas to follow here. And again, great visualization,\r \r great reproducible code that you can run yourself if you want to import this data. And I'm sure similar techniques could apply to other,\r \r census data that's from available around the world. So great post by Peter, and I look forward to learning more about this space.\r \r\n\n[00:19:34] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. I thought it was an excellent post as well. Eric and I appreciated the the two different approaches,\r \r in terms of data visualization to to representing this data. In the past, you know, when we've worked with survey data, it's\r \r for whatever reason, seems to be a little bit more tricky to work with than some of your traditional\r \r datasets, you know, that are exported out of a, you know, a database system that is the result of users entering data into your application or something like that. Right? There's a lot of,\r \r pivoting, reshaping,\r \r you know, some some filling, NA values as well, you know, some work,\r \r deciding between whether you want to use a\r \r continuous or discrete scale when you have Likert scales and and things like that going on. So I I certainly appreciate, you know, the work that went into\r \r curating this data into the visualizations that it became. This is also another reminder for me that I need start leveraging, you know, whether you wanna call them lollipop charts or donut or or, barbell charts or things like that. But, it's this might be the first time that I've ever seen\r \r a chart like this, which I think you might call, like, a barbell chart that has two dots,\r \r for each\r \r line on the y axis\r \r representing,\r \r you know, the differences between 2 categories in the legend.\r \r\n\nAnd then there is actually an arrow,\r \r pointing the direction that it it, you know, increased or decreased.\r \r And, typically, I I I feel like in a lot of these charts, I've seen a line, just a straight line with no arrow on it, connecting\r \r those 2 each of those two dots. But the fact that,\r \r he was able to to employ an arrow here\r \r in this visualization was was really, really cool to me. You know, again, sort of demonstrated\r \r the the power of ggplot and the fact that that arrow is is colored the same as the the dot that it, you know, sort of is trying to\r \r represent the most, but there is also a little alpha component too that makes it a little more subtle than the dot itself. I think it's just a a really nice sorta chef's kiss, on top of that particular data visualization. And, you know, as always in a lot of these blog posts, the the ggplot code is all there. The dplyr data wrangling code is all there.\r \r\n\nSo it it's it's fantastic in the way that it it ends with this nice faceted bar chart as well. Man, I was working in Python,\r \r this week\r \r and was\r \r using the plot trying to use plot 9.\r \r Unfortunately, for a a donut chart, wasn't able to use plot 9 and had the to switch over to matplotlib\r \r instead. And I wanted to facet, you know, have these these faceted plots as well. And it's just not quite as easy as, you know, that that one beautiful\r \r facet wrap or facet grid, function that we have in ggplot. So it gave me that additional appreciation that, I I always have for for ggplot in the r language, particularly. But fantastic blog post talk top to bottom here, and and love the data visualization.\r \r\n\n[00:22:30] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. We've always been spoiled in this community with the the power of visualizations\r \r both on the static variety and the interactive variety. So there's, yeah, there's a there's a lot going on in in the code here, but, yeah, I definitely invite you all if you're interested in replicating this to take a look at Peter's code here and and give it a spin for for your next, opportunity for these cool little barbell\r \r plots. So, yep, really, really powerful visualization and looking forward to seeing more in this space.\r \r And our last highlight today is going to be a healthy mix of some of the additional questions or items that I mentioned in our first slide about modeling techniques. But\r \r being careful about the data you're using in your model is definitely a key motivating factor for this this last highlight we have today, which is coming to us from John Mount, who is one of the principal consultants\r \r at WindVector\r \r LLC,\r \r the consulting resource. And they've historically have had the WindVector blog, which,\r \r I've been reminiscing about this in previous episodes about what were some of my original resources\r \r learning are back in the early 2000\r \r mid 2000. But, John Mount's blog has been right up there as one of the resources I've had bookmarked for many, many years. So it's always great to see posts from him come to the highlights here. But he is motivating a situation that's been inspired by real projects\r \r where there can be a bit of a disconnect\r \r between\r \r the data scientists and analysts performing\r \r modeling for prediction\r \r and perhaps data engineers that are supplying this data that maybe aren't giving you the full information, so to speak. So\r \r in his example that's inspired by real things but kind of more fictitious is that you have,\r \r an issue where maybe you wanna run a prediction\r \r on forecast, I should say,\r \r attendance at a movie theater, and you wanna incorporate\r \r attendances from past, you know, events or past movies as part of that along with other factors that might drive that, you know, that influence in the prediction.\r \r\n\nSo you may be getting from a data engineer or data warehouse, whatever have you,\r \r some metrics for each of the dates\r \r and each of the movies that were showing in that date, the time of it, and the number of people that attended that. So he's got starting the post, a little example of reading a hypothetical CSV file where we've gotten the month in the month of August,\r \r you know, a few movies. I'm not sure these are real names but whatnot, but with the attendees. And you can see there is quite a bit of variation in some of these attendance metrics, which, of course, could be the quality of the movie, but could be other factors.\r \r But to motivate the goal of building a model that relates\r \r the attendance to one of the key you know, maybe one of the key perks in a movie theater these days or always has been is how much popcorn you sell and whatever snacks you sell. Maybe that is a driver that someone might wanna look at. There could be other factors too along with that.\r \r\n\nBut\r \r but one thing to note is that when the the engineers\r \r look at\r \r what's going to happen in the future,\r \r there could be a disconnect between the type of data.\r \r Historical data is looking at the actual numbers of attendees,\r \r but the stuff that's being estimated\r \r is, of course, not known yet. So continuing on with the example,\r \r imagine that they look at the different popcorn sales. They they merge that with the attendance dataset.\r \r You're doing what looks to be a pretty decent, you know, model fit with the data you have.\r \r But now when you start to do predictions,\r \r when you look at the month of September\r \r and knowing that the month of September is giving you slightly\r \r different types of values\r \r and you see that the estimates are in the line plot that he shows here\r \r really\r \r inflated, like massively inflated\r \r from what we see the model saying in the previous month of August. So\r \r and the takeaway is that the model\r \r is predicting\r \r or predicting popcorn sales\r \r in the future are going to be double\r \r what they see in the month of data that they use to train the data.\r \r\n\nThat doesn't\r \r quite check. So doing a little diagnosis,\r \r doing some nice little distribution plots,\r \r you see that the pattern\r \r of attendance\r \r doesn't look anything alike. They look heavily skewed in September\r \r compared to the more balanced month of August.\r \r And why is this?\r \r Well, the estimated attendance figures\r \r in September\r \r were based on the capacity\r \r of the movie theater, the number of seats inside,\r \r which is different, of course, than what the actual measures were\r \r back in the month of August where they used actually the number of people sitting in the theater at that time.\r \r So this is illustrating a case where maybe\r \r there's a bit of a disconnect\r \r in terms of the type of data that's going to go into your forecast versus the type of data you're using to train the data. So to motivate what John would do in this, you know, solving the issue,\r \r instead of using the actual number of movie attendees in August,\r \r he recommends moving\r \r using the capacity\r \r of the theater as additional\r \r or replacing the metrics with the capacity\r \r numbers instead. And when you do that, then you get data that looks more realistic in his opinion\r \r compared to what we saw before.\r \r\n\nSo my takeaway from this is\r \r being consistent with the type of measures you're incorporating in both your training\r \r and then eventually your your val your validation or your future prediction set\r \r as compared to mixing\r \r the different types up. Even though they are technically\r \r the same variable, they are in much different context.\r \r So this is something I haven't really encountered myself because I'm not as much into the forecasting realm of it, But I could definitely see how this might be a bit of a monkey wrench to a certain, you know, say, to scientists or statistician\r \r that see such wildly different metrics when they look at their predictions\r \r versus what they actually observe. So\r \r interesting thing. I'll probably have to do it on that a bit more, but it was an interesting illustration\r \r of what can be a disconnect\r \r but hopefully isn't when you have harmony between the engineering of data side of it\r \r and the actual data scientist or statistician\r \r side of it. So a little bit of food for thought for your prediction,\r \r\n\n[00:29:37] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 37,
        "trans_speaker": "Mike Thomas",
        "trans_text": "adventures in the future. Yeah. Eric, like you, we don't do a ton of forecasting\r \r as well, you know, or more along the lines of machine learning and and some Bayesian regression analysis and things like that. But I really appreciate\r \r sort of just\r \r the the ideology here that\r \r as data scientists, we need to do a great job of articulating\r \r the work that we're doing. And, you know, in the conclusion here,\r \r John\r \r has this this quote that really stuck with me, and it it says,\r \r you know, most date time questions, unfortunately, you know, can't be simplified down to, you know, what's the prediction for date x? You you really need to ask a question that's more like, you know, what's the best prediction for date x using a model that was trained up through what was known at at date y and taking inputs\r \r known up through date z.\r \r\n\nSo you have sort of these these three different moving time components here, and that's where it gets into the discussion about bitemporal\r \r databases that allow you to see what data look like at at different times.\r \r And,\r \r it resonates a lot with me. It makes me\r \r feel like, you know, this AI can't automate our jobs as data scientists because there's so much nuance and and so much that we have to caveat and make sure that we are,\r \r articulating\r \r correctly.\r \r You know, I I had a presentation on on AI recently, and,\r \r unfortunately, you know, as much as I like to not look at my notes when I'm giving presentations,\r \r the way that we communicate these things is really, really important, and the words that we choose is is extremely important. So I I find myself, you know,\r \r making sure that I am spending a lot of time curating my notes for presentations like that when I'm communicating concepts around, you know, machine learning or or AI or statistical modeling, whatever we're calling it these days.\r \r\n\nBut but, really, that attention to detail and making sure you are explaining things,\r \r concretely for for end users is is really, really important because there's a lot of nuance going on here. And I think that, you know, unfortunately,\r \r out there in the wild with,\r \r you know, a lot of the, maybe, automated machine learning, I saw,\r \r Shannon Maklis post something recently\r \r where I think that the latest version of some sort of GPT,\r \r allows you to just upload a data set, and it'll make predictions for you. I don't know if you saw that come across, Mastodon.\r \r Yeah.\r \r\n\nBut, you know, that made me sort of hang my hang my head in sadness.\r \r And I would imagine that if John had seen that post, he he might be doing the same thing\r \r as well. So, you know, I appreciate\r \r John taking the time to to level set us on the importance of how nuanced,\r \r predictive modeling can be.\r \r\n\n[00:32:19] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And a lot of times, you may not\r \r really see it again until you look behind the scenes, so to speak. You look at the quality of your model fit. It's not just that p value. You've got to look at what's really happening\r \r in the actual trend of your prediction versus observed\r \r and looking at that time course. Yeah. It it's very powerful\r \r to have that critical eye looking at this carefully.\r \r And, yeah, we we cannot expect realistically\r \r that we're gonna have AI be able to figure out all those nuances. Certainly,\r \r there's a lot of responsibility\r \r at play here. That was a a similar theme to what I heard at the recent, Gen AI and pharma conference I was helping out with yesterday when we were as I'm recording this,\r \r that nobody\r \r had the illusion in our our speakers about this taking away anybody's job. And in fact, we just it's evolving\r \r the types of skills that we're we're gonna need to navigate this, but to do it responsibly\r \r and making sure that we're looking at these with the right lens.\r \r\n\nAnd there is even some good talk about having the terminology be consistent\r \r or or adopting new terminology\r \r sometimes when you look at the evaluation\r \r of these models compared to when we look at in codevelopment\r \r or or maybe application development\r \r concepts of CICD. I'm looking at, you know, regression testing and things like that. There are starting to get equivalents of that on the model assessment side of it, but it's quite different in the AI space. So I'm even, as I speak,\r \r trying to learn the best way to translate some of the things I know from traditional\r \r statistic model building,\r \r traditional, you know, software development\r \r to this new age of augmenting with these AI tools. And even though this wasn't an AI post, you could definitely see something like this happen if you're gonna use some of these resources\r \r without a lot of care in front of it. So yeah. Great. Great. Again, thought provoking post that I can't wait to dive into more.\r \r\n\nAnd with that, there's a lot more to dive into in the rest of the r Wiki issues. So before we wrap up the show, we'll take a couple of minutes for our additional finds here.\r \r And for me, I don't know about you, Mike, but I I like to, keep my GitHub, you know, repos organized with,\r \r you know, very,\r \r clear\r \r issues\r \r and with that and project boards. But with that in GitHub, one of the features I use a lot is the concept of labeling.\r \r And I got a pretty good handle on how to do that for my actual development projects, but this this, additional\r \r fine I wanna call out here\r \r is coming from Greg Wilson\r \r from the rOpenSci blog about some of the types of labels he uses,\r \r not just codevelopment,\r \r but also\r \r actual manuscript\r \r and, you know, course development.\r \r\n\nSo he calls up labels for technical writing projects, and the post itself is a pretty easy read, only a few paragraphs.\r \r But you look at interesting\r \r labels such as, like, what's the difference between adding a new feature called add\r \r versus changing something? And there's a change label that things are already there but could be better.\r \r What is required from more of a governance standpoint of the project\r \r about kind of meta issues\r \r versus general discussion?\r \r Or what's more around the infrastructure side for tooling versus, like, what's a one off thing he calls tasks that you have to accomplish? And maybe once you get it knocked out, it's going to be done. But and then also what is actual written contact with prose\r \r versus, like, the actual code itself which is in software. So\r \r it definitely gave me got me thinking for my projects where I might have a Shiny app, but then within that app, I'll have documentation,\r \r maybe an accompanying package down site to help users learn the app. I can have labels that are more tailored to that side of development\r \r and not just the actual app development,\r \r so to speak. So interesting post, and I'm I'm I I got some interesting things to ponder when I put up my next project in GitHub and what labels I use there. So, Micah, what what did you find? No. It's a great find, Eric, and I'm always interested in in what Greg has to write. He was the instructor for my,\r \r\n\n[00:36:34] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Mike Thomas",
        "trans_text": "tidyverse\r \r certified\r \r trainer course a whole long time ago.\r \r So that was that was pretty pretty cool opportunity to be able to to meet him,\r \r there. I found a blog post on Medium,\r \r published by\r \r Numbers Around Us,\r \r is the the name of the blog post. I'm I'm not sure exactly\r \r the name of the author. Maybe we can stick it in the show notes if I'm able to to pull it out here at some point. But it's it's called Express to Impress, Leveraging IBCS Standards for Powerful Data Presentations.\r \r And if you're not familiar with the IBCS\r \r standard, it is,\r \r the IBCS\r \r stands for the International Business Communication\r \r Standards Framework.\r \r\n\nAnd its intent is, I guess, sort of like, you know, our our grammar of graphics, which it it sort of aligns pretty well with, is to accomplish, I think, really, these these three different goals for any data reporting work and data visualization work that you do to ensure,\r \r that your visualizations are clear and focused,\r \r that they're consistent and standardized,\r \r which I think, especially, you know, in an organizational context,\r \r at your company, you're probably going to want to be providing, you know, consistent types of consistent looking reports, consistent visuals over time, that your users can become familiar with. And then the last one is is one that really sticks with me. It's it's actionable,\r \r and ensuring that the visualizations that you're providing are somewhat of a call to action and a very clear call to action in terms of, you know, what you expect\r \r the audience to be able to to take away from that visual and, you know, what you expect them to to actually do because of it. So there's some some great examples of, you know, migrating from pie charts to to bar charts\r \r instead, and a whole lot of great ggplot calls in here, but an awesome other database post for this week.\r \r\n\n\n\n[00:38:30] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Really. Well, I'm looking through it now. There's a lot to a lot to digest here, but all really great concepts here that I'll definitely take with me as I keep building more visualizations\r \r in my packages and apps. So great great find there. And there's a lot more to this issue. We always can't talk about all of it, and we don't have enough time, but you're invited to check out the issue itself, which is linked in the show notes at rho.org\r \r as well. And, also, this project is a community effort, so we invite your poll requests\r \r for new resources,\r \r new, blog posts, new packages.\r \r\n\nIt's all right there, all in markdown. So head to rho.org\r \r for all the details\r \r now to contribute there. We also like hearing from you in the audience. We have a contact page linked in the show notes that you can find in your podcast,\r \r player\r \r as well as a way for you to boost the show if you'd like to hear from us and get in touch with us directly.\r \r If you get value of this, then we appreciate value back, so to speak, the value for value mindset.\r \r Details are in the show notes as well, and we are on social medias. If you wanna get in touch with us personally,\r \r I am mostly on Mastodon these days with at our podcast at podcast\r \r index.social.\r \r\n\nI'm also on LinkedIn. Just search my name and you'll find me there and occasionally on the weapon x thing with that the r cast. Mike, where can the listeners get a hold of you? You can find me on mastodon@[email protected].\r \r\n\n[00:39:54] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 54,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Or you can find me on LinkedIn if you search Ketchbrook Analytics,\r \r k e t c h b r o o k. Now you can see what I'm up to lately. Very good. Very good. And, again, special shout out to our friends at Jupiter Broadcasting and Encoder Radio,\r \r\n\n[00:40:08] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "trans_timestamp": 8,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Mike and Chris for keeping the our language, train going for the official language. I'm not sure how long it'll last because those, Go and and, other folks are are nipping at the bud here, but we'll see how far it takes us. Nonetheless, we hope you enjoyed this week's episode of R weekly highlights, and we'll be back with another episode of R weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_38_highlights",
        "chap_timestamp": 46,
        "chap_text": "The R Song on Coder Radio!",
        "chap_href": "https://www.jupiterbroadcasting.com/show/coder-radio/587/"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "chap_timestamp": 52,
        "chap_text": "Surreal Visuals",
        "chap_href": "https://r-pkg.thecoatlessprofessor.com/surreal/"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "chap_timestamp": 14,
        "chap_text": "Australian Census Analysis",
        "chap_href": "https://freerangestats.info/blog/2024/09/08/sex-gender"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "chap_timestamp": 14,
        "chap_text": "Please Version Data",
        "chap_href": "https://win-vector.com/2024/09/09/please-version-data/"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "chap_timestamp": 28,
        "chap_text": "Labels for Technical Writing",
        "chap_href": "https://ropensci.org/blog/2024/09/12/labels-writing-projects/"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "chap_timestamp": 45,
        "chap_text": "IBCS Standards for Data Presentations",
        "chap_href": "https://medium.com/number-around-us/express-to-impress-leveraging-ibcs-standards-for-powerful-data-presentations-3c3a269f0ec0"
      },
      {
        "ep_name": "issue_2024_w_38_highlights",
        "chap_timestamp": 45,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_37_highlights",
        "ep_date": "2024-09-11",
        "ep_duration": 7,
        "ep_description_short": "How being fair to your research has a new and important meaning than what you may expect, the power you can unlock with custom roxygen tags, and a collection of tips you can apply today for your next visualization. Episode Links This week's curator: Batool Almarzouq - @batool664 (X/Twitter) Making your blog FAIR Create and use a custom roxygen2…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_37_highlights",
        "description_long": "\r \r How being fair to your research has a new and important meaning than what you may expect, the power you can unlock with custom roxygen tags, and a collection of tips you can apply today for your next visualization.\n\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq - @batool664 (X/Twitter)\nMaking your blog FAIR\nCreate and use a custom roxygen2 tag\nFive ways to improve your chart axes\nEntire issue available at rweekly.org/2024-W37\nSupplement Resources\n\nhttr2: Perform HTTP requests and process the response https://httr2.r-lib.org/\nAthanasia's GitHub Actions workflow files https://github.com/drmowinckels/drmowinckels.github.io/tree/main/.github/workflows\nmaestro: Orchestration of data pipelines https://whipson.github.io/maestro/\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nCrysis Crystal - Mega Man 9: Black in Blue - k-wix - https://backinblue.ocremix.org/index.php\nOf Whips and Strings - Vampire Variations: A Musical Tribute to Castlevania - Super Guitar Bros. - https://ocremix.org/remix/OCR02480 "
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://drmowinckels.io/blog/2024/fair-blog/"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://masalmon.eu/2024/09/03/roxygen2-custom-tag/"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://nrennie.rbind.io/blog/five-ways-improve-chart-axes/"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://rweekly.org/2024-W37.html"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://httr2.r-lib.org/"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://github.com/drmowinckels/drmowinckels.github.io/tree/main/.github/workflows"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://whipson.github.io/maestro/"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://backinblue.ocremix.org/index.php"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "links": "https://ocremix.org/remix/OCR02480"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back. That was a 178\r \r of the R Weekly highlights podcast.\r \r Almost midway through September already. Time is flying by, but what never slows down is also the fast pace of the r community,\r \r where in this podcast we cover the awesome highlights and other resources that are shared every single week at rweekly.org.\r \r My name is Eric Nantz, and I'm delighted you join us today from wherever you are around the world.\r \r And joining me at the hip with never a dull moment in his life going on right now is my co host, Mike Thomas. Mike, how are you doing today? Doing well, Eric. Hanging in there. I am potentially in the process of of moving, which is both\r \r\n\n[00:00:41] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Mike Thomas",
        "trans_text": "exciting and and crazy and stressful all at the same time. So all the emotions.\r \r\n\n[00:00:48] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. It's it's hard to grasp just one at a time. It all just happens at once. So our our,\r \r best of luck to you, and hopefully, you don't lose anything valuable on the move\r \r\n\n[00:00:59] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Mike Thomas",
        "trans_text": "over. I'll make sure that the microphone stays intact, and we'll be sure to to make sure that the new podcast\r \r space is is set up ready to go.\r \r\n\n[00:01:08] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 8,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Well, you know, that that's that's the real important stuff. You know, those those pets or whatever. Ah, no. You need the mic. No. I'm I'm I'm I'm good. I we know where your priorities are. We we we we get it. We get it. That's right.\r \r Yeah. I'm, not moving anytime soon because that would be a herculean effort in this, house here to try and pick up everything there. But luckily, I don't have to think about that. I get to think about the great art content we get to talk about today.\r \r And in this week's issue has been curated by Batool Almarsak. And as always, she had tremendous help from our fellow Arruki team members and contributors like all of you around the world with your poll requests and other suggestions.\r \r And so one of the biggest reasons we do our weekly is the great content that all of you out there, whether you're in the data science world or other parts of industry,\r \r have been showcasing your learnings\r \r perhaps through either personal websites, personal blogs,\r \r and whatnot.\r \r\n\nAnd, you know, it does beg the question sometimes when we put these resources online,\r \r how do we kinda guarantee\r \r really tight linkages\r \r or ways to get to that content even as the landscape of, like, web hosting providers\r \r or other ways that we're deploying these sites change over time?\r \r Well, in our first high, we're gonna look at a pretty innovative way to kind of future proof potentially ways to\r \r make your your insights on, say, a blog\r \r more easily shareable that could be durable for the test of however\r \r evolving the tech landscape is. And in particular, this first highlight is coming to us from Athanasia\r \r Mowinkle, who is a neuroscientist\r \r over in Europe where she talks about making her blog\r \r fair.\r \r\n\nNow I'm not talking about the fair that I often hear from my kids gripe to me when they say, it's not fair. I don't get to do this and that. No. I'm not talking about that kind of fair. The fair we're talking about here is an acronym for findable,\r \r accessible,\r \r interoperable,\r \r and reusable.\r \r Boy, that sort of speaks to me with a lot of the reproducibility\r \r aspects we talk about all the time with framers, like r markdown and quartile and whatnot. But, of course, this applies to any insights we author or generate.\r \r Ethe Nagia has,\r \r has worked on her blog for quite some time, and she was inspired actually about a newsletter\r \r that she subscribes to from Heidi Seibold\r \r about her approach to making her blog\r \r this FAIR compliant, if you will.\r \r\n\nAnd in Heidi's approach,\r \r we get an outline that it's basically,\r \r hosted as a Jekyll website, which for those aren't familiar, Jekyll was a framework\r \r and I believe based in Ruby to do, like, a static site kind of generation,\r \r was used very many years in the GitHub world.\r \r But Heidi also has,\r \r you know, a newsletter that she turns into\r \r RSS or Adam feed, and then that will post automatically based on the content in her site.\r \r And then she also adds her blog to a service called Rogue Scholar, which I believe is an archive\r \r for more of the academic or research type blogs.\r \r\n\nBut what comes with that\r \r is robust DOIs or these kind of unique document identifiers\r \r and additional metadata that could then be searchable\r \r and easily accessible.\r \r Athanasia's\r \r workflow is pretty similar.\r \r It's a Hugo site. Now, again, Hugo, I've been a big fan of for many years. That's what powers the blog down package that EYC has created\r \r with, his work at Posit earlier\r \r and that. And then she also hosted on GitHub Pages. Again, a framework I like to use quite a bit for hosting.\r \r Again, all marked down all the time. And with Hugo, you get an automatic RSS feed.\r \r And then she has\r \r an idea for a GitHub action\r \r that will register each new post to a service called Zenodo,\r \r another one of these research type archival services.\r \r\n\nAnd then via their API,\r \r she's going to be able to get these robust document identifiers\r \r as well as adding additional metadata\r \r so that that can be searchable as well. There are a little nuance differences from what Heidi approached, but we're going to walk through just how\r \r Athanasia\r \r has accomplished this in her workflow here.\r \r So with that, we're going to need some packages, right, because she wants to do this all in R because we want to do R all the things here. So\r \r we need to communicate with a web service, the Zenodo API. So with that,\r \r the h t t r two package authored by Hadley Wickham is a great candidate to interface with those connections.\r \r\n\nAnd then\r \r with Hugo and as well as Portal itself, another of these static site generators,\r \r many times your content will have a YAML front matter at the top that denotes certain metadata,\r \r certain options, or whatnot.\r \r So how do you interpret that? Well, appropriately enough, there is an R package called YAML, y a m l, to let you interrogate both from a consuming perspective\r \r and actually writing YAML if you need to to documents or whatnot.\r \r And then the last step is she's going to take a bit of a detour after what Heidi did.\r \r She wants to make sure her blog posts, which often have a great mix of visual content as well as tabular summaries and other narrative\r \r to be easily\r \r self contained in one artifact.\r \r\n\nSo she wants to convert these posts to PDF,\r \r and for this she is going to turn to quarto for this part of the workflow.\r \r So we're going to walk through this step by step, but the first step of this\r \r is actually\r \r trying to prepare the data of these posts so that it can be archived.\r \r And she's got some some example code here. The first grab\r \r all these markdown files that make up the source of the posts themselves,\r \r And in Hugo, you can do what are called page bundles, which basically means\r \r every new page that you make in your site is its own folder\r \r with within it an index dot MD file and many other supporting files such as images or whatnot.\r \r\n\nSo she wanted an easy way to grab the source of all those index dot MDs.\r \r So she's got a little, regex action going here and list that files.\r \r Not too difficult. She knows the file name, so it's literally index\r \r //md\r \r is like\r \r the regex on that front.\r \r Once she got that, now she's got this this vector of files\r \r on her file system to have\r \r all of the blog content.\r \r Okay. Now, examining, we walked through one of these posts that she has, in this case, about random effects.\r \r She then reads the contents of that file with the relines function,\r \r and you see if you print that out like in the example here, you've get\r \r each line or each element is a line from the file. So you got the YAML at the top and then a few blanks and then you've got the actual content itself.\r \r\n\nSo we've got the content\r \r read read in r now.\r \r Now how do we extract\r \r that metadata first? Like, let's parse the YAML first, and then we'll deal with the content afterwards.\r \r There is a handy function\r \r within rmarkdown itself that she was able to get some recommendations,\r \r from\r \r a good friend of hers that we'll hear about later in the highlights\r \r of a function called YAML front matter\r \r exposed by R Markdown itself, where you feed in the contents of that post with both the YAML and whatever\r \r the narrative you have. And it is intelligent enough to scrape that YAML section\r \r and then make variables for each field with its actual values. So you see\r \r it's got, like, the title, author,\r \r you know, date, and even the nested elements are like nested list elements. It's very handy, very,\r \r very straightforward.\r \r\n\nAnd so she's able to get that YAML metadata,\r \r but she wants to add more to it than just what's in the YAML. She wants a high level description\r \r of the post,\r \r which in the Hugo world doesn't quite come automatically.\r \r You have to kind of inspect the rest of the post to kind of maybe take a portion of it.\r \r So she wants to make some code that will do this. So she wrote a custom function\r \r that's doing a bit of a grip of, like, all that content that's after the YAML delimiters\r \r and then be able to grab that\r \r and then see what are the positions\r \r where that content actually starts.\r \r\n\nAnd then from there, she's able to then look for what's like the first paragraph of that post or maybe the first few sentences.\r \r She's able to grab that with more custom functions\r \r of a summary of it\r \r and then\r \r inject that into the existing metadata variable. So now she's got a simple 2, 3 sentence description vector\r \r for that metadata summary. So with that,\r \r she's got the metadata ready to go.\r \r Now here comes the fun part.\r \r As I mentioned, she wants to use the Zenodo service to start archiving the content\r \r and have it searchable,\r \r but\r \r just like anything, an API has got its own set of documentation, what it expects to have.\r \r\n\nAnd, apparently, she's had to do a bit of trial and error, which I can certainly relate to because sometimes I get the requests\r \r horribly wrong, and\r \r sometimes you get those cryptic errors back of, like, what happened and what didn't happen.\r \r So through this, exploration, she was able to compose\r \r kind of another list structure of those metadata fields, but in the way that the Zenodo API expects. So it looks like kind of a nested list of elements, which isn't too bad,\r \r but it's a lot of just brute force trial and error to get to that point.\r \r So then\r \r that's not all. As I mentioned, she wants a static archive of the content itself, not just from the metadata,\r \r but of the entire post.\r \r\n\nThat's where our good friend Quartal comes in where once again\r \r she's able to leverage\r \r a function from Quartal, in this case Quartal render,\r \r to compile\r \r the web based version or the markdown version\r \r into a PDF.\r \r But she had a little rabbit hole to navigate here. You know what she tried to do, Mike? She tried that types method, and that didn't quite work.\r \r But there's always a plan b. Right? And plan b is good old LaTeX.\r \r As much as I rag on it sometimes sometimes it's still the best tool to get the job done.\r \r\n\n[00:11:59] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Unfortunately,\r \r Athanasia\r \r tried types first\r \r and\r \r some of the images were not being resized correctly is what she said so that's why she had to switch back to Latex. And, you know, that's\r \r a little disheartening\r \r for me to hear. I think it's, you know, they're still working on ironing out some of the kinks of of types and how it interacts\r \r with quarto. I I do still believe it's the future, but, if you are trying to do, you know, very specific things and, you know, size images a very particular way on the page, you might have a little bit more customizability\r \r and full control\r \r when you're leveraging LaTeX,\r \r as compared to to types,\r \r especially if you you actually know how to write a little bit of LaTeX\r \r as well.\r \r\n\nWe are are in the process at Catchbook. I was hoping for our next big model validation project, which are these PDF deliverables,\r \r that we could switch over to,\r \r types\r \r instead of our our current sort of LaTex,\r \r framework. But we do need a lot of that customizability\r \r to make things sort of look perfect on the page for our clients. So,\r \r I'm I'm hesitant to make that switch yet, especially after reading this this blog post. But one of the nice things is you can try the 2 and the the quarto code is still the same. Right? You're still using quarto render with your output format PDF,\r \r for the most part.\r \r\n\nSo it really cool that she was able to do that. I guess it's sort of unfortunate that you have to to render to PDF for the Zenodo\r \r service.\r \r\n\n[00:13:32] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 32,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Right? Yeah. Yeah. My hope is that it would have some kind of dynamic view of that content, but it is what it is, I guess. Exactly.\r \r\n\n[00:13:41] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Mike Thomas",
        "trans_text": "So,\r \r as you said, sort of the the 3 packages that come together here are h t t r 2,\r \r YAML, and then what's the last one that I can't have? Quarto itself. And then Quarto itself. Right? So, the sort of the way that she's able to actually send this final request,\r \r to the HTTP\r \r RT or or to the Zenodo API via HTTR 2 is, obviously, whenever you're dealing with one of these APIs, you're gonna need an API key token. So she stores that as an environment variable called Zenodo API token, and then she has just\r \r a variable an object called Zenodo API endpoint,\r \r where she specifies the, you know, the URL endpoint of, this Zenodo API where she's going to be sending this request. And you gotta love h t t r two it just makes everything look so absolutely clean.\r \r\n\nThe the pipe syntax that we're using here in h t t r two starts with a request,\r \r then a a bearer token, essentially, where she passes that API token,\r \r and then your JSON body\r \r as well. And don't forget to use that auto on box equals true if you're switching back and forth between our lists and, JSON\r \r data that you are sending up to the API.\r \r The nice thing about HDR 2 as well that Athanasio demonstrates here is you can use the request dry run\r \r function to be able to see the query that's going out before you actually send it to the API. Take a look at that request and everything\r \r Once everything looks good, you can use, request perform to actually\r \r send your API request\r \r to Zenodo, get the status that comes back.\r \r\n\nIn in this case, it was a a 201 created,\r \r which, is is not the response that she got for many attempts as you said,\r \r while trying to figure out the all of the different metadata components for this API. And if you take a look at the blog post,\r \r there are a lot of pieces to this list,\r \r this metadata list\r \r that she puts together that need to be sent to this API, you know, essentially, different parameters that the API\r \r expects,\r \r you know, within the metadata. It's not just a title description, you know, the creators,\r \r her name,\r \r her or orchid,\r \r you have upload type, publication type, publication date, and about 5 other different parameters that have to be nested\r \r correctly in your r list in order for them to be passed correctly via JSON\r \r to the, to the,\r \r API\r \r service. It's you're able to take a look at what came back,\r \r from that JSON response and everything looks looks really, really good,\r \r and at that point in time, I think she has everything that she needs for the DOI that's actually going to be,\r \r get sent, via the GitHub action. It's gonna get published alongside\r \r the GitHub action for the most part.\r \r\n\nSo sort of the last section of of this blog post is actually adding that DOI\r \r to the YAML header or front matter, if you will,\r \r for the post, that is going to to end up being posted and published.\r \r So Afnazia is actually able to put together a single script. It looks like it's about maybe 200 lines here, that sort of put everything together,\r \r in one script and mostly it's it's functions here, which is really nice functional programming,\r \r that she's put together that walk through all of the different steps that we talked about in this blog post, in terms of, you know, sort of finding the the end of the section,\r \r you know, taking a look at whether or not a DOI\r \r is needed, you know, actually publishing to Zenodo, which is probably the biggest function,\r \r the biggest custom function that she's written and that's going to return, I believe, the path to the PDF file that has been generated by quarto.\r \r\n\nAnd then once you actually have that PDF file and,\r \r you're ready to go here it's it's just a few lines of code that she has here, with a nice little s apply\r \r to to process files that that do not have a DOI,\r \r but are published\r \r and supply,\r \r those posts essentially\r \r and and run all those posts, that need a DOI\r \r to her service. And\r \r it's it's pretty incredible.\r \r Her next step is to to work on the GitHub actions component,\r \r which I I think should be fairly straightforward\r \r given that she's put, you know, all of the r code here together as best as possible. Obviously, when you're dealing with GitHub actions that's gonna be running on a machine that's not yours.\r \r So she will have to ensure that, you know, all of the dependencies\r \r including latex, which is probably not fun,\r \r when you're doing that in GitHub actions\r \r is are installed correctly,\r \r and execute correctly on that that GitHub actions runner. But I'm very excited to hopefully sort of see a follow-up here for the next step in this process, which is the GitHub action that's gonna do this all programmatically. So every time that\r \r she authors a new post\r \r on her website,\r \r it will automatically reach out to Zenodo, get that DOI, and publish things, the way that they should be.\r \r\n\n\n\n[00:18:47] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. As you were talking, I went to that, GitHub repo, and sure enough, there are\r \r a few actions here. And I believe she's do indeed has that script that you just outlined\r \r in the GitHub, you know, workflows area itself.\r \r So I think she's got it.\r \r Credit to her. She's actually got 4 actions on there. My goodness. She's a GitHub action\r \r ninja, looks like. So I'm gonna have to take some learnings from this. But my goodness. What a what a great, you know,\r \r showcase of automation,\r \r but also just what you can do when you stitch these services and\r \r and workflows together. So I I think this shows a lot of inspiration as we're thinking about,\r \r hey, anybody\r \r generating or authoring their content,\r \r trying to future proof this to some extent? And, you know, we can't predict everything in the future. But, yeah, I'm intrigued by what this Sonoto service is offering her, but I may look at other ways too of making sure that\r \r what I produce, maybe it's, you know, the stuff I used to do with the shiny dev series or ever or this very podcast. Right? I wanna make sure this stands the test of time that no matter which fancy technologies out there, we can find a way to search it and be able to to grab it back. So, yeah, lots of lots of interesting nuggets here. And then I really appreciate\r \r towards the end of that of that script that she was outlining,\r \r she's got a check to make sure that she doesn't do this DOI\r \r process for posts that already have it, which is great to minimize,\r \r again, calls to an external service because the last thing you wanna do is accidentally DDoS something or worse yet lose your access to that API venture. So being\r \r intelligent enough to only run what you need, that's a that's a lifesaver when you do have APIs or even HPC computing. So lots of nuggets in that script that I think are quite inspirational here.\r \r\n\n\n\n[00:20:41] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Absolutely. And, Eric, you and I, you know, don't do a lot of, I guess, academic publishing, but there is a gigantic community\r \r of people out there who do that, and I think that this blog post is going to be incredibly\r \r powerful and helpful for them.\r \r\n\n[00:20:55] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 55,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. So definitely check out her, catalog on the re of the previous blog post. So there's a little bit of something for everybody\r \r in that world. Really, really good stuff.\r \r And one of the nice things about Athanasios'\r \r post is that she mentioned that she reached out to a couple of her trusted friends\r \r to give some recommendations on how to proceed. And one of those friends just happens to be the author of our next highlight here because Ma'al Salman returns to the highlights once again\r \r to talk about her recent discovery about creating\r \r and leveraging\r \r not just r oxygen 2\r \r but custom\r \r r oxygen 2 tags.\r \r\n\nNow this\r \r has been something I've never dived into myself, but I'm starting to see other packages in the our ecosystem\r \r try to do things like this where they'll have a custom tag.\r \r And based on that, their package will do additional processing or additional things on the side with it. So she, you know,\r \r introduction\r \r here,\r \r such as making sure that there are internal functions that are documented maybe for only developers and not for like the end user\r \r of a package.\r \r Also,\r \r being able to leverage or record\r \r certain standards that are expected for statistical\r \r functions.\r \r\n\nAnd lastly,\r \r having\r \r tests from within our scripts themselves,\r \r and that in particular has been contributed by a package called\r \r roxy test as well. So I've seen these come through, but I never really knew what was the nuts and bolts on it. So I was supposed to gonna walk us through her journey on this and that\r \r she was looking for a way\r \r to help with the iGraph package.\r \r And for those that aren't aware, iGraph is one of the, you know, more standard\r \r and frankly,\r \r quite powerful\r \r packages\r \r that deals with network,\r \r network generation, network analysis\r \r for simple or complex networks.\r \r\n\nNow are the r packages are binding to the c library of the same name, iGraph. And I I remember compiling this back in the day when I was getting into network analysis for the first time. And, admittedly, iGraph is,\r \r a bit of a bit of an ordeal to get into, but it's not insurmountable.\r \r But what she's learned as she's been working with iGraph is that\r \r there may be places where the r function definitely has documentation as it would have any r package,\r \r but it's depending on some source in the c library to make all that happen.\r \r And she wanted a way to link\r \r for a particular r function\r \r to the relevant\r \r c code binding\r \r and whatever it needs in terms of additional considerations\r \r within each of the functions manual pages.\r \r\n\nSo that\r \r looks like something that I wouldn't even know heads or tails of how to accomplish it, but we're gonna walk through how she,\r \r did this herself. So she starts with,\r \r outlining the workflow that ends up doing this. 1st,\r \r having,\r \r some kind of mapping of the existing\r \r documentation\r \r for the c library.\r \r Maybe you have to hand generate that yourself or hopefully you can scrape that\r \r somehow. And then in the rOxygen\r \r documentation\r \r header\r \r for a given function,\r \r add a new tag called\r \r atcdocs\r \r that's going to point\r \r to the source c function\r \r that that particular r function is using.\r \r\n\nAnd then she says that's going to be kind of manual for now, but there may be ways to do that automatically later.\r \r And then\r \r building upon the tooling that our oxygen 2 gives you, giving you a way\r \r to parse that custom tag\r \r and do the necessary bits to write the manual page to link to it.\r \r So thankfully,\r \r not just showing telling us the workflow, she's going to walk through it for a hypothetical example here\r \r where she's got a minimal R package called HGB,\r \r where it's got a simple hello world type function.\r \r But she's going to put in a custom tag with the custom, literally custom tag, in the rOxygen header. And, of course, it by itself, it looks fine. Nothing's bad is going to happen, but rOxygen by default is not going to know what to do with that yet.\r \r So\r \r now she's leveraging what's documented in the rxn2vignette\r \r to say, okay,\r \r there is a method\r \r called Roxy\r \r tag\r \r parse Roxy tag custom. Yes. That is all one function\r \r call separated by underscores there, which is telling\r \r our oxygen 2\r \r what to do when it sees a set a tag of a certain type.\r \r\n\nSo she's got some example snippets here\r \r where you can see straight from the vignette,\r \r you can write these custom functions that are going to either\r \r look at the tag\r \r and then also\r \r x and then be able to write it out as a new section in the docs based on seeing that tag named custom,\r \r taking in what was the material from it, and then putting it into this new section.\r \r And then\r \r well, we were just talking about LaTex earlier, Mike, when you look at an r\r \r help file,\r \r you see, like, a web view of it. But behind the scenes, that is LaTex style code when these are compiled.\r \r And so she has a last section a last function\r \r to format that custom rd\r \r section that she's making\r \r and puts in literally the the latex style code for the section and then an itemized list of the value of, I believe, that source file.\r \r\n\nAnd then she's got the building blocks here.\r \r Now it's not quite done yet because then she's got to create what's called a rocklet\r \r that's going to help for this custom tag\r \r to be shared potentially with other packages that wanna leverage this. So this is an optional step.\r \r But if you think you've got a workflow that could benefit the community\r \r in your particular package,\r \r this is a great way to share that\r \r via what she's done here. She's running a custom Rocklet function\r \r that's going to declare this Rocklet.\r \r It's a fun name to say out loud. Hopefully, I'm saying it right. But then be able to process that and then to be able to export that out\r \r as a way for other users\r \r to to leverage that. So again, that might not always be the case,\r \r but that is one way they set the building block of actually sharing it.\r \r\n\nAnd then there comes the question of,\r \r well,\r \r do we actually need a separate package\r \r to hold this new custom tag processing?\r \r And you may or may not need that all the time. There are cases where maybe it's so specialized it would be only your particular package is going to use this custom tag. It may not need to go to that external that extra effort of making an extra package out of it, but\r \r others\r \r might say, you know what? This is good enough or this is good for the community. Maybe we do want to share it. So there are ways that you could do that because you've got some narrative about where it might be helpful\r \r and where it might not. So in the case of the eye graph here, this was a custom tag that was already meant for eye graph itself. So she thinks that could live\r \r in the package itself. But again, there could be cases where you want to share that with a community.\r \r\n\nSo I've been fascinated by this because, again, I've seen packages come through our weekly recently where they say,\r \r add this custom tag in your oxygen header, and we're gonna do something with it. Whether it's like this testing\r \r generation\r \r or in particular that newer package that came out recently that gives you kind of a\r \r a workflow for ingesting, like, data in an ETL process,\r \r they're also built on our oxygen tags as well. So lots of interesting use cases for this. It'll take me a little bit to wrap my head around this, but it's nice to know that the machinery is there if we wanna do some custom processing with these documentation\r \r tags.\r \r\n\n\n\n[00:29:37] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 37,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah, Eric. This is interesting. Every once in a while, I come across a package that,\r \r allows you to essentially do things\r \r in your own package\r \r with, you know, these these are oxygen\r \r decorators.\r \r Right? I think Plumber is an example potentially\r \r of a package where we do that. Right? There's sort of That's right. These custom Roxygen,\r \r tags that that will stick on top of our code and and quote unquote decorate our code with that serve a specific purpose or, you know, execute the code that is underneath it or the functions underneath it,\r \r a particular way actually based upon\r \r the roxigen that's been written. You know, one of the the real standout things for me in this blog post is how many functions there are from the roxigen 2 package\r \r that I had no idea about, this tag markdown function, rd section function,\r \r rocklet function, all of these things\r \r that allow you to\r \r develop,\r \r the custom roxigen as Mel, you know, so eloquently sort of outlines here. I haven't particularly had a use case to do this,\r \r yet myself, but I I do leverage\r \r some packages,\r \r including Plumber and a couple others that that do this. And they they must have, you know, gone about this type of a process\r \r in order to develop, you know, this custom roxigen that serves a a particular purpose. So being able to sort of peel back the curtains,\r \r for those types of packages that do that, you know, leveraging Mel's blog post here was was really neat to see how it all comes together, how it all works together, you know, all of the different things that you have to watch out for including\r \r updates to the the description,\r \r file within your R package.\r \r\n\nYou know, leveraging, this this\r \r these particular packages,\r \r and the the the config, the needs, and the build, and all sorts of things like that to be able to specify\r \r exactly what you're doing here, the the custom rocklet. You know, I took a look at the vignette that Ma'el said she used for for quite a bit of this blog post, called extending roxigen 2,\r \r and was able to\r \r to take a look, at, you know, how they explain\r \r and describe\r \r going about this particular process, you know, adding a new dotrd tag and and a lot of the things that Mel did here. Obviously, you know, we look peel back the curtains on that package itself for Oxygen 2 and no surprise Hadley Wickham's the lead developer on that with a couple other folks, including Peter Dannenberg,\r \r Gavarsardi,\r \r and Emmanuel,\r \r Uster.\r \r\n\nSo a really powerful team working on this set of very powerful\r \r functions, and it's it's sort of another way. I don't know. I think of it somewhat akin to, like, object oriented programming\r \r where, you know, we're able to just push the boundaries and extend R to do, you know, some pretty incredible things just beyond sort of the functional side that we all think of.\r \r\n\n[00:32:27] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And the package I was thinking of at the name escaping until now is called Maestro.\r \r The one that we're there we covered a few weeks ago on on the show. It's gotten this new take on these data specific pipeline,\r \r but their their whole API, if you will, for getting opt into it is to decorate your function\r \r with these custom Roxtrogen tags called, like, Maestro frequency, Maestro start time. So I have to look at the source, and and if I look at the source of it, it'll probably be very similar to what I was outlining here. So like I said, it's been fascinating to see\r \r behind the scenes what's happening with the power\r \r of our oxygen to take\r \r what you can customize yourself, but then to build the machinery to do things with it. So, yeah, fascinating area.\r \r\n\nIn my daily work, I haven't had to, but now that I'm consuming more of these,\r \r types of packages, it's great to know what's happening here in case that does inspire future work.\r \r So, you know, I feel like I've only scratched the surface of what rOxygen 2 can offer. This is just another kind of eye opener for me of just the immense power that that particular package has for not just generating your documentation,\r \r but frankly, to give you the gateway to do so much more.\r \r\n\n[00:33:42] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. I think it's time to spin up a side project where we kick the tires on this.\r \r\n\n[00:33:47] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah.\r \r Don't please stop nerdcyping\r \r me, Mike. I can't take it anymore.\r \r\n\n[00:33:53] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. No. I always thought it was just pure magic, those packages like Maestro and Plumber, but,\r \r turns out there's actually something to it.\r \r\n\n[00:34:12] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 12,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Well, honestly, Mike, it wouldn't be in our weekly show without at least some visit to what I like to call the visualization corner. And we even know we're an audio podcast, we love talking about the best practice of visualization.\r \r And one of the key thought leaders in this space over the years has been the author of our last highlight today,\r \r Nicole Rene, who is, of course, a lecturer for health sciences\r \r over at the Lancaster\r \r Medical Institute.\r \r So in this great blog post, she talks about 5 particular tips that\r \r she's been using, especially in her latest visualizations\r \r where she shares her\r \r takes on the TidyTuesday\r \r datasets out there that I think we all can benefit from.\r \r\n\nOne of which, this is one that I've encountered quite a bit,\r \r is that there may be cases where by default,\r \r you'll get a certain range of your y axis that is a little more truncated,\r \r but there may be cases where\r \r maybe you don't wanna do that. Maybe you wanna show what in theory could be the lowest number or the lowest limit, and in particular for in the case of bar charts,\r \r having a start at 0 for, say, your frequencies or percentages\r \r or whatnot.\r \r Most of the time, that's going to help you potentially\r \r navigate what could be misleading\r \r representations\r \r on that. And in this example, she's got looking at the, the very fun penguins dataset\r \r looking at the number of penguins per island.\r \r\n\nAnd on the left side of this, she's got a bar chart with those frequencies where the number on the y axis starts at 0 and then another where it starts all the way at 40.\r \r Now that might not be exactly a fair representation\r \r depending on what what you wanna do\r \r with these data.\r \r Now\r \r there may be there may be cases where it ends up being appropriate.\r \r But\r \r maybe in the case where they all have a similar height, maybe you don't get a lot of going all the way to the\r \r theoretical lowest limit.\r \r But there are other cases where other parts of the data that you might superimpose\r \r on these bar charts might be more accurate\r \r if you wanna impose, say, standard deviations\r \r or other types of metrics on top. So,\r \r again, that's kind of a case by case basis. But in case of frequencies, a lot of times,\r \r especially in my line of work, we still have to start from what literally is the ground 0, so to speak,\r \r what kind of frequencies or percentages those\r \r numbers could be based on.\r \r\n\nAnd so like I said, yeah, there there is a trade off. There may be some situation\r \r such as in line charts\r \r where maybe starting at 0 kind of loses the key focus of that visualization.\r \r And the next example,\r \r she has a line chart where it shows\r \r the time course\r \r of how a variable, in this case the population of Germany, is changing over time.\r \r And in one plot, she does indeed start it at 0 on the right, but then on the left she starts it at a much higher number.\r \r So you can see the the increase, the kind of more,\r \r you know, what looks like a pretty rapid increase\r \r in the early debt part of the century versus kind of leveling off and then increasing again.\r \r\n\nYou kind of lose that nuance if you started at 0 and already the first measurement\r \r was already starting\r \r at a value already above, say, 60 or 70, you know, in 1,000,000 on that or,\r \r yeah, in 1,000,000 for that. So\r \r again, it's not like a one size fits all. You got to look at the context of the visualization you're telling here, the story that you're trying to tell or the insight\r \r to really say to yourself, do I really need to go to that lower limit\r \r or not?\r \r But that that's a nice segue into when you have, say, data of, like, 2 continuous\r \r or numeric variables and you're doing the\r \r tried and true scatterplot,\r \r sometimes you got to look at ways of doing appropriate range for that because sometimes you might not quite get\r \r the full gist of it\r \r if you are truncating that range too much\r \r or widening it too much.\r \r\n\nAnd in her example here, she's got a scatter plot that we often use\r \r in model assessments and regression models, a scatter plot of the residuals,\r \r which is basically on the y axis. You've got\r \r the residual from observed versus the fitted values\r \r on the x axis.\r \r If you are looking for patterns like, say, symmetry\r \r or other, like, you know, indications\r \r that maybe you're violating\r \r a assumption such as the\r \r normal distribution,\r \r you wanna be able to compare pretty clearly to those points approaching, say, the zero line\r \r on the y axis where the residual and the fitted and observed are basically the same.\r \r\n\nSo when you truncate the axes\r \r going more in one direction versus another,\r \r it's hard to really tease out that pattern\r \r of potential symmetry\r \r if you have, like, the points above 0, the axis limits\r \r more than the axis limits below it. So there's a good example where it's a little nuanced, but you can kind of see it'd be harder to tell\r \r that pattern\r \r if you are not consistent\r \r with the level of the range you have above and beyond or above and lower that zero value.\r \r And she says similar advice could be done with another tried and true\r \r metplot assessment called the qqplot,\r \r also used to assess normality.\r \r\n\nSo again, making sure that you're akin to what type of visual or insight you want to tell to help dictate just how you're gonna, you know, change those limits\r \r on those particular axes.\r \r Up next, Mike, I didn't wanna touch this one. I'm gonna leave it to you because this can be a controversial topic in some circles in the visualization\r \r world,\r \r is dealing with the potential of\r \r multiple y axis. So why don't you walk us through her advice here?\r \r\n\n[00:40:25] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 25,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. I remember a time where, you know, having 2 y axes on the same chart,\r \r was really, really frowned upon.\r \r And\r \r I think it got so frowned upon and and so much flack that that maybe,\r \r some folks out there started to say, hey. Well, it's maybe it's not as bad as we're completely making it out to be. But I think probably the general consensus is still that it's not the best idea and there's probably a better way to go about ensuring that the conclusions\r \r that are drawn\r \r from your visualization\r \r are the the correct and appropriate\r \r conclusions,\r \r and your audience is not being misled,\r \r by, you know, the differences in scale across these 2 y axes on on the same chart, which can have a big impact\r \r in, you know, how the data is interpreted, especially when there's intersection,\r \r between those those two particular lines,\r \r in my experience.\r \r\n\nSo I I love,\r \r the idea that Nicola had here, where instead of, you know, plotting\r \r this chart with these 2 y axes because the scale of the the y axes are very different,\r \r instead,\r \r bring them both to a down to a, like, percentage change basis, such that you can have a single y axis\r \r and you can compare,\r \r you know, these on a percent basis a little bit more apples to apples comparison,\r \r as opposed to, you know, having to wrangle those 2 very different,\r \r y axis scales. And,\r \r you know, I I think the plot that she shows here after\r \r converting to a percentage change,\r \r that the values for both,\r \r you know, sort of categories here in the legend,\r \r really tells the story that, the author would be trying to tell to the audience much better, than taking a look at what's going on in those dual y axis plots. So that's that's a great idea.\r \r\n\nThe last one, that she talks about is is how alphabetical categories\r \r often don't make sense, and you wanna ensure that you are ordering, you know, in the case of a bar chart in her example,\r \r ordering those bars in a way that is going to make the most sense for a user. So if your x axis is representing days of the week,\r \r probably not a good idea to order your x axis alphabetically.\r \r You probably wanna order it chronologically,\r \r right, from from Sunday to Saturday or from Monday to Sunday,\r \r in her example here. So you really have to think about and and we'll wrap up here at the end, but I I think a lot of what we're talking about here is just coming down to context\r \r and thinking about, you know, the practical\r \r ways that your audience are going to consume the data that you're you're showing them, and and making sure that you're thinking critically\r \r about what you are showing them. Another one here is, you know, instead\r \r of, on a horizontal bar chart, you know, if you're using chord flip and ggplot2,\r \r with a with a bar chart. Instead of, you know, ranking that alphabetically again, you might want to start with the bar,\r \r at the top that has the the highest magnitude or extends the furthest to the right, if you will. So, you wanna you wanna order your plot by the values\r \r on the y axis, if you will, as opposed to the the labels\r \r on the x axis prior to to flipping and inverting that scale. Another thing, you know, this is a very Albert Rapp style blog post. It reminds me of a lot of the the work that that he's done here that I think Nicole is doing a great job\r \r articulating\r \r as well. A little free tip out there that I think I got from either Nicole or Albert in the past is\r \r stick your conclusion\r \r at in the title,\r \r And that will really help, you know, drive home the point that you were trying to make. If there is a point that you're trying to make, you know, sometimes we're really just purely\r \r displaying data. But a lot of times, you know, when you're doing data visualization\r \r to communicate the data to an end audience, there's there's really, sort of, a standout point to that chart that you want to get across to them. And instead of saying, hey, this chart, shows, you know, car type by weight,\r \r we can say, you know, linking Continental has the the highest weight across, you know, the 20 cars in this this particular data set or something like that. You can stick that in the title as opposed to\r \r just really making that title an explanation of what's on the the x axis and what's on the y axis. So,\r \r excellent job by Nicola. You know, she's fantastic in these blog posts. Obviously, interspersed within these blog posts are the visuals as well as the collapsed code that she used to generate these visuals, I think a great way to round out the highlights this week.\r \r\n\n\n\n[00:44:59] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And I that particular point about the bar charts and, you know, the reorder that based on frequency, you often see that quite a bit as you look at the impact of different machine learning models\r \r when we look at the impact of variables inside those models, like variable importance or reductions\r \r in root mean square error or whatnot, they'll often order that by the one that's most influential according to that metric and then going down further. So, yeah, I've seen her put a lot of these things in practice even in her\r \r machine learning workshops that she's been giving a couple of times now.\r \r\n\nSo, yeah, I think that the idea of having a bit of common sense and maybe, you know, some things that I often do with my app development too\r \r is getting feedback early on in the process of, like, that particular output of that visualization, making sure that the key, you know, stakeholders\r \r or customers that are gonna be viewing that report or reviewing that app are understanding\r \r the intent of what that visualization\r \r is trying to show. So getting that feedback sometimes from other people, even if you yourself feel like you've nailed it, so to speak, but getting that extra set of eyes\r \r is never a bad idea. And we know the world of visualization\r \r can be a bit subjective sometimes. So being able to get that get that opinion early on is is a massive help for sure. That's a great point as well, Eric. Yep. And,\r \r we're we're running a little long here. So we're actually gonna wrap up the shop here a little sooner than earlier, but we're gonna leave you with our usual,\r \r calls to contribute to our weekly itself, which\r \r to get keep the project going. It's, you know, it's, of course, driven by the community.\r \r\n\nSo one of the best ways you can do that is to share that great new blog post, that new package, that new insight that has got your workflows all all, Jim, you know, improved or whatever.\r \r So you can do that via a poll request at the main website at arewehere.org.\r \r There's a link to a poll request in the top right corner. It's all marked down. You just fill out a little template, and then you'll be glad for the curator of that particular week to get that resource in the upcoming issue.\r \r And, also, we love hearing from you as well, so you can get in touch with us through a few different ways. We have a contact page linked in the episode show notes that you can grab to directly from your podcast player.\r \r You can also reach out to us on the,\r \r the the podcast apps that are more modern, like Podverse or Phon or Cast O Mac, and send us fun little boost along the way, which a little, side tangent here. But, my good friends\r \r at Jupiter Broadcasting that run the CODA radio show authored\r \r by,\r \r Chris Fischer and Michael Dominick,\r \r they've been running a little contest to see what should be the official language of the show.\r \r\n\nYou would not believe which language is up to run.\r \r Based on some recent boost, the r language is almost number 1 now.\r \r So,\r \r who knows? We may get this in vected into other podcasts as well. We'll see about that. So that that's been fun. If you listen to that show, you may hear from yours truly on that from time to time. Nonetheless, several ways to get in touch with us are on social media as well. You can find me mostly on Mastodon these days with at our podcast at podcast index dot social. You can also find me on LinkedIn. Just search my name, and you'll you'll find me there. And it's frankly on the weapon x thing at the r cast. And, Mike, working with us, get a hold of you. You can find me on mastodon@[email protected],\r \r\n\n[00:48:29] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Mike Thomas",
        "trans_text": "or you can find me on LinkedIn if you search Ketchbrook Analytics,\r \r k e t c h b r o o k. You can see what I'm up to.\r \r\n\n[00:48:37] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "trans_timestamp": 37,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Very good. Very good. Well, that's,\r \r never a dull moment in our lives. So we're gonna close-up shop here, but, of course, we thank you so much for\r \r listening from wherever you are. And, little programming note, next week, we might be on at a different time as yours truly is gonna be involved in a virtual event at our usual recording day. So we will we'll communicate one way or another what happens. But, nonetheless,\r \r we hope you enjoyed this episode of ROCE Highlights, and we will be back with another episode of Rwicky Highlights either next week or soon."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_37_highlights",
        "chap_timestamp": 46,
        "chap_text": "Playing FAIR with your research",
        "chap_href": "https://drmowinckels.io/blog/2024/fair-blog/"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "chap_timestamp": 17,
        "chap_text": "Custom roxygen2 tags",
        "chap_href": "https://masalmon.eu/2024/09/03/roxygen2-custom-tag/"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "chap_timestamp": 12,
        "chap_text": "Improving chart axes",
        "chap_href": "https://nrennie.rbind.io/blog/five-ways-improve-chart-axes/"
      },
      {
        "ep_name": "issue_2024_w_37_highlights",
        "chap_timestamp": 19,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_36_highlights",
        "ep_date": "2024-09-04",
        "ep_duration": 58,
        "ep_description_short": "A peek behind the curtain of how R handles that batch of code you send to the console, an adventure in automating the translation of Quarto documents to multiple languages, and there's no time like the present to give your code a little linting love. Episode Links This week's curator: Sam Parmar - @[email protected] (Mastodon) & @parmsam_…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_36_highlights",
        "description_long": "\r \r A peek behind the curtain of how R handles that batch of code you send to the console, an adventure in automating the translation of Quarto documents to multiple languages, and there's no time like the present to give your code a little linting love.\nEpisode Links\n\nThis week's curator: Sam Parmar - @[email protected] (Mastodon) & @parmsam_ (X/Twitter)\nLong input lines\nTranslating Quarto (and other markdown files) into Any Language\nGet your codebase lint-free forever with lintr\nEntire issue available at rweekly.org/2024-W36\nSupplement Resources\n\nNews from R Submissions Working Group – Pilot 3 Successfully Reviewed by FDA\nMastodon Accounts Posting About #RStats\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nTorvus Clockwork - Metroid Prime 2: Echoes - DarkeSword - https://ocremix.org/remix/OCR01507\nSleep, My Sephy (Judgement Day) - Final Fantasy VII: Voices of the Lifestream - Pot Hocket - https://ff7.ocremix.org/"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://fosstodon.org/@parmsam"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://twitter.com/parmsam_"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://blog.r-project.org/2024/08/30/long-input-lines/"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://edenian-prince.github.io/blog/posts/2024-08-21-translate-md-files/"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://masalmon.eu/2024/08/28/lintr-3-steps/"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://rweekly.org/2024-W36.html"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://www.r-consortium.org/blog/2024/08/26/news-from-r-submissions-working-group-pilot-3-successfully-reviewed-by-fda"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://apps.machlis.com/shiny/rstats/"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://ocremix.org/remix/OCR01507"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "links": "https://ff7.ocremix.org/"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We are back with episode 177\r \r of the R Weekly Highlights podcast. This is the weekly podcast where we talk about the awesome highlights and other resources that are shared\r \r every single week at rweekly.org.\r \r My name is Eric Nantz, and as always, I am delighted you join us from wherever you are around the world.\r \r\n\n[00:00:21] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Mike Thomas",
        "trans_text": "And you know what, folks? All is right with the world because I am not flying the plane solo this week. I am my awesome cohost, Mike Thomas, making his triumphant return to the podcast. Mike, how have you been? Been doing well, Eric. Yes. Speaking about from around the world. I feel like I've been around the world a little bit. I was fortunate enough to be able to attend posit comp and and see you there and I know we weren't able to record that week, and then I sort of went straight from there to more conferences\r \r in Boston\r \r and elsewhere and and finally just getting my feet back in the on the ground at home, back in the office. And,\r \r I apologize to to you for having to make you do it for a couple weeks, on your own, but you did a great job. And,\r \r looking forward to\r \r being back at it today.\r \r\n\n\n\n[00:01:07] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 7,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah.\r \r I survived, but, I think the listeners will agree that things are more correct now with you here. But,\r \r yeah. Back in it was a couple episodes ago, I gave my kind of, conference experience. I wanna make sure you got some time to talk about what you thought about Positconf and anything you wanna share with the audience about what you took away from that. Sure. Well, it's always just so\r \r\n\n[00:01:30] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Mike Thomas",
        "trans_text": "sort of invigorating to get to be around other, you know, data scientists and and like minded folks and listen to talks and just connect and and collaborate and be in that community face to face together. So I I thought they did a great job putting on the conference.\r \r\n\n[00:01:46] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 46,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I was able to to see some of my team members at Catch Brook that I actually hadn't seen in person before Yeah. Which is really special and really I was able to be at the table when you saw him for the first time. That was awesome. Yeah.\r \r\n\n[00:01:58] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 58,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That's right. Shout out Ivan.\r \r And it it was it was a fantastic experience you know some of the highlights for me I guess on the shiny side were you know really Joe Chang's,\r \r talk about\r \r leveraging\r \r you know large language models within your your Shiny app that are able to\r \r essentially put together a DuckDV query\r \r show you that DuckDV query\r \r just from natural language\r \r and return the results on screen to you which was pretty incredible I think we have\r \r probably no less than a 1000000000\r \r opportunities,\r \r to incorporate that into some Shiny apps that we have have currently,\r \r but you know there were a bunch of fantastic talks. I think it's easy to\r \r not\r \r or take for granted all of the work that goes into\r \r putting together these talks and and how hard folks work to be able to put these presentations together for us. So just a big shout out to to everyone that that participated and,\r \r gave a talk this year and was able to provide us with some fantastic content. So I had a had a great time. I I got to see a little bit more of Seattle\r \r as well, than I had seen in the past. Sometimes at these conferences, it's it's tricky because you're, you know, you're just sort of glued to the conference and sometimes it's hard to to make it out of the hotel but I was able to go out with a few clients as well finally was able to see the the big Pike Place Market I think downtown there which was cool and did a little walking around\r \r and enjoyed enjoyed\r \r getting out to the West Coast and seeing Seattle. So we'll see what, I guess, Atlanta brings next year.\r \r\n\n\n\n[00:03:30] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That's right. You're going to Hotlanta next year, so it'll be my my first time there. But, yeah, I'm seeing it's always funny trying to get a read of the room whenever they make those announcements. It's always, you know, mostly cheers, sometimes a couple groans, but in either way, it should be a good time nonetheless.\r \r I don't think there were any boos, so that's good. Yeah. That's true. Yeah. Yeah. No no heat, so to speak, from that announcement. But, yeah, that was that was, yeah, so that will be here before we know it because I know the the months go by fast. But, yeah, it was, again, terrific to see you once again and, just to hang out with you a bit. And, yeah, like you said, I was in I was pulled in in many different directions. So I didn't get to see as much as Seattle as I would like, but who knows? Maybe I'll be back there next year for other events or whatnot. But, nonetheless, it was it was awesome. And and, yeah, I hope that the hype I I put around Joe's shiny announcement was worth it because I for the listeners, I I had a sneak preview of that before Joe made that presentation.\r \r And poor Mike here was just asking me, any hints, any hints, any hints, and when's it coming? When's it coming? It's like, stay tuned for Wednesday. And, yep, it seems like it didn't disappoint.\r \r\n\n\n\n[00:04:37] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 37,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yep. For anybody that needs this information, Eric, it's a great great secret keeper.\r \r\n\n[00:04:44] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Eric Nantz",
        "trans_text": "When when I'm told to zip the lips, I know how to zip the lips, usually. Usually.\r \r But this time, I honor good old Joe on that one. But, nonetheless, yeah, amazing experience. And, you know, we gotta get get to business here. We got our fun our weekly issue to talk about here. This has been curated by Sam Parmer who was also at the at the POSIT Conf. I got a chance to hang out with him multiple times, and I actually had some nice dinner with him one of the nights too just walking around the Seattle area, but he and I always have lots to talk about. And for this, he had tremendous help as always from our fellow iRwerky team members and contributors like all of you around the world with your poll requests\r \r and other resource suggestions.\r \r\n\nWe're gonna go technical here, Mike, on this first one in areas that, admittedly, I kinda take for granted, but I guess could bite you if you're not careful.\r \r Now with r, r is one of those you might call interpreted languages, which means that when you launch r, whether it's through the console directly,\r \r through its own GUI interface on Windows, or through an IDE like pod you know, RStudio or the new positron or whatever have you,\r \r you're gonna get a REPL,\r \r which is kind of what the r console looks like. But if you don't know what repl is, and believe me, even when I first got in, because I had no idea what that is, that is the read,\r \r eval, print loop. And both r and Python and other languages come with this so that you can type a command,\r \r hit enter, and then you get the result.\r \r\n\nSometimes\r \r when you have a long command,\r \r you can actually\r \r space this out to multiple lines if you want and just hit enter, and you'll get with a little plus sign,\r \r not plus an addition, but plus to the new line that you're adding\r \r to that\r \r that console input.\r \r And you can do this for as much as you want, albeit you might get tired if you do this a lot in the console directly. So for most of the time, we end up writing our scripts or Python scripts depending on which language you are. And that way, you can run the whole file or you could send certain bits of that file into the into the console itself.\r \r Apparently, recently, there has been a user that\r \r had sent\r \r a lot of input to this console\r \r or to the the interpreter itself\r \r ended up being hitting a limit that r has had for\r \r historically for a while\r \r of 4,096\r \r bytes. And I did a little crack research before this. Apparently, a byte is a character, so it's kind of a one to one translation, which means that this user\r \r was sending\r \r a string of command that was over 4,096\r \r bytes\r \r in that in that session.\r \r\n\n\n\n[00:07:37] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 37,
        "trans_speaker": "Mike Thomas",
        "trans_text": "It might not actually be that long, though. Right? If it's a character, it's not like it's 4,000 lines.\r \r How many characters in a if you you get your 80,\r \r your 80 width. Right? It's what we try to adhere to. Well, yeah. For styling, sure. Yeah. For styling purposes. So in a regular 80\r \r 80,\r \r width set of lines, that's gonna be let me do some quick math here. Oh, boy.\r \r\n\n[00:08:01] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Dangerous.\r \r\n\n[00:08:02] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 2,
        "trans_speaker": "Mike Thomas",
        "trans_text": "51\r \r lines?\r \r\n\n[00:08:05] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 5,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Well, there may be something else going on here, and this is where, again, we're gonna\r \r get into the weeds a little bit by the author of this post that comes directly from the r blog.\r \r Thomas Calabrera, who is one of the members of the r core team,\r \r apparently has been diving into this issue as a result of this report that went on the r develop mailing list.\r \r And, apparently, now there have been advancements in our the development version\r \r to help get to, quote unquote, unlimited lines so you can throw through the parser.\r \r So I'm gonna give you my take on how this works. This is a lot of machinery here that, admittedly, I've not gotten into as much. But one has to wonder just what process was generating that massive\r \r set of input\r \r that was causing all these bytes to be limited. And, again, maybe I have it completely wrong on what a character translates to bytes, but, nonetheless,\r \r let's talk about how\r \r when you send a command to r, how it actually gets in there.\r \r\n\nSo, first, Thomas is quick to point out that the parser is not the issue here\r \r because the parser\r \r needs the functionality\r \r to look at code\r \r with input of technically unlimited length that could span multiple lines.\r \r And one concrete example that he highlights here\r \r is an if statement.\r \r Because in an if statement,\r \r you need to look at that entire if statement, everything going into that to know what to do in terms of the rest of the console input.\r \r So\r \r that is always going to have to be parsed\r \r in the theory of an unlimited length depending on how extensive that is.\r \r So that's where\r \r that needs that needs to happen.\r \r\n\nBut then there's not just the parser at play here. There's also the REPL itself,\r \r which, again, as I mentioned, is getting\r \r input from either the user or maybe copying pasting that code\r \r into the console.\r \r And there is under a hood an API function in r itself. They call it r underscore read console,\r \r which is modeled after a c function called fgets, again, outside of my\r \r wheelhouse here.\r \r But, apparently,\r \r that has\r \r that has a capability\r \r to know\r \r whether it's getting one massive line or if it's getting multiple lines that was separated by, say, a carriage return.\r \r Hence, like I mentioned earlier, when you type a line, hit enter, but you're not done yet, you'll get that plus sign in the console. It's gonna know\r \r how to interpret that.\r \r\n\nBut that buffer\r \r that basically that empty space, if you will, that the repo uses to grab all this all this input\r \r has been\r \r in a constant definition for the limit length which has been 4,096\r \r bytes\r \r apparently since 2,008.\r \r And before that, it was actually\r \r 1024.\r \r So it was much smaller back then.\r \r So, apparently, there are ways up until recently\r \r where you could overflow\r \r this repo buffer.\r \r I don't think that's to be confused. I'm I'm abusing terminology here, but I often\r \r hear about buffer overruns when code crashes. I don't think this is quite the same, but, nonetheless,\r \r the consequence here up until recently\r \r is that if you had an input that was expanded past this 4,096\r \r limit,\r \r it would just truncate it. So it's as if you just didn't type in the rest of your code, so to speak.\r \r\n\nSo that that again, that's been a gotcha, apparently, that some people have seen, but now\r \r seems like that is a thing of the past in the development version. So there are\r \r improvements\r \r that have been made,\r \r but there are some nuances to keep in mind when term in terms of where you're actually interacting with r.\r \r So there is on Windows historically been, since my early days of r, the r GUI that comes when you install r on a Windows machine\r \r that has again, it looks like its own mini IDE, if you wanna call it that. It's got its own console in there,\r \r but there were issues that have been identified with that,\r \r that make it so that that buffer size\r \r was getting hit more often than it should.\r \r\n\nAnd now they fix that\r \r by giving kind of an intermediate interface between the user typing in, hitting enter, and then that going to the REPL and for interpretation\r \r to help\r \r account for lines that could exceed this this limit. So, apparently, that's landing\r \r soon in production r. We don't know when yet, but it looks like there have been some improvements on that side of it.\r \r And then the r term itself, another thing within Windows,\r \r that's like the console itself,\r \r which is getting enhancements as well to help\r \r circumvent some of these limitations.\r \r\n\nAgain, I'm not a Windows user anymore, so I don't know exactly if that will affect me day to day. My guess is not for those out there.\r \r And then Linux, you know, Unix in general also\r \r have a a function here because they use a\r \r read line library\r \r whenever you start typing in the console and then sending that to the r interpreter\r \r that\r \r has had,\r \r limits before.\r \r You may run into that\r \r give or take depending on what OS you're on.\r \r I mean, Mac OS also encounters this.\r \r But in in conclusion, Thomas says that there are ways you can defend yourself against this. I think the biggest way is to\r \r put everything in a file usually if you have a huge massive\r \r chunk of code.\r \r\n\nOtherwise, it looks like if you are grabbing this code from, say, another process that's generating it,\r \r I wonder if it was kind of akin to when you have JavaScript and you can make what's called a minified JavaScript file where it takes away all those carriage returns, but then you get this, like, massive\r \r wide text\r \r that the JavaScript\r \r parsers know how to deal with. I wonder if something like that was going on with this user, and they were just getting this massive, massive string\r \r of our code that was causing these limits. Again, speculation on my end,\r \r but it looks like these limitations\r \r are hopefully gonna be a thing of the past if you've encountered them before.\r \r\n\nSo, again, pretty we invite you to check out the blog post because I've only gone high level\r \r on what Thomas has outlined here. But if you find yourself in this situation,\r \r then, yeah, this this post may help you encourage you that the new versions of r will have a more unlimited\r \r limit, if you will, as opposed to this more truncated\r \r 4,096\r \r\n\n[00:15:10] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 10,
        "trans_speaker": "Mike Thomas",
        "trans_text": "limit. Well, I tried to do it justice anyway. Like, what are your thoughts on this? No, Eric. This is a tricky one and I think you, boiled it down for us as best as possible.\r \r I think it, again, reminds me of, like, how much actually goes on under the hood when you execute in our function. Alright. There's a lot of wizardry to compile that code and to get it to execute, right, that the actual c code, right, that is is getting run\r \r under the hood.\r \r And a lot of work goes into making this all work perfectly\r \r across different operating systems\r \r as well. So it's it's it's pretty incredible\r \r how easy it is for us to to take for granted about how well that works and it's a this is a limitation I haven't run into myself necessarily before. I've,\r \r I think, seen some strange things when I I try to copy and paste, you know, large\r \r amounts of code into the console and I certainly try to avoid that especially when I'm jumping between IDE's and RStudio versus Versus Code\r \r and dev containers and things like that. I'll I'll run into some strange issues. So I think as you said, you know, a best practice to keep in mind is is to just, you know, contain everything in scripts. If you have something really long that you want to execute, you can you can source that script if you want or just highlight the the code that you want to to run and execute that code, itself as opposed to, you know, copying and pasting large amounts of of, you know, code into directly\r \r into,\r \r your your console.\r \r\n\nIt this also brings me back to my early days of r and R GUI, which is something that I had not opened up in in quite a long time and it brought back some memories pretty quickly because that is admittedly\r \r where I started in R. I'm not even sure if RStudio\r \r existed\r \r\n\n[00:16:58] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 58,
        "trans_speaker": "Eric Nantz",
        "trans_text": "when I was getting started and are not to date myself too much but, at least Speak for yourself. My goodness. You know what ID is I'd use in the past? And\r \r\n\n[00:17:09] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Mike Thomas",
        "trans_text": "and you know when you do install our I was looking looking at my local R installation and and seeing, you know, our GUI dot exe, our term dot exe,\r \r and you know these are I guess things hanging around that we we sort of take for granted. Right? That that are packaged in with our local installation of R. But if you're using R Studio or if you're using Positron nowadays or or Versus Code or whatever it is, you know, these sort of legacy\r \r items, I I would imagine that our term is still applicable but probably our GUI,\r \r isn't applicable for folks using, you know, one of those those IDEs. These legacy,\r \r executables and applications, if you will,\r \r are still there, you know, if you wanted to get some nostalgia, pop into them and and try a little bit. I remember when I after I found our studio, I started a new job and and was working with somebody who was writing a little bit of our code, but we were sort of sort of siloed so we weren't working, together\r \r very well and I went over to his desk one day and he was using our GUI\r \r and didn't know that you could write in our script and, like, save in our script that you could rerun later so he thought that you just had to, you know, save\r \r commands in like a notepad text file or something like that and\r \r that was the way I guess that his professor taught him in in university. It never showed him that you could save in our script which is is a little scary but it makes me think about how far we've come\r \r but that really really interesting blog post, you know, it sounds like this is a potentially solved\r \r issue in the coming releases of our and maybe something that we don't necessarily have to to dive too deep in the weeds on in the future or or worry about because they're handling so much of this behind the scenes stuff for us.\r \r\n\n\n\n[00:18:53] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Again, you know, all the machinery behind the the hood here, or under the hood of of our yeah. It there's we definitely need to appreciate it more in the fact that we can have modern tooling on top of it and still leverage, you know, the language\r \r in many different ways. Yeah. That's a it's a testament to how far things are going and, yeah, development is not slowing down anytime soon. So, yep, a lot of a lot of things that you can go down rabbit holes of, and and, certainly, this is this is one of those.\r \r And, yeah, speaking of having, like, modern interfaces on top of R and whatnot, of course, one of the the great interfaces\r \r or\r \r new add ons that many are using in terms of reproducible research and and then the like has been the quartile ecosystem, the quartile\r \r compilation engine for documents that can be coded up in markdown, but then have code embedded inside, whether it's r or Python and whatnot.\r \r\n\nAnd the but one of the best things about Quarto has always been the ability, of course, to write in markdown.\r \r I mean, we all I always joke kind of at the end of each episode, if you don't know how to write mark markdown in 5 minutes, e y c would give you $5.\r \r So remember that presentation in NBSW years ago.\r \r But, you know, markdown,\r \r of course, can be written in any language. Right?\r \r And we have a very diverse community in data science as we all well know.\r \r So what if you're in a situation\r \r where you've written this great mortal document\r \r and now you want to send that to collaborators that have a different you know, spoken language or primary language.\r \r\n\nWell, this next post is gonna give you some insights on how you can do just that with the advent of technology.\r \r This blog post is coming to us from Frank Aragona,\r \r and he talks about how he was able to translate Quiridon and ends any markdown file\r \r into any other language.\r \r So there are some services in play here that can account for this,\r \r but he did take a look at, you know, the existing services out there.\r \r Unfortunately, a lot of them, in his opinion, unfortunately,\r \r required\r \r API access that ends up even needing\r \r your credit card even if you're not planning on paying for it, services from Google\r \r and others like DeepL or whatnot.\r \r\n\nBut\r \r he did find into\r \r found another avenue called Hugging Face transformers,\r \r which do provide APIs\r \r to get pretrained\r \r models that are tailored for translation.\r \r And so now the key is, well, how do you actually use this thing?\r \r There is an existing R library for Hugging Face, but\r \r it required Conda to install some Python libraries. And\r \r like the author here,\r \r me and Conda don't quite get along, especially in my work environment. So, of course, I look for ways to simplify that.\r \r So he ended up coding up a more friendly wrapper to install these packages via Reticulate\r \r and the pip, you know, install interface for Python.\r \r\n\nAnd, of course, this does necessitate Reticulate.\r \r And then through his package, it'll download the hugging face transformer\r \r Python bindings,\r \r which, again, I'm not as familiar with.\r \r But once that's in there,\r \r he's got a Python package now or an R package called\r \r translatemd.\r \r He's got the coding in the blog post on how to get that onto your system once you have reticulate\r \r ready to go, but it's gonna spin up a virtual environment for you, which again in the Python world is like what we have for RM\r \r for containing your dependencies,\r \r calls it our transformers, but you can rename it whatever you like.\r \r\n\nAnd then once you have that ready to go, you can feed in a quartile document,\r \r and it will basically have a multi process approach. It'll parse the quartile document,\r \r apply the translation,\r \r and then in that kind of tidy form of the parsed translation,\r \r it'll then now rewrite\r \r to a new quartile file\r \r a new document\r \r of the translated language. So he's got a snippet of how this looks when you start parsing it, and much I already talked about in previous highlights when you talk about parsing code files,\r \r you do see\r \r different\r \r areas that have been parsed, whether it's the YAML,\r \r inline text,\r \r headings,\r \r more inline text, blocks of of of code or whatnot.\r \r\n\nAnd then once you unwrap that and then translate it, then you start to see you can see side by side in the post\r \r what he's gone from the English version\r \r to, I believe, the Spanish version.\r \r So that\r \r looking pretty good,\r \r and then he's got a little picture at the bottom of the post that shows the 2 documents side by side.\r \r But like everything, Mike, there are a little bit of gotchas here that you might want to be aware of before you translate this. Why don't you walk us through some of the little off bugs he's found here? Yeah. There's a couple a couple of bugs it seems like you might have to manually\r \r\n\n[00:24:21] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Mike Thomas",
        "trans_text": "adjust for and it's actually pretty some of them are somewhat evident,\r \r just from the 2 screenshots\r \r which are are really cool. I think an awesome feature this blog post showing\r \r on the left,\r \r the English translation or the original, I guess, quarto document if you will and then on the right side the equivalent\r \r Spanish translated\r \r version of the same quarto document. So it's really cool to see these 2 things side by side.\r \r One of the things that unfortunately happened during the translation\r \r is that a particular section header that had a single, you know, pound sign to be able to to have that as sort of an h one header,\r \r the pound sign got removed or for the the hashtag, for for the younger audience out there. So you can see sort of on the right side, that that bold heading that would correspond on the left side doesn't exist in the Spanish translation. Translation. So it's just something that you would have to go into,\r \r I think in in add that pound sign yourself. Not a huge deal,\r \r in a small document probably in a big document situation\r \r it would be a little painstaking to have to go through and do that in a lot of different places.\r \r\n\nWe just rolled out 9 reports, 9 quartile reports,\r \r that were due on the 31st that we rolled out to our clients and each one of them was about 77 pages long. So in that case would have been difficult for us to do but if you have a small little, you know quarto report it shouldn't be too big of a deal to go in and add those\r \r headers and there's there's always control f too, right, that we can try to find the particular\r \r header text and then go in there and just just stick that pound sign in front of it.\r \r The Light Parser package which is leveraged here has a a known bug as well with, quarto chunk YAML parameters and in particular if you have a chunk that is specified as eval eval false excuse me such that the code shows up but it actually doesn't get evaluated\r \r it translates that into eval no\r \r the n o instead of eval false\r \r So it looks like the Light Parser packages is working on rectifying\r \r that issue.\r \r\n\nI haven't looked into it yet. Frank,\r \r the author of this blog post, it says that hopefully this is fixed but maybe we can do a little follow-up next week to take a look at whether or not that bug still exists but,\r \r Frank also wraps up by letting you know that it's probably a good idea because we're potentially automating a lot here to go through\r \r the translated document and really with a fine tooth comb make sure that there are no other bugs because I think in situations like this right it can handle\r \r a lot for you you know maybe upwards of 90% but some of those edge cases depending on what you're trying to do in your quarto document,\r \r we do a lot of crazy stuff with include chunks,\r \r you know, child documents and things like that. So you never know,\r \r you know, if there are particular edge cases that\r \r this translator has not been able to solve yet at this point. So I think it's a good idea to to take your time and take a look at the output. Know that a lot of,\r \r you know, the the manual work that you would have had to have done has been taken care of for you, but there might still be some some little spots you might have to tune up.\r \r\n\n\n\n[00:27:36] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. It it's not\r \r a direct one to one analogy here, but I've been looking at things like this even for the production of this very show. The podcasting service that we use has\r \r a functionality where it'll\r \r produce a transcript for our episodes. Right? I mean, it's kind of like a translation from audio to to text, so it's not quite the same.\r \r But just like you said, Mike, about maybe doing a double check before you sign off on it, I even noticed that will mess up a a few keywords here and there that I tend to spot and then put a correction in, but there may be others that I don't catch. So you won't get everything perfect in these, but, of course,\r \r we we cannot, you know, understate\r \r how much\r \r time this can save, especially if you're gonna do this\r \r routinely to multiple languages. I think that's a huge win for accessibility\r \r and certainly depending on your needs. I could see a use case where maybe you have an application, whatever, Shiny or something else, and you're you know, the user's doing a bunch of stuff, and then you want them to download or reproduce a report of those findings. Hence, a cordial document or a markdown document, whatever have you, you could plug something like this in and then make have that report have multiple languages. There's lots of automation ideas you could have at play here.\r \r\n\n\n\n[00:28:49] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Very, very cool. Yeah. A little radio button allowing the user to pick which language they want, they wanna download the report in.\r \r\n\n[00:28:56] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I think, yeah, the possibilities\r \r once you get your hands on these tailored models, there's just so much fun stuff we we can do with it. So credit to Frank here for another awesome use case of both automation and portal to\r \r to to check a lot of, nice solution here. Gotta love it.\r \r Last but certainly not least in our highlights,\r \r episode here, we've got\r \r another great use case of, speaking of cleaning things up sometimes.\r \r Yeah. Yours truly code sometimes needs to get cleaned up a little bit. I know, Mike, you write perfect code every time. Right? Right?\r \r I wish. You wish. Yep. You and me both. Well, that's where\r \r you could\r \r manually\r \r look at what you've messed up, which again, I often do and make the corrections,\r \r but there are ways that you can have something else scan your code and make your life a bit easier.\r \r\n\nAnd that, again, is our last, highlight for today. Another great blog post coming from the one and only Ma'al Salman who, again, has been a frequent contributor\r \r to the highlights for a very long time now where she talks about a really\r \r great way to get started\r \r with using\r \r winter, the winter package\r \r to get your code base up in tip top shape.\r \r And I admit when I first heard of linting, I didn't know what heads or tails this was all about. Now I'm starting to come around to it, but this is a post I wish I had seen years ago when I started to see this mention or I see this magical stuff being used in other people's dev sessions or selling their code with a keystroke just so it's perfect. And I'm like, how does that even work? Well, now we're gonna figure out how that works.\r \r So, again, the lint r package is what drives this in the r ecosystem, but many languages have equivalents\r \r in their in their, package ecosystems.\r \r\n\nThe first step is you need to tell winter what it's going to do, and that is through a configuration\r \r file.\r \r And so that is with the syntax\r \r name of dot winter. So it's by default a quote unquote hidden file. But if you put that at the root of the project that you're gonna use the linter on, you can then put different options\r \r here. And you can start by letting linter do everything it wants to do, and that's where in the snippet she has here\r \r in the post,\r \r there is a function called linters with tags,\r \r and tags is an optional parameter. If you make a null, it's gonna use everything,\r \r every check that it wants to do. And then also the encoding as well, which most of the time you can do UTF 8. Sorry for any Windows users that have to do something different in that, but that's usually what I stick with.\r \r\n\nAnd then once you have that,\r \r if, say, you're writing a package, like in the use case of this post,\r \r you wanna lint it. It's just lintrcoloncolonlint_package,\r \r and then it's gonna depend on the environment you're running in,\r \r say in RStudio ID, you're gonna get another tab appear next to your code or console\r \r where it'll highlight all the different issues that the linter has identified.\r \r And, yeah, yours truly sometimes has a long list of this, and I have to parse through this a little bit. So\r \r now you know what the issue is.\r \r What are you gonna do about it? So\r \r Miles outlines a few\r \r points here. Mike, why don't you take us through what you might wanna do once you found the problems?\r \r\n\n\n\n[00:32:45] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 45,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Once you've identified, you know, some of the problems,\r \r some of the things that you can do, I guess, for for one example that Mael\r \r provides here is is maybe you have a function that is is reading a super long path and sometimes,\r \r you know, hopefully, we're not doing too much of hard coding a specific path on our machine. We're using things like the here,\r \r the here package to be able to sort of build out that path, you know, relative\r \r to anyone else's system who might be running our code. But you can break that up instead of supplying that path directly within the function argument. You could define that path as a variable first\r \r and then pass that variable into the following function that is going to,\r \r you know,\r \r access that particular path or or apply the logic\r \r against that path. So it's it's interesting things like that, you know, some simple stuff that you can integrate.\r \r\n\nOne of the nice things,\r \r about the this linting functionality\r \r is that and I know that I always have, you know, particular edge cases in my code where maybe it's just not possible to get this line down to 80 characters, for example. Like, it's not feasible. I would have to use, you know, glue or or paste statements and it would start to get ugly and it's, you know, it's only 83 characters and it just really sort of makes sense to leave it the way it is. So if I wanna skip the linting for a particular line,\r \r you can actually add,\r \r this this string\r \r called no lint, and then the name of the linter exclusion\r \r to a specific line\r \r in your dotlinter file, I believe.\r \r\n\nOne of the cool things as well about the linter package is if I remember correctly\r \r that you can sort of set up,\r \r custom\r \r linting, you know, based upon\r \r the the styling\r \r guidelines that you might have internally.\r \r So, you know, depending on if you like your arguments written in wide format versus long format,\r \r there's only actually one correct answer there. It's long format but we could have a whole podcast about that sometime soon.\r \r So you you can do interesting things like that and then you know one of the I think final really nice things as well\r \r is the ability to,\r \r you know, put this all in a GitHub action for CICD purposes\r \r where you can just specifically lint\r \r changed files which is nice so that you're not running this CICD and spending your GitHub actions minutes\r \r on your entire,\r \r package repository or your entire just our repository if it's not necessarily a package but you can just run your linter against the new stuff,\r \r as part of your your CICD process and then\r \r get those warnings or corrections\r \r you know during that that pull request,\r \r before things end up in the main branch of your repository and headed to prod. I I think that's that's really interesting. It's something that we haven't leveraged\r \r at Catchbrook,\r \r before. You know, most of our,\r \r CICD is is just around either rebuilding the package down site or running unit tests, but but linting I think is a really cool additional additional use case for, you know, having these automated checks as part of your, you know, continuous integration workflows and I really appreciate my Elle\r \r calling out the ability, to be\r \r able to introduce,\r \r linting\r \r as part of your your CICD process\r \r and particularly only linting, the change stuff because that's something that we struggle with,\r \r as well on occasion is using up a lot of GitHub actions minutes,\r \r on code that's already been checked before.\r \r\n\n\n\n[00:36:13] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. One interesting thing about, you know, the relatively newer\r \r IDEs out there or new uses of IDEs out there is that even just writing our code itself depending on your settings,\r \r I'm thinking,\r \r of course, of the Versus code r extension,\r \r it will, by default, run linter already, and it will already highlight in your code where you're like, yeah, pass 80 character width or other things where things you're referencing a variable that hasn't been defined yet.\r \r And I admit there are times where, like, I don't wanna see that right away. I just wanted you to see that, like, maybe when I'm close to, like, my cleanup stage. So there there are ways that as as Mel's hotline here, you can turn certain checks off. I'm still getting to know, like, the best use cases of that\r \r for me. I admit I haven't put in GitHub actions yet because I always\r \r I don't wanna say I have trust issues, but it's like something that's gonna edit your code. You're kinda little nervous. Like, is it gonna get it right? When we just saw about the translation thing, it might not get all these translations correct. So but maybe I need to trust more. Trust the process as a old sports cliche goes.\r \r\n\n\n\n[00:37:21] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Me too, Eric. Yeah. It it's hard during development when you see, like, you know, in Versus Code,\r \r the the problems,\r \r panel. Right? Just just loaded down with all sorts of problems with the linting\r \r of your code and it can, you know cause you to to I guess spend some unnecessary\r \r time at the beginning of the process as opposed to doing that that final cleanup once things are in a better state. But maybe maybe that's just my workflow and maybe it's actually\r \r helpful to to rectify those things up front. So teach their own.\r \r\n\n[00:37:52] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. Exactly. I I still remember doing those,\r \r Twitch livestreams back in the day, and suddenly I'd boot up Versus Go and this file has, like, 10 or 20 these squigglies on their line. I'm like, oh, the poor the poor viewers are seeing my sloppy code. Oh, no. So then I quickly turn that winner off, and it looks like everything's perfect. Wink wink. Exactly. Not really.\r \r The they each your own. Exactly. But, yeah, as as always, the the tooling is there.\r \r It's your experience, right, how you wanna tweak it, but it's, again, great that we have all this at our disposal for sure. And we have a lot at our fingertips, if you will, when you look at the rest of the article we issued that Sam has curated for us. And we'll take a couple of minutes here for our additional fines.\r \r And a huge\r \r congratulations\r \r must go out to my\r \r fellow,\r \r members of the R Consortium\r \r submissions working group because\r \r the R Consortium submission pilot 3\r \r has officially been approved by the health authorities at the FDA.\r \r\n\nThis is monumental\r \r in this particular pilot.\r \r This was looking at the ways of using R\r \r to create what in the pharma industry we call\r \r ADaM datasets.\r \r That's a specific format that is kind of longitudinal\r \r in nature,\r \r but it's often a key intermediate\r \r layout that is used to populate,\r \r tables, figures, and listings that often go into our clinical study reports.\r \r So, again, a great way to show\r \r that, yes,\r \r we can use r in many aspects of the clinical submission process.\r \r This was certainly\r \r a key focus of my positconf talk on the efforts of Shiny and web assembly. But again, we're looking at all the different\r \r parts of a pharma\r \r submission process.\r \r\n\nAnd like always,\r \r they are all the materials are reproducible.\r \r All the materials are on GitHub. We wanna make sure it benefits\r \r all the entire industry.\r \r And again, we invite you to check out the blog post where it's got all the key contacts. I've been involved with this. So my thanks to everybody\r \r that led the project, go from the working group side\r \r and the regulator side. We could not do this without them. So, again, major congratulations.\r \r And that means I'm up next, so to speak. I'm on deck for pilot 4, so I'm super excited.\r \r\n\n[00:40:24] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Congratulations\r \r to everybody involved, Eric. That is monumental,\r \r really exciting to see, especially the industry that that you're working in really\r \r adopt are so heavily and, really sort of pushing the language to be able to to change the world in a lot of ways. So so that's fantastic. Really excited for you.\r \r One additional find that I had is\r \r a look what looks like a,\r \r you know, shiny live potentially app, that's hosted,\r \r by Sharon Machlis that she created,\r \r and it leverages\r \r the Artut API, which interacts with, Mastodon.\r \r And,\r \r what she has is a nice little interactive table here. It looks like d t,\r \r that posts that a list of all of the accounts\r \r on Mastodon\r \r that have made a post with the r stats hashtag at least twice in the last 30 days. So there's some familiar names on here.\r \r\n\nI see,\r \r I see Dirk Edelbuttel,\r \r Steven Sanderson,\r \r Luke Pembleton. I see a lot of folks that I follow in the r Kelly Baldwin data science community\r \r as well.\r \r So it's really cool little app to be able to explore\r \r and, I believe congratulations\r \r goes out to Sharon as well on her recent retirement, but it seems like she is not\r \r retiring from doing, continued r and data science exploration.\r \r\n\n[00:41:48] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I got credit to her. She's always been\r \r very, enlightening her her work to the fall, and she seems to be enjoying her next stage of life. And she was recently on the, data science hangouts with with Rachel and Libby this past week. So, hopefully, the recording of that will be out soon for those that weren't able to tune in live on that. But, yeah, I always like to see these great resources shared. Again, taking advantage of technology,\r \r things like, again, compiling Shiny into a web browser. You cannot have it better than that.\r \r And Exactly. There's a whole bunch of more to choose from in this issue. We wish we could talk about it all, but we got our\r \r our day jobs to get back to. But we're gonna leave you with our usual,\r \r where do you find all this? It's at rok.org.\r \r\n\nThe for the current issue is always at the home page. And, of course, the archive is available too if you wanna check all the back catalog out as well. It was searchable bar if you wanna search for specific topics as well.\r \r And this project is driven by the community, so we invite you\r \r to share that great resource you found online wherever you wrote it or you found someone else's great resource.\r \r Please give us a poll request, which is linked at the top right corner ataruk.org,\r \r all marked down all the time. You won't need a fancy API to translate that. Just put in your link. You are all set to go. We have the template right there for you. And as well, we love to hear from you in the audience that is we got a few ways of doing that. So you can get in touch with us, via the contact page, which is linked in the episode show notes in your favorite podcast player that you're listening on.\r \r You can also send us a fun little boost if you have a modern podcast app as well.\r \r\n\nYou can also get in touch with us on these social medias,\r \r and the aforementioned mastodon is where you'll find me the most. I am at our podcast at podcast index on social.\r \r You'll also find me on LinkedIn. Just search my name, and you'll find me there.\r \r And on the x thingy, occasionally, we've got the r cast. Mike, where can the listeners find you? Sure. You can find me on mastodon@mike_thomas@fostodon\r \r\n\n[00:43:54] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 54,
        "trans_speaker": "Mike Thomas",
        "trans_text": "dot org, or you can find me on LinkedIn. If you search Catchbrook Analytics,\r \r k e t c h b r o o k, you can see what I'm up to.\r \r\n\n[00:44:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Very good. And, yeah, you got a lot of things cooking, man. It must have taken a lot of time to write all those quarter reports.\r \r Great job nonetheless.\r \r\n\n[00:44:10] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 10,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Thank goodness, for parameterization.\r \r\n\n[00:44:13] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Let's just put it that way. Oh, yeah. That was a hot topic on the last episode if you wanna listen to that as well. Yep. I've been using that a lot in my day job too. I cannot live without it. So\r \r we can't prioritize everything in our life, but we can prioritize reports. So\r \r with that, we're gonna close-up shop here again. Great to have you back in the saddle once again, Mike. It's great to not have to do this alone for a 3rd week in a row.\r \r\n\n[00:44:40] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Mike Thomas",
        "trans_text": "No. I'm back for a while now. That's awesome.\r \r\n\n[00:44:43] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome. Yeah. Exactly. So we're gonna close-up shop here, and I'll do it for episode 177\r \r of our weekly highlights. And we'll be back with episode 178\r \r of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_36_highlights",
        "chap_timestamp": 27,
        "chap_text": "Mike's posit::conf takeaways",
        "chap_href": "https://blog.r-project.org/2024/08/30/long-input-lines/"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "chap_timestamp": 27,
        "chap_text": "Long lines of code",
        "chap_href": "https://edenian-prince.github.io/blog/posts/2024-08-21-translate-md-files/"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "chap_timestamp": 35,
        "chap_text": "Translating Quarto documents",
        "chap_href": "https://masalmon.eu/2024/08/28/lintr-3-steps/"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "chap_timestamp": 28,
        "chap_text": "Lint-free with lintr",
        "chap_href": "https://www.r-consortium.org/blog/2024/08/26/news-from-r-submissions-working-group-pilot-3-successfully-reviewed-by-fda"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "chap_timestamp": 36,
        "chap_text": "R Submission Pilot 3 Approved!",
        "chap_href": "https://apps.machlis.com/shiny/rstats/"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "chap_timestamp": 44,
        "chap_text": "Mastodon #rstats postings"
      },
      {
        "ep_name": "issue_2024_w_36_highlights",
        "chap_timestamp": 19,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_35_highlights",
        "ep_date": "2024-08-28",
        "ep_duration": 31,
        "ep_description_short": "A few tools you can use to find those elusive bottlenecks in Shiny app performance, adding a dash of interactivity to a reactable table, and save yourself many hours of manual effort with Quarto parameterized reporting. Episode Links This week's curator: Colin Fay - @[email protected] [@ColinFay]](https://twitter.com/ColinFay)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_35_highlights",
        "description_long": "\r \r A few tools you can use to find those elusive bottlenecks in Shiny app performance, adding a dash of interactivity to a reactable table, and save yourself many hours of manual effort with Quarto parameterized reporting.\nEpisode Links\n\nThis week's curator: Colin Fay - @[email protected] [@ColinFay]](https://twitter.com/ColinFay) (X/Twitter)\nUnveiling Bottlenecks (Part 2): A Deep Dive into Profiling Tools\\\nCreating interactive tables with reactable\nAutomating Quarto reports with parameters\nEntire issue available at rweekly.org/2024-W35\nSupplement Resources\n\n{golem} 0.5.0 is now available\nShiny Developer Series Episode 12: Reactlog with Barrett Schlerke https://shinydevseries.com/interview/ep012/ \nThe Coding Cats shop https://www.etsy.com/shop/thecodingcats/\nA visual journey through world exhibitions https://georgios.quarto.pub/a-visual-journey-through-world-exhibitions/\nSix ways to find better content on Mastodon https://www.infoworld.com/article/2338712/6-ways-to-find-better-content-on-mastodon.html\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nTails and the Music Maker - Picolescence - zircon - https://ocremix.org/remix/OCR02176\nThe Amazon Session - Ducktales - Gux - https://ocremix.org/remix/OCR00402"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://fosstodon.org/@colinfay"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://twitter.com/ColinFay)"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://www.appsilon.com/post/a-deep-dive-into-profiling-tools"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://albert-rapp.de/posts/28_reactable_intro/28_reactable_intro.html"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://posit.co/blog/parameterized-quarto/"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://rweekly.org/2024-W35.html"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://shinydevseries.com/interview/ep012/"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://www.etsy.com/shop/thecodingcats/"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://georgios.quarto.pub/a-visual-journey-through-world-exhibitions/"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://www.infoworld.com/article/2338712/6-ways-to-find-better-content-on-mastodon.html"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://ocremix.org/remix/OCR02176"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "links": "https://ocremix.org/remix/OCR00402"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_35_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back at episode 176\r \r of the Our Weekly Highlights podcast.\r \r This is the weekly podcast where we talk about the latest great resources that have been shared\r \r every single week at rweekly.org.\r \r It is basically your one stop shop for curated art content made by the community\r \r and for the community.\r \r My name is Eric Nantz, and I'm delighted you join us from wherever you are around the world in your favorite\r \r listening device or wherever you're tuning in.\r \r And, well, once again, I am flying the plane solo here again this week. Mike is still heads down on his, urgent project that he's tidying up now. Hopefully, he'll be back next week, and we can hear all about his adventures.\r \r But, nonetheless, we got some great highlights to talk about today, just you and me. We have a little cozy session here. But, of course, the Our Weekly Project itself is driven by the community\r \r in the form of our curators.\r \r\n\nAnd our curator this week was Colin Fay,\r \r the author and architect of all things Golem, which, by the way,\r \r congratulations.\r \r Go to Colin and his team, I think, are for the release of Golem version 0 dot 5 that just got released. We'll put a link to their announcement blog post in the episode show notes. But, nonetheless, he had tremendous help as always from our fellow, our weekly team members, and contributors like you around the world with your poll requests and other suggestions.\r \r Speaking of Shiny,\r \r have you been here before? If you create an application that's used by, say, more than just you,\r \r You get it done. You get it released. Everything seems fine,\r \r and then you get that user feedback.\r \r\n\nThis can be both a good thing and maybe not so good thing depending on your perspective.\r \r A lot of times in my experience, my feedback would be,\r \r you know what, Eric? The app looks good, but it's just kinda slow\r \r compared to some of the other ones I use.\r \r And I'm thinking to myself,\r \r boy,\r \r when did where did I go wrong? There wasn't anything completely obvious. Right?\r \r Well, sometimes that puts you in the situation of trying to get to the bottom of this because in the end,\r \r the user experience of your Shiny app is a critically important piece\r \r to, obviously, get your users on board and to make sure that the application\r \r is having a sustained life cycle, if you will.\r \r\n\nSo you wanna get to the bottom of this right, but you're not quite sure where to start because the term profiling\r \r may give you a little bit of fear and when you hear that,\r \r but no fear here. We got a great blog post that showcase a couple of different\r \r tools that you can utilize\r \r along with a new tool that I wasn't aware of to look at different aspects of your shiny ass performance.\r \r And in particular, we're gonna be talking about a blog post from the Appsilon blog\r \r that was authored by Harsh Verma, one of their data scientists and developers\r \r at Appsilon,\r \r where he is talking to us about\r \r the different ways that you can go about profiling\r \r that Shiny application\r \r that has given you maybe a little bit of performance fits, if you will.\r \r\n\nThere are a couple different perspectives that he highlights here. The first of which is trying to figure out just\r \r you made all those inputs, you know, the elements that you can use in your Shiny app to, like, you know, enter text, change the slider value,\r \r drop down menus, and whatnot that the user is interacting with.\r \r And, of course, those are probably going to feed into some type of outputs in your app, maybe a visualization,\r \r a table of data, which we'll hear more about later, and other, you know, output, maybe HTML widgets, for example.\r \r And in between, you probably have a set of what are called reactive objects that are helping\r \r kind of facilitate\r \r processing\r \r into objects that are gonna be continuously updated depending on, say, inputs that are changing or other factors that are going on on the client side.\r \r\n\nAnd as you build up more of these, it can be pretty easy to lose track of just what is actually connected to what and just how much you might say chatter is happening between\r \r the what the user sees and what the back end is producing to get to the outputs that the user sees.\r \r And that's where the first tool that Harsh,\r \r highlights here is the react log.\r \r The react log is something I hold close and dear to my shiny heart as a wonderful way to visualize\r \r this dependency graph of your inputs, your downstream reactives that are feeding into the outputs of your application.\r \r And trust me when I say, maybe it starts simple, but as you build the complexity, especially when you add modules in the mix, this can be a lot of things to keep track of. So the react log is a widget that will display,\r \r interactive\r \r flowchart of sorts\r \r where you can\r \r basically run the application\r \r in a typical flow,\r \r and then you can stop that and then put the react log in focus\r \r where it's going to let you traverse through that previous session where you were clicking inputs and then generating\r \r those outputs. So you've got a great way to kind of stop the steps, so to speak, so you can hone in on them further,\r \r and it's got all the connections between these inputs,\r \r reactives, and outputs\r \r in a very clear diagram. Again, highly interactive as well, so you can zoom in on certain points.\r \r\n\nYou can also filter based on different names of inputs.\r \r You get the state of the inputs such as whether they're ready for something new, whether they're actually calculating,\r \r or the process of invalidation\r \r where now they know something's wrong in that particular\r \r upstream dependency or should say outdated,\r \r so it's got to do some recalculation\r \r and whatnot.\r \r So this is a great way for you to see\r \r maybe you have a lot of reactive\r \r processing in between an input and a downstream output.\r \r Maybe there are opportunities to refine that a bit.\r \r And really seeing that that graph in front of you is a wonderful way to highlight\r \r just how complex that application's\r \r dependency graph has actually become.\r \r\n\nAnd, again, I hold the prof\r \r again, I hold the React log very close to my dev toolbox.\r \r And if you wanna hear more about react log itself over in this little, you know, few minute overview I gave you, you wanna tune in to a previous episode of the shiny developer series that we have linked to in the show notes where we sat down with the architect of the react log from the Shiny team, Barish Slurkey,\r \r for a really fun conversation about the enhancements he made to reactlog many years ago.\r \r Now that's great to kinda get the overall picture of your dependency\r \r layout in your application,\r \r But there's also the fact of, well, when you're actually doing the calculations,\r \r what's really going on in terms of resource usage and time spent?\r \r\n\nThat's where a professor is, another wonderful,\r \r package in the R community\r \r authored by Winston Chang, also a member of the shiny team. That's where it comes to play to really help you in these situations.\r \r It can be used for things things besides shiny apps, but it runs very nicely to shiny apps as well.\r \r The flame graph is a great way to see, you know, a snapshot\r \r of just the number of steps or functions that are actually being called in these different operations\r \r that you're running in your application\r \r and then seeing just how long they're taking because the the x axis, the horizontal axis\r \r of this flame graph is the time spent in this application\r \r to create or, you know, produce the result of that function call.\r \r\n\nAnd this is where you can maybe see,\r \r perhaps there's a, say, a data processing step that's just taking a lot of time\r \r and you can hone in on these different bars of these different pieces of your app functionality\r \r and start to see just what's really happening here. It's a great way to, again,\r \r pinpoint the bottlenecks\r \r and figuring out just how complex some of these operations actually happen to be.\r \r So a lot of times, the time spent is probably where you're gonna most focus on, but, again, it will have other outputs\r \r in terms of memory usage\r \r and other,\r \r number metrics that might be helpful to you.\r \r\n\nNow this isn't like an either or. I think they both complement each other quite well, and that's what Harsh,\r \r talks about in the middle of the post.\r \r There isn't really a thing about which one is better. It's more about these are giving you different perspectives\r \r on the complexity of your Shiny application from that dependency graph\r \r all to just what is actually happening when the code's being executed.\r \r And then his post concludes\r \r with a new tool, new to me for sure, called shiny dot TikTok.\r \r And this is not an R package.\r \r This is actually\r \r a JavaScript utility\r \r where you can simply include this into your application\r \r with simply a call\r \r to a JavaScript script that's linked to in the blog post as part of your\r \r way in Shiny where you can arbitrarily execute a JavaScript, you know, script file. You just feed in via the tags $script\r \r function call\r \r and feed in the actual,\r \r CDN link\r \r to this utility.\r \r\n\nAnd then once you have that in your app, you can just run your app as usual, say, in your local setup,\r \r do much like what I mentioned in the React log, just go through a typical usage.\r \r And then to view the output,\r \r you're gonna go into your browser's developer tools or browser tools, depending on which browser you're using.\r \r This is often what I'm using to look at the CSS\r \r behind certain elements, especially, you know, trying to theme things like my quartile presentations\r \r or for Shiny apps or bslib or whatnot.\r \r But there's also a JavaScript console in this browser tools\r \r where you can type in JavaScript commands on the fly.\r \r\n\nAnd so he's got a, you know, narrative here for which commands you can run here, such as\r \r showing all the measurements in this job that were produced by the JavaScript utility.\r \r You can download all these into a CSV if you wanna post process them into R or other languages,\r \r and you can get a nice summary\r \r report, also in HTML format,\r \r where you could look at that, you know, as a as a separate web page.\r \r And it's kinda like a hybrid of the flame graph from profit is,\r \r albeit it's,\r \r you know, a little more, you know, organized, a little more streamlined, you might say.\r \r But it's also got color coding based on what are the outputs,\r \r also for calculations\r \r that are happening on the server such as, like, you know, server side loading or whatnot,\r \r and then also custom message handlers, which you might be utilizing in your app. But that's an interesting way for you to kinda get a quick take on how long some of these processes are taking,\r \r kinda like emerging between the maybe not so much emerging between the React log and the prophys visualizer, but it's an interesting take on it none nonetheless.\r \r\n\nAnd what's nice is you could use this in your production apps.\r \r I don't believe it's causing a performance hit, although I haven't tried it yet. So you may wanna, you know, try that out yourself before you put it into production right away, but you can most certainly use this in a development version of your application locally as a quick way to get that, you know, more streamlined profiling output.\r \r So as always on our weekly highlights, I learn something new every time I talk about these great stories, so I will be adding\r \r shiny TikTok to my, developer toolbox alongside\r \r you know, again, much love to the react log package, and profit is has always been very\r \r illuminating in my, shiny profiling adventures.\r \r\n\nSo excellent blog post by Harsh, and, yeah, really looking forward to playing with shiny TikTok after this.\r \r You know, I can recall,\r \r you know, I would say many years ago as I was first getting into the art community, you know, fresh into my day job and fresh off my dissertation.\r \r In the way back years of, say, 2007,\r \r 2008.\r \r Again, to date myself, I've done that too much on this podcast episode already. Nonetheless,\r \r one of the things that was a bit of a challenge at the time\r \r was finding a really neat way to create polished looking tables\r \r outside of the typical Latex type setup. Nothing against Latex, but, it gave me, quite a bit of fits in my grad school days.\r \r\n\nYou fast forward to the today,\r \r and we have what I call an embarrassment of riches with how you can create really polished,\r \r aesthetically pleasing,\r \r powerful tables,\r \r both in the static format but also in the interactive\r \r format. And I'm really a big fan\r \r of the interactive format,\r \r hence I was, you know, psyched to give a submission to the recent POSITABLE contest of an interactive table.\r \r And the package that drove much of my contest submission\r \r was reactable.\r \r And it was a thrill to see or I should say, to meet the author of reactable, Greg Wynne.\r \r And it was a thrill to actually meet the author\r \r of reactable, Greg Lynn, from posit at the recent positconf. I just, you know, thanked him many times for reactable. I just had a tremendous time using it. So\r \r reactable\r \r gives you, again, yet another great way to create a\r \r really nice looking table in R,\r \r and our tutorial to talk about this of how to change it from a static representation\r \r to a very interactive\r \r table\r \r is coming from Albert Rapp,\r \r who returns to the highlights once again. It's been a little bit, Albert, but we're great to have you back on here.\r \r\n\nAnd he is a business analyst working on some really interesting AI and ML stuff, apparently.\r \r He's also producing great content on his YouTube channel, so you should check that out if you haven't already,\r \r but he wrote a recent blog post with an associated video tutorial\r \r on how you can create an interactive table of reactable with a few lines of code and some great examples throughout.\r \r You know, I I really love making tables in r. Some might say I am the table sometimes. That's a little inside joke for some of you. But, nonetheless, let's get right into it. Shall we? So as usual, let's find some fun data to put in this table.\r \r And even though it's not the focus of this tutorial,\r \r the GT pack is by Rich Yone. It has a great set of built in datasets,\r \r and, yes, it happens to be with maybe some of my favorite food, pizza, of course. So\r \r he's got, Albert sets up with the,\r \r a filter data set of this pizza place data set for the pizza sales from Hawaii.\r \r\n\nMan, that's on my bucket list to go to someday, maybe someday.\r \r Nonetheless, he does a little processing. We got a nice little tidy table here\r \r with the the sales by month and quarter,\r \r and the revenue that's being generated at that particular time.\r \r So\r \r what's nice is we just wanna get started right away with this tidy dataset.\r \r You just feed it into the reactable function.\r \r Feed in that dataset, and you've got yourself\r \r a nice interactive\r \r already kind of interactive table because\r \r in the blog post, you see this in action.\r \r It shows by default\r \r the first 10 rows, and there are actually 12 rows, one for each month. And you'll see at the bottom a toggle already go to the next set of rows,\r \r but Albert didn't have to write any code for that. It was already in the table function\r \r by reactable. So you already got a little interactivity along the way, but this is just using the default column name. So, of course, you might wanna\r \r spice things up a bit. So the first step is to add\r \r better, you know, human, you might say, human label\r \r type column names.\r \r\n\nNow this is where there is a contrast to the GT package where in GT, it very much follows follows a ggplot\r \r or piping kind of flow where you can iteratively\r \r modify or add to the elements of your table.\r \r With reactable, everything is basically done in one particular function call, but with parameters that\r \r have a lot of associated sub parameters or general structures inside.\r \r One of those is for the case of column labels,\r \r you wanna leverage the columns argument of reactable and feed in a list\r \r with each list element named to the particular column you wanna add an attribute to.\r \r So in this example\r \r he's adding\r \r the new names of these columns\r \r using what's called the caldef function, also part of reactable,\r \r where you can feed in different aspects that you want to tweak in this column, and in this case it's just tweaking the name of the column. So once you get the hang of that,\r \r very easy to now have nice nice looking labels\r \r in your table of column names.\r \r\n\nNow that's just the table on its own. Maybe you wanna start thinking about how you wanna publish this or share this with the community,\r \r so you wanna add a title and subtitle.\r \r There are ways in Reactable. If you know CSS and JavaScript, you can add almost anything you want to these tables,\r \r but there has been another great package in the r community\r \r that I've often used. In fact, I use this for my table contest submission as well.\r \r It is a, you might say, a\r \r an extension to reactable\r \r called\r \r reactable\r \r formatter or FMTR.\r \r I'm just spelling it out formatter there. And this package is authored by Kyle Kuiva. Hopefully, I'm saying that right. But he, or he or she\r \r but reactable formatter has a handy set of functions.\r \r\n\n2 of them are adding a title\r \r and adding a subtitle.\r \r And when you change the style, though, should you wish,\r \r whereas he's a or Robert is able to change,\r \r say, the font weight of the subtitle to not be bold, but to be a normal type weight of font. So we've got a nice title\r \r above the table.\r \r But if you look at the table in the post, you notice that the revenue column\r \r is not quite\r \r nice yet because it's in that typical decimal\r \r notation.\r \r But we're talking about money here in US dollars. That's what the data set's using.\r \r So in that cal def function, you you can change much more than just the name of a column.\r \r\n\nYou can also change the format of the cells, and that's using the cal format function\r \r where this could be anything from, like, a date or, in this case, currency,\r \r or even customizing\r \r a custom format of your own.\r \r So here, Albert just simply specifies as the USD for the currency, you know, type,\r \r and then to add separators, I e the comma the commas between each each three digit for larger revenue.\r \r And now you've got a table that has, you know, nicely formatted lined up\r \r values of revenue in that last column.\r \r Now as you look at this table, you notice that we know we don't just have month, we also have quarter as well.\r \r\n\nBut wouldn't it be nice to be able to let the user kinda toggle\r \r easy navigation\r \r between these groups? Maybe they're more interested\r \r in, say, the Q2 or the Q4 or whatnot.\r \r Well, reactable gives you a nice way to add groups,\r \r and, again,\r \r this could not be more simple\r \r in the reactable construct because there's a parameter called group by.\r \r You feed in the name of the column that you wanna use as your grouping,\r \r and right away, you'll see in the output\r \r from the blog post, you've got a nice\r \r collapsible\r \r element\r \r next to each quarter, a little caret arrow, if you will. You click on that, and now you've got the month sales and revenue showing up. And you can expand all of them, you can expand none of them. You get to choose, and now we have\r \r and now we have an even more interactive table for you to play with.\r \r\n\nLooking nice here. Right?\r \r Well, maybe let's take it up a notch if we wanna share this with, say, a stakeholder or the community.\r \r You might want some nice, you know, summaries for each of these\r \r quarters as well.\r \r And what can we do for that?\r \r Well,\r \r what we can do there\r \r is we can say, okay. In the quarter view, if everything collapsed,\r \r what if we wanna add all the values under sales so that that displays when it's, like, nested, but when you unnest it, then you get the individual values right below it.\r \r So that's where you can now add an aggregate\r \r call\r \r to that call def of the sales column,\r \r and you can choose which aggregation method you wanna do such as the average or mean or in this case a summarization\r \r or sum.\r \r\n\nSo that's great. Now you can have for each group the total sales\r \r showing up in that default view with everything collapsed.\r \r Again, we're talking about interactive tables. Right? Well, what if you wanna instead of point and clicking, you wanna filter\r \r for a particular month?\r \r Well, reactable, again,\r \r has a handy little parameter in calldef called filter\r \r easy for me to say. Has a handy little parameter in the calldef called filterable\r \r where you enable that toggle to true,\r \r and then that particular column now has a nice little text box right under the column heading\r \r where you can type in the name of a particular, say, month you want,\r \r and it will auto complete, or I should say dynamically update based on the first few letters.\r \r\n\nSo I just start typing j a, I'll immediately get January\r \r showing up under the quarter quarter 1, you know, grouping.\r \r Again,\r \r very easy way to add filtering elements right away. You could have done that with sales as well, but in the end, this is a great great little showcase of even more interactivity\r \r without any custom CSS or JavaScript required.\r \r Now hold that thought for a second because we're gonna dive into that a little bit here, because\r \r what if at the very bottom of this table\r \r you want, you know, a common question to be answered of just what is the exact total\r \r of all the years revenue\r \r and all the years sales.\r \r\n\nSo\r \r there is a way to do this a couple of different ways in reactable,\r \r one of which is adding a table footer\r \r using our code\r \r to basically cuss\r \r define a custom function\r \r that takes as inputs the values for that particular column\r \r and the name of it, if you wish. If you want to do some of it, you can.\r \r And that's where you can use any ordinary r function.\r \r In this case, he's using the sum function again to summarize all to add up all those revenue values. And then from the scales package, he's making sure that's represented in the near currency format using the scales dollar function.\r \r Again, that's based in r. That's not based in reactables\r \r formatting.\r \r\n\nAnd once you do that,\r \r yeah, it it does work,\r \r but there's a little nuance here.\r \r Let's say you wanna do that filtering after all. Maybe you wanna go to January\r \r instead using that annual text box filter.\r \r Well, you notice\r \r when you do that, that revenue summarization\r \r and that sales summarization\r \r does not change.\r \r It's not respecting\r \r that filter because that filter\r \r is being done in what we call client side interactions.\r \r The the summarization\r \r itself was computed ahead of time\r \r before\r \r the table was actually rendered.\r \r And unlike in Shiny, there's no, like, direct communication\r \r between\r \r what the user is doing on the filtering side\r \r and the underlying r function that created that summarization.\r \r\n\nWell, have no fear, folks. If you're willing to invest in a little JavaScript\r \r knowledge here,\r \r you can have a dynamically updating summarization\r \r with JavaScript code.\r \r Now this is where, you know, if you're new to JavaScript, it'll it'll look maybe a little different at first. But once you get the hang of it, I think you can do little basic things like this without too much trouble. But the example blog post, of course, has the code\r \r where Albert is defining a custom JavaScript function\r \r that initializes\r \r an empty total of 0. And then\r \r basically for each\r \r row that's currently present\r \r using this state object,\r \r again, the state is like what JavaScript sees is what the user is seeing in that table.\r \r\n\nSo for example, if they're creating a filter, they're just gonna see\r \r what that state object is just gonna represent,\r \r what is actually showing on that table. Great. So he takes that and then for each\r \r of the rows that are in that state of the filter,\r \r he's gonna add up\r \r the values based on the column ID that's being supplied here and then return that total. So he does that for both the sales and the revenue\r \r along with some formatting of the revenue using some JavaScript,\r \r you know, functions as well, which, again, you can see in the show note I mean, in the blog post.\r \r And there you go. Now when you do that filtering, I'll even type it while I'm recording here.\r \r\n\nSure enough, when I filter for January,\r \r that total\r \r is now\r \r updating accordingly.\r \r So\r \r this is terrific.\r \r A terrific way to make sure\r \r that you get that shiny like experience, but again, this is all done in client side,\r \r and reactable\r \r has JavaScript bindings that you can customize\r \r as much or as little as you like.\r \r Lastly, speaking of making things look good,\r \r Albert wants to change\r \r the style\r \r of those, what I call, nested group rows\r \r versus\r \r the, you know,\r \r the rows of the actual data itself.\r \r His first attempt at this\r \r actually ends up coloring every row in the same color, which kind of defeats the purpose, doesn't it? But that's a artifact\r \r of using\r \r this row group this theme function\r \r with the reactable theme,\r \r function,\r \r and that,\r \r by proxy, is selecting every row for that theme. So, uh-oh, that's not quite good.\r \r\n\nWhat can we do differently? Well, again, we can go in the JavaScript world\r \r where he defines a JavaScript function to say, you know what?\r \r I'm gonna take\r \r the row\r \r itself, which is called row info. It's like metadata for the rows each in each of the in each of the table.\r \r And for each of these groups, that first row,\r \r which is just showing the quarter name\r \r and whatnot,\r \r that's level 0. Remember, JavaScript index start at 0, not 1 like an r, so that might trip you up a bit. But he's saying if that level is 0 that's being shown,\r \r then do the custom background on the cell, you know, color.\r \r\n\nOtherwise, leave the rest the heck alone. And sure enough, at the end product,\r \r you've got those quarter rows\r \r with that nice little, you know, shading so you can quickly visually distinguish those from the actual data cells as well.\r \r And last but not least, he does a little change up to the style of the footer,\r \r and this is again\r \r very simple to do.\r \r Again, a little bit of,\r \r CSS\r \r demonstrated here\r \r where you can add a footer style with custom CSS\r \r function from the HTML tools package, or you can give it, like, the font weight, and in this case a little line at the top called border top. So you can quickly see just like you might be writing this on paper, putting a line\r \r under the numbers you're calculating, and then making sure that visually pops out.\r \r\n\nSo again, a tour de force of how you can take\r \r a native reactable table that just comes with that data frame being fed into it,\r \r all the way to a very nice, polished, and again highly interactive,\r \r multiple levels,\r \r table for you to look at.\r \r Again, reactable and GT,\r \r wonderful packages for creating tables. Albert's been doing a lot of content on each of these, so you wanna check out the archive of his post\r \r for of his blog, I should say, for many of our posts that talk about using these these great packages in action. So I am\r \r thrilled thrilled to see this.\r \r\n\nAnd rounding out our highlights today is another great showcase of another awesome piece of technology\r \r using a framework that's quite familiar to those that have been in the R Markdown ecosystem to save you a bunch of time and a lot of future effort. And, yeah, I think future you will thank you for investing in such techniques.\r \r We are specifically speaking about the Quarto publication system, which has been a hot topic ever since it was announced at Posiconf back earlier\r \r in 2022. I can't believe it's been that long, but, yeah, Quartle has been around a little bit already.\r \r And in particular,\r \r it has a lot of functionalities\r \r under the hood, but one of those which is definitely been inspired by the R Markdown predecessor\r \r is the idea of creating parameterized\r \r reports,\r \r in that you can\r \r compile\r \r a report\r \r and feed into it a set of values, I e parameters,\r \r to maybe update or dynamically change some content depending on those parameters.\r \r\n\nAnd one of the real innovative thought leaders in this space of taking advantage of parameterized\r \r reporting\r \r from the Rmarkdown ecosystem and now Quartal\r \r is the author of this latest blog post on deposit blog, JD Ryan, who has had quite a career transition, I must say, as she has gone\r \r from being literally in the field or you might say in the streams\r \r working in the Washington State Department of Agriculture\r \r as an environmental technician, and now she is leveraging her data science skills more in the, I guess, an office type environment.\r \r But I had the great pleasure of seeing JD again at the aforementioned positconf earlier this month,\r \r and I must say for the many conversations we had, whether it was at the data science hangout or, you know, here pepping me up for my talk or even afterwards as the\r \r conference is winding down.\r \r\n\nYeah. Her, her energy is infectious and,\r \r sometimes I wonder where did I get that energy? Where can I get that? That fountain of youth that she seems to be drinking from? But nonetheless,\r \r it was great to touch base with her and and yes, she was kind enough to give me a little sticker too. And by the way, if you want some awesome swag, if you're a cats lover like she and I are and you want to flaunt R at the same time, you want to check out her awesome little shop on Etsy, which I'll link to in the show notes. Nonetheless,\r \r JD has been in this, world of creating privatized reports\r \r for quite some time,\r \r and she mentions\r \r how much it's been extremely helpful as she was transitioning\r \r to her data science role\r \r in terms of creating\r \r in upwards of hundreds of these reports\r \r for farmers across the area\r \r based on their particular data needs.\r \r\n\nAnd instead of hard coding all this 1 by 1 for, like I said, over 300 of these,\r \r she was able to leverage the parameter\r \r equals the parameter functionality\r \r to create both interactive\r \r and static or PDF versions of these reports and have them dynamically render\r \r in a batch setting.\r \r So how do you actually get there? That's where the meat of the post dives in here,\r \r where there are different kind of high level goals that\r \r you want to look at depending on how far you want to take it.\r \r Obviously, if you only have a few reports, maybe maybe manual is the better ever for you, and that might be might be what you're used to. But then,\r \r as like I said, the scale starts to escalate.\r \r\n\nIf you find yourself regenerating a lot of these things manually, that's when you're on and start investing into\r \r the idea of parameterized reports.\r \r So how do they actually work? Well, no matter if you're doing a report based in r\r \r or based in Python,\r \r you will have a capacity\r \r to be able to specify these parameters\r \r either\r \r in the front matter YAML of that quartile report if you're leveraging the knitter engine, I. E. Using r,\r \r or if you're in the Jupyter setting, if you're leveraging Python,\r \r you can do a specific code chunk\r \r with a optional,\r \r tag attribute\r \r called parameters, and you can literally just type in the values 1 by 1.\r \r\n\nObviously,\r \r the parameter values are more optimized for, you know,\r \r textual type parameters, maybe numbers.\r \r You're probably not going to be able to use complex classes because it's got to be something that can be\r \r specified in text,\r \r by the renderer.\r \r But once you have that going and once you have those parameters defined,\r \r then you have many different ways\r \r to actually compile this.\r \r First of which is within a IDE like Rstudio or leveraging\r \r the quartile extension in Versus Code or positron,\r \r you can compile the report and it will use the default values of those parameters that you specified\r \r so you can get a feel for if the parameters are working as expected.\r \r\n\nAnd so another option\r \r is maybe you want to keep those default values as is, but you wanna experiment with changing maybe 1 or 2 of them.\r \r Well, quartile is not like a r package, like rmarkdown was. It is actually a utility,\r \r a software utility on its own with its own command line interface.\r \r So you can run the quartal\r \r render\r \r function\r \r and feed in the quartal markdown document, you might call it template,\r \r and then you can specify 1 or more parameter\r \r values\r \r with the dash capital p flag,\r \r and then give the name of the parameter, a colon, and then that parameter value.\r \r So that's a great way if you don't want to change your your default parameters and you want to get a quick take\r \r on maybe changing those parameters on the fly,\r \r you can quickly do that.\r \r\n\nOr if you don't want to type those command line flags,\r \r you could have a separate YAML file called params.\r \r Yaml,\r \r where then you can simply put them much like you would in that frontliner. Yaml for the default parameter settings,\r \r and just in the Kortal renderer call\r \r use the dash dash execute dash params\r \r flag,\r \r feed in that YAML, and now you've got again that that report\r \r compiled using those new values.\r \r And there is more, of course. If you are in the R ecosystem,\r \r there is the quartal R package, which again is not the quartal engine itself, it's just you can think of it as like an API type package\r \r to the quartal static rendering engine,\r \r where then that has an execute underscore params argument, and you can feed the parameters\r \r as a list object,\r \r and then feeding it as input the name of the file that you're going to render.\r \r\n\nSo you could do that from R itself, and now the wheels are probably turning here. You got all these different ways of executing\r \r and compiling the report with parameters.\r \r What are ways you can actually automate that? Well,\r \r there are a few techniques here and I've used a couple of these already, but they're they're really,\r \r really solid.\r \r One of which is to have a data frame\r \r which has all the combinations\r \r of the parameters that you're interested in rendering\r \r as each row.\r \r So in her example, she's got a year, a producer ID,\r \r and literally does a expand grid\r \r of these 2 year values and 4 ID values, and you'll get then this, 8 row data frame\r \r with each of those parameter combinations.\r \r\n\nThat's pretty straightforward, and what you do with that is you can augment then\r \r the different output formats you want. Maybe it's HTML,\r \r and then the actual file name using a little paste magic,\r \r and then\r \r you can have then a nested column\r \r that has\r \r these parameter\r \r values as lists, I. E. The columns that are already in this data frame,\r \r and make it a named list. And she's got a nice little snippet of code that does this with the purrr package,\r \r another one I simply can't live without, and again,\r \r if you love your cats, then how can you not love the purr package? So it seems like fit for purpose here.\r \r Then once you have that, then you can have a customized tidy\r \r kind of data frame organized by 1 row per iteration,\r \r and then back to purr you can use the handy function called p walk\r \r which you can feed in the data frame itself\r \r and then\r \r that basically means that each column of the data frame is like a function parameter\r \r That can get fed into the quartal render function,\r \r and those parameters\r \r are going to be fed very clearly,\r \r as named arguments.\r \r\n\nSo again this may take a little getting used to, but again you can leverage her snippets of code that she has in the post and try it out for yourself,\r \r and this can be part of a larger scale pipeline.\r \r Just imagine that you want to do these on a routine basis, you know, you can find ways to automate this.\r \r Heck, you you know, quarto is a first class citizen output format of the targets package that I speak so highly about. You could lever something like this in your targets reports as well. There are lots of interesting ways\r \r you can use this, technique,\r \r again, to save you a boatload of time and effort\r \r in the future.\r \r\n\nSo JD definitely has a lot more materials than what this blog post has here, and she's done a workshop about this in the past. She's done a presentation at Pazitconf,\r \r last year about this workflow and how it applied to her daily work. So, yeah, you'll be invited to check those out as well\r \r And again,\r \r love love the cat pics in this. I got it. Yeah. Makes me miss my cats from the yesteryear. But nonetheless,\r \r really great blog post by JD here. You can tell it's got all the bells and whistles of quarto itself in the blog post because it got\r \r nice little tabbed interface to go from the r snippet\r \r for that automated execution\r \r to a bash scripting,\r \r which links to another blog post by Solomon Moon who talks about how you can do this in a bash script. So again, whatever your flavor is, you've she's got you covered with different examples here.\r \r\n\nAnd if that wasn't enough, boy, this issue has got a whole bunch in here that we wish we could cover today, and on in its entirety, but, yeah, time's not unlimited, unfortunately.\r \r But you can find all the additional resources at roku.org,\r \r and we'll take a minute here to talk about one of my additional finds that I think, might be worth looking at as you listen to the show and afterwards.\r \r And we heard announced at Posicomp in one of the talks\r \r a wonderful new extension for Quartle\r \r called Close Read.\r \r And what this is giving you is a way to have that kind of scrolly telling functionality\r \r in your quarter report that you often see in these websites that are kind of this hybrid of infographics\r \r and other, you know, neat neat utilities.\r \r\n\nAnd the way you scroll through it, it kinda updates the content dynamically based on where you're at. It maybe freezes certain elements.\r \r Well, this this extension, Close Read,\r \r is\r \r really really great in this space. We haven't really had any we've had attempts at this before in the art community, but I think this one really nails it.\r \r So this, link is from Georgios\r \r Cameronis.\r \r I believe he also gave a talk at Posikov\r \r and this is a visual journey\r \r through world exhibitions\r \r and you kinda have to see it to believe it. I can't do enough,\r \r you know, enough justice on the audio form,\r \r but it's got this great interactive map that depending on where you're going in the story,\r \r it's gonna zoom in on different regions\r \r wherein it talks about the narrative behind these different exhibits.\r \r\n\nIt'll splice in some authentic pictures from these exhibits,\r \r but it's a great showcase of what is possible with close read and I am definitely\r \r going to take a look at this as I think about content that can be engaging\r \r to different audiences.\r \r I mean, gosh, my wish is I could do something like this in life sciences. I'm not sure if that type of material would be fit for it. Hey, you never know. Maybe so. But maybe I could find some other uses for it. But, Close Read\r \r is still early days, but it looks like a few people are already putting it through the paces.\r \r In fact, I saw another contributor to our weekly,\r \r highlights in the past, Nicole Raney\r \r has also done an example of her tidy Tuesday visualization\r \r in a close read document as well. We'll have a link to that in the show notes. So starting to see it in the wild, and I'm definitely interested in seeing where the uses of that extension end up going.\r \r\n\nAnd yeah, like I said, there's a lot more to this issue, but we're gonna have to wrap things up here as as we're winding down. But of course, I like to always close with telling you how you can get involved to help the project, as well as this very podcast.\r \r First, where can you get involved with our weekly? Well, again, visit our weekly dotorg,\r \r and we welcome all your contributions\r \r to that great new blog post showcasing R and Data Science,\r \r maybe a great new package that you discovered or something that's had a new release,\r \r a great workshop tutorial, or maybe another podcast or videos out there.\r \r\n\nEither way, there are different categories for each of these type of content,\r \r and the best way to do that is via a pull request already linked in the top right corner in that handy little ribbon on the Our Weekly site. You click that, you'll be taken to a predefined template. You'll fill out a little bit of metadata,\r \r and all we need is a link, all marked down all the time. Just like when you're writing that fancy quartile parameterized\r \r report, you use a markdown for that too.\r \r So we invite you to share your resources on there and the curator of the week will be glad to merge that in.\r \r And also, we are definitely open for a curator spots as well. We would love to hear from you on that front.\r \r\n\nWe have details on the process at rweekly.org,\r \r and that will take you to the GitHub repo where you have a nice reading that's been put together about how to get involved on the curation front.\r \r And also we'd love to hear from you on this very podcast, so we have a little contact page directly in the show notes\r \r that you can you can use to quickly send myself and Mike a message.\r \r You can also, if you're on a modern podcast app, some of my favorites are Podverse and Fountain.\r \r Also\r \r for iOS users, Casa Mac, I hear great things about.\r \r With one of those apps, you can send us a fun little boost along the way that goes directly to us on the on the podcast team and no middle party involved.\r \r\n\nSo that's available as well, but also you can find me on these social medias out there.\r \r Mostly on Mastodon these days\r \r at our podcast at podcast index.social.\r \r And I did, have a good friend of mine on one of the other communities I'm part of\r \r trying to figure out the best way to get started with Mastodon.\r \r If that is something you as well are trying to get into, I'll put a link to a couple,\r \r great write ups that I found helpful in the community. If you're new to your Mastodon journey, because I'm starting to see a lot of my friends from data science and the art community are starting to get on Mastodon,\r \r but the key is finding the best way to get in touch with them so you can find their content. So I have some resources about that in the show notes of this episode.\r \r\n\nYou can also find me on LinkedIn as well. Just search for my name and you'll find me on there\r \r and somewhat sporadically on the weapon x thingy with at the r cast.\r \r Well, that'll do it for this episode of Rookery Highways. Can't believe we're at episode\r \r 176 already.\r \r Gosh. We're 200 is not that far away, so hopefully we'll get there. One way or another, I hope. But again, next week I hope to have my trusty companion here, Mike, back on the mic with me, so that will be, you know, a welcome change instead of just hearing me blab all by myself.\r \r In any event, we're gonna close-up shop here that will wrap up episode\r \r 176 of our weekly highlights\r \r and we'll be back with a new episode\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_35_highlights",
        "chap_timestamp": 29,
        "chap_text": "Shiny profiling tools",
        "chap_href": "https://www.appsilon.com/post/a-deep-dive-into-profiling-tools"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "chap_timestamp": 29,
        "chap_text": "Interactive reactable tables",
        "chap_href": "https://albert-rapp.de/posts/28_reactable_intro/28_reactable_intro.html"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "chap_timestamp": 49,
        "chap_text": "Parameterized Quarto reports",
        "chap_href": "https://posit.co/blog/parameterized-quarto/"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "chap_timestamp": 55,
        "chap_text": "Visual journey of world exhibitions",
        "chap_href": "https://georgios.quarto.pub/a-visual-journey-through-world-exhibitions/"
      },
      {
        "ep_name": "issue_2024_w_35_highlights",
        "chap_timestamp": 5,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_34_highlights",
        "ep_date": "2024-08-21",
        "ep_duration": 2,
        "ep_description_short": "Eric flies solo for this episode with a recap of his positconf 2024 adventures! Also how not to panic when you see a merge conflict in Git, the genesis of the new R ARUG community in India, and a great primer on creating your own Quarto templates. Episode Links This week's curator: Eric Nantz: @[email protected] (Mastodon) and @theRcast…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_34_highlights",
        "description_long": "\r \r Eric flies solo for this episode with a recap of his positconf 2024 adventures! Also how not to panic when you see a merge conflict in Git, the genesis of the new R ARUG community in India, and a great primer on creating your own Quarto templates.\nEpisode Links\n\nThis week's curator: Eric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nPlease let me merge before I start crying and other things I've said at the Git terminal\nA New R Community in Ahmedabad, India, focused on Clinical Research and Pharmaceutical Industries\nDesigning and deploying internal Quarto templates\nEntire issue available at rweekly.org/2024-W34\nSupplement Resources\n\nShiny-based clinical submissions using WebAssembly https://rpodcast.github.io/shiny-webr-posit2024/#/section\nIntroducing saperlipopette, a package to practice Git! https://masalmon.eu/2024/01/18/saperlipopette-package-practice-git/\nNORC crime tracker Shiny app https://livecrimetracker.norc.org/#home\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nYou Are Not Confined - Final Fantasy IX - Sonicade - https://ocremix.org/remix/OCR01064\nSeven Pipes to Heaven - Super Mario Land - Nostalvania - https://ocremix.org/remix/OCR03256"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://meghansaha.github.io/please_let_me_merge/"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://www.r-consortium.org/blog/2024/08/12/a-new-r-community-in-ahmedabad-india-focused-on-clinical-research-and-pharmaceutical-industries"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://meghan.rbind.io/blog/2024-08-14-quarto-templates/"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://rweekly.org/2024-W34.html"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://rpodcast.github.io/shiny-webr-posit2024/#/section"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://masalmon.eu/2024/01/18/saperlipopette-package-practice-git/"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://livecrimetracker.norc.org/#home"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://ocremix.org/remix/OCR01064"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "links": "https://ocremix.org/remix/OCR03256"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_34_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back of episode 174 of the Our Weekly Highlights podcast.\r \r My name is Eric Nance, and I'm so delighted you joined us from wherever you are around\r \r around the world on your favorite podcast player or other media device.\r \r This is the weekly show where we talk about the latest happenings and resources\r \r that are shared every single week on the rweekly.org\r \r site.\r \r And, again, my name is Eric, and this is usually the part where I tell you I really don't do this alone anymore. But, unfortunately,\r \r I am flying solo today because my awesome co host, Mike Thomas,\r \r is cranking on on a tight deadline. He's he's creating some, sure, very innovative solutions with VAR and probably Shiny involved. But he's heads down with that, so he's not able to join us this week. Then he'll be back soon enough. And with the week off that we had last week, I wanted to make sure we got an episode out to you this week. So, yeah, I am fine solo, but this was a rather unique situation where,\r \r yeah, guess who the curator is. It was yours truly. Yay.\r \r\n\nAnd it just so happened to be the week that I was at Positconf,\r \r which is actually gonna be when I first talked to you about here. And, by the way, if you're listening to this show on one of the more modern podcast players, you may notice that we have chapter markers inside. So if you're not as interested in learning about my experience at POSITCONF, feel free to skip over to the next section. But since it's fresh off, my week at POSITCONF, I wanted to take a few minutes to share some of my takeaways and just my overall experience.\r \r First of all, yep, Seattle was a nice area. I've never been there before, but, yeah, the Pacific Northwest was was quite nice on the ice, so to speak, and had relatively\r \r smooth travel there. And right away, I was,\r \r you know, pretty busy, I must say.\r \r\n\nMy first day,\r \r I guess, conference related, if you will, was attending\r \r what we call the r pharma\r \r summit,\r \r which happened last year at PasaComp, but I could not join because I was actually teaching a workshop about Shiny with my co host, Mike,\r \r last year, which again was very well received. But\r \r this time around, they had the\r \r summit the day before workshop. So\r \r then a lot of my colleagues are in the pharma industry that I've been collaborating with quite a bit with the r pharma conference and my efforts of the submissions working group and whatnot,\r \r and it was, very nice to collaborate\r \r on some potential new project ideas,\r \r going over some new things that we can do with Shiny\r \r in the clinical space,\r \r and things we can do with data formats and package validations\r \r and qualifications\r \r as a whole. So\r \r great shout out to all my our pharma peeps that were there, lots of great ideas\r \r and had a lot of engagement to pursue some\r \r new adventures that you may be hearing about very soon from yours truly.\r \r\n\nSo then the next day was the workshop day, and\r \r I have been enamored with the DuckDV\r \r database system, which you've heard us mention in many highlights of this year and last year.\r \r So I was thrilled to be given the opportunity to learn at a workshop this time around\r \r led by Kyro Muir who is the lead of Syncra Research,\r \r a consulting firm\r \r in Europe, and\r \r he is\r \r such a wizard with databases.\r \r Some of you know that he has spearheaded\r \r many of the R database packages. He's actually worked with the R Consortium\r \r to get funding for that effort,\r \r and it was\r \r thrilled to see him\r \r lay out some of the basics, but also some of the advanced features that DuckDV\r \r offers you as an R user, data scientists,\r \r trying to analyze large datasets,\r \r and I am\r \r more than ever convinced\r \r that this is a tooling that I need to pay attention to, and I want to start implementing in my future projects. So the workshop was awesome. A great mix of lectures and hands on exercises.\r \r\n\nYou know sometimes cliche but Wi Fi issues hampered us for the first hour but I was a good little student if you will and downloaded all the materials beforehand\r \r and was able to get it working\r \r on positron no less I decided to live dangerously\r \r and use positron\r \r beta version as, like, the IDE for working on the workshop exercises,\r \r and I've done a little bit of quirks here and there and actually performed quite well.\r \r So that was a good way for me to test the waters of Positron\r \r in a, real applied setting. So\r \r I'll definitely have more thoughts on that as I get more use of it, but, overall, again, the workshop was spectacular\r \r and DuckDV is definitely going into my toolbox very, very soon.\r \r\n\nAnd on to the main conference itself. So yours truly had the pleasure of giving a a talk about my adventures of WebAssembly\r \r and Shiny\r \r in the context of my efforts of the r consortium\r \r submissions working group.\r \r It was early in the conference. It was right after the first keynote and one of the first sessions,\r \r which had the awesome name of\r \r drugs not bugs,\r \r you know, efficient uses of orange and Python in in clinical work.\r \r And, again, really really fun presentation.\r \r I hope it was well received. It seemed like it was.\r \r Definitely had more of a story to tell in the initial goings, but my main point I wanted to articulate\r \r was that this is a fundamental\r \r paradigm, you know, shift in technology that I think can really supercharge\r \r many efforts were tedious\r \r static reports of some nature\r \r could be made interactive and shared efficiently\r \r across, let's say, different reviewers or different audiences.\r \r\n\nSo I was thrilled to be given the opportunity and, certainly, my thanks to Pazit for\r \r accepting my abstract and letting me be a part of this session.\r \r Had a really good turnout in the room.\r \r Lots of great questions both, in the q and a panel as well as afterwards.\r \r So, again, huge thanks to everybody that listened there live, and the recordings will be out fairly soon. And I can't wait to share that with all of you.\r \r Nonetheless, I will put a link to my slides in the show notes in case you wanna look at that before the recording. It's got some nice links to\r \r the GitHub repository\r \r and whatnot that I've created\r \r for the projects, and like I alluded to in the presentation,\r \r there's much more to come in this space as we finalize our submission to the FDA, as well as our adventures with the container piece of the submissions working group pilot\r \r as well.\r \r\n\nSo, yeah. 1 then I could breathe again so to speak with the presentation done and I attended many talks and, you know, as usual it's hard to choose and you got a lot of good talks happening at the same time.\r \r I've learned some great new things about Shiny development that I'm gonna take back in my\r \r my work, especially with some production apps I'm working on currently.\r \r Some good best practices of user interfaces\r \r and other great tooling that I think I'm gonna adopt quite quite soon in terms of structure\r \r and ways I organize some of my files and whatnot. Lots of\r \r good content as well.\r \r\n\nAnd, honestly, one of the best features of these,\r \r conferences is the hallway conversation. So\r \r lots of great conversations both with my fellow compatriots in life sciences, but also\r \r listeners out there that are fans of this very podcast that came to say hi and I was very\r \r appreciative of that. It's always humbling\r \r to hear that this little humble effort that myself and Mike lead here is, helping people in their data science journeys\r \r That never gets old no matter how long I've been doing something like this,\r \r and having that feedback is a great way to keep motivated\r \r and keep going with this effort.\r \r\n\nSo I met a lot of new faces as well.\r \r I met, Colin Gipsy from jumping rivers. He was there at the conference. I had lots of great conversations with him.\r \r And, also, I was thrilled to meet Charlie Gao who had a joint presentation with my teammate, Will Landau,\r \r on the use of Mirai and crew for high performance computing\r \r and asynchronous processing.\r \r Wow. It was an awesome presentation. I can't wait for that recording to go out because Charlie and Will absolutely knocked that one out of the park and it was just the enthusiasm was infectious when you can see them talking about this, great tooling that they've been working on and, yeah, I was just kind of beaming with pride in the audience there where I barely found the seat it was almost standing room only so lots of lots of excitement in this space. So credit to Charlie and Will for a fantastic talk there. But, yeah, it was an absolute thrill to meet Charlie in person as well and met many other many other people I've seen online, you know, lots of great conversations and in fact we had\r \r a mini reunion of sorts of our streamer group. The the group of including Tan Ho,\r \r Daniel,\r \r Kyle, and others,\r \r and Jeremy as well from posit. We we met him for for the first time in person.\r \r\n\nIt was great, great to catch up on memories even though we've\r \r all, for better or worse, have not been able to stream as much as we would like\r \r since those early days of the streaming during the COVID pandemic.\r \r Nonetheless, it was great to catch up on memories and see what they're all up to and, yeah, lots of lots of fun time to be had in those\r \r conversations as well.\r \r And certainly, yeah, the conference kind of flew by at that point. And before I know it, I'm flying out early Thursday morning back here to the Midwest.\r \r That was a early early flight\r \r so that day was kind of foggy, but I was already\r \r looking at my notes of things I want to research when I get back, and I'm already doing that research\r \r as of now. So lots\r \r of overall a really great experience, and next year it will be in Atlanta,\r \r I think, for the first time.\r \r\n\nSo who knows what my adventures will lead to in terms of that conference. However, I'll be given another talk, maybe another workshop. You never know. But, nonetheless, it was a great experience.\r \r Again, I think my biggest takeaways are catching up with some of my my good friends from online, as well as meeting some new faces as well, and, yeah, some really spectacular talks\r \r and offer conversations throughout. So\r \r again, the recording should be out hopefully in a couple months, and you can bet that our week we will be featuring those when they are released.\r \r Well, enough of my positconf wrap up, and certainly when Mike rejoins us on the podcast we'll be sure to get his takeaways from his\r \r experience, and it was always fun to meet with him as well. We don't get to meet face to face often enough. We haven't met since last year at the conference, so it was great to catch up with him as well.\r \r\n\nWell, without further ado, let's dive into\r \r our actual r weekly issue. And as I mentioned earlier,\r \r it was curated by yours truly, but thank goodness we have some great tooling and automation to put the post together.\r \r So I had tremendous help from our fellow Arruku team members\r \r and contributors like you all around the world with your poll requests and suggestions.\r \r Our first highlight to discuss today is actually stemming from the aforementioned PosiConf\r \r and one of the talks that I could not see live,\r \r but I was able to catch the special, you might say, sneak peek at the recording.\r \r And it is a topic that if you've been developing our code for a little bit, whether\r \r solo or in an organization with team members,\r \r you're likely leveraging version control.\r \r\n\nHow you leverage it, you know, that can vary across the spectrum, whether you're, you know, a git wizard or you're just doing enough to get that commit up to GitHub so to speak but our first, highlight today is a presentation from Megan Harris\r \r who is a data scientist at the prostate cancer clinical trials consortium\r \r and in fact she was also one of these students at the database workshop I remember she was sitting in the front row where I was close to but in any event\r \r her talk\r \r was titled\r \r please let me merge before I start crying\r \r and other things I've said at the git terminal.\r \r\n\nYeah. I feel seen with my early days will get when I read that title.\r \r So, obviously, when you see the recording of this, you'll get a lot more of the I'll call the first half of the presentation.\r \r We got the links of the slides in the show notes. And, by the way, Megan,\r \r you are\r \r easily one of the top, like, slide crafters I've ever seen with quartile.\r \r These slides need to be seen to be believed. It's a great mix of visuals\r \r and just\r \r really gets to the point of what she's trying to address. But, yeah, really in great engaging talk.\r \r And some of the takeaways I'll call out as I as I saw the talk and thought about how it relates to my journey we get.\r \r\n\nThe biggest thing is that it is easy, especially if you're new to this,\r \r that when you encounter an issue we get\r \r to kind of almost freeze a bit and might have, like, a panic moment of figuring out\r \r what did I just break and more importantly,\r \r how the heck do I get out of this emergency\r \r situation.\r \r But one of Megan's big talking points here is that there really aren't a lot of emergency\r \r situations we'll get.\r \r You can handle this. You just gotta kind of step back, calm down,\r \r and, you know, leverage some practical tips\r \r to get through\r \r situations such as merge conflicts.\r \r\n\nSo she does a great job in this in this presentation\r \r about,\r \r you know, just what exactly emerged conflict\r \r actually is\r \r and really giving you as the as a git user\r \r a few different ways that you can interact\r \r with trying to solve these merge conflicts.\r \r And, certainly, some of these\r \r are gonna be very basic, whether you're booting up a text editor,\r \r looking at the ways that a merge conflict is denoted,\r \r web what's the syntax for the branch that's trying to come in\r \r that particular side of development\r \r versus the branch is trying to merge into. There's different notation around how that looks and it can look very\r \r kind of cryptic at first, but once you get the hang of it, it's really not that bad.\r \r\n\nAnd she has a great snippet in the slide deck of her literally solving the example merge conflict in her slides\r \r with the dates being different for what was called a data cut,\r \r and she literally just shows how in a text editor within our studio itself\r \r she just took one of those two dates cut out the cruft\r \r committed it and pushed it up the main or master branch so\r \r it does once you kind of get that sense of, you know what, all merge conflicts\r \r will eventually boil down to something like that, and perhaps there's more than a handful of lines,\r \r but the process is the same.\r \r\n\nStep back, don't panic,\r \r and find what you're comfortable with to resolve that conflict.\r \r And, really, it's up to you how you resolve that. She has a fun little, shout out to retro gamers like me about how you could put some fun ASCII art in your\r \r in your, in your, final file that you're gonna push up. Maybe that's not a good idea for production code, but the retro gamer may sure loved it.\r \r But they really the other key takeaway I'll highlight here is that merge conflicts\r \r you often will find yourself, especially you're new to this, blaming git for all your troubles. Like, if I just didn't have to use git, I wouldn't have to worry about this.\r \r You know what? Maybe,\r \r again, take a step back\r \r because these conflicts are not really related to Git itself. They are more practical in nature.\r \r\n\nMaybe you and a team member didn't communicate clearly enough on who was doing what. And maybe there's a more optimal way to set up the structure of your project so that merge conflicts are minimized.\r \r And, honestly,\r \r to be proficient in these situations,\r \r you do have to do a little bit of, you know, upskilling,\r \r if you will,\r \r on, you know, the basics of git. Maybe you can get away with using\r \r a third party tool like GitHub desktop or the,\r \r the pane in r studio or the the version control pane where it gives you some point and click ways to get your commits done or revert or things like that,\r \r but it can't do everything.\r \r\n\nSometimes getting a little dirty, so to speak, with the terminal and\r \r exploring ways to kind of get out of danger so to speak if you're really nervous about\r \r dealing with that merge conflict.\r \r There's a there's a command called abort for your merge that you can get back to right where you left off before you started that merge,\r \r that merge request\r \r so there are little nuggets like this throughout her talk\r \r that I think once you get the better handle on and you have some real practice with it's not like something you can just watch this talk and immediately you know be changed forever\r \r You have to really put these things in practice.\r \r\n\nSpeaking of practice, she doesn't have this in her resources, but I'll call it out because it's been featured\r \r in our highlights podcast before.\r \r But my Al Salmon has created that\r \r fondly\r \r named r package called seperpultate.\r \r I probably got that wrong again. I sorry, Ma'al.\r \r But this is a great way for you\r \r to literally practice\r \r different situations of Git right in the confines of r itself.\r \r So we'll put that link in the show notes as well so you could put a lot of the principles that Megan is talking about here\r \r into practice\r \r in a non production type project, but it's gonna mimic these real world scenarios. So I think booting up that package\r \r in RStudio or your preferred IDE of choice\r \r is a great way to explore, you know, dealing with merge conflicts, dealing with the tooling around it, and not frankly ever tooling around git itself.\r \r\n\nI think the best way to learn with git is to actually do something with it, and if you want like a you might say a safe space to do that with,\r \r my else package is a great way to do that. Again,\r \r fantastic talk by Megan. Can't wait for you all to see the recording,\r \r but she related to a lot of her journey we get to,\r \r her adventures of parenting and travel, which again is a parent who recently traveled\r \r there in the summer on a long road trip yes I completely relate to all that and it was a great to make those connections so\r \r again slides are in the show notes the recordings will be out hopefully in a couple months\r \r but highly recommend to check this out especially\r \r if you do get that little twinge of panic or despair\r \r whenever you think of git\r \r Moving on to our next highlight today. It's always wonderful to see the diverse nature of the art community,\r \r especially in terms of geographic distribution\r \r and ways of the community getting together in different avenues to share their knowledge and insights\r \r and really help each other in their journeys of using our data science.\r \r\n\nSo our next highlight is a new blog post on the R Consortium\r \r talking about\r \r the new R community\r \r in Ahmedabad,\r \r India\r \r that is called the Ahmedabad\r \r R user group or ARUG for short, and some of its journey to bring those in the life sciences industry in that region\r \r together to share their insights about r.\r \r And so the interview was with Sanket Sanjo\r \r Sanojia.\r \r Sorry if I didn't pronounce that right.\r \r He has many much experience in statistical programming,\r \r in data science in the clinical industry.\r \r And it was in about 2021\r \r that he was meeting with some fellow collaborators\r \r and wondered how they could bring\r \r this growing community\r \r of our users\r \r in Amadaba together\r \r to share their knowledge, and, hence, they had the idea of setting up the ARAG group.\r \r\n\nAnd it over time, they started to get together more, and then they actually,\r \r after a lot of planning, a lot of work to mentor new members and start\r \r the foundation so to speak,\r \r they had\r \r their first meetup earlier this year in July\r \r and this was a very highly anticipated event\r \r called r evolution\r \r shaping the future of clinical trials.\r \r Again, this is right up my wheelhouse, so to speak,\r \r where they had many different featured talks talking about the spectrum of where r is being used\r \r throughout the industry. All from, say, creating innovative Kaplan Meier plots or survival\r \r visualization,\r \r looking at ways of Shiny,\r \r you know, innovations with Shiny with different use cases,\r \r having a roundtable\r \r on the different trends in r and the ways to prepare for conferences\r \r in terms of getting the most out of that,\r \r and really just bringing people together, I think, is the key point here.\r \r\n\nHe talks about how they're leveraging platforms such as GitHub and Meetup\r \r to get in touch with the users,\r \r but in the end from what I've seen in this post it was a highly attended session\r \r and it looks like there is a lot of enthusiasm\r \r to\r \r to\r \r to level up each other along the way, wherever you're new to the industry and are are those that are wanting to give back so to speak some of their learnings.\r \r So the link the post has links to how people are interested in joining the group there are links to join on that\r \r but overall it is terrific to see\r \r our gaining a lot of momentum in this space and not just you know in my neck of the woods here in the United States but around the world whether in Europe\r \r or Asia Pacific or other parts of the world\r \r we're seeing R really take off to bring life sciences to another level so\r \r needless for me to say I'm here for it and I'm really great to it's really great to see these user groups spin up and really getting the community together.\r \r\n\nLast but certainly not least, we're gonna close out the highlights,\r \r section today\r \r with a great use case in leveraging what is becoming a rapidly growing and very, you know, influential\r \r communication platform\r \r that we're all many of us are now using in our daily work, and that is quarto, of course.\r \r And in particular,\r \r when you are working in an organization\r \r and you have maybe you've done,\r \r say, a report or a slide deck and there's always, like, a few common themes\r \r or common elements that you want throughout these\r \r shared in your organization,\r \r what is the best way to get people started on the right foot so that you're all are kind of starting from the same template, if you will.\r \r\n\nSo this last highlight is addressing just that and it comes to us from Megan Hall, who is a technical product manager\r \r of the hockey group as Xelliss Analytics.\r \r And, coincidentally enough, that's also where my good friend, Tan Ho, is, is working as well as a machine learning and and software engineer and statistical data scientist as well.\r \r So credit to them for joining the conference. But Megan's,\r \r talk, which again I couldn't see live,\r \r but she has an accompanying blog post about how\r \r they have designed and deployed\r \r internal portal templates at Xelliss Analytics\r \r and some of the tips that you can take from this if you wanna go on this journey\r \r for creating internal resources around quartile.\r \r\n\nSo\r \r first of all, motivation for why you wanna do this, certainly for me,\r \r you wanna have consistency\r \r in, say, your organization's, like, theming of these different communication\r \r reports\r \r or slide decks, again, whatever have you. And you don't want every scientist or data scientist to\r \r create these by hand if you want to just make it easy for them to get started.\r \r So having a template I think is quite valuable and we've seen this also\r \r in the R markdown ecosystem quite a bit. Lots of templates have been shared in the community in respect to that and I think in quarto we've already starting to see that as well.\r \r But, again, you can't always use the publicly facing one. Sometimes you have\r \r various elements that you wanna share only within your organization,\r \r Hence, the need to figure out how to build these\r \r internally.\r \r\n\nSo what actually goes into a template?\r \r Megan talks about\r \r you want to put in probably some styling elements, whether it's CSS,\r \r custom theming, which again the quartal site\r \r does a terrific job of documenting how you can get one of these off the ground.\r \r So you might have, you know, say theming also associated with the visualizations\r \r you're doing. Maybe you have a set of core r packages that should be used in each report\r \r to help set up some of these more aesthetic elements.\r \r She talks about having customized themes for ggplot2\r \r and the GT package for creating tables\r \r so that the the scientist who's developing this report can just already have that snippet of code ready to go\r \r to load these internal packages that are giving these themes.\r \r\n\nSo that's a great win right there for, you know, reducing manual effort.\r \r So she has examples about how\r \r they design a certain element\r \r to tell that a report is confidential and not to distribute it outside of their of their walls so to speak\r \r she talks about how they how you can go about customizing that element\r \r and where that actually goes in your theming and CSS files so that again you can just put that anywhere you like\r \r and if you're still you know learning the nuts and bolts of how CSS actually works\r \r trust me I'm no expert in this either\r \r she has a great tip about using the dev tools\r \r you know interactive element in chrome\r \r so you can get to the actual CSS for each element using its inspector or whatnot,\r \r and then on the fly experiment with different parameters such as like the rounding of corners around this box that she puts at the top of the report. So you can kind of demystify\r \r what can be, you know, quite\r \r quite, daunting I would say when you look at CSS for the first time. You're not really sure what these parameters are doing.\r \r\n\nSo really getting getting your hands on it in the browser itself is a great way to learn. She also points to resources like the Mozilla docs\r \r that are great for learning CSS as well,\r \r And so lots of lots of practical tips on that front.\r \r Well, it's one thing to create this bundle. How do you actually share it with the rest of your organization?\r \r Much like the R Markdown ecosystem, if you're in the you're in the r landscape like we are,\r \r you probably want to make an r package for it. And r packages work just as well with quartile templates\r \r as they have with r markdown templates.\r \r\n\nSo she has a great example with some visuals\r \r on how they have constructed\r \r a bundle where the package within its INST\r \r folder which is the part of a package where you can put\r \r ancillary or accompanying files that will get installed with the package itself\r \r when the user installs it on their system.\r \r She has folders for\r \r these extensions\r \r that hold\r \r the both the HTML\r \r and the LaTex or you might say PDF\r \r styling files so that both the printed version and PDF, so to speak, or the static version, as well as the web based HTML version\r \r have,\r \r you know, accompanying style files over its CSS,\r \r wherever it's custom LaTex code,\r \r along with the\r \r the quartile document\r \r that actually has the template itself.\r \r\n\nAnd when the user utilizes a function, she calls it create Xeliss HTML for the HTML version.\r \r It will copy everything to their working directory\r \r and then get that template file set to go as a new file.\r \r And then the user can customize it as they wish, but they're already up and running\r \r with utilizing that template.\r \r And so she is, you know, gained inspiration from this from Spencer Sheehan\r \r and by proxy Tom Mach, who I also got to see at the conference. It was great to say hi to Tom, but she leveraged a lot of their previous resources that they've shared on their blog posts\r \r to put all this in action\r \r and then lastly in her post she has a nice animated gif to show what this actually looks like when the user\r \r sets this up a simple call to that\r \r Xelliss HTML\r \r function gives it a title\r \r and right there your portal document is is right there open\r \r with everything filled in.\r \r\n\nWhat a great way to make this as easy as possible\r \r for your rest of your organization\r \r to leverage your innovative quartile templates.\r \r I definitely need to start doing this because I was just talking with Will about some day job stuff a couple weeks ago\r \r about, hey, we love using quartile for our slide decks.\r \r We, not the biggest fans of PowerPoint. At least I'm not. I don't think he is either. So we're thinking of making an organization template based in quartile\r \r for our slide decks because,\r \r well, it's another story for another day, but\r \r HTML interactive content.\r \r\n\nYeah. I think that's a little more engaging than PowerPoint stuff. That's a battle. That's gonna be a battle, so to speak, but one I want to take with quartle\r \r at my hip, so to speak, so that we can start leveraging interactive slide decks at my company. So this Megan's post here is very timely because I'm gonna use some of these principles and practice to to make all this happen.\r \r Well, much like I tell you every week there is so much more that goes into an r weekly issue. So\r \r we we will close-up here. I'll talk about an additional find that I have.\r \r Again, somewhat related to the conference, but it was\r \r eye opening to say the least.\r \r\n\nSo as I mentioned, I visited the shiny track,\r \r at at positconf,\r \r multiple times after my presentation,\r \r and there was a terrific session\r \r on kind of innovations with Shiny. One of the talks was from\r \r Keegan Rice\r \r talking about\r \r what are some what are ways that you can build, you know, user friendly\r \r data exploration,\r \r you know, paradigms\r \r in your Shiny application.\r \r And she,\r \r she was inspired\r \r by, you know, many of the principles that we talked about in the community quite a bit,\r \r but she shared\r \r kind of the what were the the boilerplate\r \r of how she created this\r \r live crime tracker as part of her daily work at the NORC\r \r at the University of Chicago.\r \r\n\nAnd this application,\r \r my goodness, when you look at this\r \r you are gonna be blown away.\r \r This is\r \r amazing.\r \r An amazing application.\r \r You would not know it's shiny by looking at this. It actually has a lot of vibes similar to what I saw shared\r \r at the Shiny conference earlier this year by Appsilon.\r \r I'm one of the apps that,\r \r that that I was enamored by.\r \r Great organization,\r \r great use of interactive maps with tooltips throughout,\r \r and a great, you know, comprehensive documentation\r \r that's styled very clearly\r \r both about the tracker crime tracker itself and the methodology around it.\r \r This is a great showcase of great user\r \r experience,\r \r you know, elements.\r \r\n\nAnd again, if you just shared it with somebody there is nothing here\r \r that, you know, screams shiny so to speak in terms of the typical UI layout.\r \r I don't exactly know exactly what's under the hood on this just yet. I just know that it is a very engaging experience\r \r and,\r \r knock on wood, so to speak, if things go well later this year, we may, dive into this with with her even more detail\r \r if I can spin up the shiny developer series once again because I'm hoping to have Keegan on for an episode that we dive into this much further. But in any event, if you want to be inspired by optimal UX design\r \r in a shiny app, I invite you to check out this live crime tracker part of the NRC\r \r at the University of Chicago\r \r by Keagan Rice.\r \r\n\nAlright. As much as I'd like to talk about the rest of the issue, I'm gonna have to close-up shop here, so to speak. But\r \r as always, where you can go to find more information on our weekly, well, hopefully, it's one place to go, and that's our weekly dot org. That's where everything\r \r that's our central hub, if you will. That's where every issue lands on the on the front page\r \r as well as the archive of all previous issues in case you missed any in the past. There was a great issue last week where Mike and I couldn't record because we were literally at deposit comp, so you'll wanna check out the archive if you haven't already.\r \r And, also, what's the best way to help the project?\r \r\n\nGetting involved. We have multiple ways to get involved.\r \r If you've seen that great new blog post package that just came through CRAN or that great resource that you saw throughout or maybe one that you created yourself,\r \r we're just a pull request away. It's at the top right corner, a little banner there. Click that. You'll be taken directly to the pull request template in GitHub.\r \r You can do it right in the GitHub\r \r editor. No friction required on that front. It's all marked down all the time. I've lived marked down. Who knows? Maybe in my dreams, I'll dream of markdown. Well, maybe not that far. Either way, I use markdown so much. Hopefully, it's intuitive enough for you to put in that link to that great resource.\r \r And, also, we are always looking for additional curators to join our team. There is more information on that on the our weekly GitHub repository if you're interested in joining our team where we definitely could use some additional help, you know. People have real lives and we've lost a couple of curators along the way to their real life duties, so being able\r \r to have others join the team would be a welcome addition.\r \r\n\nAlso, we love to hear from you in the audience for this humble little podcast.\r \r On the show notes of this podcast, you'll find a link to our contact page where you can get in touch with us directly on that front. And if you're listening to a mod with a modern podcast app like Podverse, Found, or Cast o matic. You can send us one little boost along the way and share your love for the show there.\r \r And, also, I am on social media, you know, sporadically on the weapon x thing with at the r cast, but you'll find me more often on Mastodon\r \r where I am at our podcast at podcast index on social, and I'm also on LinkedIn as well. You just search my name and you will find me there.\r \r\n\nSo, again, thank you so much for joining me in the solo effort today. It's never the same without my trusting cohost, but he'll be back soon enough.\r \r And again, huge thank you to all of you at the conference that said hi and also\r \r best wishes to many of the, you know, colleagues I met. There are more than a few of you that unfortunately have contracted COVID, so I hope you're on the road to recovery quite well.\r \r I know in these times, these events, there's always at risk, but I'm thinking of you all And thank you again so much for the great conversations, and I hope you all recover soon enough.\r \r Well, that'll do it for this episode of our weekly highlights.\r \r\n\nThank you so much for joining me today,\r \r and we or at least I will hopefully be back with another episode either next week or shortly thereafter.\r \r Until then, that's end of line."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_34_highlights",
        "chap_timestamp": 27,
        "chap_text": "Eric's positconf recap",
        "chap_href": "https://rpodcast.github.io/shiny-webr-posit2024"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "chap_timestamp": 39,
        "chap_text": "Git Tears",
        "chap_href": "https://meghansaha.github.io/please_let_me_merge/"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "chap_timestamp": 45,
        "chap_text": "ARUG",
        "chap_href": "https://www.r-consortium.org/blog/2024/08/12/a-new-r-community-in-ahmedabad-india-focused-on-clinical-research-and-pharmaceutical-industries"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "chap_timestamp": 19,
        "chap_text": "Quarto Templates",
        "chap_href": "https://meghan.rbind.io/blog/2024-08-14-quarto-templates/"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "chap_timestamp": 7,
        "chap_text": "NORC crime tracker Shiny app",
        "chap_href": "https://livecrimetracker.norc.org/#home"
      },
      {
        "ep_name": "issue_2024_w_34_highlights",
        "chap_timestamp": 52,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_32_highlights",
        "ep_date": "2024-08-07",
        "ep_duration": 44,
        "ep_description_short": "A realistic take on converting the NY Forest Carbon Assessment modeling pipeline to the tidymodels suite, and a review of R package development workflows in the Positron IDE. Episode Links This week's curator: Jon Calder - @[email protected] (Mastodon) & @jonmcalder (X/Twitter) Converting New York’s Forest Carbon Assessment to Tidymodels R…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_32_highlights",
        "description_long": "\r \r A realistic take on converting the NY Forest Carbon Assessment modeling pipeline to the tidymodels suite, and a review of R package development workflows in the Positron IDE.\n\n\nEpisode Links\n\nThis week's curator: Jon Calder - @[email protected] (Mastodon) & @jonmcalder (X/Twitter)\nConverting New York’s Forest Carbon Assessment to Tidymodels\nR package development in Positron\nEntire issue available at rweekly.org/2024-W32\nSupplement Resources\n\nTidy Modeling with R e-book: https://www.tmwr.org\nmaestro: Orchestration of data pipelines https://whipson.github.io/maestro/\nPharma RUG: The Rise of R in China’s Pharmaceutical Industry https://www.r-consortium.org/blog/2024/08/01/pharma-rug-the-rise-of-r-in-chinas-pharmaceutical-industry \nR/Pharma APAC track call for talks: https://rinpharma.com/post/2024-07-17-apac-track/\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nPerson, Place, or Groove? - Pictionary - The Orichalcon - http://ocremix.org/remix/OCR01548"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://fosstodon.org/@jonmcalder"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://www.mm218.dev/posts/2024-07-19-tidymodels/"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://blog.stephenturner.us/p/r-package-development-in-positron"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://rweekly.org/2024-W32.html"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://www.tmwr.org"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://whipson.github.io/maestro/"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://www.r-consortium.org/blog/2024/08/01/pharma-rug-the-rise-of-r-in-chinas-pharmaceutical-industry"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://rinpharma.com/post/2024-07-17-apac-track/"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "links": "http://ocremix.org/remix/OCR01548"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with episode 174 of the Our Weekly Highlights podcast. This is the weekly podcast where we talk about the terrific resources and the highlight sections that are being shared along with much more content\r \r in this week's our weekly issue. My name is Eric Nantz, and I'm delighted you joined us from wherever you are around the world. We are in the month of August already, and time has flown by quick. So, of course, I gotta, you know, buckle up my virtual seat belt here as we get along\r \r the ride to an eventual conference next week. But, of course, I need to bring in my awesome cohost who I never do this alone, of course, because he's joining me here, Mike Thomas. Mike, how are you doing today?\r \r\n\n\n\n[00:00:42] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Doing well, Eric. I am 6 days until my flight leaves, and I I can't,\r \r be more excited\r \r\n\n[00:00:49] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Eric Nantz",
        "trans_text": "to get to Seattle. That's right. In fact, yep. As as you've heard in the previous episodes, Mike and I will both be at Posit Conference Seattle, which means that,\r \r you know, usually during our, quote, unquote, recording time next week, I'll actually be giving a presentation around that time. So, you won't be having an episode next week, but, nonetheless, we'll make it up to you later in the month. But, nonetheless, we've mentioned this before, if you are gonna be in the area for POSITONV, please come say hi to us. We're gonna be out and about. I'm actually arriving pretty early because I'll be part of the Our Pharma summit that's happening on Sunday\r \r before the conference, and I'll be in one of the workshops or databases.\r \r\n\nSo I'll be around. Mike, you're getting in on Monday, it sounds like. So, yeah, we'll definitely looking forward to connecting with you listeners out there.\r \r\n\n[00:01:36] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Please say hi. Yes.\r \r\n\n[00:01:38] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome stuff. Yeah. And And, again, I can't confirm or deny now. I have some sticker swag with me. I'm still trying to get stuff together. I still have to pack, so lots of things to to bring with me. But\r \r good thing we don't have to bring, you know, writing an article show ourselves. We got a handy curator team that handles that for the project. And\r \r speaking of going above and beyond, for the 2nd week in a row, our curator this week is John Calder. He really stepped in to help out with our scheduling for the rest of our curator team. So, again,\r \r many of you hopefully know this by now. Our weekly is a complete volunteer effort. So anytime we can pitch in and help each other out, it it it it's it's just so valuable to us. So our curator team always goes above and beyond. So, certainly, my thanks to John for stepping in. And as always, he has always had tremendous help from our fellow RM Wiki team members\r \r and contributors like all of you around the world with your poll requests\r \r and suggestions.\r \r\n\nAnd, yes, it's been great to see the momentum behind, you know, the adoption\r \r of the tidy models ecosystem for many machine learning,\r \r prediction,\r \r and other pipelines in the modeling space. We've covered numerous,\r \r segments here in the podcast about some of the recent advancements\r \r on the internal tooling that's been happening over the years. And it's always great to see,\r \r members of the community\r \r start to adopt this to their existing workflows, especially in cases where they've had maybe some internal custom solutions.\r \r And now they wanna see where does tidy models fit in terms of giving them advantages,\r \r reconstructing their modeling\r \r pipelines,\r \r and what that experience is like. So our first highlight today is doing just that. It comes to us from Mike Mahoney,\r \r who is now at the USGS as one of their scientists and biologists,\r \r which is the US geological survey for those who are outside of our US circle here.\r \r\n\nThey've been doing some great work in the art community while they're tooling.\r \r But in particular,\r \r Mike is involved with a very important effort\r \r for the New York Forest Carbon Assessment,\r \r which in a nutshell\r \r is trying to objectively measure the amount of forest coverage\r \r within the state of New York and helping predict the changes in this coverage\r \r as part of the recent climate,\r \r Protection Act\r \r that was trying to minimize their use of carbon emissions from, obviously, fossil fuels and other things like that, by the year 2050,\r \r I believe. They want, like, an 85% reduction in that, which means that, you know, they're trying to take advantage of what, you know, forest\r \r and other plants can provide in helping offset some of the some of those, decreases.\r \r\n\nSo this summer, they've been working on version 2 of their automation pipeline and modeling pipeline\r \r of this assessment\r \r where, again, they've had some internal functions to help with the tuning\r \r and creation of these stacked ensembles.\r \r But now they wanna use now the broader ecosystem of tidy models\r \r to kind of bring all that together in one cohesive\r \r structure.\r \r Now, unfortunately, he can't share the actual data they're using for this ensemble project at this time, but the blog post does a terrific job\r \r of taking advantage of publicly available data\r \r from actually not far from your neck of the woods, Mike. They're\r \r taking advantage\r \r of tree canopy data,\r \r from online sources in the in the city of Boston from 2019.\r \r\n\nAnd the goal of this post is to illustrate\r \r very similarly to how they're adapting their New York forest carbon assessment\r \r by fitting 2 types of models,\r \r the Mars, which is a multivariate\r \r adaptive regression splines,\r \r as well as gradient boosting modeling, which, again, these are highly popular in the machine learning and prediction space.\r \r So the first part of the post talks about how he assembles the actual prediction data, the outcome data,\r \r which, again, I think is very comprehensive.\r \r If you're into learning how to obtain these data,\r \r Mike definitely has you covered with all the data preprocessing steps,\r \r the various packages you need. And lo and behold, once you do some, you know, data preprocessing and visualization, you now have a tidy dataset\r \r with the outcomes of interest that he wants to predict.\r \r\n\nSo with that, now it's time for the model fitting.\r \r And so there\r \r they got the a cell values object, which is again, hosting the outcome data and the prediction data.\r \r One little nugget here right off the bat is that just like of anything in r, when you're doing a prediction model,\r \r you need to have some kind of formula object to help denote what are the relationship between the outcome\r \r and the predictor variables.\r \r And there's a handy little function in base r called df 2 formula, which I wasn't familiar with,\r \r which basically\r \r will be intelligent enough to determine if your data set has the outcome variable as the first column,\r \r and then the rest of the columns are prediction variables,\r \r you don't actually assume that structure, and then you don't have to write like the typical formula syntax of outcome, tilde,\r \r and then all the different combinations of predictors. It literally just takes that data\r \r as is and builds your form of your object right off the bat. So that's another one of those hidden base r nuggets that you see from time to time. It's always great great to see those.\r \r\n\nNow in the tiny models ecosystem, there is kind of a stepwise fashion to how to produce these workflows.\r \r The first step is to register\r \r the recipe, which is kind of gonna be the building blocks\r \r for the actual fit itself where you simply feed in the formula\r \r and the dataset that contains your observations.\r \r Simple enough for the recipe,\r \r recipes package\r \r to do that. And then now it's time to fine tune the model specifications,\r \r which, again, one of the great things about the tiny models ecosystem\r \r is that it has dedicated packages\r \r to help with some of these things. Now that may not always work well, well, which we'll get to later on,\r \r but he outlines 2 specifications,\r \r one for the GBM\r \r model and one for the Mars model,\r \r which, again, depending on the model type, you may have different sets of parameters to specify.\r \r\n\nAnd then throughout that, for many of the parameters where he doesn't know right off the bat, what are the best values of\r \r such as, like, the number of trees or the tree depth and the GBM side of it,\r \r Tiny models, of course, lets you\r \r tune for those parameters, optimize for those\r \r leveraging the hard hat package and its tune function.\r \r But you'll see in the code, it's actually littered throughout this model specification\r \r with no arguments. So it's trying to do a lot\r \r for you from an abstraction perspective,\r \r which, again,\r \r may or may not be always perfect, but we'll get to that in a little bit.\r \r\n\nYou've got those specification in the model now. Now it's time to set up the workflow,\r \r which is again coming from the workflow sets package where you can put in your recipe\r \r as well as your 2 model specifications\r \r and making sure you've got all that integrated together\r \r gives you this nested data frame back where you can see your 2 recipes in this case,\r \r the information inside.\r \r And then once you actually do the prediction, it'll capture the results\r \r as well.\r \r But what Mica's saying high praises of is that\r \r a lot of this takes a lot of code back in the days before tidy models, a lot of things you had to build on the fly.\r \r Certainly, Max Schoon had offered the carrot package well before tidy models. Many people use that to orchestrate their flows. Still, you had to learn the nuances on how to stitch all this together.\r \r\n\nTidy models\r \r is trying to abstract away a lot of that manual effort to stitch all this together\r \r so that you can have fit for purpose functions\r \r to define all this. So, again, we'll we'll come back to the benefits and trade offs of that\r \r in in later on.\r \r And then once it's ready to go,\r \r you've got to now start\r \r composing your samples, your re samples of the data,\r \r as well as tuning your workflow sets. In other words,\r \r finding what are those optimal parameters.\r \r So with the workflow map function, which is gonna actually take that\r \r set\r \r of combinations\r \r of the recipe\r \r and the model fits.\r \r\n\nYou feed in a certain met set of metric or parameters such as your space for the grid search.\r \r And then also some two arguments that we'll come back to later on, the metrics and the control argument,\r \r which is gonna help with specifying some defaults\r \r that can be surprising if you're not ready for it. We'll come back to that in a little bit.\r \r And then once you have that done, it's time to actually run the tuning\r \r and see what your best fit is based on your metric of interest.\r \r So in this case, in this example, he's looking at the root mean square error to see which model or which set of parameters of the model\r \r fit best.\r \r\n\nAnd he's able to locate for each of the model types which particular model. It's got a\r \r somewhat ambiguous name of, like, preprocessing\r \r preprocessor\r \r 1, model 09 because it's actually fitting different models for each of these combinations,\r \r so it gives it a unique ID on it.\r \r But\r \r he's not interested in just cherry picking the best fits of these. He wants to use the ensemble technique,\r \r which basically is able to take all these model fits,\r \r figure out then with some analysis\r \r which are the, quote, good enough parameter sets\r \r that then we can he can use later on in the actual prediction side of it. So taking advantage\r \r of the information from all these different model types.\r \r\n\nAnd this is a great advancement in tiny models ecosystem.\r \r They have a package called stacks,\r \r which is gonna be able to add all or literally stack together all these different model fits\r \r and then be able to see what is the highest weight in terms of the model giving the best performances\r \r and really get objective measures around that.\r \r So then he's got a nice tidy output here of the top 4\r \r members contributing the best prediction outcome\r \r or prediction, I should say, power, you might say. And it is a mix of the light GBM and the Mars model\r \r for these different, you know, combinations of the preprocessing\r \r and the model fit itself.\r \r\n\nAnd then he can take that and feed it just directly into the predict function.\r \r That's pretty neat. Just predict\r \r this ensemble object that he's created with these stacks,\r \r the dataset that has the amp predictor values,\r \r and you'll get a tidy data frame with the predictive values back. That, again,\r \r another,\r \r you know, less code solution to get your predictions out of that.\r \r And\r \r this is a pretty comprehensive\r \r start to finish flow on this.\r \r And I will say\r \r there were\r \r some little gotchas along the way that he want he is able to talk about in the next section of the post.\r \r And Mike has a unique perspective on this, our author of the post, because\r \r he was\r \r an intern to the tidy models team years ago. So he's had some inside look on this, and that makes his, critiques here even more fascinating. So, Mike, why don't you take us through that?\r \r\n\n\n\n[00:13:31] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 31,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Mike was an intern back in 2022\r \r on the tidy models team, and I have to imagine that while that must have given him a a huge leg up in converting their their legacy code\r \r into tidy models,\r \r 2 years in tidy models time\r \r must be like a decade,\r \r in terms of the amount of new functionality\r \r and packages\r \r and design choices that have been added to the ecosystem since then. I mean, we have survival analysis and tidy models now and that that was never on the radar back in in 2022,\r \r at least as far as I could tell.\r \r And, you know, as we know that ecosystem\r \r in that that universe of of packages within tidy models\r \r has grown. And it reminds me a little bit of that recent blog post that we had about creating package universes. And, Eric, you and I discussed\r \r some of the trade offs that you have to consider when doing that. Right. And it reminds me a little bit about sort of the end of of Mike's blog post\r \r here. Because a lot of these tidy models packages\r \r work together.\r \r\n\nAs Mike notes, you know, there's sort of 3 packages that work together just for hyperparameter\r \r tuning itself.\r \r The tune package takes care of grid searching.\r \r This hard hat developer oriented package\r \r owns sort of the infrastructure around hyperparameter\r \r tuning, and then the DIALS package\r \r owns the actual grid construction.\r \r And when you think about\r \r hyperparameter tuning itself and trying to,\r \r you know, create these different methods, you know, within each of these these packages and having them work together, Well, not only do you have to do that for 1 modeling one type of model but I'm assuming that you have to create different object oriented methods\r \r for all of these functions across all of these packages\r \r for all of the models\r \r that tidymodels\r \r supports. And I know on the the tidymodels, you know, homepage, they have sort of a list of all the different modeling algorithms\r \r that they support tree based, you know, regression based algorithms, all all sorts of different stuff. And they there's a ton within that ecosystem that they have supported,\r \r but I imagine that once you want to add an additional model type,\r \r it's a pretty extensive process to be able to ensure that you can support that model type not just in one package but across all of these different packages that work together\r \r to create these modeling workflows.\r \r\n\nSo I am not a\r \r user of of scikit learn. I'll be honest. I've reviewed some scikit learn code in the past. I know it's it's very highly regarded in the Python ecosystem. I don't know this for a fact, but I have to imagine that the tidymodels team\r \r must have had the benefit of taking a look at, you know, what works well in in scikit learn and what doesn't work well in scikit learn when they went to, you know, sort of move from caret to tidy models and create this new framework.\r \r So I I'd be curious to see if Python sort of suffers from these same sort of of issues\r \r or if not, you know, how they're handled in scikit learn. Because I have to agree with Mike that this is somewhat of a pain point if you are doing some pretty hardcore\r \r machine learning and predictive modeling as Mike and his team are clearly doing. Right? Creating a lot of different types of models, trying to ensemble them together, trying to tune hyperparameters, and and do it in a way\r \r such that the code is as efficient\r \r as possible. Right? There's a function in here that I didn't even know existed from the workflow sets package called workflow map which I have to imagine is like a purr like approach to, developing workflows across a bunch of different models, hyperparameter\r \r tuning, and evaluating,\r \r and comparing those models,\r \r you know, sort of really in this this programmatic\r \r approach as opposed to hard coding things for each one of these models\r \r and then trying to compare and evaluate,\r \r the the outcome of these models\r \r separately. So\r \r I would advise you to to try to take a look, you know, I don't know how far down in the weeds that we want to go into to some of Mike's sort of specific,\r \r gripes, if you will. I think complaint is sort of a strong word that that's what he uses in the header here. But I think he's really just pointing out,\r \r you know, some of the things that you,\r \r as a Tidymodels\r \r user, the the deeper you get into it, will face as well. And calling out some of the things that worked for him in terms of workarounds, some of the things that that he learned is he admits that some of this stuff is is straight in the documentation,\r \r and some of it is not. And you have to sort of, you know, take a lot of time to figure out yourself. He he and this is super relatable. I think there is something that that was documented\r \r in a package here that Mike spent 26 hours,\r \r trying to trying to figure out before he was able to actually, you know, figure out what was going on here.\r \r\n\nAnd and it had to do I think with the defaults in hyperparameter tuning and some of these workflows that we're failing extremely slowly,\r \r unfortunately, and weren't sort of, you know, bringing to light the errors,\r \r quickly enough to the end user.\r \r This is all to say at the end of the blog post that that they're still using tidy models because I think net net at the end of the day, Mike and his team believe that,\r \r you know, the\r \r the pros and the benefits\r \r that they've received from switching over to tidy models outweigh the cons. And I think like anything, you know, with an open source software,\r \r hopefully,\r \r some of the the complaints and the issues that they faced are things that will be, you know, resolved. And over the years, we'll move\r \r within the Tidymodels ecosystem to enhancing these things and making that user experience\r \r a little more easy. I've used Tidymodels, you know, many times before,\r \r really enjoyed. It's definitely a little bit of a learning curve from from Karat. I think you have to,\r \r have more of a sort of per like thought process, a higher level design sort of thought process\r \r in mind when you're leveraging,\r \r tidy models and understanding how all of these different packages like Parsnip, r sample, yardstick,\r \r you know, work together,\r \r at workflows to be able to, accomplish what you're trying to accomplish. But it is it is super powerful,\r \r and and I'm glad to see that the team is is still sticking with it. And,\r \r I'm this this is like a wealth of\r \r information around tidy models and is a great crash course,\r \r on if you are trying to get into the weeds of machine learning and R on some of the design choices that that Mike and his team made to to\r \r create these models and evaluate them programmatically.\r \r\n\nIt's fantastic. I'm not sure, Eric, if I've seen a blog post recently that goes into this level of detail\r \r within tidymodels\r \r for us. So,\r \r very welcome blog post. I think it's a great\r \r not only technical discussion but also sort of practical discussion,\r \r from a team perspective on on what's worked well for them and and what hasn't and where they're planning to go in the future. I was wracking my brain as you were walking through this, and I\r \r\n\n[00:20:38] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Eric Nantz",
        "trans_text": "don't recall one in in the recent, you know, months or probably even year of anything this comprehensive\r \r because there is a great mix here, again, of one of the points he he mentions towards the end\r \r is\r \r that this\r \r you you you may think you can kind of, you know, hone in on one particular aspect of tidy models, but he's saying that it really took him having this holistic view\r \r of how these different pieces fit together.\r \r That may be an issue for those that are kinda new to these, you know, suite of packages that have a cohesive API\r \r or opinionated way of integrating together.\r \r\n\nNow as I say that, you may be thinking to yourself, well, that sure sounds an awful lot like the tidy verse itself. Right? I mean, certainly, they got inspiration\r \r from the tidy verse on a few things,\r \r But what I when I do data processing pipelines with the tidyverse,\r \r most of my time is spent with, I'll call, a core set of maybe 2 packages,\r \r maybe 3 at the most, like dplyr,\r \r tidr,\r \r and per to help with some, you know, mapping processing.\r \r Oftentimes, I don't quite have to get into the weeds so much as some of the other packages, but sometimes I do. And so it's always helps as you're building these cases or these use cases\r \r for yourself or maybe for your team to document these intangible kind of learnings that as comprehensive documentation might be for these given packages,\r \r it's how they're integrating together.\r \r\n\nAnd, certainly, the tiny models team has done great work to put these freely available, you know, online books online about, you know, all the the different ways that tidy models can be used. Some, you know, Max Kuhn, Julia Silge, and others have been very front and center with that, and we highly recommend\r \r you check out the tidy model site to get links to those\r \r particular cases.\r \r I do think though that having a post like what Mike has done here touches on things that, again,\r \r are kind of on the more practical side.\r \r And I have been victim as someone who uses HPC systems on a weekly basis.\r \r\n\nOftentimes with jobs that won't complete in a day or sometimes 2 days,\r \r it can be costly\r \r when you thought you had a default set right, and then you find out after the fact\r \r you forgot to save that prediction result. You forgot to do that one little adjustment to p values in my case, and\r \r whoops, gotta go back to it. So\r \r there are some things that you can do to help minimize the impact of that, which I don't know works as well for the models. But when we tell people\r \r on our team is if you have a simulation\r \r pipeline and you wanna do, like, 10,000\r \r simulations, you know it's gonna take a while.\r \r\n\nYou really only wanna do a few of them first to make sure you've ironed out all your connections,\r \r all your outputs you're saving so that you're not surprised after writing\r \r them over that amount of time. So I I I had the feels when I read that part of of my exposes. I've been there many, many times,\r \r but these are all things that, again, you kind of have to learn by doing, but then documenting your learning process is so helpful.\r \r And I do think there's going to be tremendous value for those that are adopting tidy models to their pipelines right now to kind of see, again, our literal real world usage of this\r \r and the and the, lessons along the way.\r \r\n\nI'm confident that the tiny models team will take this hopefully constructive\r \r feedback here, and maybe we'll see some enhancements to, like, these more\r \r use case approaches, the documentation,\r \r and not just the, developer facing that you might see\r \r in the weeds of a package manual or when you go help for itune or whatnot or whatnot.\r \r You're not really getting the full picture at that point.\r \r So maybe we'll see improvements on that, but, again, this is\r \r the kind of the unofficial contract you sign\r \r when you leverage a suite of packages that, again, are meant to be coupled together tightly.\r \r There may be cases where the abstraction\r \r doesn't give you the full store. You need to kinda get in the weeds a little bit like Mike has done here.\r \r\n\n\n\n[00:24:52] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I agree, Eric. And that's a great call out to,\r \r the tidy modeling with our book I think if you are interested in tidy models or if you're stuck on something that can be a great resource. We'll put that in the show notes, but it's tmwr.org.\r \r\n\n[00:25:06] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Couldn't be easier to get to. That's right. Yeah. And it should be on your virtual bookshelf or even your printed bookshelf there. It's a valuable resource. And, again, the the the ecosystem is always evolving too. There's always, like I think they do quarterly updates from time to time on the tiny models blog. I've seen Max and Emil and others, you know, do a great job of writing that up. But, yeah, what Mike has done here in this post is is tremendous value to the community.\r \r Alright. We talked about, you know, looking at things from a developer perspective and a user perspective. We're gonna put our dev hats on, Mike, a little bit because\r \r we're gonna talk about what has been a very, you know, well spoken or hot topic these days\r \r and how that applies to package development workflows.\r \r\n\nAnd if you recall, it was a couple a month ago or so. It was kind of quietly put out there, but there is a new IDE\r \r authored by Posit called positron.\r \r And, again, the geek in me cannot ignore the fact that the name of my favorite movie ever is in the name Positron. So to take that for what it's worth, I have visions of the MCP talking to me right now.\r \r End of line.\r \r But in any event, this is\r \r really interesting to see the uptake on this, and I dare say we'll be hearing a lot more about this at Pasa Comp in a week from now.\r \r But what we're seeing here is a post from,\r \r well, Stephen Turner\r \r who,\r \r coincidentally,\r \r when I started my our journey many, and I do mean many years ago,\r \r there were 2 blogs\r \r I discovered that helped me in my journey, especially as coming from another language like SAS trying to make heads or tails or what r was doing under the hood.\r \r\n\nStephen Turner, the author of this post, was one of them because he wrote this terrific blog\r \r called getting genetics done, just\r \r was so instrumental in my learning journey\r \r with R, and it is just terrific to see him\r \r resurrecting this effort in a new in a new blog. But this post is one of the latest that he's put on this, I believe launched earlier in July. So,\r \r it's a huge thank you for Steven. And, you know, I don't think I've met you personally or or if I have, it must have been years ago, but you have been very instrumental to my journey of ours. So it's terrific to be able to cover one of your posts here in the highlights.\r \r Nonetheless, what he talks about in his post here is his early adoption and user experience of positron\r \r to mimic what he's done in the Rstudio IDE and before that, e max of ESS over the years, and that is building in our package. What is the experience like in that space?\r \r\n\nSo we're gonna dive into some of his, findings here in in the highlights now.\r \r And first of which is\r \r for if you're not familiar with how positron\r \r operates,\r \r positron is actually a fork\r \r of\r \r the open source version of visual studio code. They call it code o s s.\r \r So when you look at positron, it's gonna look different than your studio ID, but that's by design because it literally is the Versus code shell\r \r with posits,\r \r you might call design choices on top\r \r to help bring some of that RStudio\r \r IDE functionality.\r \r Not quite all of it because this is a beta product, which we'll get to in a little bit. But he puts links to great resources about positron if you're new to it, such as the Wiki on their GitHub repository.\r \r Absalon's\r \r done a nice intro to Positron as well as Andrew Heiss, who's been frequently featured on the highlights, his experience of positron too. So definitely have a look at those after you listen to this,\r \r but let's get to the actual package development workflow.\r \r\n\nSo\r \r in our studio, what do we typically do? We like to create a new project\r \r in our studio to help house our package code, and\r \r positron brings their own spin on this as well. This is, again, one of their\r \r additions\r \r to the top of the visual studio code like experience\r \r where they let you choose 3 different project types, either a Python project, an R project, or a Jupyter notebook. So right off the bat, you've got a little wizard to guide you along the way. So, of course, he chooses\r \r the R project, and you've got,\r \r again, that familiar looking R project file created for you, which is just like what you would have in our studio. So there's already\r \r a familiar, part of your experience.\r \r\n\nAnd then how do you actually create a package?\r \r Many of us are now using the use this package to create\r \r a package from scratch in that same directory. He does that. No gotchas there. He's got the scaffolding right off the bat in a package he's calling hello,\r \r and then he puts a simple function called isay. It's kinda like your hello world type, but just a little\r \r sampling of different strings in there. He writes that function.\r \r Now we get to some of the differences because there is a\r \r very convenient feature in in our studio ID\r \r that I use every time I make a new function for a package.\r \r\n\nThere is a either a keyboard shortcut or a menu entry\r \r to dynamically\r \r insert in our oxygen\r \r skeleton of the parameter\r \r documentation\r \r right there above your function with just a click or a keyboard shortcut away.\r \r Unfortunately, that's not in positron yet, so you're gonna have to write out the docs yourself. Of course, it's not too difficult. You'll get code completion,\r \r but it is just one of those conveniences that hasn't quite been replicated\r \r to the positron experience yet. But nonetheless, he's able to\r \r document his function and now comes the iteration. Right? When you're writing a package,\r \r you wanna develop your function, you wanna test that things are working,\r \r update the documentation,\r \r manual pages dynamically.\r \r\n\nAnd what's nice about positron is you can import\r \r a keyboard mapping of shortcuts that will mirror very closely what you might have done in Rstudio's\r \r keyboard shortcuts. So you can you can import that in optionally, and then you can use that familiar,\r \r say, command shift or control shift d\r \r to populate the documentation\r \r manual pages on the spot,\r \r that works just right here as well.\r \r So that's gonna take care of, again, the the manual pages. They're gonna take care of putting the function name in the pages. They're gonna take care of putting the function name in the namespace for exporting so you don't have to do any manual effort on that front just knowing the shortcut or the command palette. You'll be able to do\r \r either one of those.\r \r\n\nAnother interesting thing is from time to time, we like to install the packages in our local environment as we're iterating on it.\r \r Before in RStudio,\r \r it would call the r command install\r \r function verbatim.\r \r In positron, it's actually leveraging the pack package.\r \r Pack colon colon local install, which again,\r \r I didn't know existed. So a little learning there. It's not a surprise that posit would use some of their tooling of the\r \r rlib suite of packages that they have. Excuse me. The rlib suite of packages to help automate some of these processes behind the scenes. So fair play to them.\r \r Of course, as you develop a package, you're gonna see your fair share of warnings if you need to update, like, documentation\r \r names or other things like that or the license entry. You get all that in the console just like you would with RStudio.\r \r\n\nSo\r \r no surprises there. You can run dev check,\r \r get the results there.\r \r You can build in your tests. We'll test that\r \r very quickly or use this to launch the test. It's gonna open that up right in your ID. Again, we're seeing a lot of similarities\r \r there.\r \r There is one other thing that's kinda missing from a development perspective that you might use from time to time\r \r is that for things such as the cover package to help you look at all your test\r \r coverage percentage with the functions you develop.\r \r There is always a handy add in, r studio add in in the r studio ID that will let you kind of run that report quickly of a menu click.\r \r As of this recording,\r \r positron's not supporting r studio add ins yet. I think that's something that is being worked on because\r \r even in my visual studio code experience with developing our projects, I can get add ins on that, thanks to the efforts of Miles McBain and others from the community. So I think\r \r that's on the road map, but that's something to be aware of if you wanna adopt positron right away.\r \r\n\nSo\r \r from most of the, you know, actual workflow,\r \r package development looks pretty seamless with Positron.\r \r Now there are some additional things that are missing\r \r in the positron experience that I leverage heavily when I put on my Versus Code hat back for a second.\r \r That is\r \r remote\r \r container and the remote connection,\r \r functionality, meaning that\r \r I could have Visual Studio Code on a one system,\r \r but then have another server either on my local LAN or my local HPC environment or in the cloud\r \r that actually has the R process built into that, and then I can just farm out my computations on that, but look as if it's local.\r \r That's not quite there yet in positron. They are working on that. That would be a game changer for me personally\r \r when they adopt that. But what was interesting, what Steven was able to do here is that little did I know,\r \r on top of writing great content about r, he's actually authored a package\r \r to help\r \r with\r \r getting a Dockerfile\r \r built from your package project\r \r called\r \r pracpack.\r \r\n\nSay that three times fast.\r \r But, nonetheless, this is new to me. I've only been familiar with the Docker filer package by our our friends, think r.\r \r But this looks pretty nifty, and he even has a link to the paper about the package as well. We'll put that in the show notes, but he was able to actually, even in positron,\r \r uses pracpac\r \r package to create the Dockerfile with rmbakedin\r \r without any fuss. So at least he can get the Dockerfile going. He just can't do remote container development with that Dockerfile\r \r in positron. But, hey, it's great to see that he's able to get a Dockerfile on there. So if you wanna throw this into another environment\r \r and have those same dependencies from both the system level and the R package level ready to go. But he says the experience of that was very smooth because\r \r positron\r \r does take advantage of most of Versus Code's features such as syntax highlighting for batch scripting\r \r and other file types. So if you're in the multilingual\r \r environment,\r \r yeah, Positron is definitely gonna be a big help to that.\r \r\n\nSo the nutshell to me is that\r \r things are looking promising.\r \r But, again, this is beta.\r \r Be warned about that.\r \r But I do think that the seeds are planted. And if you're want to put on your speculation hat with me, Mike,\r \r Steven kind of has this in a comment in the post.\r \r It looks like a lot of the development energy is going to positron now, so we may have to,\r \r put a little toast out there to our friendly art studio ID because because I don't know if it's days or numbered. I guess we'll find out next week. What do you think?\r \r\n\n[00:36:42] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Maybe we'll find out next week.\r \r I know that some folks have raised that question and the messaging\r \r thus far, I think, is that our studio is gonna continue to be\r \r supported.\r \r You know, Positron's\r \r sort of for\r \r you know, there there's a lot of different levels of skill of our developers. Right? There's our beginners. There's a lot of folks that are probably\r \r are intermediate\r \r where they are consumers of our packages,\r \r right, and do a lot of their work and and ETL stuff and analysis and R, but maybe aren't\r \r developing\r \r our packages or or doing anything, you know, much more hardcore than than analysis. I I think that's a probably a large portion\r \r of the R community\r \r out there and, you know, those first two classes, they are developers and they are,\r \r sort of intermediate folks or our consumer or our beginners, I should say, and,\r \r our consumers\r \r mostly.\r \r\n\nI'm not sure how much\r \r incentive they have to to move from our studio. I don't know if positron feels like a more welcoming\r \r environment than RStudio, but I'm I'm super biased because RStudio was probably one of my first ever IDEs.\r \r And then\r \r I I looked at Versus Code for a long time.\r \r It looked so scary to me when I originally,\r \r you know, booted it up for the first time and and tried to do some work in Versus Code. I had no idea where anything was but it's it's probably my bias\r \r from, you know, just being so used\r \r to our studio and and the layout there and and where the features are. So so I don't really know the answer to if, you know, someone starts out in RStudio versus starts out in positron, sort of who is able to make the best progress\r \r the quickest.\r \r\n\nBut it would be interesting to\r \r to see how that plays out, you know, for new users whether they're they're migrating directly to positron or in the future or or whether folks are still starting out with our studio.\r \r But, you know, as you said, Eric, you know, for for those of us that need some of these maybe niche\r \r features that we get in in Versus Code, you know, around remote SSH as you talked about so that you can work locally,\r \r or feel like you're working locally while actually, you know, SSH'd into some remote environment,\r \r that that's pretty powerful. I think that that's probably going to come\r \r fairly soon,\r \r to the Positron ecosystem. When I was looking through the issues and the discussions on GitHub,\r \r it looks like that one,\r \r is is fairly promising\r \r in terms of, you know, Posit's ability to actually get that incorporated.\r \r\n\nThe other one sort of that hurts me, you know, that we've talked about before is the idea of these Versus Code dev containers that allow you to develop as if you're in a Docker container, you know, while you're in a containerized\r \r environment.\r \r That's huge for us in collaboration on our team, but I fully understand that that is\r \r proprietary Microsoft code, that extension, that Versus Code extension. So there's not an easy way\r \r for Positron or any other IDE for that matter\r \r to be able to recreate that unless Microsoft someday decides to actually open source how they go about doing that. So\r \r I don't know which one's going to come first,\r \r whether Microsoft\r \r will open source it or Positron will\r \r incorporate it, but that's that's a big one for me that I would love to be able to see,\r \r incorporated. But, you know, again, these are these are niche things that for probably the majority\r \r of the R community may not\r \r necessarily care about. And, you know, some of the the trade offs here and the things that we're getting from Positron,\r \r you know, I I think are are huge benefits for\r \r potentially a lot of that intermediate class. So it it'll be interesting to see,\r \r you know,\r \r the adoption\r \r of Positron,\r \r sort of what takes place as it moves from beta to alpha, and what significant changes get incorporated\r \r for for quality of life for folks.\r \r\n\nBut, you know, one of the\r \r issues\r \r I I imagine that Pauseit is up against is accommodating so many different levels of our users. Yes. Right? Yes. It's tricky. It's tricky. So I don't envy, you know, what they're trying to do. It's a it's a large scale\r \r problem to solve.\r \r But I do think that\r \r being able, you know, the fact that Versus Code is open source and allows,\r \r you know, posit to sort of tailor it to whatever they want it to be is is powerful in and of itself and I guess another testament to open source. So we'll we'll see how things progress here.\r \r I love the fact that folks are starting to dive into it and and pick up on the strengths and the weaknesses of it for the rest of us to be able to get up to speed early as we adopt it.\r \r\n\nSo, you know, kudos to Steven as well for doing that.\r \r\n\n[00:41:35] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 35,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Absolutely. And one thing I think about is,\r \r first, I do want to mention that I've\r \r used my fair share\r \r of attempts at IDs before our studio. They were hit or miss at best.\r \r I remember one in particular on the Linux system called rkward\r \r that tried to do a lot of things, and then others tried to make the Eclipse IDE try to fit with our projects.\r \r Oh, boy. That was gnarly, buddy. If you if anybody listening remembers that, give me a shout because I I can share stories of you about that.\r \r But I knew at that time,\r \r I was trying to learn it. But\r \r as, you know, R was starting to take more adoption in industry, it was gonna be a tough sell\r \r to get people to develop and those kind of IDs\r \r much less than a command line. I mean, hey. I love command line as much as anybody, but,\r \r it's not for everybody. Right? So\r \r when our studio came out, I mean, you can't underscore the influence it had\r \r on not just those getting new to r, new to data science, having this cohesive experience,\r \r everything in one place, so to speak, in your development journey.\r \r\n\nBut, boy oh, boy, did it help with adoption.\r \r It certainly did in my industry. So that's why I'm I'm cautiously optimistic\r \r that Positron will eventually, you know, hopefully be tailored in in more usability\r \r fashion to those\r \r use cases for those new to the language and who are not interested in, say, package development. They just wanna get their data science done, get their statistics model fits done, get that quarter report out there, and get on your way. Like, I think the bones are there. It's just gonna be a little while. But with this soft beta that they or that they rolled out, I think now we're they're getting their issue tracker is quite extensive now if I last checked. There's a lot on there, so it's a lot for the the team to prioritize.\r \r But, yeah, we shall see. There is one little nugget more on the,\r \r speaking of open source, there's always the issue of licensing. Right?\r \r\n\nLittle hidden nugget here in what Steven mentions at the end here, which I think we should call out here\r \r is that Positron is not using things like GPO,\r \r not using Apache.\r \r It's using what's called the elastic license 2.0, which you may have not heard about unless you're really familiar\r \r of all the nuts and bolts of software licenses. But let me read the\r \r the blurb that he calls out here that I think I may know the backstory about, but let me read it first. And he says,\r \r you may not provide the software to third parties as a hosted or managed service\r \r where the service provider\r \r provides users with access to any substantial set of the features\r \r or functionality\r \r of the software.\r \r\n\nThere have been vendors,\r \r I won't name names,\r \r that have\r \r bundled\r \r the open source version of RStudio\r \r into their,\r \r what I call, platform as a service offerings.\r \r And I've heard, unofficially, I won't put names on this, that Pazit was not too thrilled about this business practice.\r \r So it does not surprise me that they would go this next step with this fresh start\r \r to put this in there, but that may change\r \r where positron can actually be integrated. So I guess we'll see\r \r this space, but that's something to watch out for if you are in that in that kind of\r \r software,\r \r you know, provider space. So that was a little nugget I didn't expect to see, but we'll we'll stay tuned on that.\r \r\n\n\n\n[00:45:09] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. It's interesting\r \r to\r \r Eric, that's why we have you on the podcast because you you know the backstory\r \r around all of this. You have the you know, environments like the the one that Steven works in, you know, environments\r \r like the the one that Steven works\r \r in where you may need to to host something like our studio server.\r \r Right? Mostly\r \r internally, maybe you're doing some sort of a consortium collaboration, right? And you you wanna stand that up in a way that,\r \r is easily\r \r accessible you know cloud hosted something like that to, a group of individuals maybe internally\r \r or externally. So\r \r I would love to see this license, like, say something like you're not allowed to resell,\r \r Positron in that fashion but if you wanna stand it up for for free and not make any money off of it, you know, in a similar fashion to how you would, you know, stand up our studio server, then then go for it.\r \r\n\nBut this definitely, you know, as as Steven mentions\r \r in his case, he's he's not a lawyer, but it looks like, you know, Positron's license may preclude\r \r the ability to do something like that. Yeah. That's,\r \r\n\n[00:46:23] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 23,
        "trans_speaker": "Eric Nantz",
        "trans_text": "that's looking more likely. Maybe, again, these will be things we hear about more in between sessions at at next week's Posikoff.\r \r But,\r \r if you're in tune to this space of those in the data science, you know, platform as a service area, Let me just say that if you're a fan of pizza in the US, you can probably guess the name of the company I'm thinking about. I'll leave it at that.\r \r I can't say that. But, nonetheless,\r \r this this was a very comprehensive post by Steven here. And, again, it's a pleasure to have him on the highlights, and I'm really looking forward to see how he continues to use positron and other\r \r efforts like this as I'll be testing the waters a little bit in my continued shiny development. There is one thing that I want to have that hopefully I can talk to deposit folks next week about.\r \r\n\nPlease,\r \r please make a NICS package for positron,\r \r please,\r \r then I'm\r \r I'm happy.\r \r Hey. It's open source. Pull requests are welcome. Yeah. I know. I I don't know if, Bruno, you're listening. Maybe we need to to talk about it. Maybe we need to strengthen numbers on this one.\r \r\n\n[00:47:29] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Mike Thomas",
        "trans_text": "There you go.\r \r\n\n[00:47:30] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Well, now strength in numbers is also a way you can say, you know, what's the benefit of our weekly itself. It is the strength of the community that populates every single issue.\r \r So we'll take a couple of minutes to talk about our additional fines here. Now I'm gonna talk about something that I totally did not expect to talk about, especially in the the circle I operate in.\r \r We have a new package that's been released in the our ecosystem\r \r called Maestro\r \r positioned to create and orchestrate\r \r data\r \r pipelines\r \r in R.\r \r\n\nI know a little bit about pipelines because I happen to work closely with the author of targets himself, Will Landau. So, of course, the first thing I'm thinking of is\r \r what is Maestro all about? So\r \r we'll put a link to this in the show notes of Khos, but at a high level,\r \r Maestro is definitely positioning itself in the realm\r \r of data processing.\r \r I don't envision it's trying to approach on the comprehensive\r \r ability of targets to be flexible\r \r in many types of analytical\r \r workflows that we often see in data science and operational automation efforts.\r \r But the the nuts and bolts of Maestro are kind of fascinating where they're taking advantage of our oxygen tags\r \r in a function that you create for your data processing or your ETL processing\r \r to define characteristics such as the schedule of when the or pipeline will run such as, like, the frequency,\r \r what's the actual start time of that job,\r \r and there there are other decorators as well. And then once you have your functions decorated,\r \r you use some of the functions built into Maestro to build that schedule\r \r and then to execute it. So\r \r they do leverage other packages that help with, you might say, more of the\r \r high demand, you know, computation\r \r such as\r \r the future package and the FIR package. You wanna have that map like\r \r functionality for your running schedule. It looks like it can\r \r interface with those quite a bit,\r \r but\r \r I don't think this is an either or. I definitely when I saw Maestro get mentioned, I went immediately to their package site, and they have an article on their motivation\r \r for creating,\r \r Maestro.\r \r\n\nAnd, of course, there is a section on comparison of Robert Paggins. I was pleased that they talked about targets on this because I was gonna be some I would have reached out to the office right away about if I hadn't seen this. But it looks like they are interested in seeing\r \r where Maestro and Targets can complement each other because,\r \r at least in some of the target\r \r critiques I've heard over the years,\r \r it's a little more difficult for these more ETL, especially the\r \r extract portion of data processing pipelines. Again,\r \r especially if you're interfacing\r \r with databases or APIs that you're ingesting data from,\r \r There are ways you can use targets with it. You just have to get a little more into the nuts and bolts of how you orchestrate your return objects and whatnot. So I'll be very interested to see if this ends up being a cohesive relationship or not. But with that said, if you're in this space of producing comprehensive data pipelines,\r \r Maestro may be worth a look.\r \r\n\n\n\n[00:50:42] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Absolutely, Eric. I'm in very interested to see how that evolves. That sort of came out of left field. For me, that Maestro package wasn't something that I had had on my radar,\r \r but it's it's really, really interesting, you know, especially as we've been getting into a lot more targets projects lately, a lot more of these sort of pipeline, types of types of projects,\r \r so it'll be, you know, a potential new tool in our tool belt as well. I have sort of a different highlight that I wanted to call out. It is an interview\r \r with the R Consortium published and held with,\r \r Pharma Rug China organizer,\r \r Zhou Xu,\r \r who who spoke with the R Consortium about how he has grown the R community\r \r in China, you know, specifically\r \r in the pharma\r \r space.\r \r\n\nI think it's something that we don't necessarily talk about enough is how international\r \r r is. One cool a couple cool facts about Joe is that he studied or he has his PhD in statistics where he studied in New Zealand, which we know is the birthplace\r \r of r. He worked at at Roche for, the past 4 years where he helped open source 30 software packages.\r \r There there's 4 that are called out here.\r \r I'm not super familiar with them, Eric, but you might be, you know, being in the pharma ecosystem,\r \r formatters,\r \r our tables, our listings in turn. Oh, yes.\r \r Sounds like there's there's many more beyond that.\r \r\n\nThis this our community\r \r in China\r \r has done a lot of collaboration and I think is involved pretty heavily in the pharma rug,\r \r pharma r user group sort of in general.\r \r And there's just a lot of great talks about how Joe has helped organize a lot of events, a lot of hybrid events, and how he's been able to pull those off using Microsoft Teams as well as, you know, hosting,\r \r the these hybrid events\r \r in person as well. So I I thought it was a really nice interview,\r \r for anyone who's looking to learn about, you know, organizing,\r \r our groups, you know, within their their neck of the woods that you might get something out of this interview.\r \r\n\n\n\n[00:52:46] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 46,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I'm really glad to see this because we are seeing a lot more momentum of our our colleagues in Asia Pacific regions adopting our in life sciences. This is hugely instrumental to making that journey\r \r hopefully easier for those that are that are on this. And, you know, very closely related to this,\r \r some of you know I'm one of the organizers\r \r of the annual Our Pharma Virtual Conference.\r \r One thing that we've always struggled with is how do we best accommodate\r \r our our fine friends over in the Asia Pacific region because we're mostly a US based conference in terms of time zones and the way we stream our our talks.\r \r Well, I'm happy to say that, you know, alongside reading this post,\r \r if you are in the Asia Pacific region, there is going to be an r pharma specific event tailored to Asia Pacific.\r \r\n\nSo we're gonna have a link to that. It's actually in our this week's our weekly issue that call for talks\r \r is open for that particular effort. We'll put that in the show notes just in case here too.\r \r Jonathan Caroll has actually been quite nice to to advertise that on Mastodon and whatnot. So, yeah, this is a wonderful time\r \r if you're in the life sciences space\r \r in in Asia Pacific region to\r \r to dive into this momentum.\r \r I liken it to what we, you know, when our farmers first introduced in 2018.\r \r None of that had been built before.\r \r Now we're trying to expand the scope of this because we wanna take advantage and get everybody across the world\r \r a unique opportunity to share their learning and learn from each other along the way. So, yeah, gratifying to see the Arkansas team keep,\r \r keep on spotlighting these these great use cases. And, yeah, I'm very excited to see where the future goes here.\r \r\n\nAnd, of course, you can't just be excited about that. You gotta be excited about the rest of the issue. There is a boatload of additional content here following the full gamut of new packages, many of which we wish we could talk about here today, but there's only so much time in a day. But there's lots of great tutorials as well. I see a full gamut of spatial visualizations,\r \r tidyverse pipelines,\r \r even a great post by Nicola about creating\r \r typewriter\r \r styled images. I think that's great for my retro feels as well. Love to see that. So much more content there. Where do you go for it? If you don't know by now, you know now it's rweekly.org.\r \r You bookmark that every single week. We got a new issue for you. And if you wanna contribute to the project,\r \r we rely on your contributions in the community.\r \r\n\nSo, please, if you find that great new blog post, maybe you wrote that post, you find a great package, a great tutorial,\r \r send that to us via a poll request directly linked at the top right corner of the home page.\r \r It's all marked down all the time. Right? Markdown is how I live in writing my content, and as\r \r for some internal presentations having to go back to PowerPoint, it just doesn't feel right. I feel right writing a markdown\r \r in quarto or our markdown, and I'm gonna put my foot down on that. Hopefully, that becomes more of a trend in my industry, but I digress.\r \r Either way, I'll markdown all the time so you can send your poll request right there. We'll be glad to merge that in for the week. And, also, we love to hear from you as well. We got a contact page in this, podcast episode show notes directly linked there. Did a low HTML hacking to get that together after we moved our podcast hosting. So hopefully it works out for you. But, also, you can get in touch with us on social media.\r \r\n\nI am on Mastodon these days at our podcast at podcast NSR social,\r \r also on LinkedIn. Send me a shout there. And, again, if you're gonna be at Pazikov, I will be there at this time next week for sure. So we hopefully hope to hear from you. And, Mike, where can listeners get a hold of you? You can find me on mastodon@[email protected].\r \r\n\n[00:56:30] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Mike Thomas",
        "trans_text": "You can find me on LinkedIn just by searching Catchbrook Analytics,\r \r ketchb\r \r r o o k, to see what I'm up to lately. Or, Eric, as you said, find me in person next week if you're gonna be in Seattle. We'd love to chat with you. Yep. I'm gonna do my best to wear some kind of r related swag shirt every single day, so I'm easy to spot.\r \r\n\n[00:56:49] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Eric Nantz",
        "trans_text": "But who knows? Maybe everybody wearing r swag so it may not be easy to spot.\r \r\n\n[00:56:53] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'm gonna print up some rweekly highlights podcast,\r \r t shirts for us. Oh, yeah. Because it this is an audio podcast. People might not have a single clue what I look\r \r\n\n[00:57:05] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "trans_timestamp": 5,
        "trans_speaker": "Eric Nantz",
        "trans_text": "like. Yeah. I still remember one time at a at a the first shiny dev conference,\r \r I was spending a question. Somebody looked over and said, hey. I know that voice. Yeah. So we're gonna get, I'm sure, our fair share of that. Nonetheless,\r \r we could blab around all day. We're always excited to talk about this stuff, but we got a close-up shop here. We got our day jobs to get back to, but we're very happy you joined us today for listening to this latest episode of our weekly highlights. And, again, we will not be back next week because we'll be at Pazacom, but we look forward to connecting with you all again with a new episode in 2 weeks from now. So until then,\r \r goodbye, everybody."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_32_highlights",
        "chap_timestamp": 35,
        "chap_text": "Converting forest assessments to tidymodels",
        "chap_href": "https://www.mm218.dev/posts/2024-07-19-tidymodels/"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "chap_timestamp": 45,
        "chap_text": "Positron for package development",
        "chap_href": "https://blog.stephenturner.us/p/r-package-development-in-positron"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "chap_timestamp": 43,
        "chap_text": "maestro: Orchestration of data pipelines",
        "chap_href": "https://whipson.github.io/maestro/"
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "chap_timestamp": 8,
        "chap_text": "Rise of R in China's Pharma Industry",
        "chap_href": "https://www.r-consortium.org/blog/2024/08/01/pharma-rug-the-rise-of-r-in-chinas-pharmaceutical-industry "
      },
      {
        "ep_name": "issue_2024_w_32_highlights",
        "chap_timestamp": 29,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_31_highlights",
        "ep_date": "2024-07-31",
        "ep_duration": 46,
        "ep_description_short": "Episode Links This week's curator: Jon Calder - @[email protected] (Mastodon) & @jonmcalder (X/Twitter) Let's Talk About the Weather 2024 Shiny Contest Entire issue available at rweekly.org/2024-W31 Supplement Resources https://lorenzwalthert.github.io/precommit/index.html https://www.kenkoonwong.com/blog/llm-rag/ Supporting the show Use the…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_31_highlights",
        "description_long": "\r \r Episode Links\n\nThis week's curator: Jon Calder - @[email protected] (Mastodon) & @jonmcalder (X/Twitter)\nLet's Talk About the Weather\n2024 Shiny Contest\nEntire issue available at rweekly.org/2024-W31\nSupplement Resources\n\nhttps://lorenzwalthert.github.io/precommit/index.html\nhttps://www.kenkoonwong.com/blog/llm-rag/\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter) \nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nA Flea and His Giant - Megaman X: Maverick Rising - Chuck Dietz - https://maverick.ocremix.org/music.php"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://fosstodon.org/@jonmcalder"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://jcarroll.com.au/2024/07/27/let-s-talk-about-the-weather/"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://posit.co/blog/announcing-the-2024-shiny-contest/"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://rweekly.org/2024-W31.html"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://lorenzwalthert.github.io/precommit/index.html"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://www.kenkoonwong.com/blog/llm-rag/"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "links": "https://maverick.ocremix.org/music.php"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with episode 173 of the R Weekly Highlights podcast. This is the weekly podcast where we talk about the terrific resources that are being shared every single week at rweekly.org.\r \r My name is Eric Nantz, and I'm delighted you're joining us today. And I admit I look at the calendar at the top of my screen as I record this, and I cannot believe it's July 30th already. We are almost in August, which means my kids are almost in which might be a little bit of normalcy for those parents out there,\r \r if you can relate to that. But, nonetheless, we're here to talk about all things are in our weekly. And I don't do this alone as always. I'm joined by my awesome co host, Mike Thomas.\r \r\n\nMike, where did the time go?\r \r\n\n[00:00:43] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I don't know, Eric, but, I imagine\r \r potentially like you you may be also scrambling,\r \r to put a presentation together for a conference in August. That's sort of where I'm at. These conferences have come up quite quickly.\r \r And,\r \r Yeah. It's crunch time.\r \r\n\n[00:01:00] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 0,
        "trans_speaker": "Eric Nantz",
        "trans_text": "It is crunch time. Yes. I'm gonna frantically put in the finishing touches on my\r \r upcoming talk about WebAssembly.\r \r Very excited for it. Having some initial good feedback, so I won't put any spoilers out here, but I got some good stories to tell with that with that effort.\r \r But, yeah, less than 2 weeks from now. So as you heard from last week weeks before, Mike and I will be there at Positconf, and definitely\r \r welcome for you to come say hi. And I cannot confirm or deny that I might have some stickers with me. We'll find out, but nonetheless,\r \r come say hi nonetheless. We're always all connecting to the listeners\r \r over at these events, and, yeah, this will be an exciting time.\r \r\n\n\n\n[00:01:38] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. Absolutely. I have a presentation not at Pazitconf, a different conference.\r \r It's on the topic of AI\r \r and you're gonna like this. My first slide is you might not need AI.\r \r\n\n[00:01:50] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Good. Hit them quick with it.\r \r Really setting the tone. You should. You should. That that's terrific. Now I I but, yeah, who knows? And, you know, give or take here here and there, but there are some\r \r fluffy efforts going on in various industries. So, yeah, you keep it real, Mike. You keep it real. That's what we do. That's all we do. And what else keeps it real? Well, it's organically real in terms of the awesome content at our weekly every single week. And as you know, we have a rotating set of curators that pitch in\r \r on different weeks to help, assemble the issue.\r \r\n\nAnd this week's our curator is John Calder,\r \r another one of our OGs, if you will, of the our weekly team. And as always, he had tremendous help from our fellow our weekly team members and contributors like\r \r all of you around the world.\r \r And our first highlight just happens to come from one of our fellow curators.\r \r And looking at this a phenomenon that unfortunately can occur\r \r when we grab our data from online sources and things get kind of uprooted from us, but the community\r \r comes to the rescue once again.\r \r This blog post is coming from Jonathan Carroll, who again, on top of his awesome efforts of our weekly\r \r is always looking at new things to learn in his blog. And it's always a fascinating read.\r \r\n\nWell, he's taken a bit of a detour from his programming language\r \r exploits and other languages. He's gonna talk to us a bit about the weather in Australia,\r \r and he's actually looked at this for quite a while now. In fact, since the mid 20 tens,\r \r he's been grabbing weather data from Australia that's been\r \r exposed by the Bureau of Meteorology.\r \r He says don't call it the bomb.\r \r I won't do that.\r \r But this has been keeping track of weather for a good while now.\r \r And but there's a bit of a bad news is that\r \r unlike other services,\r \r maybe you shouldn't be surprised about this. They may have an official API to download all this.\r \r\n\nSo Jonathan would leverage his scraping skills using the various utilities that we've covered\r \r many times in this podcast and elsewhere.\r \r There are many awesome packages in order to help with web scraping\r \r in particular, like the Arvest package, but there's many others in this space.\r \r Well, he's been doing that for a good bit.\r \r But there was a recent,\r \r mishap, if you will,\r \r where the service\r \r back in 2021,\r \r his function to do the scraping was not working anymore.\r \r No code changes. What gives? Right?\r \r Well, turns out as he did a little investigation\r \r in terms of user agents and other pits here,\r \r There was an official statement that was released.\r \r\n\nIt says, and I quote, the bureau is monitoring screen scraping activity on the site and will commence interrupting\r \r and eventually blocking\r \r this activity\r \r on this site from Wednesday, 3rd March 2021.\r \r Well,\r \r epic fail. Right?\r \r That's not good.\r \r And now, rightfully so, John's a little peeved about this because this is from a government site. You know, Australia, like other countries, we have taxes. We're open to pay the government from these kind of services. So\r \r oh, kinda throw your hands up on that one.\r \r Mike's biting his tongue here. I can tell there. Yep. Been yep. Yep. We've we've been there with these things getting uprooted\r \r from various sectors and government.\r \r\n\nBut\r \r the community comes to the rescue once again, unfortunately, where Adam Sparks, who's also been interested\r \r in weather data from Australia as well,\r \r he discovered yet another site that was kind of filling the niche of what was happening with the bureau site\r \r called silo.\r \r And he and Adam has built a new our package, which also is actually included in this our weekly issue\r \r called weather Oz\r \r and actually has an accompanying paper in the journal of, statistical software, the boots. So lots of lots of effort behind this,\r \r which helps have a compliant R package to grab the weather data from this silo site.\r \r\n\nTerrific. Okay. Back of business, John says. Now he can leverage this new package\r \r to have a very handy function called get stations metadata,\r \r which he's able to put in the station name\r \r and then which API to use. And by default, I believe it is a silo API.\r \r And sure enough, you get a tidy data frame back of the various metadata\r \r associated with this.\r \r And once you get the station code, then he can actually grab more of the data itself.\r \r And this is where he started now updating his functions\r \r to grab, you know, the various metadata associated with temperatures and whatnot, longitude, latitude,\r \r lots of other metrics here. I'm looking at the glimpse of the data frame here. There is a lot going on here. So if you're a weather junkie or weather nerd, this one's for you. There's lots going on in this space.\r \r\n\nSo he was able to grab almost 50,000\r \r observations\r \r over the last 135 years. So there you go. You got yourself some time series, if I do say so myself.\r \r So after a bit of tidying up, he decides, okay. You know what? I used to do some plots of this in the past as I was investigating some questions. Let me run these again. And sure enough with the new data and the tiny format, a little bit of g two code, and he's got a nice set of charts, Mike. Why don't you walk us through what he's trying to visualize here?\r \r\n\n[00:07:21] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Sure. So it looks like John originally had tried to create these chart charts\r \r using a package called Bombrang,\r \r which I was not familiar but appears to be be superseded,\r \r and now we're transitioning to ggplot, and I really really enjoy the ggplot\r \r code that he's written here. 1st, he's taking a look at the daily maximum temperatures and as you said, Eric, there is a lot of data here. We're we're going back, from 2024\r \r back to 18/89.\r \r So we have a scatterplot here with a beautiful curve on it, that shows, you know, has a different point for the day of the year,\r \r for each year between 18/89\r \r and 2024 and what the temperature\r \r was on the y axis,\r \r and we have some some color gradients based upon the decade\r \r as well, which I I think is a really\r \r unique and sort of interesting way to,\r \r add this additional dimension to the data as well. And it produces this really nice curve really beautifully done in g ggplot. We're we're using Viridis,\r \r to accommodate the color blind folks out there. So I can't say enough about this. It has a great caption on it as well. One of the things that I really appreciate,\r \r that John does, you know, throughout some of the other plots in this, chart\r \r is the use of I don't know if you would call them, like, Lambda functions for for additional filtering. But within the ggplot\r \r syntax you can pass,\r \r starting with like a a tilde a dplyr filter statement where the data frame itself that's being used by ggplot\r \r is, you know, referenced by this dotx placeholder.\r \r\n\nAnd there's multiple examples here in the code of how John goes about doing that and it's a really clean, nice syntax. It's probably something that I don't use enough.\r \r So if you are starting to get into, you know, a little more complicated\r \r ggplot visualizations,\r \r where in certain aspects of the plot or certain layers you you wanna use a portion,\r \r only a portion of the data and not the entire dataset,\r \r such as, in this daily minimum temperatures plot that John creates. He wants to highlight\r \r specifically in red so that these points stand out, you know, really really obviously\r \r to the user. All the observations,\r \r from June onward\r \r in the year 2024,\r \r so that you can see those really on top of the the rest of the Viridis, you know, gradiented,\r \r points on this daily minimum temperatures\r \r plot. And it's it's really\r \r simple\r \r syntax, I would say. Just this really nice dplyr filter statement and it's it's great that we have this beautiful concise\r \r interoperability\r \r sort of between ggplot and dplyr,\r \r to allow us to use those tools together to add these layers, you know, some that have a filtered context and and some that do not. Then we move into fastening as well where he has a daily maximum temperature plot,\r \r fasted by each month of the year. And one of the nice things here, again, is where we are,\r \r again, sort of calling out a specific point\r \r on each facet based upon a dplyr filter context where we're we're actually slicing the max, the the highest particular temperature across all\r \r 100 plus years, whatever that math is, between 18/89\r \r and 2004.\r \r\n\nAnd we're coloring that particular point red and we're sticking a geomtext label on top of it to let us know what year,\r \r that highest temperature in that particular fasted month took place in. So it makes it really, really easy to consume and take a look at this this chart to see the the temperatures,\r \r over time in a particular month, but then also call out the year that had the highest temperature\r \r in that month. It's it's really, really well done data visualization and he does the same thing, with the daily minimum temperature.\r \r And one sort of neat visual trick is that instead of,\r \r highlighting those those, you know, maximum\r \r or highest, temperature\r \r dots with the color red,\r \r as he did in the maximum temperature side, he will,\r \r highlight those with the color blue because these minimum temperatures are the the coldest temperatures,\r \r that that took place or that the year that had the the coldest temperature in that particular month I thought that was that was really nifty and something that I probably would not have thought to do but it's really interesting. And the the captions here and really the attention to detail\r \r are are beautiful and it's just a one of those really nice data visualization,\r \r blog posts, Eric, that I know you and I really love and appreciate because I'm a visual learner. This stuff stands out to me. Most of the work that we do for our our clients,\r \r ends or or, you know, utilizes some sort of data visualization as well to get our point across because it's it's one of the the ways that we communicate data the most effectively. So if you are just looking to either up your ggplot game or just get a little refresher and and take a look at what, John has put together here and some of his ggplot work. I can't recommend this blog post enough.\r \r\n\n\n\n[00:12:24] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. It's such a great introduction\r \r to a very concise EDA with a novel dataset too and very logically exploring\r \r these trends that he has seen as the years have gone by.\r \r Can we see, like, a seasonal type pattern in terms of the variation of these temperatures? And, yeah, he has noted that it's been a\r \r 2024. Apparently one of these lowest points was a negative 5 degrees Celsius. And yeah, that's a bit chilly.\r \r And, someone who who's lived in Michigan over my formative years. Yeah. I know how cold things can get. But,\r \r yeah, it's interesting to see. Again, the facets really show the story of how the spread tightens in the middle of the year and then spreads more out at the extremes or, I should say, the beginnings\r \r and ends of the year. Yeah. Really, really novel use. Like I said, that way, I'm the like functionality.\r \r\n\nThe key point there is these geomes in these data arguments. As long as you're getting a data frame back, you don't have to do this pre computed in fashion. You can do it in line, so to speak, in the geo, which again is great, especially if you're doing this EDA and you wanna iterate on this pretty quickly and with some pretty concise code. So I think it's a novel technique that, like you, Mike, I have not utilized this enough.\r \r So I have to take a take a bit of learning here as I revamp my simulation\r \r or visualizations of simulations that we're trying to do a better job of these days.\r \r\n\n\n\n[00:13:51] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 51,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yep. And you know me, Eric, you know, in terms of code review and things like that and collaborating with the team, I'm always trying to arrive at code that is\r \r as concise\r \r as possible while getting, you know, the point obviously\r \r across as effectively as possible about what it's trying to accomplish. And I I think this is a great example of doing that.\r \r\n\n[00:14:12] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 12,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. And and John never just stops there. He's got a\r \r a truckload of other amazing posts in his learning adventures. So if you really wanna get into the the nuts and bolts of other programming languages and how from an our user's perspective\r \r that he relates to them, there is a lot going on in his his blog. So if you haven't bookmarked it before, you absolutely should.\r \r\n\n[00:14:36] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. And his session info, he's got the the OS.\r \r\n\n[00:14:39] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 39,
        "trans_speaker": "Eric Nantz",
        "trans_text": "The OS says pop, p o p with an Yes. Information on the pop up list. That's what I'm using on this very machine, PopOS.\r \r A Linux. It's a Linux distribution. It's,\r \r made by the vendor called System 76 who makes hardware dedicated to Linux. So this, box I'm talking to you right now is called a Feilio PC\r \r that they make right here in the US and Colorado.\r \r And I've had it for about 4 years. Yep. If not longer, actually. Yep.\r \r So Very cool. A fellow PopOS user. That's awesome.\r \r He's a he's a fellow Linux nerd. So that's awesome. Love it.\r \r You know, Mike, I always wonder if someone was kind of missing this year as the months have gone by. Well,\r \r there is a tradition\r \r that certainly a shiny enthusiasts are very eager to see happen, and it is back. What am I talking about?\r \r\n\nIt is the 2024\r \r shiny contest\r \r run by posit is officially\r \r up and underway.\r \r And this blog post comes from us from the author of shiny himself, Joe Chang, as well as our posit, community manager, Curtis Kephart.\r \r And then the blog post is pretty short and sweet. If you've familiar with the contest before, there's not a lot of changes. But if you're new to this, this is the annual tradition where they are reaching out to the community and inviting them to submit their entries of their innovative\r \r ways of creating\r \r and and deploying shiny applications.\r \r\n\nThere are a set of requirements to be aware of is that both the data and the code\r \r behind the app should be open source publicly available.\r \r So, obviously, it goes about saying you probably don't wanna use your company's internal data for this, but that's neither here nor there.\r \r And they also invite you to deploy the application\r \r on this time around\r \r the recently launched posit connect cloud service, which I believe just went publicly available a month ago or so. In the past, that's been Shiny apps. Io. But if I'm, you know, that's the usual evolution of a enterprise and their software products, I must say. And that you store the code in a public repository that could be GitHub, get lab, that bucket, whatever have you.\r \r And there is a set of judges, which I don't believe, you know, the names just yet, but there will be a set of judges that evaluate\r \r each of the applications based on a set of metrics.\r \r\n\nI speak a little bit of,\r \r experience on this because it was like a few years ago, I was a judge on one of these contests and\r \r my goodness,\r \r the submissions were such high quality. It was really tough.\r \r Great to see the applications, but, man, trying to find\r \r trying to judge these in a fair way when you just wanna say they're all great. Right? So it's a there's a set of judges to help compete with these metrics and a lot of nice awards at the end there with you are a runner-up or an honorable mention and the grand prizes. They have all the details there. Yes. There will be a bunch of stickers being thrown your way,\r \r and the grand prize winner actually gets a half hour\r \r private meeting with members of the shiny team. So my goodness. That's a that's an awesome opportunity in and of itself to go over your app and what you can do in the future.\r \r\n\nSo you may wonder\r \r where can I go to look? Well, I will say that but and the nice thing in this post is they've linked to the previous blog post where they talked about the winners\r \r and runners up all the way back to 2019.\r \r I still remember that you're very fondly of being like, okay. I'm all over this.\r \r I had fun creating a Lego mosaic app as part of a shiny contest of yesteryear. That was a that was a fun time. Of course, if you look at that code now compared to what I do now, just don't judge too harshly.\r \r But, nonetheless, it's a great time of year. We're always excited to see what the community comes, comes to bear with this. So,\r \r yeah, if you're a shiny\r \r and a shiny enthusiast, this is this is a great opportunity to test your might if you will and see what you can bring into the community.\r \r\n\n\n\n[00:18:53] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I agree here. I can I feel like there's\r \r so many more\r \r options\r \r in the shiny ecosystem\r \r nowadays and so many different sort of branches and paths that you could pursue as as you you know make your entry into this contest you know is it are you just going to have the the repository\r \r are you going to deploy your app somewhere is it going to be on shiny apps that I owe or is it going to be on shiny live right\r \r you know\r \r leveraging the web our framework are you going to use shiny for Python or are you going to use shiny for our or are you going to use that the teal framework for building shiny apps which is popular among folks you know in your space Eric and and farm on in life sciences\r \r and they did note that they are going to have a special recognition for developers\r \r shiny so if you were someone just getting started with shiny don't be intimidated by this contest actually embrace it because you could potentially get the the special recognition for for giving it a shot\r \r and I\r \r believe that that you will find if you are a new developer to shiny and you take place, in this contest and you participate\r \r in it, you know, one of the I think sort of where this is hosted is is the posit community? Correct. So I would recommend that you ask any questions that you have along the way within that Posit community forum. People are really responsive.\r \r\n\nI hope and I would, you know, based upon my experience, I think that you'll find it welcoming. I think that you will find, folks pretty responsive to a lot of your questions,\r \r especially, you know, within the context of of this particular contest and everybody\r \r trying to put their best work forward. So,\r \r welcome\r \r everyone, 1 and all. It's put your submission in. I think the deadline is, Eric, when did we\r \r when does it look like the deadline is? Let me take a look. I should know that. Check this out beforehand.\r \r Deadline for submission is September 15th at midnight,\r \r anywhere on earth.\r \r\n\nSo you've got a little bit of time. It looks like we've got about a month and a half here, if my math is correct, based upon the time that we'll put this, this episode\r \r out. So\r \r get to developing.\r \r\n\n[00:21:06] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That's right. And and certainly kudos to the shiny team and Curtis for\r \r working with, like like you mentioned earlier, this is the first time that we're really calling out the opportunity in the life sciences space to leverage the t o framework,\r \r which is making huge waves in our industry to help build these\r \r very comprehensive shiny ass of a modular structure\r \r that are tailored for reviewing the, you know, the types of clinical data that we deal with on a daily basis. So this is an awesome opportunity to see what you can do with that. And I've even seen others in the community that are not not necessarily part of pharma levers teal to do some really fun exploratory\r \r data analysis of a shiny front end. So, yeah, definitely, if you're a teal enthusiast,\r \r like, that's growing pretty rapidly. Yeah. This is a great opportunity to put your put your work out there as well. And certainly, like you mentioned earlier, for our friends in the Python space,\r \r Shawnee 1 dot over Python was just released. So another great opportunity if you've been wanting to test your mind with the Python side of things. This is a great place to do it. I always think in general,\r \r finding,\r \r a dataset\r \r or or a domain that you're interested in\r \r in and having an opportunity like this is such a great learning opportunity too. Because again, you're going to see\r \r not just your submission being put into the queue. You're going to see in real time as these submissions come in, there will be a post on posit community\r \r dedicated or a category dedicated to this contest and you'll see these start to trickle in and you get can get really inspired to see what what everybody's up to. So I remember\r \r going down to the wire on my Lego one and seeing just the, the, the high quality submissions\r \r and have admittedly a first time have low imposter syndrome. Like, oh my gosh, I can't believe this. But then again, I'm liking it to great learning opportunity\r \r and it's an, someone else will benefit from what you're putting out there. It always happens. So I remember\r \r getting some nice, comments on my submission, but then many others were providing\r \r questions and comments on these posts. So, again,\r \r very big emphasis on learning and having fun learning, I might add.\r \r\n\n\n\n[00:23:17] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Absolutely. I can't wait to\r \r get my hands on keyboard and see what our team can come up with for a submission. I'm gonna hold myself to it.\r \r\n\n[00:23:24] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Yeah. Once the dust settles on deposit comp, I might have some more geeky opportunities to do shiny stuff with podcasting data again. We'll see. We'll see.\r \r But, yeah, we're on this podcast now. Right? And we wish we could talk about the rest of Arwek issue, but, there's always so much that we have time in today. So we're gonna wrap up here. Well, a couple of our additional fines that we saw in this week's issue, which again is always linked in the show notes of this episode.\r \r And I've always been, you know, trying my best to leverage, get effectively,\r \r especially with, you know, nice commit messages, you know, following, you know, standards\r \r that we maybe code reviews are gonna make easier if we follow the standards of\r \r one area that I admit I don't do enough of\r \r is there is a mechanism and get\r \r that will basically check before you commit\r \r run, I should say, a custom script\r \r that might check for various things, such as maybe number of files you're committing, maybe number of lines, maybe the type of commit message, maybe you have, like, a a very formal framework of\r \r it. You can build what are called pre commit hooks in your local Git repository\r \r to help be that kind of frontline check before you actually do the commit.\r \r\n\nWell, there is a new package in your ecosystem called pre commit, which will let you author these pre commit\r \r hooks from the comfort of your r installation itself.\r \r And there is also, I believe, a little bit of requirement for Python as well.\r \r So this might be using reticulate under the hood. I'm not quite sure.\r \r But once you have everything set up, you're gonna be able to do, you know, a very nice, there's a nice package documentation site that we'll link to in the show notes going from the motivation of why you want to leverage this as well as some built in hooks that you can leverage\r \r such as for styling,\r \r such as making sure your read me is up to date if you're doing our markdown for your read me, making sure you're not leaving\r \r a browser statement in your code because who would ever do that? Oh goodness gracious. Who would ever push that into production? I don't\r \r know. My goodness. Where was this few years ago? But, yeah, there's a lot to choose from here, so,\r \r I may need this. What do you think, Mike?\r \r\n\n\n\n[00:25:42] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That's an awesome resource, Eric, and I may need that as well.\r \r Yeah. That that could have saved me many many many times over so I need to check that out.\r \r I found a really really cool blog post called llama llama oh give me a sign what's in the latest IDSA\r \r guideline.\r \r And I could probably just leave it at that. That's such a cool blog post title but I won't. Right. This\r \r this one is authored by Ken Koon Wong\r \r and it is all about leveraging,\r \r you know, open source, I believe,\r \r LLM,\r \r RAG to be able to ask questions\r \r of the latest guidelines from the Infectious Diseases,\r \r Society of America\r \r and it is incredibly\r \r comprehensive.\r \r\n\nIt,\r \r uses Reticulate as well to interrupt R and\r \r Python to be able to to stand this solution up and lots of gifts, lots of content,\r \r it's an incredibly\r \r of blog post and if if this is something, that you might find interesting in using LLMs and and rag to be able to ask questions or or summarize\r \r a particular\r \r document or set of documents or or guidance that's out there such as,\r \r the the Infectious Diseases Society of America guidelines.\r \r I would highly recommend checking out, how can went about doing this. It's incredibly comprehensive.\r \r\n\n[00:27:05] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 5,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Oh, this is incredibly useful too because in many enterprises,\r \r it's not just about trying to be, quote, unquote, future proofing your questions, but taking what you already have,\r \r whether it's these documents of, like, important information\r \r or metadata associated with, like, infrastructure\r \r or where you're designing experiments or whatnot.\r \r Being this is a great pose. I'll kind of walk through what is that process of feeding those documents in,\r \r creating under the hood what these vector databases they caused. So then the LM\r \r will use that as a source to help answer these questions. So this is a a very hot topic. And and and my industry is we deal with, you know, thousands upon thousands of study documents and patient\r \r documents and whatnot to be able to, you know, effectively put an LM in front of that to explore what we have.\r \r\n\nHeck, you know what? Even in the podcasting space, there's been talks of trying to consume our show notes and having an LOM in front of that to maybe figure out, Hey, when did Mike and Mike and Eric talk about that, that, that new shiny package or that or that new, portal thing? You know? Boy, that would be the dream. Right? That little bot in front of that. I don't know. Just saying. Sweet.\r \r It's all the metadata is there, folks. This may maybe we'll help to build that, but this post is a good good way to get us started, I think.\r \r\n\n[00:28:27] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Add us to the side project list.\r \r\n\n[00:28:29] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Eric Nantz",
        "trans_text": "As if it wasn't long enough already. What am I doing to myself? And on top of that, I'm trying to learn Nicks to boot on this. So my gosh. What what am I doing to myself?\r \r Nonetheless,\r \r no side project\r \r elsewhere here. We're gonna\r \r tell you about how you can contribute to rweekly itself. That doesn't have to be as in-depth as a side project. We are just a pull request away.\r \r If you find a great new resource, new package, new blog post, whatever have you, we it's all marked down that comprises the our weekly site. So if you know how to put a link in our markdown or markdown itself, you know how to contribute to our weekly. It's basically that easy. You have a template and a GitHub issue,\r \r or a poll request template to navigate you through the requirements. Again, very straightforward. We welcome all your contributions.\r \r\n\nAnd, of course, we welcome hearing from you as well. As we mentioned in a couple weeks, Mike and I will be in Seattle for Positomp. But in the meantime, if you wanna get a hold of us, there's a few ways to do that. We have a contact page in the episode show notes when you download this in your favorite podcasting software of choice. You also if you're on a modern podcast app like Podverse or Fountain, you can send us a little boost along the way as well. We got details\r \r on how to do that in the show notes, and you can find us on the various spheres of social media\r \r circles.\r \r\n\nI am mostly on Mastodon these days with [email protected].\r \r You can also find me on LinkedIn. You search my name. You'll find me causing lots of fun stuff there potentially\r \r and on that weapon exiting from time to time with at the r cast. Mike, where can listeners get a hold of you? You could find me on mastodon@[email protected],\r \r\n\n[00:30:09] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Mike Thomas",
        "trans_text": "or you can find me on LinkedIn if you search Catchbrook Analytics, k e t c h b r o o k. You can see what I'm up to.\r \r\n\n[00:30:17] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Very good. I'm always every time I boot up in the morning, I'm looking looking for Mike's newest adventures, so I'm always pleased when I see that.\r \r Nonetheless, yeah, lots of adventures that we have to get on to the rest of our day. But, of course, we thank you so much for listening from wherever you are around the world. We really enjoy doing this every week, but we're gonna close-up the the proverbial mics here, and then we're gonna invite you to join us for another episode of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_31_highlights",
        "chap_timestamp": 36,
        "chap_text": "Unpredictable weather",
        "chap_href": "https://jcarroll.com.au/2024/07/27/let-s-talk-about-the-weather/"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "chap_timestamp": 27,
        "chap_text": "Shiny Contest 2024",
        "chap_href": "https://posit.co/blog/announcing-the-2024-shiny-contest/"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "chap_timestamp": 51,
        "chap_text": "Precommit",
        "chap_href": "https://lorenzwalthert.github.io/precommit/index.html"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "chap_timestamp": 52,
        "chap_text": "llamas all around",
        "chap_href": "https://www.kenkoonwong.com/blog/llm-rag/"
      },
      {
        "ep_name": "issue_2024_w_31_highlights",
        "chap_timestamp": 38,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_30_highlights",
        "ep_date": "2024-07-24",
        "ep_duration": 25,
        "ep_description_short": "Creating retro-gaming sprites rendered from the comforts of R? Yes we can! Plus an honest take on the utility of Github's Copilot Workspace in the context of package development, and taking the concept of code trees to another level with treesitter. Episode Links This week's curator: Ryo Nakagawara - @[email protected] (Mastodon) & @RbyRyo)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_30_highlights",
        "description_long": "\r \r Creating retro-gaming sprites rendered from the comforts of R? Yes we can! Plus an honest take on the utility of Github's Copilot Workspace in the context of package development, and taking the concept of code trees to another level with treesitter.\nEpisode Links\n\nThis week's curator: Ryo Nakagawara - @Rby[email protected] (Mastodon) & @RbyRyo) (X/Twitter)\nTile-style sprite delight\nSome thoughts after a trial run of GitHub's Copilot Workspace\nExtracting names of functions defined in a script with treesitter\nEntire issue available at rweekly.org/2024-W30\nSupplement Resources\n\ntree-sitter-r https://github.com/r-lib/tree-sitter-r\nShiny.telemetry 0.3.0 https://www.appsilon.com/post/shiny-telemetry-0-3-0-update\nIntroduction to R with the Tidyverse https://introduction-r-tidyverse.netlify.app/session1_notes\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nMoonlight Vibin' - Mega Man X5 - DCT - https://ocremix.org/remix/OCR02053\nForest Through the Trees - Shea's Violin - Final Fantasy Mystic Quest - https://ocremix.org/remix/OCR04484"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://mstdn.social/@R_by_Ryo"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://www.rostrum.blog/posts/2024-07-14-tilebased/index.html"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://epiverse-trace.github.io/posts/copilot-workspace/"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://masalmon.eu/2024/07/18/extract-function-names-treesitter/"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://rweekly.org/2024-W30.html"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://github.com/r-lib/tree-sitter-r"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://www.appsilon.com/post/shiny-telemetry-0-3-0-update"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://introduction-r-tidyverse.netlify.app/session1_notes"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://ocremix.org/remix/OCR02053"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "links": "https://ocremix.org/remix/OCR04484"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with episode a 172 of the Art Wicked Highlights podcast.\r \r If you're new to the show, this is the weekly podcast where we talk about the latest highlights and awesome additional resources that are shared every single week in this week's our weekly issue. My name is Eric Nantz, and I'm delighted that you join us wherever you are around the world. It's hard to believe July is almost over, but, of course, we got a lot more great art content to talk about with you today.\r \r And I never do this alone as you know. So at the virtual hip right here on this split screen here is my cohost, Mike Thomas. Mike, how are you doing today? Doing well, Eric, at the virtual hip.\r \r Only for a couple weeks until we get to see each other again in Seattle maybe? That's right. Yeah. Her her the countdown is on, so I gotta get all my bits sorted out and hopefully get that get that talk ready to go, but all all in good time. But, yes, the you might say the nerves are starting to hit a little bit, but again, it'd be great to see you again and see all the the wonderful peeps in data science and other sectors that frequent that conference every year.\r \r\n\n\n\n[00:01:06] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. I'm super excited as well. We have a ton of clients that are going to this conference\r \r this year, so I think it's gonna be a big one. I'm I'm almost surprised how many folks I I know that are gonna be there. So it's gonna be it's gonna be a party.\r \r\n\n[00:01:19] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Party as well. Yeah. You're gonna be high in demand, my friend. I hope they even get a few minutes of you after all that.\r \r\n\n[00:01:26] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 26,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Quick short story is last time that last year when we were at Pawsit Conference,\r \r Eric and I met and it wasn't 2 minutes after, you know, we met, I guess, for the first time in real life that somebody came up and asked me to take a picture of you and them because you are the celebrity at this conference,\r \r Certainly not me. So Oh. Goodness. Goodness. Yeah. That was how it started.\r \r\n\n[00:01:49] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That's yeah. That's how it always starts. Yeah. But you know, I think the tables will turn this time around. But, nonetheless, we're gonna have fun connecting with everybody. And, yeah, we're we're both gonna we're gonna have a lot going on there, but we got a lot going on here, my friend, with the mic in our hands. So let's get going here. Our issue this week was curated by Ryo Nakagorua,\r \r another one of our OG\r \r curators and longtime contributors to our weekly.\r \r And as always, he had tremendous help from our fellow Rwicky team members\r \r and contributors like you all around the world with your poll requests and suggestions.\r \r\n\nAs you may have heard in previous episodes,\r \r I admit the teas has input ever over like a few months ago\r \r that I think who needs that like\r \r game development engine, like unreal or anything. We can use our developer games. And there is yet another milestone in this workflow here that we're gonna talk about leading off this episode. And we are talking about the latest blog post from Matt Dre who has been on this quest\r \r to leverage not only tooling that he's creating, but also augmenting some of the awesome tooling that's being created by Mike Chang who you may also known as cool but useless on the social interwebs.\r \r\n\n[00:03:01] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Mike Thomas",
        "trans_text": "So probably the highlight of this blog post is that we know the full name of of Mike FC. Cool but useless. Right?\r \r\n\n[00:03:08] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 8,
        "trans_speaker": "Eric Nantz",
        "trans_text": "You are correct, sir. This may be the first time we've ever seen that spelled out. So\r \r I guess the mystery is over.\r \r\n\n[00:03:15] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 15,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I know. I apologize to Mike if he was trying to, keep that from us for because I he did a pretty good job for a long time,\r \r until\r \r this blog by Matt has come along.\r \r\n\n[00:03:26] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 26,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. You know, I I liken this to, you know, for those of you that follow pro wrestling, there are always that those days in the eighties where you didn't know that Hulk Hogan is really named Terry Beleja\r \r until, like, you were much older. Maybe it's just one of those reveals, like the gimmick the gimmick. The time's up for the gimmick, but nonetheless, we we know who you are, Mike, nonetheless.\r \r But, Yes. You've been you've been hard at work on these packages. So what Matt talks about in this post here is that\r \r he is leverage what Micah's created\r \r called the Nara package, which is\r \r basically super charging R's ability to produce raster based graphics, but\r \r tailor made to things like pixel art.\r \r\n\nAnd he, and Matt what Matt has done is he's augmented the narrow package tooling\r \r with his previous package called rogue like, which if you recall from a highlight episode probably 4 or 5 months ago,\r \r was a way in r to create these, in essence, randomly generated\r \r dungeon crawlers all in text based format. So you get a nice ASCII art of the dungeon with the layouts, and it would respond to your key presses\r \r to have you as the player with a little, you know, maybe p symbol in the middle there going up, down, left, right, and then the randomly\r \r generated enemies or other artifacts\r \r would move along alongside you.\r \r\n\nSo he simply now merged the ability to do this, but now instead of the textual representation of those dungeons,\r \r he is augmenting\r \r some nice retro style looking sprites here. In fact, he's leveraging\r \r an open source framework,\r \r from a,\r \r username Kenny.\r \r He has what's called a tiny asset pack of all these different sprite arts that are 16 by 16 pickle\r \r pixels. So\r \r really, really nice, and if you ever played those\r \r RPGs of yesteryear, like, say, dragon warrior or final fantasy, yeah, these are gonna look right at home\r \r in those in those artwork.\r \r\n\nSo how does this actually work? Well, as I mentioned,\r \r there is a lot of the underpinnings have already been made by Matt in this roguelike package,\r \r But now instead of the textual representation,\r \r he is mapping\r \r that mesh\r \r which basically is a matrix\r \r of, you know, 16 by 16 or whatever dimension\r \r where each cell has either\r \r a movable space\r \r or an obstacle,\r \r the player or the enemy.\r \r And so that's already randomly generated up the front, but then that is being trans translated into these tiles that are being created\r \r by the narrow package.\r \r So in the blog post, you see the textual structure of it, which again will look very similar to if you use Matt's roguelike package, but then that handoff\r \r is then translated, like I said, into this tile based\r \r board. And now you see the nice image\r \r going going under the matrix representation.\r \r\n\nIt just looks literally\r \r picked out of a retro game. It it really is\r \r absolutely amazing what's going on here.\r \r And you can do all sorts of things of this. Obviously, you can make this as big or small as you want,\r \r but there is a lot more that is coming, and that's, tooling here.\r \r He wants to make, you know, really a true loop of the game, which if you played\r \r RPGs or roguelike dungeon crawlers in the past, you know that as you move along the board, you get a random encounter with an enemy, do the battle, win or lose, rinse and repeat. But, of course, it's almost like an infinite loop per se.\r \r So he's looking at ways of having that true kind of gaming style loop\r \r in the back end here. And of course, like any RPG, you're gonna have it after your inventory at some point. Right? You gotta have those weapons, those potions,\r \r those antidotes when you get poisoned or whatnot. So,\r \r obviously, this is probably gonna be a huge rabbit hole if they choose to go down this route. But I am very much eagerly watching this. But, of course, the first major step is what the user actually sees.\r \r\n\nSo what's seen here with this, package that's Matt's created, he now calls a tile based. This is the start, folks.\r \r Like I said,\r \r who needs to pay for that unreal engine or that unity engine? Boot up your r console and go to town. Right, Mike? Absolutely. And it's you know, just reminds me of the old adage that\r \r\n\n[00:08:02] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 2,
        "trans_speaker": "Mike Thomas",
        "trans_text": "R is only a programming language for statistical analysis. Right, Eric? Can't can't do anything else well. Yeah. Not at all. Not at all. And this also throws me back to,\r \r I think these graphics are like equivalent to\r \r at least, you know, the the Game Boy Color\r \r at times of the world. This is reminding me of my Pokemon Blue game that I used to to play on long car rides quite often. Oh, yes. I think the graphics\r \r are are quite akin to that. It's it's pretty incredible that I think, as you mentioned, Eric, there's only\r \r like 4 they look like emojis, but I guess we're calling them,\r \r the these objects from\r \r a tiny asset pack which is some resource\r \r out there\r \r that has all of these different 16 by 16 pixels\r \r that you can use. I imagine that they're like Creative Commons licensed or something like that, which is why\r \r Matt chose to to use them and incorporate them and this whole entire game it looks like the graphics are just made from these 4 different emojis if you want to call that which is it's pretty incredible.\r \r\n\nThe idea that you know\r \r the the things that we're looking forward to here in the next iterations of this\r \r potentially could be, as you mentioned, a true game loop, a way to have some sort of an inventory system.\r \r The sound generation is really cool to be able to have some sort of a soundtrack\r \r to this game as well. I think I've seen some some more things from Mike FC coming out on Mastodon lately, if I'm not,\r \r if I'm not mistaken,\r \r around our packages that are doing some audio things.\r \r So maybe there's a potential chance that that could get integrated into this package as well\r \r but, you know, it's it's hard to do this justice in audio form. You really have to check out the blog post, see the visuals that are there,\r \r install the package from GitHub yourself, and try not to waste a couple hours,\r \r going down, you know, playing games in R. I I I dare you to try. And so this is this is really really cool stuff. I think it's a fun way to start off the highlights, this week, and I'm looking forward to what else is to come here. Yeah. The creativity\r \r\n\n[00:10:09] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Eric Nantz",
        "trans_text": "possibilities\r \r here are practically\r \r endless. And, of course, I as I'm watching this, I'm wondering,\r \r well, how would you be able to distribute this?\r \r Can you imagine a web assembly app that puts all this together? Good grief. I mean, I've seen, you know, maybe I shouldn't say too much here on audio, but I'll say it anyway. There are even on the Internet archives, some of these web assembly powered,\r \r you know, emulators of the classic arcade games that have long passed your IP\r \r windows, but it's all in your browser. It's like using native JavaScript to do it. Just imagine if, you know well, you know, we've been watching the WebAssembly space quite a bit.\r \r I wouldn't put a pass either me or someone else maybe working with Matt or Mike to throw their hand at this and see what happens because\r \r just imagine how easily you could distribute something like this. Just mind blowing possibilities here. Absolutely. No. Sort of reminds me that that\r \r\n\n[00:11:04] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Mike Thomas",
        "trans_text": "the shiny contest is back. I probably should have saved that for my additional highlight, but I saw that, yesterday. I'm come across on my social media feeds, but it sort of reminds me of that the Appsilon app. I believe that was like the shark or underwater. That's right. The Shark Attack app. Yeah. That was awesome. That can be hosted on WebAssembly.\r \r Ivan from my team has recently, you know, published his first shiny live experimental app that's a card game.\r \r So, yeah, I think the the gaming Shiny Live,\r \r you know, crossover\r \r here is is gonna happen pretty soon.\r \r\n\n\n\n[00:11:39] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 39,
        "trans_speaker": "Eric Nantz",
        "trans_text": "It's not a matter of if, Mike. It's when.\r \r\n\n[00:11:43] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Sounds like you found your next side project.\r \r\n\n[00:11:55] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 55,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Speaking of trying things out, unless you've been living under a rock, you know that some of the biggest advancements in our world attack have been the use of generative AI and large language models to help with all sorts of things in our daily lives and especially in the world of software development.\r \r You've sure you've heard about efforts such as what Microsoft at piloted years ago with what's called copilot,\r \r which if you opt into that in your IDE such as visual studio code, also there are plugins to this with, say, our studio and whatnot. You'll get these, you know, auto completed like suggestions as you're typing out code. Maybe it's some boiler plate for a function call. Maybe it's helping flesh out some additional parameters or whatnot.\r \r Well, there obviously this space is moving quite fast and our next highway today talks about some recent findings\r \r that have been explored by the Epiverse team\r \r on their explorations of what's called the copilot workspace initiative.\r \r\n\nSo as I mentioned, this is coming from the epiverse blog. It's got a set of authors here. We got Joshua Lambert,\r \r James Azzam, Pratik Gupta, and Adam Kucharski. Hopefully, I said those right. They have teamed up here to talk about as they've been watching this space of how\r \r AI and LOM models are helping with development.\r \r What would be the what would be the situation\r \r of trying to leverage this new copilot workspace,\r \r which is kinda taking\r \r what was mentioned earlier by me in this copilot initiative to the next level\r \r and not just auto complete code as you're typing,\r \r but actually take a set of requirements that are surface Savia GitHub issue\r \r and just see how to actually produce the code or produce a solution to the problem at hand.\r \r\n\nSo they decide, let's do an experiment here. They teamed up with a group of professors and their organization\r \r to do 3 different experiments with this copilot workspace to see how it works in the real world.\r \r The first experiment, and they tried to go, I guess, from easy to difficult as we go through this\r \r is\r \r say, they have a function in their r package\r \r that has been internal up to this point, but maybe they got user feedback and says, hey. You know what? That's a useful function. Maybe we should export that.\r \r So using their epi now 2 package,\r \r they looked at an existing issue that was, again, was already filed about,\r \r hey, this function called epi now 2_cme\r \r c m d stand underscore model function\r \r should be exported.\r \r\n\nSo they let the copilot workspace turn loose on this\r \r and\r \r it did get the job done, albeit\r \r in ways that probably aren't as intuitive to an R user. So let me explain a bit by bit here.\r \r The Copilot workspace\r \r did determine that, oh, you know what? We need to replace that keyword of internal in the r oxygen documentation of that function\r \r and replace that with export\r \r and also having to update the namespace.\r \r Now there were some little shenanigans\r \r here because apparently it does change the formatting one of their other function arguments.\r \r I guess doing some text tidying up, which again, yeah, that's fine and all.\r \r\n\nBut in the end, it did technically get the job done.\r \r But this Copilot workspace is not intelligent enough to understand\r \r how documentation is updated with the modern r tooling for package development,\r \r such as using things like dev tools document\r \r or, you know, more natively of our oxygen to the re reupdate the name space dynamically. It did it itself manually like you would maybe in the early days of package development.\r \r Package development.\r \r So context itself, not quite there yet,\r \r but you can't say it didn't get the job done with this. It just did it in a much more\r \r manual fashion. So, you know, so far, you know, pretty promising.\r \r\n\nLet's take the difficulty up a notch, Mike, because now in the next experiment, they wanna add\r \r a new model\r \r to the package,\r \r albeit not too difficult from a complexity\r \r perspective, but this is upping the ante into what the Copilot workspace can do. How did this one fare? What do you think? Yeah. Not quite as well, Eric. They wanted to add what's called a simple epidemic model,\r \r\n\n[00:16:21] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Mike Thomas",
        "trans_text": "to the r package,\r \r that contains, you know, a bunch of different models as well. So they, I believe, created a new issue if I'm mistaken, to add a basic SIR model, it's called, with a couple sentences on exactly what they were looking for.\r \r What happened was get Copilot created\r \r a script,\r \r a an R script\r \r with a naming convention that followed the naming convention of the other modeling scripts that they had. This one was, you know, within the R directory which was good\r \r and, the name of the script was model_sir\r \r which again, you know, follow the the naming conventions that they've used in this epidemicsr package\r \r that they have right now.\r \r\n\nAnd I think this follows a lot of sort of the the same things that I've seen, you know, over and over again with Copilot, with chatGPT,\r \r with some of this,\r \r it gets you close to the right answer and puts down, you know, some of the the the right things that you would want there, but not in the way that you would necessarily\r \r want that things organized,\r \r if you will.\r \r You know, so the code that was generated, you know, constructed that basic SIR model,\r \r used roxigeon 2 as as well,\r \r to document the code,\r \r but but a lot of aspects of the code, you know, didn't match what they asked for in that issue.\r \r The code contained what they call some inadvisable coding practices in R, you know, what we like to call code smells,\r \r and the model it self, you know, followed the standard set of of differential equations that are solved using the the desolve\r \r which is one,\r \r that they had actually requested\r \r in their issue, but it didn't have any options to input, you know, things that are are really important to them like interventions,\r \r which is, you know, what they the the Copilot\r \r had suggested that it would actually include but but failed to do so.\r \r\n\nThe other downside is that they they use the require,\r \r dissolve\r \r they use the require function to import the dissolve action,\r \r function package, excuse me, in the body of the generated code. And as you know, Eric, when we are developing\r \r our packages,\r \r that's not something that you want to include in your function. Right? Yeah. The smell was stronger that one. Oh, my goodness. That one stinks to high heaven.\r \r And you know, we use a lot of utility functions\r \r like from the dev tools and they use this package if we want to leverage a new package within our our package\r \r in\r \r a right in a proper way we could do you know use this use underscore package dissolve Right? And that'll add that to our description file.\r \r\n\nIt might add it to the namespace where appropriate.\r \r And obviously, we could,\r \r request the use of that package in our roxygen, right, import or import from\r \r code decoration\r \r above that particular function. So that's a pretty bad one right there as well.\r \r So you know a a few different code smells here. I don't think that the function itself accomplished exactly what they were looking for that model\r \r to do as well as, you know, some of the kind of ugly best practice\r \r things. So we're we're starting to head a little bit in the wrong direction here as we get into experiment 3.\r \r\n\n[00:19:44] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And so talk about upping the ante a little bit, but, yeah, it's something that is very relatable to every one of us that are developing, you know, intricate code bases.\r \r They wanted to see if this Copilot works makes it actually do an intelligently\r \r driven\r \r code review of the package itself. As you know, as you get, you know, maybe new features put in bug fixes or whatnot, you get that,\r \r point of eventual re release, maybe an update you wanna release on crayon or whatnot.\r \r You wanna have that code review to make sure that all the things are looking good. You're being efficient with memory usage, efficient with coding best practices.\r \r I always saw a little glimpse that, yeah, it may not be the best at coding practices.\r \r\n\nSo what they are expecting to see is hopefully in this issue of asking it to do the code review, they would have a documented set with, you know, links to particular snippets of code or maybe things could be\r \r optimized or maybe even just asking questions about the code or whatnot.\r \r Well, bad news is it didn't actually do any analysis of the code itself.\r \r It basically\r \r regurgitated\r \r some of the changes that were already described in the poll request\r \r and looking at change log, I e, from the news file and just kinda\r \r bundling all that together as a narrative,\r \r which in essence means that it does a great job of reading\r \r the news that is\r \r not so much looking at the actual code\r \r than the thing changes that could be made to make the code better.\r \r\n\nSo this is where, you know, humans aren't being replaced on this one by by a long shot.\r \r But what I do appreciate is a, they gave this, you know, 3,\r \r again, realistic use cases\r \r and not all difficult. I would say that the first one, the first experiment is definitely the easiest one, and it did get the job done.\r \r Just not in the way\r \r of you as an our developer\r \r wouldn't carry that out. So I think the takeaway here is that\r \r as we as I agree with them and their takeaways here, there's a long ways to go.\r \r There are avenues of success here, but I think you as the end user\r \r definitely need to be vigilant\r \r on making sure that whatever prompts or requirements you're feeding into these\r \r are being accurately,\r \r you know, addressed in the results you get. And if you're getting code back,\r \r yes, you definitely should not take that blindly, so to speak. You need to make sure\r \r does that fit your overall paradigm of a code base, your stylist,\r \r you know, your style guides, if you will, your best practices for your team.\r \r\n\nObviously,\r \r there's much more work to be done to make these, in my opinion, more dynamic so that\r \r as it looks at the code base for a package or maybe even a set of packages\r \r that it can really\r \r grok if you will.\r \r What are the key paradigms that are governing that code base instead of relying on a whole bunch of additional sources of who knows where it gets it with respect to this effort.\r \r I think being intelligent enough about what's actually being done in the project is is the way to go\r \r For research software engineering context, like what this is based on,\r \r yeah, maybe some help, but in the end,\r \r sometimes\r \r you you just can't get away from doing some of this manually\r \r right now. But this space is moving fast. And again, I really appreciate\r \r their their attention to detail\r \r to put it through the paces.\r \r\n\nBut in the end, I'm not I'm not moves asleep over the fact that the AI bots are gonna take over package development anytime soon. What do you think? Me neither, Eric. You know, I I'm trying to be, like, open minded\r \r\n\n[00:23:28] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 28,
        "trans_speaker": "Mike Thomas",
        "trans_text": "about it and I think as long as you have the expertise to be able to to sniff out the good from the bad,\r \r running your code, you know, through Copilot\r \r for any of these purposes,\r \r can still be useful. Right? I'm not sure if I want it to actually physically make these changes,\r \r to my code in any way, but maybe, you know, it's not such a bad thing for it to\r \r provide me with suggestions. Right? There might be something if I ask it to do a full blown code review, there might be a little thing that it finds that I missed or or somebody in our team missed, because, you know, programmatically\r \r pouring through the the code, having a computer do that, might be able to catch things easier than, you know, we can catch with the naked eye.\r \r\n\nEven looking at our our code for a little while. So I think I'm open to suggestions, let me put it that way, from Copilot and from the chat GPTs\r \r of the world, but I'm still in a place right now where I am going to to often take those with a grain of salt and, you know, leverage sort of my expertise\r \r over in what's coming back from those types of models.\r \r\n\n[00:24:34] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. One use case I'm seeing more and more often in many industries or many organizations\r \r is\r \r the process\r \r of maybe refactoring\r \r from, like, one type of code base to another, especially when you're shifting languages.\r \r A lot of companies are turning to LLMs and AI to help with that conversion.\r \r I've always had a little bit of spider senses tingling at this because\r \r with that new code,\r \r will it look like somebody with competent skills and whether it's r, Python, JavaScript, or whatnot,\r \r will it look like they wrote it, or is gonna look like a hodgepodge of tutorials that have found online and trying to do all, like you said, these\r \r mix mash of different coding styles and practices. So\r \r I think we're still a ways there but I know that is a hot topic in many circles\r \r to see how fast it can get you to that next step And there may be cases where it gets you really close and you just have to maybe enough or 10% of your time to revise it. There may be other cases where it just gives you absolute garbage, you might as well throw it away.\r \r\n\nSo in any event, I think keeping an open mind and being realistic,\r \r I think are very important in these\r \r still early stages of this whole tech sector or this whole industry.\r \r But I think I think good things are coming. Just gotta use it responsibly, of course.\r \r\n\n[00:25:54] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 54,
        "trans_speaker": "Mike Thomas",
        "trans_text": "We'll see.\r \r\n\n[00:26:04] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And then rounding out our highlights today, speaking of refactoring things, you may have a situation\r \r where there are some things you could do manually,\r \r but then as you do it over and over again,\r \r especially as you're dealing with a large code base, maybe not even the one you wrote yourself,\r \r you wonder there's got to be something that can help me get there even faster.\r \r So our last highlight today comes from a frequent contributor, Myel Salman, from her recent blog\r \r about her recent journey\r \r to look at all the names of functions under defined in a script or set of scripts and a new approach that is new to her and frankly new to me as well.\r \r So this is fresh off the recent USAR conference where I'm seeing some of the videos of that come online, and it sound like it was a terrific event. Of course, I have a little FOMO every time I see that because I still haven't been to a user yet, but someday that will be checked off the bucket list. It just wasn't able to this year.\r \r\n\nBut one of the talks that my old discovered that she didn't see live, but she heard about after the fact\r \r is, Davis Vaughn,\r \r from the PASA team\r \r talked about a framework called tree sitter.\r \r What tree sitter actually is is a mechanism\r \r to parse code\r \r for somewhat like what we've heard in the past with things like abstract syntax trees and trying to parse either variable names, function names, or whatnot.\r \r Apparently, tree sitter is a c library and I guess maybe other libraries as well\r \r to help with that mechanism of parsing, you know, code intelligently.\r \r So her use case was a following is that\r \r she\r \r wanted to help out,\r \r finding\r \r wanted help finding functions\r \r in pat in, in the package eye graph. And if you know what an eye graph is, it's kind of like the standard bearer of doing network\r \r visual\r \r network, you know, data representation,\r \r which you can turn into network diagrams, you know, very much like tree setups are very\r \r intricate networks.\r \r\n\nI graph has a long history. We've covered it before on the show and it is a massive code base.\r \r So she wanted\r \r to have a use case of okay what functions and I graph\r \r now there is a certain operator that I graph has. It's like a bracket or square operator.\r \r She wanted to see\r \r how many functions were only using within this special operator.\r \r So she had to literally go within this operator function to find all the utility functions throughout.\r \r The example she has in the post only has a couple of them just for kicks, but imagine there's, like, a whole bunch of them.\r \r And she wanted to be able to she had to refactor these, but she wanted to or at least get to the point of refactoring them, And she didn't want to manually copy paste all these function names or discover them.\r \r\n\nSo\r \r she has used things like XML parse data in the past. We've covered on a previous episode\r \r of our expirations without the parse, a complicated function.\r \r She wanted to see what it'll look like with tree sitter to do that similar\r \r operation. So she talks about her for use case here. She loads the package,\r \r and then she loads the parser for the r language and that\r \r reads in that function text or that script that has the function text.\r \r And then she wanted to figure out, okay,\r \r where is the root of that tree that is now gonna govern all the child nodes\r \r of that function.\r \r\n\nSo\r \r this gets a little in the weeds here, but there is a function in tree sort of called query\r \r that you can feed in kind of a snippet of code that you wanted to look for.\r \r And there is like a little kind of YAML like structure to it. You define\r \r what's on the left side,\r \r what's on the right side, and you give it kind of like the plain text like label of that, wherever it's identifier,\r \r a definition,\r \r and then you kinda give it looks like a regex kind of comparison\r \r about what you wanna match it to. This is all news to me. I've never seen the tree sitter syntax before.\r \r But sure enough, when you run that\r \r and then you get a nested list back in r,\r \r that gives you the text of what it found\r \r versus the the actual text itself,\r \r the expression that's kinda more translated to the tree sitter notation of it. And then\r \r you've got\r \r you gotta step it away there. She didn't find the children functions yet,\r \r but guess what? There is more\r \r It's almost like you have to do a nested query to get to that point.\r \r\n\nYou then do the similar kind of syntax. You're looking at the left side and the right side definitions,\r \r finding another query of the previous query and then she was able to find\r \r the names of these different functions,\r \r again, internal functions\r \r that are in this Square operator. And that's a huge list that after that point.\r \r But then through some gripping to that, she was able to get\r \r all of those hidden function names\r \r in that square operator.\r \r There's about 5 or 6 of these in in\r \r intact, but this this all programmatically\r \r shouldn't have to look at all this herself.\r \r\n\nSo you can imagine if you scale this up to, like, a 100 times this size\r \r with a huge r package,\r \r this might be a great way to kind of do this kind of, like, unique query language\r \r with TreeSetter\r \r to get to what you need.\r \r Admittedly, I have never even ventured near these rabbit holes before,\r \r but I could see for our legacy Go base. And, again, I stress maybe one that you yourself didn't write as you're getting familiar of it. Because I've looked at iGRAPH before, and, yeah, there there's a lot going on under the hood on that one. So I wouldn't know where to look with trying to pick out these internal functions.\r \r Looks like tree sitter is something to to take a look at. And fun fact about tree sitter that I discovered after briefly looking at Davis's talk,\r \r this is being incorporated directly\r \r into posit's new IDE\r \r positron\r \r as part of its base for when you look at, say, the outline view of a script and getting those function definitions, which we've seen in our studio as well. But now I believe tree sitter is doing the heavy lifting to grab all those\r \r contexts around those functions. So it looks like tree sitter is here to stay for sure, but, what an interesting use case here to have to take a note of if I have to deal with legacy code based discovery in the future.\r \r\n\n\n\n[00:32:34] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Eric, I feel like Mal always brings us some pretty interesting use cases on the highlights. This is actually quite similar to a blog post that she authored\r \r a little while back where she did something very similar but,\r \r in XML\r \r instead using an XML parsed data\r \r R package,\r \r I believe. So this is if you wanna take a look at that blog post and this one side by side, I think it'll give you 2 different\r \r approaches to essentially doing the same thing.\r \r And it looks like there's about, you know, 5 or 6 different functions from the tree sitter\r \r package,\r \r that Maelle is is really leveraging here. And she does note that, you know, she went through a lot of different emotions as a beginner to this tree sitter package and not all of them were positive. One of them that I must have imagined taking a lot of tinkering with is where she does define that that sort of\r \r string that she's looking to to parse\r \r which involves, as you said, this this regular expression\r \r type of notation that we're looking at to try to,\r \r call out sort of the the particular function definitions that we're interested\r \r in here\r \r and being able to return that as a list that is is parsable.\r \r\n\nAnd so I think sort of the the chief different functions that she's employing from tree sitter after she does that are the the query, the query captures,\r \r and then, this node text which I I think sort of turn this list that gets returned\r \r into something that's a little more easily parsable, if you will, within r and obviously at some point in here we're leveraging per because, we are out outputting a list, the the map character function,\r \r to be able to break things down into just this final, you know, simple handful of of sip 6 different names of functions,\r \r that she's interested in. There is one footnote in this blog post. It says, no, I have not installed positron yet. So my l is doing this\r \r all from the RStudio IDE\r \r at this point. Yeah. But it's interesting to hear that TreeSitter is\r \r obviously gaining some some ground. I'm not sure how new in and of itself the the TreeSitter\r \r C utility\r \r is but it's something that we're we're new to seeing I think in the R Eco system as there's recently been some other blog posts as as you mentioned that you know the folks at Positron\r \r are using it as well. Well. So it's\r \r very interesting to me. Obviously, you know, I I could see if we have some large code bases where you have to do some sort of, you know, profiling of that that code base or extracting of\r \r of particular\r \r portions of that code in a way that just really isn't,\r \r you know, useful to do manually, the old copy and paste method, and it makes more sense to do that programmatically.\r \r\n\n\n\n[00:35:23] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 23,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Grateful to the fact that my EL has now given us 2 different ways to go about doing that. Yeah. And I'm looking at this tree sitter repo, and I will put this in the show notes if you haven't heard of this before. Like, we didn't hear about this before. It looks like a pretty mature project\r \r of a lot of modern bindings,\r \r nonetheless, and they're trying to be\r \r dependency free to start. But then if you wanna hook it in the rust, guess what? You can. Wanna hook it in the WASM or web assembly? Yes. You can. Even has its own COI to boot. So there is a lot going on under the hood with this, and the best part is\r \r you can use this wherever you're comfortable with. It doesn't have to be in positron as you said. This could be in any r session. You can put it as on Versus code or whatnot. So, again, what I appreciate is, yeah, being able to learn about these discoveries, but then to be able to use this in my preferred environment. So this will be great. Again, I think the trial with a low friction way to get start and there's an r package now that has been author. We'll put a link to the r package itself in the show notes that ties ties all this together. But, yeah, you never I guess you'll never look at your code the same way again when you're looking in the forest, getting the forest from the trees or whatever it says.\r \r\n\n\n\n[00:36:32] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 32,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Exactly. Exactly. And that's a that's a good, tree related pun\r \r\n\n[00:36:35] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 35,
        "trans_speaker": "Eric Nantz",
        "trans_text": "here. Yeah. I know. I try I try I try. But, you well, you hopefully, you don't get lost then as the rest of this\r \r because there's a lot a lot of great content here. But as always, we put these in nice sections for you to digest,\r \r whether it's new insights, you know, uses in the real world, package updates,\r \r tutorials, or whatnot. There's always something for everybody here. So it'll take a couple minutes for our additional finds before we close out here. And\r \r for me, a reality in my industry, and I'm sure many others as well\r \r as they're building enterprise apps, maybe those that don't necessarily go outside the firewall, so to speak. But yet you have\r \r leadership,\r \r you know, stakeholders that are asking, hey. You built this great tool.\r \r\n\nWhat's been the user adoption? You know, what where are areas that people are spending their time in the most?\r \r Not always questions I really want to have to answer, but if I do have to answer, I wanna make it as easy as possible for me to get those metrics.\r \r And that's where Epsilon has pushed an update, a major update to their shiny dot telemetry\r \r package version 0 dot 3\r \r comes in with a lot of great updates here,\r \r including\r \r some very nice\r \r quality of life improvements, like actually\r \r checking whether it's an authenticated\r \r based app\r \r to get the user ID, if you will, of that session, which can be great as you're looking at different usage patterns or whatnot\r \r and to be more transparent about what you actually want to track. Because but if you don't wanna track all the inputs in your app, you wanna be able to wait to exclude them but not have to exclude them name by name, you can now do a regex if you have all your inputs name of a certain prefix in front or whatnot that you don't wanna\r \r include in, you can, you can throw a reg X that way too.\r \r\n\nOther enhancements\r \r include\r \r actually tracking the errors that can occur in your app. And boy, that can be very helpful for diagnostics.\r \r Not that I would ever have an app that crashes. Wink wink.\r \r But also\r \r if you wanna take advantage of an unstructured database to put these metrics in or these uses patterns in, They now support from MongoDB, which, of course, is very popular\r \r for unstructured\r \r nested type data data representation.\r \r So lots more under the hood with that, but they also have updated their package documentation\r \r with 3 different vignettes all about the different use cases that you can have for shiny telemetry. So really kudos to them. Looks like a great package, and, yep, this is some idea with\r \r every single day. I roll a new app out, so I'll be keeping a close eye on this.\r \r\n\n\n\n[00:39:07] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 7,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Me as well, Eric. That sounds really, really exciting. It's something that a lot of our clients are always asking for, right? You you finally get over the hump and build your your beautiful app and deploy it out to the world and then almost immediately, we get the question, oh, you know, can we get some user metrics\r \r on this app as well? So I'm excited to check out those new enhancements.\r \r An additional find that that I saw in the highlights this week are from, doctor Sophie Lee, who's the founder and director of s cubed,\r \r a statistician and educator. Now has a 2 day introduction to R with the Tidyverse course.\r \r\n\nIt looks fantastic.\r \r I'm seeing some,\r \r really, really nice,\r \r visuals here\r \r on this website which I believe are probably borrowed from,\r \r who who's the the person in the art ecosystem? I think she may work for observable\r \r now. Is it Alison Horst? Alison Horst. Yeah. Alison Horst that used to make the the really nice R,\r \r you know, types of of graphics and and imagery. So I see one of those here and that just tells me all I need to know that this is gonna be a fantastic,\r \r 2 day training\r \r here from November,\r \r or excuse me, September 24th\r \r to September 26th. So if that's something that that you're interested in or somebody in your team might be interested in, it's gonna cover everything from, R to R studio, data management,\r \r visualization, and and ggplot and EDA, and then some best practices for doing re reproducible\r \r research. So,\r \r you know, I think we cover a lot of in the weeds things sometimes on the highlights and I wanna make sure that we don't forget about those particularly\r \r new or or trying to, learn about ours. So this might be a good opportunity\r \r to to try to make that jump if that sounds like you.\r \r\n\n\n\n[00:40:55] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 55,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Fantastic\r \r resource here. I'm I'm looking at it. It's a definitely a portal based site and the the styling is fantastic,\r \r easy to navigate. So, yeah, yeah, kudos to her and the team. This looks like a fantastic\r \r thing to highlight here, and thanks for calling that out. And, boy, we love to call everything out, but, yeah, we're there's always so much time in the day, folks. But, again, that's why we put this link in the show notes. All the highlights you've seen, you've heard us talk about today and those additional resources are all in the show notes and also\r \r at arugia.org.\r \r\n\nIt's the easiest place to bookmark to find all these all these, terrific content and the back catalog of issues as well. And so if you wanna help the project, the best way to help is to share those new resources you found wherever you created them or someone in the community has created them. And it's just a poll request away, all marked down all the time. There's a link in the upper right corner. That fancy little octa octa con cat, whatever you call it is in the upper right corner. Just click that, take them directly to get help pull requests. You don't need an AI bot to fill this out. It is all marked down all the time. Very easy. They get started quickly. We have an issue template to get you up and running quite quickly as well.\r \r And if you wanna get a hold of us, we have a few ways to do that. We have a contact page directly in this episode show notes. We are on all the major podcast providers, so you should be able to find us wherever your favorite preferred listening,\r \r preferences.\r \r\n\nAnd, also, you can get a hold of us on these social medias as well. I am at our podcast at podcast index dot social on the Mastodon servers.\r \r I'm on the weapon x thingy sometimes with at the r cast. I'm mostly on LinkedIn as well. Search by name. You will find me there. And, Mike, where can the listeners get a hold of you? Yep. You can find me on mastodon@[email protected].\r \r\n\n[00:42:42] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Or you can find me on LinkedIn if you search Catchbrook Analytics, ketchbrook,\r \r or you can find me in Seattle in a couple weeks. Shoot me a message if you're gonna be there and and would love to to chat all things are.\r \r\n\n[00:42:56] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Likewise. Yeah. Yeah. Like I said, the time is coming close. So, yeah,\r \r not packing just yet, but that's not too far away, to be honest. And I always bring some tech gadgets too. Who knows? I might, maybe, I might bring a couple mics with me. I'll I'm just saying. I'm just saying. We'll find out. But, nonetheless, we're gonna close-up shop here for this episode of our wicked hot lights. We thank you so much again for listening to our humble little banter here, and we will see you back here for another episode of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_30_highlights",
        "chap_timestamp": 23,
        "chap_text": "Putting the R in RPG Graphics",
        "chap_href": "https://www.rostrum.blog/posts/2024-07-14-tilebased/index.html"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "chap_timestamp": 55,
        "chap_text": "GitHub's Copilot Workspace with R projects",
        "chap_href": "https://epiverse-trace.github.io/posts/copilot-workspace/"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "chap_timestamp": 4,
        "chap_text": "Code trees with treesitter",
        "chap_href": "https://masalmon.eu/2024/07/18/extract-function-names-treesitter/"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "chap_timestamp": 0,
        "chap_text": "shiny.telemetry 0.3.0",
        "chap_href": "https://www.appsilon.com/post/shiny-telemetry-0-3-0-update"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "chap_timestamp": 30,
        "chap_text": "Intro to R with the Tidyverse",
        "chap_href": "https://scubed.netlify.app/courses/1_intro_r_tidyverse/"
      },
      {
        "ep_name": "issue_2024_w_30_highlights",
        "chap_timestamp": 11,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_28_highlights",
        "ep_date": "2024-07-18",
        "ep_duration": 10,
        "ep_description_short": "The world of web-assembly in R continues to move fast with key updates to the webrcli & spidyr packages, and what has us excited about the mapgl package for producing amazing spatial visualizations. Episode Links This week's curator: Batool Almarzouq - @batool664 (X/Twitter) webrcli & spidyr: What’s new Create a Compare slider widget Entire issue…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_28_highlights",
        "description_long": "\r \r The world of web-assembly in R continues to move fast with key updates to the webrcli & spidyr packages, and what has us excited about the mapgl package for producing amazing spatial visualizations. \nEpisode Links\n\nThis week's curator: Batool Almarzouq - @batool664 (X/Twitter)\nwebrcli & spidyr: What’s new\nCreate a Compare slider widget\nEntire issue available at rweekly.org/2024-W28\nSupplement Resources\n\nmapgl package site https://walker-data.com/mapgl\nMike's migrate package https://ketchbrookanalytics.github.io/migrate/\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\n \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\n \nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nSuper Buck II - Super Mario Bros 2 - Estradasphere - https://ocremix.org/remix/OCR00577"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://colinfay.me/webrcli-and-spidyr-whats-new/"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://walker-data.com/mapgl/reference/compare.html"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://rweekly.org/2024-W28.html"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://walker-data.com/mapgl"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://ketchbrookanalytics.github.io/migrate/"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "links": "https://ocremix.org/remix/OCR00577"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. Did you miss us? Yes. We are finally back with another episode of the Our Weekly Highlights podcast.\r \r This is the show where we talk about the latest and greatest new packages,\r \r blog posts, other terrific resources that are featured\r \r in the highlights section of this week's Our Weekly Issue.\r \r My name is Eric Nance. And yes, we had a little bit of\r \r a break, both self\r \r imposed and some unexpected reasons for the break. But nonetheless, we were coming back hopefully refreshed. And,\r \r for me personally, I was able to take the family on a little road trip to Niagara Falls early in July. It was a spectacular time. And if you haven't been in that area, if you have the means to do it, I highly recommend that as a future vacation. It was a, I drove there, so that was a long drive, but\r \r made it through in one piece, which is sometimes a miracle in itself when you have 2 kids that are angry at, you know, on highways going through farmland as the Midwest typically is. But nonetheless,\r \r back here in the humble boat here, and I'm very pleased as always to be joined from my awesome co host, Mike, who's had his own adventures both good and probably not so good lately. But, Mike, how are you doing? I'm doing well, Eric. I am as equally impressed in your r and shiny skills as I am in your skills taking your family halfway cross country,\r \r\n\n[00:01:24] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Mike Thomas",
        "trans_text": "with 2 young boys,\r \r in a car for for that long. So kudos to you in a successful\r \r vacation. I got some vacation time with my family,\r \r in Vermont as well over the 4th July here, our Independence Day. And, yeah,\r \r happy that we were able to have the break, but also very happy to, be back.\r \r\n\n[00:01:44] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Absolutely.\r \r Yeah. I was I was thinking, yeah, just doesn't seem right. No. All is right with the world. It's a great recording session with you. And we've got a couple awesome highlights to talk about today. And this issue\r \r has been curated by Batool Almarsakh, another one of our longtime contributors to the rweekly project. And as always, she had tremendous help from our fellow rweekly team members and contributors like you all around the world for poll requests and other suggestions.\r \r So let's\r \r dive right into it. And our first highlight today is a callback from something that we\r \r put the spotlight on in episode a 156.\r \r\n\nYou can check out the back catalog for that. But,\r \r you know me, and if you heard the podcast recently,\r \r I've been\r \r espousing my,\r \r affection and really big enthusiasm\r \r for web assembly and web are in the world of our and web development.\r \r And there are a lot of different ways to spin this now. We've been historically talking about\r \r the amazing work that George Stagg at at Posit's been doing with the WebR package,\r \r the web assembly framework tie ins with WebR\r \r is just immensely powerful.\r \r But there are some other perspectives that you can take\r \r and really massage these tools to do some interesting use cases.\r \r\n\nAnd way back in episode 156\r \r earlier this year, we had talked about Colin phase adventures\r \r with building his own rappers on top of WebR\r \r and combining with no JS to kind of fill a perspective\r \r of how to efficiently\r \r expose\r \r functions and are from say in our package,\r \r what looks to be native functions\r \r and a no JS runtime.\r \r And so we got some follow-up on that in our first highlight today because, yes, Colin Faye is back at blogging his recent updates\r \r to his web r COI and spider utilities,\r \r encoded up in in JavaScript\r \r to help with this perspective\r \r of exposing\r \r these great R functions that you can compile with web R into a no JS runtime.\r \r\n\nSo what's new? Well, as usual, as you get things bootstrap for the first time and you start iterating on it, you see some ways to make things more efficient and also\r \r helping the new user get onboarded more efficiently.\r \r Their first of which is that\r \r the web are COI package\r \r combined with spider will help bootstrap a template file\r \r for you to start that kind of boilerplate integration\r \r of the R functions from a package into the node JS runtime.\r \r And he's been able to simplify\r \r the template a bit so that it's about now maybe what 10, 11 lines of code.\r \r And he's hopeful that even if you're not an expert at JavaScript just yet, they'll be able to grok what's happening here. And I dare say he's got,\r \r he's mission accomplished on making that a lot more\r \r easy to grasp. I mean, he\r \r decomposes the explanations of the template in the blog post\r \r where there is a bit of setup to initialize\r \r these spider projects that's gonna help with the hand off, help with that integration,\r \r and then helping to import the r functions that have been bootstrapped into\r \r the directory where this project is being bootstrapped from. And then you can see then for a simple hello world example,\r \r you just put a prefix of our funds\r \r dot hello underscore world if that's the name of your r function,\r \r And there you go. Now you just called\r \r that r function from JavaScript.\r \r\n\nAnd what's interesting about that actual execution of it is that this actually doesn't need our at that point to do the execution. It's all already been pre compiled\r \r\n\n[00:05:37] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 37,
        "trans_speaker": "Mike Thomas",
        "trans_text": "in the JavaScript. That's just bonkers to me, but it's amazing. Yeah. No. That that's that was probably the most interesting part of this whole article to me\r \r is that there's no R session running while the Node. Js app is running. It it's the spider package imports an R function\r \r converted to a native JS. So I guess that must happen beforehand.\r \r\n\n[00:05:57] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 57,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That's my understanding is in that bootstrapping process as you initialize a project. I believe it's compiling all that in in that initial pre step. So then the Node. Js side of it when you're just executing these functions,\r \r it's treated no differently than any other JavaScript function you would run-in that. That's just, again, amazing to me. Mind blown. 101. Yes. And Colin does it again. We we should be used to this by now from him after all the GOLM exploits, but, boy, he always teaches us something new.\r \r And then other tidbits in the post here that I think are gonna be great from a reproducibility\r \r standpoint\r \r and efficiency\r \r is kinda taking a page of how we do dependency management\r \r is making sure\r \r that when you bootstrap a WebR COI\r \r project\r \r that it will store\r \r the packages that are being installed in a packages dot JSON file\r \r so that then\r \r if you say move this to another computing environment or whatnot, as long as you version control that lock file, that JSON file, not to dissimilar what you would do with our end than the typical r setup, It'll bootstrap these these packages\r \r back down if they're not installed already. So I think that's paving the way for more efficient dependency management in this new workflow.\r \r\n\nSo he's got a nice schematic towards the end of the post where he kind of shows the workflow in a nutshell,\r \r which I believe is gonna be kind of the source of some\r \r additional documentation that he plans to author as he wants to have more than an end of one of users for this framework. He claims he's the only one using it. I highly doubt that. I'm sure there are others that are putting it through the paces. But he's got some other future items that I'm gonna keep an eye on for this is that\r \r in terms of reproducibility,\r \r he wants to make sure that when you initialize these projects\r \r that you can actually specify\r \r the web r version\r \r itself\r \r during that bootstrapping\r \r process. I mean, that will be, again, huge as web r takes more fruition as companies or organizations\r \r start to use this\r \r in critical pipelines\r \r just like with r itself. You wanna be to say, okay, I built this on web R version, you know, 4 dot whatever. I want to make sure that I can standardize on that for the future.\r \r\n\nAnd another tidbit I'll keep a close eye on, we've seen George Stagg mentioned he's been plugging in ways\r \r to install\r \r package, you know, WebR\r \r compliant our packages from our universe.\r \r That's been a new thing that he and your own have been working on. Colin wants to make sure that in this framework, in the WebR CLI,\r \r that you can install WebR compliant r packages from our universe as well. That will be massive for opening the door for additional functionality,\r \r down the road. So sounds like he's not stopping anytime soon with this. So I'm very curious where he goes. And again, the perspective here, I think, is definitely important, especially\r \r as many in in software development, you know, data science pipelines,\r \r you may have a team that is writing very intricate, very powerful code via our functions and hence our packages.\r \r\n\nAnd maybe they have the luxury\r \r of a separate team that's doing all the web interface layouts in their preferred JavaScript framework.\r \r This is tailor made for that scenario. The data science team can configure the business logic and r and doing all the powerful model fitting and everything.\r \r And then they just give this\r \r compiled with WebR COI to the web dev team. They're they they're no worse for wear so to speak. They just call it like they would any JavaScript function. I think it's gonna open a lot of possibilities for, again, using WebR and WebAssembly\r \r\n\n[00:09:50] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Mike Thomas",
        "trans_text": "in even more context than initially we realized. Are you insinuating that the web dev team won't be writing in Shiny?\r \r What?\r \r No. You know, I I think one of the really\r \r interesting things that's going starting to go on right now, and obviously Colin is one of the folks who's spearheading\r \r that effort, is we have pretty good frameworks for building, you know, what, Eric, you and I call, like, production grade\r \r Shiny applications,\r \r right, that have a have sort of a dedicated server,\r \r component to them.\r \r And now that we're moving on to to WebR and Shiny Live and things like that, that dedicated server kind of goes away. But, you know, up until till now, and I I don't think we're quite there yet,\r \r a lot of the,\r \r you know, things that you really need to go from, you know, just a a toy POC\r \r app to production, like, you know, environment variables and authentication and and things like that haven't really existed in in this new WebR and Shiny Live world, but it seems like we're slowly but surely starting to get there and maybe there is a day coming.\r \r\n\nI don't know how how near or far in the future where essentially everything that we can do in in WebR,\r \r is equivalent to what we could do, you know, with the\r \r old, quote, unquote\r \r framework for for building Shiny apps with a dedicated server. And and as Colin notes, I believe it's in his WebR CLI\r \r utility that there is a share n,\r \r function that allows\r \r the user to copy 1, several, or all environment variables\r \r from node to the WebR\r \r instance, I think, which is is really interesting. It's really important. I don't really build any Shiny apps these days\r \r that don't,\r \r leverage environment variables for, you know, secure authentication to a database or or something like that.\r \r\n\nSo that's a huge, you know, hurdle that I sometimes need to need to get over when we're looking at new frameworks\r \r like this. And it looks like, you know, Colin's already thought about some of this stuff, to be able to help us out when we we do get to that point. And I have not dove too deep yet, admittedly, into WebR and and Shiny Live. But, yeah, besides seeing what others in the community, like yourself, Eric, are doing,\r \r and building, but I am pretty confident that it's it's not gonna be too far in my future where I'm I'm not gonna necessarily have a choice and and going to have to start, learning about that because I think that there are quite quite a lot of benefits here depending on your use case,\r \r to to leverage that that WebRamp framework. And it's just getting better and better\r \r every every month, every day, every week, it seems like.\r \r\n\n\n\n[00:12:29] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I always whenever I see in my notifications, I'm massing out a new post from George. You know, I'm always like, okay. Read it now because it's gonna be something that I think I'll be able to benefit from very quickly. Yes. I this is a new world to us\r \r as I've been, you know, thinking about framing my talk for the upcoming positconf, and I talk about our adventures of WebR and WebAssembly\r \r and your consortium pilot submissions. I've always been trying to think of an intuitive way to describe\r \r this paradigm shift. Maybe it's not so much a paradigm shift, but it is a\r \r traditional server side hosting process to what is now being exposed.\r \r\n\nIn essence, the user's web browser is the new engine. It's the new server. That's where everything's being\r \r conducted.\r \r And what are the benefits and trade offs of that? A lot of benefits that we're seeing. I mean, you've heard me mention on previous episodes or we're seeing in quarto,\r \r what we're seeing and be able to build these educational type materials\r \r showcasing\r \r the the native execution of our code so the users cannot just see examples,\r \r but literally play with it in their browser\r \r without that need of a shiny like server on the back end. That's still one of those use cases that I think is just beginning to really take fruition.\r \r And I think it's just\r \r only a matter of time as those principles get built into what we're doing in data science pipelines\r \r that we've historically done with shiny and still, of course, who's the number one fan of shine wearing their t shirt today for goodness sakes. Of course, I love my shiny and to be able to combine it with WebR. I mean, that's still this intersection that I'm very passionate about and certainly to be abreast of this technology,\r \r abreast of what we can do in this space.\r \r\n\nThings of what Colin's doing here with WebR CLI and Spider\r \r along with the adventures that Bob Rudis has had on his various blog posts and what he's been doing with WebR. He's been just as excited about this as anyone else. So it's great to be well rounded into, like, the different ways you can spin\r \r this technology.\r \r And, again, the end product,\r \r you're gonna be able to build these very sophisticated\r \r web our web assembly powered apps\r \r in many different frameworks. That's the key here. Right? We're opening so many doors for every teams to get into this. So, yeah, I'm it sometimes be it sometimes makes me shake my head just how fast this is moving. But once that initial hurdle got overcame last year,\r \r with bringing WebR\r \r to the r, you know, web assembly to the r process itself,\r \r the floodgates have opened, and I'm here for it. Me too.\r \r\n\nAnd rounding out our highlights today, we're gonna dive into the world of spatial visualizations,\r \r which we touched on quite a few times with some of the amazing efforts\r \r in the art community to expose some very powerful frameworks\r \r in the mapping and geospatial\r \r space. And we got another highlight\r \r that is actually more of a function that's exposed into an overall effort that I think is gonna be very important for those that are looking to take advantage\r \r of innovations and web technology\r \r in the spatial visualization\r \r space into there are processes.\r \r\n\nCertainly, this has a nice fit for shiny too that we may touch on as well. And we're talking about the mapgl\r \r package,\r \r which has been authored by Kyle Walker who has been featured on previous Arrukia highlights in the past. He runs, I believe, his own consulting company. We're gonna do a lot of spatial visualization\r \r analysis and visualization,\r \r and the map GL package.\r \r This looks\r \r really nifty to me because\r \r it is, Mike, many in the HTML widget ecosystem\r \r trying to get the our user and intuitive interface to an extremely powerful web based visualization\r \r platform.\r \r\n\nAnd there are 2 of them to be exact that this package exposes.\r \r It's the Mapbox GL and the Map Libre\r \r GL mapping services.\r \r They age are slightly different, but yet they're very important use cases\r \r and map GL is a framework to bring that to the our user\r \r very efficiently.\r \r And, Mike, I don't know if you had a chance to look at their getting started vignette that Kyle has on the website.\r \r Holy moly. Some of the visuals he can produce in this are extremely powerful here. Yeah. It's absolutely incredible, and I've seen Kyle quite active\r \r\n\n[00:17:09] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Mike Thomas",
        "trans_text": "sharing the progress on this package, this mapgl package\r \r on, I think, Mastodon primarily, maybe LinkedIn as well is is where I've seen it, and\r \r the amount of new features and development that's going on in the packages is incredible.\r \r You know, it seems like they're they're rolling out functionality\r \r constantly.\r \r And one thing I think that strikes me, you know, it's a big takeaway from a lot of what Kyle has been sharing on social media\r \r is really the the performance,\r \r of this package and what you're getting from I think the underlying APIs, the Mapbox,\r \r GL JavaScript\r \r and Map Vibre\r \r GL JavaScript APIs.\r \r\n\nIf I'm not mistaken,\r \r those 2 API services\r \r are are paid. Maybe you can get a free free version, but you will need an an access token,\r \r I believe.\r \r\n\n[00:18:00] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 0,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. Yep. You need an access token depending which features you wanna utilize. I believe you have to pay for at least the first one, the map library one. I'm not so sure. I haven't played with it, you know, carefully, but I know to get started. And once you get the access token, you're good to go for a course set of features. I\r \r\n\n[00:18:17] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Mike Thomas",
        "trans_text": "think, you know, one of the things that folks doing, you know, pretty heavy geospatial\r \r data science,\r \r run into sometimes\r \r is performance because there's a lot going on on screen when it comes to geospatial data. The data can be large in and of itself and sort of heavy when your your data is representing polygons and things like that, not just\r \r individual points.\r \r And then obviously the the visual component as well. Right? Your maps are are complex\r \r visualizations\r \r and\r \r traditionally maybe not the the quickest visuals\r \r to render. But what we're seeing out of the the mapgl,\r \r package right now that Kyle his team have put together is some incredible enhancements, and it looks like those underlying APIs,\r \r though those services have have done a lot of work to try to make, these\r \r geospatial visuals as performant\r \r as possible. And one of the ones, you know, that we're calling out today in the rweekly highlights is this compare function,\r \r from mapgl.\r \r\n\nIt allows you to\r \r create a comparison view between 2 Mapbox GL or map libre\r \r GL Maps and what it'll do is it'll provide this sort of horizontal bar\r \r in the middle of the visual itself that you can drag to one side or the other,\r \r to be able to expose\r \r more of either the left map or the right map, and compare those 2 sort of side by side. This is something that, we have actually done, you know, quite a bit when we have sort of an overlay often of of the same,\r \r geographic\r \r area,\r \r but we're trying to\r \r maybe represent, you know, 2 different,\r \r you know, data\r \r sets on top of that same geographic area. So maybe 2 separate surveys in the same area,\r \r something like that, and you're comparing,\r \r one to the other. So you have those things side by side and you can go go left and right, 2 different simulations,\r \r you know, of, an ecosystem or something like that. That's things that we have done in the past leveraging that compare slider widget in the leaflet ecosystem\r \r and this seems to be pretty comparable\r \r to a function\r \r in leaflet called add map pane.\r \r\n\nI don't know if there's a more recent one but that's the last time that I was working, with leaflet on exactly that that type of problem. We were able to create like a left map and a right map and the function that we used was add map panes. This looks, this compare function from mapgl\r \r looks quite equivalent to that.\r \r Again, you know, these maps look beautiful. The ability to drag left and right is something that, users of our apps that have done that when we've implemented it in leaflet\r \r have absolutely loved.\r \r I I think it's probably one of the the the most favorite pieces of functionality\r \r that our end users\r \r let us know that they really like on our geospatial data science project. So it's pretty cool to see that also exist here\r \r in, the mapgl GL package. And, you know, from everything that I'm seeing,\r \r if you did wanted to migrate from Leaflet to, you know, this map GL package, it looks fairly straightforward. A lot of the syntax, a lot of the,\r \r arguments to some of these functions look quite similar.\r \r\n\nAnd obviously, the visuals at the end of the day aren't necessarily too far apart. So you may be able to to migrate fairly quickly and and pick up some of those performance gains that it looks like MapGL\r \r is able to offer or maybe there are just some aspects of MapGL that sort of make more sense, to you,\r \r to use,\r \r as opposed to, you know, the traditional leaflet or other geospatial packages. So if you haven't had a chance to check it out and take a look at everything that Kyle and his team have put together in mapgl,\r \r I highly recommend it because it is looking like quite a powerful\r \r R package that I I believe is gonna rise to the to the surface here pretty quickly within the r ecosystem.\r \r\n\n\n\n[00:22:08] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 8,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And then we'll put a link in the show notes to the the the vignette section of this package. Kyle's done a spectacular job of documentation here as somebody well, I was telling Mike in the pre show. I'm still pretty new to the spatial visualization space. This is definitely something if I was getting in this field, I would take a close look at because I always have a bias towards towards\r \r those packages that are putting attention to detail in that user experience of getting onboarded quickly. So on top of the getting started vignette, he's got a great section on how to efficiently use the wear layering system, which again, be very familiar to anybody coming from these special packages,\r \r the fundamentals of how to design your maps with mapgl.\r \r\n\nAnd, yes, he does mention one of his original motivations was to plug this into shiny in the first place, and he wanted to put all this into a concise package\r \r that then could be sourced in the shiny quite easily. And he's got a whole vignette\r \r dedicated to that about the inputs that are being exposed. So, of course, Mike Mike and I know you can do almost anything you want with shiny once you get access to these inputs. So he's got a couple great, great little, teaser\r \r apps in in the vignette that you can get started with. So I think, yeah, this is something that we'll be we'll be paying close attention to in this space. It's all open source. So if you feel so inclined to get involved yourself, there's there's 7 issues out there that I'm sure Kyle would,\r \r appreciate some help on. So definitely check it out. Absolutely. So, again, links in the show notes and, yeah,\r \r I'm really impressed with what Kyle has accomplished here. And Kyle is just one of many in the r community that we're impressed with, and we're very fortunate to r weekly. Every single week features these great innovations from everybody in the community because this is a community project and this is where we'll take a couple of minutes to tow out some additional fines we've seen either in the issue or\r \r elsewhere. And from this particular issue, I do wanna\r \r I I had a couple ideas, but again, I'm I've been on a a kick recently with some of the great packaging that Bruno Rodriguez has been doing with the Knicks ecosystem. I'm not talking about Knicks here. I'm talking about a video that he's put into the issue.\r \r\n\nWhy as an our user,\r \r you might want to invest into using GitHub actions.\r \r So it's a great 20 minute video and it's,\r \r great if you're new to this. Because I think a lot of people may have heard about GitHub actions, but they just don't know where to start. They don't know what's in it for them. Bruno does a terrific job of summarizing it. I will mention, now this may be not so much applies to his video, more of my random exploits.\r \r The bugging GitHub actions can sometimes feel like you're in the wilderness without any line of sight, and I\r \r had that a couple times in the last couple of weeks where I was, troubleshooting,\r \r get a failure, don't know why, rinse and repeat.\r \r\n\nThe YAML is like the engine to the GitHub actions that there's a YAML file where you put in all the steps of your workflow and any\r \r associated parameters. So hopefully,\r \r the teams behind these different steps have good documentation and unfortunate that most of the workflows I was using were authored by EverPosit or other members of the community where it was pretty\r \r pretty well easily understood how to grok the options and stuff. But sometimes when you try to do things a little different, be prepared for a little debugging time. But once you get it working,\r \r my goodness, the peace of mind to say, okay, guess what? That's gonna run like once a week, and that's gonna run on every PR.\r \r\n\nI'm doing this with shiny testing recently. I finally got it working.\r \r I was an achievement unlock with shiny test 2 and GitHub actions, but I finally cracked that nugget. That's just one way you could use GitHub actions. Well, like I said, lots of different ways you can use it from, like, you know, automated processes or scraping data\r \r from an online source. I do this with that fancy,\r \r podcast index dashboard that was a runner-up in the table contest recently. So I've been putting that, putting that through the paces quite a bit, but it's been a fun learning journey for me. So Bruno does a terrific job of highlighting that in his video. And I'm not sure if we touched on it last time we spoke because it's been a little while, but congratulations on your runner-up and in the table contest. Your your app was awesome.\r \r\n\n[00:26:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "They were all incredible. The winner of the Spotify app was absolutely incredible too.\r \r So great job by everybody who participated in that. It's really cool to see the community sort of come together\r \r for things like that, which is awesome.\r \r One of the blogs that I wanted to shout out is is one from Absalon this week, and it is on the power of transitioning to a\r \r verse approach in your r package development.\r \r It's, you know, it was a really interesting blog post about, you know, whether you\r \r should take the packages that you may have developed internally\r \r and create a sort of tidyverse or pharmaverse\r \r around them that would allow you to install,\r \r multiple\r \r of those packages\r \r at one time. And they talk about sort of the pros and the cons of that. Right? Obviously, if there are\r \r sort of\r \r breaking changes,\r \r in one package, then you might,\r \r you know, sort of be be hit by that a little harder if you are sort of\r \r leveraging this verse approach in a lot of your applications. But,\r \r they they call out companies like Apple that choose to introduce on purpose breaking features with every other OS\r \r iteration,\r \r you know, and they sort of effectively\r \r eliminate their need to support the legacy\r \r software that they create.\r \r\n\nSo it it sort of depend That hurts, but it's so true. It sort of depends how much you wanna support your your legacy software and your your legacy products a little bit. How,\r \r sort of what the benefits would be for your end users if they were able to, you know, install dot packages from a a verse as opposed to specifying\r \r each one individually\r \r every time. I have mixed feelings about this, but I can definitely see some particular use cases where it would make sense and and some particular use cases where it wouldn't make sense. So it was a really interesting read. It's, sort of a topic that I haven't seen discussed very often, so kudos to the Appsilon team.\r \r And in particular,\r \r Fabian He for putting that blog post together. I will do sort of a self indulgent shout out as well.\r \r\n\nWe had a R package that got a very significant update after 3 years, I think was the last release. It's called migrate for building state transition matrices. So if that's something that you you do, if you work in an insurance or credit risk or something like that, Maybe of interest to you, some pretty exciting enhancements there. Oh, congratulations,\r \r\n\n[00:28:44] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Mike. That is awesome. 3 years in the making, That that's a lot of updates there. Yes. Yes. A lot of updates, a lot of\r \r\n\n[00:28:52] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Mike Thomas",
        "trans_text": "user enhancement requests that people had been very patiently\r \r very patiently waiting on that hopefully, we've gotten across the finish line now.\r \r\n\n[00:29:00] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 0,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Oh, that's awesome. And I, yeah, this this resonates with me back in my dissertation research. I was looking at state transitions of these mark off processes.\r \r So, yeah, I can definitely see a ton of value into this. So we'll make sure to put a link to your updated package in the show notes because it is, you know, great job with the vignette, my friend. You are you're putting the attention to detail\r \r\n\n[00:29:24] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Mike Thomas",
        "trans_text": "The transition matrices for Markov processes, that's what it's all about. Sorry. We didn't sorry. We didn't make it sooner for you, Eric.\r \r\n\n[00:29:31] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 31,
        "trans_speaker": "Eric Nantz",
        "trans_text": "You know, you were just about 20 some years too too late, but that's okay. That's okay. I'm not I'm old enough. I don't need to say anymore. But, nonetheless,\r \r I'm gonna definitely check that out if I delve into that world again. But, also, we invite all of you to check out the rest of the our weekly issue. And, yeah, we were off for a couple weeks. So don't forget to check that back catalog\r \r too. There are a ton of great resources ever shared recently. Really some terrific highlights\r \r from the past couple weeks. So everything's available at ourweekly.org.\r \r You'll You'll find a link to this issue right at the front page as well as all the other issues\r \r that we that we curate throughout the years, and it's been many years, and the project\r \r keeps on going, but it keeps going because of your support in the community. So, again, if you've authored a great new package or updated as another package, if you've done a great resource online that you wanna share, getting it on the issue is just a poll request away. All linked at the upper right corner of the r wiki dotorg\r \r homepage. It's all marked down all the time.\r \r\n\nMarkdown is where I live when I can. I do admit I've had a couple,\r \r instances this past week or 2 where I've had to go back to PowerPoint and it just doesn't feel right. I love making my stuff in markdown. It's just so much better. What can I say? I thought you're gonna say Microsoft Word.\r \r Well, that too, but not not as in-depth as the slide making nightmare that I've had to put myself through. But,\r \r I I went down a rabbit hole.\r \r Who's ready for story time with our\r \r\n\n[00:31:00] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 0,
        "trans_speaker": "Mike Thomas",
        "trans_text": "podcast?\r \r Bebe. I'm\r \r\n\n[00:31:06] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Eric Nantz",
        "trans_text": "in a story time here. I was trying\r \r to convert a PowerPoint to have, like, these placeholder boxes\r \r for\r \r putting, like, text of, like, you know, we call these 1 pager summaries or whatnot.\r \r It was I thought, hey. You know what that looks like?\r \r That looks like a portal dashboard with the cards, you know, just kinda neatly arranged. And I got close, my friend. I got really\r \r close, but they want PDF exports of it, and I couldn't quite print it effectively to keep the formatting. But had they stuck a web based formats, it would have been perfect. But\r \r ran into the dead end on that one, so them's the brakes.\r \r\n\nI've been there. I've been there. Luckily, you won't find those, pitfalls when you contribute our weekly. We're not gonna switch formats on you. It's all marked down. It's staying that way. That's the wave of the future if you dare say if I dare say so myself.\r \r So links to that at r o g dot r o g. And, of course, you can get a hold of us in different ways. We have a contact page directly linked in the episode show notes. You can send us a shout out or a question or a comment.\r \r We love hearing from you, especially how you're using these resources in your daily work or your daily\r \r exploits and are. And, also, you can get a hold of us on the social medias. I am on Mastodon where I'm at our podcast at podcast index.social\r \r as well as sporadically on the Twitter weapon x thing with at the r cast, and I'm on LinkedIn. Just search for my name, and you'll find me there. Mike, where can the listeners get a hold of you?\r \r\n\n\n\n[00:32:34] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Mike Thomas",
        "trans_text": "You can find me on Mastodon at [email protected],\r \r or you can find me on LinkedIn if you search Catchbrook Analytics, ketchb\r \r\n\n[00:32:44] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Eric Nantz",
        "trans_text": "r o o k. You can see what I'm up to lately. Yep. That's where I got. One of your awesome, package updates. So, yes, stay tuned for more great stuff from from you on that platform. And, yep, with that, we're able to dust off the cobwebs, I think, pretty efficiently this week. So we're back in the saddle again, and great to have you joining us or listening to this episode.\r \r And we hope to see you again for our next episode of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_28_highlights",
        "chap_timestamp": 14,
        "chap_text": "webrcli & spidyr update",
        "chap_href": "https://colinfay.me/webrcli-and-spidyr-whats-new/"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "chap_timestamp": 20,
        "chap_text": "mapgl overview",
        "chap_href": "https://walker-data.com/mapgl"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "chap_timestamp": 5,
        "chap_text": "GitHub Actions for R Users",
        "chap_href": "https://www.youtube.com/watch?v=aZ38ph9plOU"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "chap_timestamp": 35,
        "chap_text": "Building a package verse",
        "chap_href": "https://www.appsilon.com/post/the-power-of-transitioning-to-a-verse"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "chap_timestamp": 22,
        "chap_text": "Migrate 0.5.0!",
        "chap_href": "https://ketchbrookanalytics.github.io/migrate/"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "chap_timestamp": 54,
        "chap_text": "Story Time!"
      },
      {
        "ep_name": "issue_2024_w_28_highlights",
        "chap_timestamp": 45,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_26_highlights",
        "ep_date": "2024-06-26",
        "ep_duration": 56,
        "ep_description_short": "The latest updates to the rayverse bring new meaning to smoothing out the rough edges of your next 3-D visualization, the momentum of DuckDB continues with the MotherDuck data warehouse, and the role nanoparquet plays to bring the benefits of parquet to small data sets. Episode Links This week's curator: Eric Nantz: @[email protected]…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_26_highlights",
        "description_long": "\r \r The latest updates to the rayverse bring new meaning to smoothing out the rough edges of your next 3-D visualization, the momentum of DuckDB continues with the MotherDuck data warehouse, and the role nanoparquet plays to bring the benefits of parquet to small data sets.\n\n\nEpisode Links\n\nThis week's curator: Eric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nSculpting the Moon in R: Subdivision Surfaces and Displacement Mapping\nJoining the flock from R: working with data on MotherDuck\nnanoparquet 0.3.0\nEntire issue available at rweekly.org/2024-W26\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\n \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\n \nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nThe Amazon Session - Ducktales - Gux - https://ocremix.org/remix/OCR00402\nDoomsday - Sonic & Knuckles - elzfernomusic - https://ocremix.org/remix/OCR02532"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://www.tylermw.com/posts/rayverse/displacement-mapping.html"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://discindo.org/post/joining-the-flock-from-r-working-with-data-on-motherduck/"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://www.tidyverse.org/blog/2024/06/nanoparquet-0-3-0/"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://rweekly.org/2024-W26.html"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://ocremix.org/remix/OCR00402"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "links": "https://ocremix.org/remix/OCR02532"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back at episode 170\r \r of the our weekly highlights podcast. Gotta love those even numbers as we bump up the episode count here. My name is Eric Nance, and I'm delighted you joined us from wherever you are around the world listening on your favorite podcast player.\r \r This is the weekly show where we talk about the awesome resources that have been highlighted in this week's current,\r \r our weekly issue.\r \r And I'm joined at the virtual hip as always by my awesome co host, Mike Thomas. Mike, how are you doing today?\r \r\n\n[00:00:32] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 32,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'm doing well, Eric.\r \r I'm taking a look at the highlights\r \r this week. I see that there's there's no shiny highlights, so this couldn't have been curated by by you.\r \r\n\n[00:00:43] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Oh, the plot thickens. Oh, yes. It was. It was my turn this week. Good. That's so sure. There is some good shiny stuff in there that we may touch on a bit later. But, yeah, it was my\r \r my turn on the docket. So as usual, I'm doing these curations in\r \r many different environments, Mike. You're gonna learn this as your,\r \r little one gets older. You gotta be opportunistic\r \r when the time comes.\r \r And I was curating this either at piano lessons or swim practices\r \r or whatnot, but it ended up getting curated somehow. So we got some\r \r fun, great post to talk about today. Never as short as a great content to draw upon.\r \r\n\nBut as we always say in these, in these episodes,\r \r the curators are just one piece of the puzzle. We, of course, had tremendous help from the fellow curator team\r \r on our weekly as well as all the contributors like you around the world who are writing this great content and sending your poll requests for suggestions\r \r and improvements.\r \r So we're going to lead off. We're going to get pretty technical here in a very\r \r have\r \r in many different domains that honestly\r \r you would least expect.\r \r But we're gonna talk we're gonna go to the moon a little bit here, Mike. Not quite literally, but we're gonna see\r \r how\r \r R with the suite of packages authored by none other than Tyler Morgan Paul, who is the architect of what we call the raverse\r \r suite of packages\r \r for 3 d and 2 d visualizations\r \r in R.\r \r\n\nHis blog post as part of this highlight here is talking about how to use r to produce not just images of the moon and other services,\r \r but very accurate looking images with some really novel techniques that\r \r I definitely did not know about until reading this post.\r \r So I'll give a little background here, but\r \r when you look at graphics rendering and you'll see this in all sorts of different domains, right, with, like, those\r \r CGI type movies or images or, you know, animations,\r \r of course, gaming visuals and whatnot that have to do with some form of polygons.\r \r Little did you know, little did I know at least, that the triangle\r \r geometric shape is like the foundational building blocks of many of these computer graphics,\r \r which gets you\r \r really long ways,\r \r but it's not as optimal when you have to\r \r render a surface that is on 2 different sides of a spectrum.\r \r\n\n1st,\r \r maybe something that looks\r \r completely smooth. No artifacts.\r \r No, you know, jagged edges or whatnot.\r \r Or the converse of that,\r \r something that has unique contours,\r \r unique bumps, if you will, such as, say, the surface of the moon with its craters and other elevation\r \r changes.\r \r Now there are 2 primary methods that Tyra talks about here that can counteract\r \r kind of the phenomenon of these triangles not really being optimal for this rendering.\r \r One of these is called subdivision\r \r where, in essence, these polygons are subdivided\r \r further into micro polygons\r \r often smaller than a single pixel, which means we're blurry looking at something small here to help bring a smoother appearance with tweaking a certain parameters.\r \r\n\nAnd then on dealing with the converse of that, again, like dealing with bumpy surfaces or contours,\r \r you have what's called displacement\r \r of the vertices of these associated\r \r polygon\r \r to help bring this kind of artificial\r \r detail to the surface that, again, mimics\r \r what you might see in the real world with these contoured\r \r surfaces.\r \r And Tyra says that the Raver suite of packages now\r \r have capabilities to handle both of these key\r \r algorithmic kind of explorations or rendering steps\r \r to make these more accurate looking visuals.\r \r And as I think about this, as we walk through this example here, I harken back.\r \r\n\nAgain, Eric's gonna date himself here to my retro gaming roots where\r \r I remember very distinctly.\r \r It was in the, you know, early nineties, maybe mid nineties\r \r that the local arcade started having these racing games that\r \r were not those, like, sprite filled racing games like the yesteryear, like Out Run or whatnot.\r \r I remember vividly Sega making a game called virtual racing, which was on the first times I had seen in an arcade\r \r really robust looking\r \r racing cars in 3 d type perspectives,\r \r but you could tell they were made with polygons.\r \r And they were smooth. Some were smooth, and yet some are really jagged as heck when you went out crashes or sparks, and you could kinda see if you, like, if you had a pause button in the arcade, you can see these little artifacts that appear\r \r that look like little geometric shapes.\r \r\n\nAnd in essence, that's what can happen when you render\r \r an image in the beginning, and he's got an example where he basically renders what looks to be,\r \r kind of like a cross between a sphere and a hexagon\r \r in a 3 d contour\r \r and then a,\r \r cube and then the r logo.\r \r But when you render this first of a few parameters that he does with one of his, packages,\r \r you can see, yeah, they're little polygon shapes. They look like what I would see in that kind of first attempt at that virtual racing game.\r \r But then he starts to show example code, again, new to the ravers\r \r of called subdivide_mesh,\r \r this function which lets you define\r \r just how deep you do this subdivision.\r \r\n\nAnd he starts with levels of 2, and then he, you know, re renders the image. And now, in the second image, you look the left image.\r \r Again, you want to look at this as we're talking through it if you have access to the screen.\r \r That first, ball on the left looks like the Epcot\r \r center\r \r or a golf ball and, on on the golf course. You can tell. You can see those little triangles splitter throughout, which is not what he wants. He wants to make this look completely smooth.\r \r So\r \r guess what? It's all iterative in these steps.\r \r He tries another subdivide mesh call\r \r with, you know, first trying to make things look a little more smoother\r \r without going new subdivision\r \r levels,\r \r and it doesn't quite get the job done. They still look, you know, a little bit off, but he's rounded out some of the edges to that aforementioned cube,\r \r but he's still gotta go deeper. And, basically,\r \r he finds this sweet spot\r \r of, like, subdivision levels of 5,\r \r which means\r \r this is upping the count on these little small triangle\r \r shapes that are composed in each of these images.\r \r\n\nAnd going from the start to finish of this,\r \r that added\r \r many, and I do mean many additional triangles to each of these shapes as compared to what he started with. It's a huge increase, and, in fact, it was a 1024\r \r fold increase\r \r in these number of triangles, which may not be the best for your memory usage in your computer, although I there are no benchmarks around that. But I know\r \r from my, you know, brief explorations and things like,\r \r what's a blender for rendering, 3 d and Linux and other software,\r \r that as you make these shapes more complex, yeah, your computer is gonna be doing a lot more work with that. So in the end of this example, he's got 3\r \r versions of the the rendered scene, what he started with, and then one in the middle, which is kind of like a compromise of like the subdivision levels\r \r and kind of moving some of these vertices around, and then the last one of using like all these triangles at once.\r \r\n\nThe good news is is that this shortcut approach in the middle, you can't really see a visual difference of the naked eye\r \r between that and the more complex version with the additional triangles.\r \r But the key point is that, a, Ray the Rayverse packages support this, and you're gonna have to experiment with it for your use case to get that sweet spot of the smoothness\r \r that you're looking for.\r \r So that was a great example how you want to give this kind of smooth appearance\r \r without those artifacts fault coming into play.\r \r Now, we turn our attention to the bumpier contour surfaces\r \r with, say, the moon as inspiration.\r \r\n\nAnd he mentions that this will be familiar to anybody who deals with GIS type data in the past with elevations.\r \r He has a nice render of both the moon image as well\r \r as, moderate bay where you can see the contours very clearly\r \r in the black and white images,\r \r And then he starts by drawing a sphere of what looks like the moon, but when you look at it, it just looks like a very\r \r computer graphic looking moon with, like, a shade on the left and light on the right, but you would not tell that's anything really.\r \r So then comes the additional\r \r kind of experimentation\r \r of,\r \r okay, how do we\r \r first\r \r figure out what is the current displacement\r \r information that's in that image so you can get a sense on what's happening here\r \r and how many pixels are being sampled to help do this\r \r rendering by default.\r \r\n\nSo there are some handy functions that he creates to kind of get into this metadata.\r \r And he notices that in the first attempt, there's only about point\r \r 0 9%\r \r of the pixels from that moon image are being\r \r sampled to produce this more artificial image,\r \r and that's why it's not looking like a moon at all at that point.\r \r So gotta up the ante a little bit. Again,\r \r kind of like a iteration\r \r of this\r \r to figure out, okay, maybe I need to use more\r \r pixels to sample in this. It starts going from like 1.4%\r \r of them,\r \r Still not quite looking right as you look at the post.\r \r Ups it further,\r \r and he's got a handy function called generate moon mesh that he kinda ups the levels 1 by 1.\r \r\n\nAnd eventually, he gets to a point where,\r \r hey, we're now we're getting to what looks like the craters on the image\r \r where about 5 or 6% of the pixels are being sampled.\r \r Still not quite there yet, but he ups the ante even more with this, levels. And then he finds what looks like,\r \r you know, a really nice looking moon where it ends up sampling about 89%\r \r of the pixels,\r \r which means that there is a lot going on behind the scenes in this image.\r \r And in fact, this would take up a lot of memory,\r \r And you can see there is kind of a there's a point of diminishing returns the more pixels you subsample here for this displacement.\r \r Not really a lot of change visually. So ends up, he finds a sweet spot\r \r between\r \r not going to the extreme of, like, 2,000,000\r \r pixels resampled\r \r somewhere in between.\r \r\n\nAnd hence, he's got a really nice visual at the end where you can see\r \r it it's getting getting much closer once he brings us back to the sphere shape.\r \r And there's a nice little phenomenon kind of towards the end where it looks like at each of the north and south poles of the moon,\r \r when you do it by default, it kind of looks like things are being sucked in like a vacuum. It's hard to explain.\r \r But then when he does the applying the contour more effectively,\r \r you see that it just looks like any other surface on the moon, nice\r \r little craters and whatnot.\r \r\n\nAs you can tell, I've been doing my best to explain this in an audio form, but what's really cool is that you can see\r \r kind of Tyler's thought process\r \r of when you have a problem he wants to solve with his raver suite of packages.\r \r These steps that he takes that go from start to finish,\r \r not too dissimilar to what I see many of the community do when they teach things like ggplot2.\r \r Start with your basic layer, start to customize layer by layer bit by bit until you get to that visual that you think is accurate given the data you're playing with. And in case a toddler's visual is here, to closely mimic what you might see if you put your telescope out there and look at the moon at night. So, again, a fascinating look to see the power of r\r \r in graphics rendering,\r \r which if he had told me this was possible 10, 15 years ago, I would have laughed in your face. But this is really opening the doors, I think, to many people making\r \r so many sophisticated\r \r images,\r \r not just in the 2 d plane but also in 3 d and really insightful\r \r walk through here. And you can tell when you read Tyra's writings\r \r just how much time and effort he's put into these packages\r \r to make all these capabilities\r \r possible. But yet with, you know,\r \r geological\r \r and very fit for purpose\r \r past.\r \r\n\nSo a lot to digest there, but, again, I think it's a very fascinating field.\r \r\n\n[00:14:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Eric, I I couldn't agree more. I'm always fascinated by Tyler's work on this particular\r \r project. I think, you know, when the raverse sort of first came out,\r \r it was pretty revolutionary, I think, to the our ecosystem. You know, we had ggplot, and we could do, you know, a a lot in in ggplot and some of the other plotting packages that were available. But in terms of 3 d\r \r visualization,\r \r animations, things like that, you know, we never had\r \r anything like that as far as I know until Tyler came along. So these suite of packages in the in the Rayverse and in particular the ones that he's highlighting today and their new functionality are RayVertex\r \r and Ray render are pretty incredible.\r \r\n\nI have tried to do some of this myself in the past. I think,\r \r I think you can expect your laptop fan to to a little bit\r \r as you try to do this. So get your GPUs\r \r ready, if you're especially if you're trying to add, you know, additional complexity\r \r and do some pretty in-depth things within these packages. But the the fact that we can do this at all is is absolutely\r \r incredible, and\r \r I loved the callback to sort of your early, you know, eighties nineties video game experience because that is that exactly what a lot of this blog post reminded me of as he leverages that subdivision levels argument in the subdivide mesh,\r \r function.\r \r\n\nAnd you can sort of see how the the pixelation just starts to smooth out as that that number\r \r increases in terms of how many, subdivision levels\r \r are being used. And it's it's almost, you know, conceptually, like,\r \r following video game graphics from the eighties nineties to the 2000 as you sort of get away from these these triangles and the pixelation into something that looks, you know, much smoother,\r \r into the naked eye. You you really can't even see the pixelation\r \r at all.\r \r Great summary by you. I'm not sure if there's a whole lot more to add to it. It's an incredibly visual blog so it's difficult for us to do it\r \r spend a lot of time in, you know, 3 d visualization,\r \r I think you'll still find it fascinating.\r \r\n\n\n\n[00:16:35] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 35,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And it does remind me there is ripe opportunities\r \r that we often see shared on social media from time to time. They'll call it, like, accidental art when you're trying to do a neat plot, yet it doesn't come quite outright, but yet it's so interesting to look at. You wanna post it anyway.\r \r These things are ripe for accidental art, especially if yours truly is the one coding it up. But,\r \r I do think as you look at the evolution of these images, back to that racing example, it's like when I saw that virtual racing game back in the early nineties and, again, you could tell it was like Sega's, you know, first real attempt at making\r \r somewhat perform at Polygon renders.\r \r\n\nAnd then it was like a couple years later, those of you who remember that Daytona USA\r \r racer game, it looked real. Like, everything was smooth. Everything was sharp. Everything is 60 frames per second. That is like you can have that same transformation\r \r as you play with these displacement,\r \r parameters and, again, the contour parameters. It's it's fascinating. It's absolutely fascinating.\r \r And\r \r what, who would imagine r could be an engine for graphics like this?\r \r And I've been following on social media kinda the other side of the spectrum\r \r where it's a slight tangent here, but Mike FC AKA Cool But Useless have been making all these packages\r \r that help me make sprite rendering\r \r even more easier in r itself.\r \r\n\nAnd it's like, my goodness. We can make almost any type of game in r now. It's just a matter of time, really.\r \r\n\n[00:18:08] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 8,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Absolutely. It's it's incredible stuff. Incredible stuff. And I do remember Daytona USA\r \r very fondly.\r \r How much fun was that?\r \r\n\n[00:18:16] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Oh, lots of quarters of spending that one, and then, of course, the computer racers have just eat my lunch. But that was part of the design to get your money back in those days.\r \r So we're going to shift gears quite a bit here,\r \r to get into more of the data side of things because there are some really promising developments in some of the ecosystems\r \r that Mike and I have been speaking really highly about in recent episodes\r \r of our weekly highlights. And in our next highlight here, we're gonna go back to,\r \r the\r \r now getting a lot of traction, so to speak, the DuckDb\r \r paradigm, the DuckDb database\r \r that just got supercharged\r \r with a new plugin\r \r and a new capability of using a service that's new to us from the our side of things.\r \r\n\nSo and it happens to be called Mother Duck, and that's an awesome name. But, Mike, what is this all about?\r \r\n\n[00:19:17] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Mike Thomas",
        "trans_text": "So Mother Duck is a way to run as far as I know. It's sort of a whole cloud based data warehouse system,\r \r or platform,\r \r from the developers of DuckDb themselves\r \r that allow you to not only store data, in the cloud but to also run DuckDV\r \r itself in the cloud so that you don't need DuckDV\r \r installed on your own laptop. You just need to be able to authenticate\r \r into your Mother Duck account that you have, and you can run, you know, serverless\r \r cloud based analytics\r \r using DuckDb,\r \r but not needing anything installed on your own laptop which is is really cool besides, you know, the the packages to authenticate\r \r into it. So currently,\r \r and and, you know, one big component of this that that's noteworthy that I think we should touch on is DuckDV just released version 1.0.0\r \r on June 3rd.\r \r\n\nSo this is\r \r incredibly exciting, you know, for the folks that have been following this project, for the folks that have been working on this project that we have a first sort of major,\r \r release\r \r of the project. And it's, you know, I think it's a a framework that we've seen,\r \r play out a few times, you know, in the data science ecosystem where\r \r a team will develop an amazing open source,\r \r framework or functionality. I think we've seen this,\r \r with the\r \r DBT\r \r package. If you're if you're, familiar with DBT software that I think allows you to do,\r \r more versionable\r \r ETL,\r \r They also have, I believe, a paid offering of that as well. I know that the team at Pymc sort of has some similar things\r \r going on, and it looks like the DuckDV team obviously has this incredibly powerful open source software that we can now use for\r \r doing some\r \r pretty incredibly efficient,\r \r ECL and and SQL querying\r \r on large datasets\r \r in,\r \r like, no time at all. But they've also built out, obviously, a, sort of privatized side of the business that allows them to to hopefully make money and to continue to,\r \r enhance DuckDV\r \r itself and that's this Mother Duck offering that we're talking about here. So there's pretty good documentation\r \r on,\r \r how to connect to your mother duck,\r \r service\r \r from Python but it looks like there's not necessarily any documentation\r \r out there yet on doing this in R.\r \r\n\nAlthough the author of this blog post, Novikha\r \r Nakhov,\r \r notes that it's it should be pretty straightforward to do so,\r \r if you follow sort of the the Python framework and just adopt it leveraging, you know, what we know about how to connect to DuckDV databases\r \r using r. So that's what, Novica is doing in this blog post. He is outlining how you would go about connecting to a mother duck instance\r \r from our,\r \r leveraging our 441,\r \r on Linux with DuckDB version 1.0.0.\r \r It's pretty easy to connect, to, you know, a DuckDb database and in memory database and he has a nice little code snippet of how to do this, how to populate that database using a data frame, and then how to query it using SQL syntax. And, it also notes that we do have the new duckplier package that would allow you to do this in a more dplyr like approach as opposed to having to write a sequel string in your db get query argument.\r \r But for the purposes of this blog post we're not going to explore\r \r Duckplier.\r \r\n\nSo I Novica\r \r details the Python approach first to connecting to to mother duck,\r \r and really it's pretty simple. And this Mother Duck Extension\r \r actually comes native to the Python duckdb package. And it's just a little one liner essentially that allows you to connect to your mother duck instance.\r \r You'll automatically get a notification in the terminal\r \r telling you what URL you should enter in your browser to be able to authenticate\r \r to your mother duck service,\r \r and then you're essentially good to go from there.\r \r In R, it's a little little trickier. The syntax looks pretty similar. It's a a one liner to try to connect to your your mother duck instance.\r \r\n\nBut one of the first things that you have to do is actually from the terminal, I think write a little bit of code,\r \r to create a local database that's called md or shorthand for for mother duck.\r \r So the reason that you have to do that at nova deposits is that, the duck dp package for r doesn't automatically figure out that it needs to load this additional mother duck extension the way the Python package does.\r \r So you have to sort of do that yourself\r \r but, again, Novica has all the code for us to do that here and it's it's fairly straight forward.\r \r You have to run a DB execute command to load this mother duck extension\r \r and then you're pretty much good from there, to be able to connect your mother duck instance and write your SQL queries that are going to execute in the cloud as opposed to\r \r locally.\r \r\n\nSo it's a a fairly, you know, straightforward blog post. It's really really helpful, I think, for those of us that are exploring DuckDB and want to try out Mother Duck. I will note that there's a free tier of the mother duck offering that gives you I think 10 gigabytes of storage,\r \r up to 10 compute unit hours per month which is probably a lot, you know. I'm not sure, you know, we know how fast DuckDV queries execute. That's right. Most of my DuckDV queries even on parquet files, you know, that are\r \r gigabyte, 1 or 2 gigabytes in size\r \r will run-in\r \r maybe a second or 2, and there's no credit card required for this free offering.\r \r\n\nSo there's no reason to not try out this mother duck service if it's something you're interested in. And if you need to go up to, the the paid tier, it's $25 a month per organization,\r \r I guess not per user, which is pretty incredible.\r \r If you're an organization that wants to leverage this mother duck service, that gives you a a 100 gigabytes of storage and a 100 compute unit hours per month, which I, you know, unless you're doing some pretty crazy stuff, I can't imagine that you would you would hit that. So I think it's a very sort of generous price point that we have here, and, obviously, it's amazing that we have this free tier that allows you to to try it out first, if you if you want to and and maybe that's all you need as well. So pretty incredible. Great walk through by NovaCon on how to use this in R because up until now, I don't think there's been any documentation\r \r on how to connect to, the mother duck service from our and it seems like there there was a little tricky hack that he pointed out. That's definitely going to help. Those of us who wanna try this out ourselves, probably save us a lot of hours. So we're very grateful that he went down that rabbit\r \r\n\n[00:25:57] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 57,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That's for sure. Ever since 1.0 was released. And I do recall, that's for sure, ever since 1.0 was released. And I do recall having to do some extension\r \r installation in my explorations a few weeks ago where\r \r I had to install a couple extensions,\r \r one of which was to help\r \r interactive object storage in AWS that didn't come by default. But, yeah, it's a similar syntax with what, Novica outlines here in this post. And, yeah, I guess, I'm interested in exploring mother duck to just see, you know, on a on a very basic basis just kinda how it plays in my workflows.\r \r One thing I'm immediately thinking of, Mike, is that if you're an organization\r \r or you're a smaller or big company and you wanna leverage\r \r DuckDV as your database back end for things like shiny apps or whatnot. It sure does seem like having that hosted in a data warehouse would be an intriguing idea to help offset some of that storage footprint from you\r \r to that to that vendor. Of course, we were remarking in the preshow that, you know, you you wanna at least have, like, a couple, you know, plans, if you will, of where you host these files because, you never know what can happen on hashtag just saying.\r \r\n\nBut in any event, what's nice about this service, I think they have some examples I was perusing yesterday\r \r where they did hook up a couple I don't know. It was either observable notebooks or some other custom web apps with,\r \r say, the New York City taxi data and doing simple queries on that and some drop downs. And it was, as you said, blazing fast with these queries to get the results back to the browser\r \r and not making your browser do all the data munging itself. It's gonna, know, do that on on the server side. And it does look like they're also exploring interactions\r \r with,\r \r wait for it, WebAssembly too. So there's gonna be lots of interesting,\r \r I think, applications\r \r to play here. And, again, I'm intrigued to see to see where this goes in the future.\r \r\n\n\n\n[00:27:59] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Absolutely. Me too. It's, an exciting space\r \r to watch. I've only dipped my toe in it. One really cool thing about the RStudio\r \r IDE is if you do have a dot SQL file in your RStudio IDE, every time that you save that file if you have a more recent version of RStudio,\r \r it'll re execute the query for you and show it up in in sort of the query output pane of our studio and that works great in duck DB as well I was playing around with it against\r \r parquet file,\r \r just editing my my DuckDV query and seeing the results\r \r come out real time without even having to, like, highlight the code and and click run or anything like that. It's pretty incredible.\r \r\n\n\n\n[00:28:40] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Eric Nantz",
        "trans_text": "All these save so much time when you add it all together. That is for sure.\r \r Did you say parquet files, Mike? I did, Eric. You sure did, man. That's a perfect segue to our last highlight today because, honestly, one of the building blocks that we have been, you know, espousing the praises of in many recent episodes is parquet as kind of this next generation\r \r data storage format. And, certainly,\r \r when you hear us talk about a lot of the use cases are when you have a collection of large data that you can do pretty, you know, sophisticated group processing with. So you can get really fast and and real time kind of analyses,\r \r being executed on it. But that's not the only use case because\r \r our last highlight here is,\r \r awesome update\r \r to the nano parquetr\r \r package,\r \r created by Gabor Society, a software engineer\r \r at posit. And his latest blog post talks about some of the key updates to this package and some of its use cases. So, Mike, why don't you walk us through what's new here?\r \r\n\n\n\n[00:30:01] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'd be happy to, Eric. You know that I am,\r \r want to sing the praises of the parquet format\r \r and everything around it. So very excited about this Nano Parquet.\r \r Our package and the 0.3.0\r \r release,\r \r that Gabor worked on, I believe,\r \r Hadley may have worked on it as well and some others, on the the Tidyverse team\r \r at Posit.\r \r So one of the reasons that they created the Nano Parquet package is that, they wanted to be able to,\r \r you know, interop with Parquet files\r \r without necessarily\r \r needing,\r \r some of the the weight that comes along with like the arrow package because\r \r the arrow package does have a fair amount of dependencies on it and it can be a little heavy to install.\r \r\n\nSo one of the things about this nanoparquet package is that it has no package or system dependencies at all other than a c plus plus 11 compiler.\r \r It compiles in about 30 seconds into an R package that is less than a megabyte in size.\r \r It allows you to read multiple parquet files which is in a traditional sort of data lake,\r \r structure\r \r very very common,\r \r with a single function, you know, sort of like what we have in the reader package. I I don't know if this is little known or if it's well known but if you just point that to a directory\r \r instead of a file\r \r it will read in all of the files in that directory assuming that they have the same schema,\r \r and essentially append the data together into a big data frame. And that's the same thing that the nanoparquets\r \r readparquet\r \r function will do for us. It also supports writing most our data frames to, Parquet files\r \r and has a pretty solid set of type mapping rules between our data types\r \r and the data types that get embedded as metadata\r \r in a parquet file,\r \r which is, you know, again, another reason why,\r \r you know,\r \r parquet format exists and I think was another part of the motivation for this nano parquet\r \r package that it gets a little bit of a reputation, the parquet\r \r format, for only being for large datasets.\r \r\n\nLike, you only wanna use parquet file format when your your data is big.\r \r And, I think what Gabor is trying to argue here in this blog post and that I would agree with\r \r is that that's not necessarily,\r \r you know, the case. And I think that anyone can make a case for leveraging the parquet for file format for storing data of of any size. And one of the, I think, big reasons for that\r \r is,\r \r the, you know, ability to not only have the data in the file but also metadata\r \r around the data including the data types\r \r such that when you hand that parquet file off to to someone else, they don't have to in their code the the way we used to do when we read a CSV and and define what the data type for each column that's coming in. You don't have to do that because it's embedded in the file itself.\r \r So we have a lot more safety around,\r \r you know reading data frames and writing data frames and ensuring,\r \r portability,\r \r you know, not only between languages but between users essentially so that, you know, what you see is what you get.\r \r\n\nSo I I think that's really helpful. You know, we know that Parquet is performant and typically\r \r a smaller size\r \r than, you know, what you would store in a traditional delimited type of file,\r \r which is is helpful\r \r as well.\r \r And, you know, there's additional things like concurrency,\r \r a parquet file can be divided into to row groups so that parquet readers can can read, uncompress, and decode row groups in parallel parallel as Gabor points out.\r \r So just a lot of I think benefits\r \r for leveraging the parquet file format and I think this is maybe one of the first blogs that I've seen\r \r make the case for the parquet for file format for small data as opposed to big data. So I'm super excited about the nanoparquet,\r \r package because I think that there are some\r \r particular use cases, you know, potentially Shiny apps that I'm developing that are maybe reading a a smaller dataset where I don't necessarily need to,\r \r leverage the whole Arrow suite of tools and maybe I just need to to read that data set in, you know, one time,\r \r from a parquet file, and the nano parquet package might be all I need.\r \r\n\n\n\n[00:34:23] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 23,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I'm I'm with you. I'm so glad they give, you know, the spotlight not just to the the typical\r \r massive, you know, gigabyte gigabyte datasets. I think what Nanoparque is doing here, again, great for the small dataset,\r \r situation,\r \r but I really like these metadata functions that are put in here too because I think\r \r nano parquet could be a great tool\r \r for you, especially being new to parquet,\r \r getting to know the ins and outs of these files, knowing, like you said, the translation between the r object types and the parquet object types in the dataset. There are lots of handy\r \r handy functions here that maybe they are part of the arrow package. I just didn't realize it, but to be able to quickly have these simple functions that grab, say, the schema\r \r associated with parquet,\r \r grabbing the metadata\r \r directly in a very detailed printout\r \r of, you know, a nice tidy data frame of these different attributes. I think this is a great way\r \r to learn just what are the ins and outs of this really powerful\r \r file type. And, of course, Gabor is quick to mention\r \r some limitations\r \r for this. He does say he probably wouldn't recommend using this to write\r \r large parquet files because this has only been optimized for single threaded\r \r processing.\r \r\n\nBut with that in place, I still think this\r \r is an excellent way to kind of dive a little bit or really deep into what are the ins and outs of parquet. And then when you're ready for that transition,\r \r say, to a larger datasets,\r \r he obviously at at the conclusion of his post calls\r \r the Arrow project out as well as DuckDV out. So you've got it all it all leads somewhere. Right? You may your your situation may be that Nanoparquet is gonna fit your needs, and that's awesome. More power to you. And then as you escalate your data sizes, then you can still use par k. You're just maybe transitioning to a different package\r \r to import those in or the write those out. So\r \r I think it's it's a great introduction\r \r piece\r \r as well as\r \r I'll be honest. I'm putting on my life sciences hat for a second.\r \r\n\nI would absolutely love to use parquet format as opposed to a certain format that's in that ends in 7 b that. You know what I'm talking about, those out there. This would be a game changer in that space.\r \r\n\n[00:36:50] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I mean, the word parquet just sounds a lot smoother than, you know, SaaS 7 beat at. It it sort of sounds like, I don't know, r two d two or or I don't know. You know? Well, at least r two d two out of personality.\r \r Oh, goodness.\r \r Let's switch quickly and one acknowledgment,\r \r that they that Gabor makes in this blog post that I do wanna highlight\r \r just for the sake of talking about how small of a world it is out there in the data science data engineering community\r \r is nanoparquet\r \r is actually a fork of an R package that was being worked on called mini parquet,\r \r and the author of mini parquet that r package\r \r was Hans Nielsen,\r \r who is the\r \r founder of DuckDV.\r \r\n\n\n\n[00:37:35] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 35,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Well, well, well, it all comes full circle, doesn't it? Oh, this is what a fascinating time. Awesome awesome call out. And I believe Hans will be keynoting at positconf this year, if I'm not mistaken.\r \r\n\n[00:37:49] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Mike Thomas",
        "trans_text": "You are correct. Yes. I As well as like every other data science conference, I think, this year.\r \r\n\n[00:37:56] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Eric Nantz",
        "trans_text": "He's been a busy man for sure.\r \r\n\n[00:37:58] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 58,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Deservedly so.\r \r\n\n[00:37:59] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Lots of momentum here. And, again, it's great to see\r \r every every all these frameworks and are now being a great beneficiary\r \r to this amazing work and giving us the tools,\r \r multiple tools to interact with these these systems. However, like you said, we have multiple packages.\r \r They're not with DuckDV itself, not multiple packages that interact with parquet.\r \r You've got lots of choice here. And, yeah, the time is ripe as it does seem like we're we're moving on to, like, these newer newer formats, these newer database formats that the the sky is indeed the limit here.\r \r And, yeah, thanks for riding that ship. I was about to go on more rants about another format, but we're gonna keep it positive here because\r \r this issue has much more than just what we talked about here in the three highlights here. I had lots of fun looking at the new packages, the updated packages,\r \r and much more. So we'll take a couple of minutes for our additional fines here. And, yeah, going back to the, sports theme for a second,\r \r now that we have a lot of interesting tournaments going on right now in the world of soccer and football. You might wanna visualize some of those, you know, head to head matchups, and I've got the package just for you for that one. A new package called brackets\r \r offered by Vera and Limpopo, who you might familiar be familiar with. She's been a frequent contributor to the shiny community\r \r and many talks and presentations.\r \r\n\nBut brackets is an HTML widget that lets you very quickly\r \r visualize\r \r the bracket\r \r of a tournament.\r \r And I could see\r \r lots of use cases in the world of sports analytics for darn sure, but the ever fascinating part of this package is that it was actually built\r \r during a course that Virla teaches\r \r about supercharging\r \r your HTML widgets, which is part of the analytics,\r \r platform that she recently joined alongside David Grandgen.\r \r So they've been both,\r \r hard at work on some of these courses about Shiny\r \r and HTML widgets.\r \r And, yeah, Brackets is one of the products of those courses. But, yeah, when I get back to doing more sports analytics in the future, I think I'm gonna put Brackets in my Shiny app just for fun alone, but I could see lots of lots of cool utility with that.\r \r\n\n[00:40:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That's a great call out, Eric. And when I saw that, really, I guess, clean\r \r way to visualize,\r \r you know, tournament brackets,\r \r I was I don't know. I thought it was super cool too. So I'm I'm very glad that you shouted it out. I am not surprised. I did not realize that Virla is the one who put that together,\r \r and I'm excited to see more from that, especially,\r \r as we continue\r \r to dive deeper into a couple tournaments in my favorite sport, soccer or football for the rest of the world.\r \r A lot of bracketology\r \r going on these days so looking forward to more in that, area.\r \r One call out, that I wanna make is\r \r a Frank Harrell's blog, Statistical\r \r Thinking, has a new slide deck,\r \r that he gave as a presentation\r \r at the International Chinese\r \r Statistical Association Applied Statistics Symposium\r \r in Nashville,\r \r recently,\r \r and the talk is titled Ordinal State Transition Models as a Unifying Risk Prediction\r \r Framework,\r \r and he presents a a case for the use of discrete time mark of ordinal longitudinal\r \r state transition models.\r \r\n\nIf if we can pack all of those words into the same sentence and really the purpose there is is estimate estimating\r \r risk, and expected time in a given state,\r \r and and it's really, you know, in the vein of clinical trials in that area. But\r \r I took a look at these slide decks and,\r \r state transition matrices and models are something that I deal\r \r a ton with in, banking and financial services\r \r because most,\r \r loans\r \r banks have a particular rating assigned to that loan based upon, how risky it is to the bank, you know, the likelihood\r \r of that loan going bad, essentially, or likelihood of re repayment or or the borrower not repaying it. And, you know, they continue to to reevaluate\r \r that state that that loan is in.\r \r\n\nYou know, it could be monthly, it could be quarterly, it could be at some longitudinal\r \r time horizon. And then we want to take a look at how the volume within that loan portfolio shifted from one state to another,\r \r across a given time period.\r \r So I have in our package out there called migrate that is due for some updates,\r \r or due for a re release on crayon. We've had some work done on it recently but I just need to push it over the hump. So,\r \r I would check out these slides if you're interested in this type of stuff but mostly I'm calling, this\r \r slide deck out as a call to action for myself to get some work done on the migrate package\r \r and hold myself to it, out in the public here.\r \r\n\n\n\n[00:42:57] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 57,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hey. Our weekly has many benefits. Right? Making you do more work.\r \r That's awesome.\r \r\n\n[00:43:03] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. Right. But you're a great set of slides by Frank.\r \r\n\n[00:43:06] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Frank did a terrific job here, and and you you tell us a small world. I remember a lot of the the, you know, the mathematical notation and the concepts here\r \r because my dissertation very much had a component of theory around state transitions and competing risk methodology\r \r and whatnot. So I'm getting flashbacks of writing that chapter in my dissertation.\r \r It was not easy back in those\r \r days. But Frank has is one of the great thought leaders in this space, and, yeah, it's great to see him sharing this knowledge in many, many different formats and many\r \r venues. And there's so much more knowledge you can gain from the our weekly issue. Again, we could talk about it all day, but, yeah, I wish we had that time. But we're gonna invite you to check out the rest of the issue. Where is it you ask? Oh, you know where it is. It's atoroakley.org.\r \r\n\nIt's right here on the on the index page, current issue, as well as the archived all previous issues if you wanna look back to what we talked about in previous episodes.\r \r And, also, this is a community project. Again, no\r \r big overload company, you know, funneling down our vision. This is all built by the community, but we rely on your contributions.\r \r And, honestly, the easiest way to do that is to send a poll request to us with that great new package, blog post, presentation,\r \r resource, call to action. You name it, we got a section for you in the RN Week issue\r \r all marked down all the time. Just send us a pro request, and we'll curator of that week will get it into the next issue.\r \r\n\nAnd, also, we wanna make sure we hear from you as well. We, of course, love hearing from you. We've had some great shout outs recently, and, hopefully, you keep that coming.\r \r The best way to get a hold of us is a very few ways. We got a contact page\r \r linked in the episode show notes. You can directly send us a message there. You can also find us on these social medias where I am mostly on Mastodon these days with at our podcast at podcast index dot social.\r \r I am also sporacling on x, Twitter, whatever you wanna call it with at the r cast and on LinkedIn. Just search for my name, and you will find me there. And, Mike, where can the listeners get a hold of you? Sure. You can find me on mastodon@[email protected],\r \r\n\n[00:45:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "or you can check me out, to what I'm up to on LinkedIn\r \r if you search for Catchbrook Analytics,\r \r ketchb\r \r r o o k.\r \r\n\n[00:45:30] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Very nice. So we're very much looking forward to that new package release when you when you get that out the door. Hopefully, that'll be, top of the conversation in a future episode.\r \r But, yeah. I think we've we've, talked ourselves out. We're gonna close-up shop here with this edition of our weekly highlights.\r \r And, hopefully, we'll be back at our usual time. We may or may not because this is a time of year where vacations are happening, but one way or another, we'll let you know."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_26_highlights",
        "chap_timestamp": 45,
        "chap_text": "Sculpting the moon with the rayverse",
        "chap_href": "https://www.tylermw.com/posts/rayverse/displacement-mapping.html"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "chap_timestamp": 34,
        "chap_text": "Motherduck in R",
        "chap_href": "https://discindo.org/post/joining-the-flock-from-r-working-with-data-on-motherduck/"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "chap_timestamp": 59,
        "chap_text": "nanoparquet 0.3.0",
        "chap_href": "https://www.tidyverse.org/blog/2024/06/nanoparquet-0-3-0/"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "chap_timestamp": 57,
        "chap_text": "brackets widget",
        "chap_href": "https://github.com/hypebright/brackets"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "chap_timestamp": 57,
        "chap_text": "State Transition Models",
        "chap_href": "https://hbiostat.org/talks/ordmarkov3.html#1"
      },
      {
        "ep_name": "issue_2024_w_26_highlights",
        "chap_timestamp": 42,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_25_highlights",
        "ep_date": "2024-06-21",
        "ep_duration": 48,
        "ep_description_short": "How the newly-released CRAN package deadline metadata inspired multiple learning journeys of the latest Shiny features with one of your podcast hosts joining the ride, a fresh coat of frontend paint to the amazing R-Universe, and the innovations R brings to forensic analyses of handwriting. Episode Links This week's curator: Ryo Nakagawara -…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_25_highlights",
        "description_long": "\r \r How the newly-released CRAN package deadline metadata inspired multiple learning journeys of the latest Shiny features with one of your podcast hosts joining the ride, a fresh coat of frontend paint to the amazing R-Universe, and the innovations R brings to forensic analyses of handwriting.\nEpisode Links\n\nThis week's curator: Ryo Nakagawara - @Rby[email protected] (Mastodon) & @RbyRyo) (X/Twitter)\nExpose CRAN deadlines and DOIs\nA fresh new look for R-universe!\n{handwriter} 3.1.1: Handwriting Analysis in R \nEntire issue available at rweekly.org/2024-W25\nSupplement Resources\n\nEric's pull request to fix the shinylive version of the CRAN deadlines app https://github.com/matt-dray/cran-deadlines/pull/3\nThe handwriter package documentation site https://csafe-isu.github.io/handwriter/index.html\nScraping the R-Weekly Highlights podcast https://github.com/iamYannC/r-podcast\nSimulations for 2024 Euro Cup and Copa America https://lukebenz.com/post/intlsoccer2024/\nForecasting the UEFA Euro 2024 with a machine learning ensemble https://www.zeileis.org/news/euro2024/\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\n \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\n \nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nAcrophobia - Earthworm Jim - about:blank - https://ocremix.org/remix/OCR01568\nCross-Examination - Phoenix Wright: Ace Attorney - PrototypeRaptor - https://ocremix.org/remix/OCR01846"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://mstdn.social/@R_by_Ryo"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://www.rostrum.blog/posts/2024-06-12-cran-db/index.html"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://ropensci.org/blog/2024/06/12/runiverse-frontend/"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://cran.r-project.org/package=handwriter"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://rweekly.org/2024-W25.html"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://github.com/matt-dray/cran-deadlines/pull/3"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://csafe-isu.github.io/handwriter/index.html"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://github.com/iamYannC/r-podcast"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://lukebenz.com/post/intlsoccer2024/"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://www.zeileis.org/news/euro2024/"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://ocremix.org/remix/OCR01568"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "links": "https://ocremix.org/remix/OCR01846"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're at back of episode 169 of the R Weekly Highlights podcast.\r \r Yeah. We're coming at you slightly a little later this week because, real life never slows down for either Mike or myself, but I'm delighted you're here. My name is Eric Nansen as always. It's great fun to talk about all the greatest,\r \r highlights that we have in this week's our weekly issue on this very podcast.\r \r\n\n[00:00:25] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 25,
        "trans_speaker": "Mike Thomas",
        "trans_text": "And I never do this alone. I've got who's been on an adventure of his own, Mike Thomas. Mike, how are you doing today? Hanging in there, Eric. Hanging in there. We're, yeah, like you said, a little late this week because real life happens, but we're still trying to get it out there for the people.\r \r\n\n[00:00:40] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. We're getting it out there. And, yeah, we we've been taking some mild inspiration from a certain team in Canada that's now dragged the uncertainty from Florida to game 6 of the Stanley Cup finals. So if they can come from a 3 hole deficit,\r \r we can knock out another podcast today, I dare say. I like that analogy. Yes.\r \r Yeah. It it works for me today anyway. So what also works is our weekly itself is a project where we have a rotating set of curators for every single week. And this week, it was curated by Ryo Nakagorua,\r \r another one of the OG's of the Arruki project itself.\r \r\n\nAnd as always, he had tremendous help from our fellow Arruki team members and contributors like all of you around the world with your awesome poll requests and\r \r certain suggestions.\r \r So we lead off with an issue that if you ever have released a package on CRAN,\r \r you are probably familiar with at one point or another.\r \r Whether it's your package or one that you depend on,\r \r is sometimes\r \r on the CRANS system, there are packages that may fail certain checks.\r \r Happens to all of us, and then there may be such a failure\r \r that the CRAN team says,\r \r okay. We've detected this, failure.\r \r\n\nNow, you have until a certain amount of time\r \r to fix this.\r \r And that can be scary for a lot of people, myself included, especially if it's a package that is a very important part to my workflow or is a dependency\r \r of an important part of my workflow.\r \r But you may want to know just at a glance\r \r what is really happening in this landscape.\r \r And this first highlight covers that and another bonus feature to boot that's come into R recently\r \r where Matt Dre, another frequent contributor to Rwicky highlights in the past,\r \r has created\r \r 2 very neat interfaces.\r \r\n\nAnd the first of which we're gonna talk about is this grand deadlines dashboard.\r \r This is very interesting, and the way this has been generated is that\r \r you may not know this, but in the base version of R, there is a handy function\r \r called crannpackagedb\r \r where this is literally grabbing\r \r an online source of data that the CRAN team maintains about package metadata.\r \r And you may be thinking to yourself, well, wait. Isn't this based on my current installation of r? No. No. No. This is a publicly\r \r available dataset that is updated regularly. Not quite sure the frequency of the updates,\r \r but there were 2 new fields that were introduced recently\r \r in this data frame. And in Matt's post, he shows first the typical metadata. You get, like, the package name, the version,\r \r and the maintainer,\r \r but there are 2\r \r additional columns. The first of which\r \r is called deadline,\r \r and deadline is giving, as the name suggests, the date\r \r that the CRAN team has given that package author or that package itself\r \r to fix whatever issues have been flagged\r \r in their check system.\r \r\n\nAnd you sure enough on the CRAN page, you could go to each package's website. You could then see\r \r the notes of these check failures on that package\r \r site itself on CRAN.\r \r But what Matt has done here is he took this opportunity to learn, become the latest and greatest in shiny development, which, of course, will please me in Mike's ears quite a bit. He has leveraged bslib\r \r and some pretty nifty ways of constructing the UI\r \r to create a very attractive looking,\r \r very fit for purpose deadline\r \r dashboard\r \r with individual\r \r cards as in the BSweb system\r \r that give\r \r at a high level the number of days remaining until that deadline, or,\r \r unfortunately, it could be the days that have passed since that deadline.\r \r\n\nAnd you can see that very nicely. You have color coded boxes here, so you could quickly\r \r grok in the order. It goes from the ones that have they're\r \r running the longest in their update up until the ones that have more time.\r \r But you could scroll through this and see very quickly then which packages have been flagged, and it'll give you a direct link\r \r to the detailed\r \r check failures that you can navigate to directly from this page.\r \r Really nifty interface here,\r \r and he's not alone in this. Actually, Hadley Wickham himself has also built a similar report, albeit it's built with what it looks like an automated portal kind of GitHub action\r \r deployment, but it's got similar metadata\r \r associated with it. So you got 2 great sources\r \r for this information.\r \r\n\nAnd I got wind of this not so much from Matt's post, but from a post he did on Mastodon as he was experimenting with this.\r \r And I pull up this interface, and I'm thinking to myself,\r \r oh, this is nifty. When I pulled up the interface,\r \r it was running on shiny apps. Io. It is a shiny app after all, but, immediately, in my head\r \r you wanna guess what was popping in my head, Mike, as I thought about what this could be good with?\r \r\n\n[00:05:55] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 55,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Shiny Live WebR.\r \r\n\n[00:05:57] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 57,
        "trans_speaker": "Eric Nantz",
        "trans_text": "You got it. I'm on the the Shiny Live web train as you know from my\r \r recent efforts on the ER consortium pilot. So I wondered,\r \r I wonder what why maybe that wasn't done. Well, sure enough, it went to the GitHub repo, and I'd see that Matt did indeed attempt this,\r \r but it wasn't working.\r \r So this got me thinking here. You know what? I've been in the Shiny Live game for for a bit here with this other project.\r \r Maybe I could have my hand at trying\r \r to get to the bottom of this.\r \r Hence, my rabbit hole. So it's a little bonus,\r \r dev story time of Eric here. I pulled it up, cloned it on my local system, and I tried to look at the errors. And Matt did,\r \r have, like, a a general version of this error and an issue on his issue tracker on GitHub.\r \r\n\nAnd I noticed that for whatever reason, the shawnee live app could not download\r \r that aforementioned\r \r CRAN database from that handy function inside of r.\r \r Why is that?\r \r This gets really interesting because, apparently,\r \r there are\r \r security controls in place in your web browser\r \r for accessing certain versions of URLs\r \r behind the scenes\r \r due to what's called the cores or the cross origin\r \r something or another. I'm not as in-depth with this, but I have seen posts from George Stagg in the past on, like, the WebR\r \r issue repository or the Shiny Live issue, tracker repository\r \r saying that you have to be careful about how you download files. And in fact,\r \r in web web r, you have to use the download that file function more often than not to actually download something, and you have to hope that the browser is able to access that URL because of these built in security protocols.\r \r\n\nSo I noticed that even I tried to download the file directly after I scanned the source of this, CRAN package DB function,\r \r I still couldn't get that RDS file. It just would not register.\r \r Then I went down another rabbit hole to figure out, I wonder if others have experienced this with RDS files. I wonder if it was just specific to that or, you know, just shooting throwing darts at a dartboard at that point.\r \r I stumbled upon another issue on the WebR repo where somebody put up a clever workaround\r \r to use this kind of openly available\r \r domain, like, referral service\r \r where you can transform a URL to meet these core security requirements.\r \r\n\nIt's kinda like when you have in, certain, you know, web lingo,\r \r you can put in a base URL, and then one of the query parameters is like the URL that you're actually interested in.\r \r There is such a thing as this that I stumbled upon in the issue tracker, and I'll put a link to my poll request in the show notes where you can get the the full details of this.\r \r But it's so I I plugged in this kind of more modified URL,\r \r and sure enough,\r \r I could get the RDS file from the CRAN site once I made this modified URL. So I thought, okay. I'm in business now.\r \r So in the in the source code of Matt's dashboard here,\r \r I now have\r \r a handy function to detect\r \r if the app is running in a web assembly process. And that's credit to Winston Chang from the WebR repo\r \r to basically detect if we're in what's called the\r \r web and scripting\r \r kind of functionality and web assembly. Again, I'm still learning all this, but it's kinda like a a simple true false if you're in it or not. So then if I'm in it,\r \r I know to use this custom function that I developed to modify the URL\r \r with download that file directly and then import that into r as a typical RDS file. Whereas if you're running this in a traditional r process, you can use that function that Matt shows in the post as is. No no big deal there.\r \r\n\nAnd so\r \r so once I figured that out, I thought I'd solved everything then. But, no, there was one other kink here, Mike, and, you know, it never stops sometimes.\r \r WebR\r \r is currently still using our version 4 dot 3 dot 3.\r \r And Matt has,\r \r as he's actually covered, I believe, in one of his recent Mastodon posts, in version 4.4,\r \r now there is a handy function in BESAR that we've actually covered called sort underscore buy,\r \r where you can sort a day frame very quickly. It'll be very familiar to any of you that use the dply or arrange function.\r \r Well, guess what? In the web assembly version, that function doesn't exist because that's running 4 dot 3. So then I have another\r \r trick where if I'm running in web assembly mode, I use the more, you might call traditional\r \r order function in base r with the data frame referencing the variables\r \r directly.\r \r\n\nAgain, dusting off my, you\r \r might say, our development skills from pre 2015 on that, but, hey, Gradle was useful again. Right? So once you put both of those things in, then the web assembly version actually works.\r \r\n\n[00:11:06] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Mike Thomas",
        "trans_text": "So I felt I felt pretty vindicated, so I'm I'm geeked out. I'll send that PR to Matt. He merges it in. He recompiles the app, and now it's on Shiny Live. So woo hoo. Little dev fun with Eric there. That was that was a good time. Eric, that's awesome. I think, Matt, as he notes in his blog post, was super grateful for your help. I don't know when you sleep. I don't know how you do this stuff. I don't know how you figure it out and keep up with the shiny lab stuff, but, you are clearly\r \r leading in this space somewhat. If I remember correctly. You might even be giving a little bit of a talk at Pawsit Conferences here on this exact topic. So it sounds like you were the best the best man for for the job, so to speak, on this one. And, the the end result of this app that Matt has put together is is excellent. So I know he's grateful\r \r to you for that work that you put in and that pull request that I'm I'm taking a look at right now. It's it looks like it's full of rabbit holes that you went down. So\r \r Yeah. That that short narrative doesn't do it justice, but it was there. Every bullet point is like a a rabbit hole in terms of how I'm interpreting it. So that that's that's fantastic.\r \r\n\nAnd the app is the app is great. It's really cool to see the the Shiny Live use case here. I know that that's something that Matt was trying to tackle here and was also trying to up skill a little bit on bslib.\r \r So the the app that came, out of it looks looks really nice. I think, you know,\r \r an alternate approach if you didn't care about, you know, going the the bslib route and the shiny live route would be you could potentially,\r \r have like a GitHub actions script, right, that would reach out to the the CRAN database that doesn't need, you know, Shiny Live or anything like that,\r \r you know, to be able to run and collect that data, maybe store it as an RDS file on a nightly basis that gets refreshed in the the repository\r \r\n\n[00:12:54] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 54,
        "trans_speaker": "Eric Nantz",
        "trans_text": "and then, you know, create a a GT table or a reactable table or or something like that. Right? And maybe that sounds sort of like what Hadley That put together. That's basically exactly what Hadley has done. Right? So it's it's great to see both of these approaches side by side, though. And and as Matt says, this is an awesome learning opportunity for him, and I, of all people, love going down rabbit holes for learning opportunities\r \r\n\n[00:13:16] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Mike Thomas",
        "trans_text": "in our ecosystem. Awesome learning opportunity for me as well just to read through this to be able to see the repository and see how it all came together. It's fantastic.\r \r And as you mentioned, one of those other columns that comes back from that, CRAN database,\r \r function in BaseR\r \r that we have is is DOI.\r \r And a DOI is a digital object identifier, and it sounds like CRAN has recently been\r \r tagging on these DOIs to,\r \r most, if not all, R packages that are on CRAN. I'll have to check if the package that I have on CRAN have a DOI right now.\r \r\n\n[00:13:51] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 51,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I haven't checked mine yet, and I'm not sure if they've gotten to everyone just yet. But, boy, I've seen a lot of excitement about this on on the social sphere, so to speak, with, being able to use this as a very important,\r \r you know, reference for somebody's, you know, development and research journey. It's it's terrific here. Absolutely terrific.\r \r\n\n[00:14:11] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 11,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. And I imagine as, you know, I am not the expert on DOIs,\r \r citations,\r \r things like that. But I I think this is a way to be able to track,\r \r you know, how often this DOI gets used out there in the wild and and really that the purpose of that DOI is for citation purposes. Right? For someone else to someone else to be\r \r able to to not only, you know, cite your work in their paper but if they stick that DOI somewhere on the web, I believe that you'll be able to sort of track,\r \r where your work has been used. And it sounds like these DOIs can be either project specific or like blog specific, I think, or article specific, something like that, as well as perhaps,\r \r user specific, individual specific DOI. I'm not sure how you would,\r \r you know, essentially\r \r have a profile that that has multiple DOIs under it, right, for all the different articles\r \r that you have or different R packages in this case.\r \r\n\n\n\n[00:15:07] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 7,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I would love to hear from listeners because I know a lot of package authors will put what's called their ORCID identifier in the package manifest if they can link all this together somehow, but it's a fascinating time to as you said, I think this is a first step to getting some real tangible\r \r metrics on package usage,\r \r in in whatever domain people are interested in. And, what Matt's done here is really awesome because he has a handy little function, right, that called get cran DOI badge where, you know, basically, on your GitHub repos or in your readmes, you you often see these awesome little badges about, like, the version status or if it's on crayon or whatnot. Now you get a very attractive DOI badge free of charge, right, from this function. Really, really nice stuff here. Yes. The big shout out to Matt for making this very easy\r \r\n\n[00:15:58] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 58,
        "trans_speaker": "Mike Thomas",
        "trans_text": "for us, via his his Badger package to just stick that in our our readme and have, you know, another great badge to stick on top of our our packages. So that's that's awesome that he's made that so easy for us, and I'm excited to dive into the world of of DOIs, especially as it relates to the r packages that we have out there and see if I can add some badges this\r \r\n\n[00:16:21] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Eric Nantz",
        "trans_text": "week. Yeah. I've been, slowly getting on that badge craze, but I see some other prominent developers have, you know, quite a few of them. Like, how do you do that? Because it's all still kind of foreign to me. But, hey, this is this is, quite handy here. And,\r \r this is catching, you know, it's catching, you know, you know, a lot of momentum here because on on this particular feature alone,\r \r Dirk Edebutel, who, of course, is famed with RCPP development and are on Linux,\r \r he's created now a simple fetcher to his Littler\r \r script pipeline, which I use a lot of my Docker,\r \r files for installing our packages\r \r when they're using the rocker base images. Littler is kinda like a\r \r short COI like interface to r to say install a package from CRAN, install a package from GitHub. Apparently, he's also got now a way to fetch those DOI,\r \r information directly\r \r in Whitmer as well. And then another fun, you know, time is all together is that Mike FC, I'll be, also known as cool but useless on Mastodon and Twitter.\r \r\n\nHe's trying to make a list of all these kinda like CRAN metadata\r \r dashboard, you know, situations. And now Matt's positing,\r \r oh, wait. Maybe we need a a search that aggregates all these together. So it's like inception overload with all this metadata\r \r\n\n[00:17:40] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Mike Thomas",
        "trans_text": "scraping. But, hey, I'm here for it. This is this is terrific stuff here. Me too. Me too. Shout out, Matt. Great blog post, great walk through. I think this is a fantastic sort of I don't want to call it simplistic but it's a a pretty straightforward thing that he's trying to accomplish and and being able to to have this very straightforward use case\r \r for Shiny Live makes it it really consumable for me to understand what's going on.\r \r\n\n[00:18:17] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And we just mentioned, Mike, how yeah. What Matt's produces very aesthetically pleasing, and we're gonna go from simple to what is a very intricate system that just got a really big face lift to the end user perspective and a whole lot more. What we're speaking about here\r \r is the very influential and very powerful\r \r Our Universe project,\r \r which just got a very, you know, welcome revamp to its user interface and user facing functionality.\r \r So this next highlight comes from a blog post from the architect of our universe himself, your own oombs, who talks about,\r \r guess what? The web interface for our universe has a brand new front end, and this is not\r \r not a trivial front end by any means.\r \r\n\nIt's actually based in\r \r the express JavaScript framework with some server side rendering that,\r \r Jerome says has been greatly helpful\r \r to getting results appearing on the our universe page much more quickly,\r \r much more efficiently.\r \r I even did a little,\r \r GitHub investigation\r \r last night in this repo, and it's even using mongodb\r \r as well of all things. My goodness. Talk about supercharging\r \r your UI and back end processing.\r \r But,\r \r obviously, this is an audio podcast. We can't really show you over in this little chapter marker. I've got a, image of it, but we'll describe kinda what he is most excited about in these updates. And what I saw when I scanned this earlier\r \r is that now this the UI of it, it's gonna be very much optimized\r \r to multiple, you know, resolutions wherever you're looking at this on, like, a a phone screen or on a big monitor. He's done a lot of attention to detail to make the page very responsive,\r \r which we all kinda take for granted now when we build our shiny apps with bsweb or other frameworks like that. And as I mentioned,\r \r server side processing for a lot of these rendering results. So your client browser\r \r isn't having to do as much of the heavy lifting as it's pulling this information from the our universe services.\r \r\n\nAnd he's also\r \r made a little bit of rearrangement\r \r to where you see the information on the owner\r \r going on the left sidebar now.\r \r And then, also,\r \r each package now gets a dedicated section to we just talked about earlier, citation information, which I'm sure the DOI,\r \r framer from CRAN may or may not play a role there.\r \r And also some handy\r \r contribution\r \r charts that are showing now proper time stamps\r \r and kinda capping out at 12 contributors in case you have a package that gets a boatload of contributors and not overwhelming\r \r the graph. But,\r \r he's also\r \r been able to\r \r optimize the table\r \r representation of\r \r package help pages.\r \r\n\nHe looks like the HTML of the help pages has been greatly enhanced as well,\r \r And he's also made some rendering of the vignettes inside a package\r \r look a little more native to a web browser and not just kind of, like, pasting in text from you can tell on different source. It all looks very\r \r cohesively\r \r constructed here.\r \r Really nice stuff. We invite you to check out the post\r \r for, obviously, links to the information.\r \r And he was very careful to keep backward compatibility\r \r here with the various URLs at different parts of our universe such as the\r \r packages,\r \r cards themselves, the articles.\r \r\n\nYou're gonna still get those same URLs. So don't fret if you're a package author on our universe. I'm wondering, oh, no. I passed this link to, like, my team or or in my, you know, Twitter or Mastodon,\r \r shout out to you. You'll still be able to use those same links. But, again,\r \r really, really polished interface here, and it just goes to show you that it seems like your own never stops on his our universe development adventures, but really really awesome UI enhancements here.\r \r\n\n[00:22:17] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I couldn't agree more, Eric. You you know,\r \r when our universe originally came out that the UI to me that we now had\r \r around, you know, these individual package sites was like mind blowing that we had something like this now. Right? Instead of having to go to, I guess, GitHub and take a look at the the read me or or the package down site. Right? This our universe serves a lot more purposes than just that\r \r and\r \r thinking back to what the UI looks like before this facelift,\r \r this one no offense to the old UI but like because that blew me away, but this one has blown the other one away.\r \r So this is just much much cleaner. The navbar looks fantastic.\r \r\n\nIt looks like they have, you know, these different cards. Reminds me very much of like a bslib\r \r card type of situation that we have going on here that breaks out the section content with really nice headers as well as footers,\r \r which are are fantastic and and then it all the readmes,\r \r and the vignettes the way that they have rendered now I think everything is just a little bit cleaner which is fantastic.\r \r I'm looking at at one of my own for my package migrate and somehow,\r \r up here I have a link to my\r \r or Yaron has a link to my mastodon account next to my name. I'm not even sure I ever supplied that.\r \r I must have at one point in time because I imagine that he's not doing that by hand, but it's it's you have to see it for yourself and and take a look at the new Our Universe face lift, you know, search your favorite package,\r \r take a look at what the site looks like. I need to start installing packages from our universe. I need to to shift over there\r \r from some other package managers because I think there's a lot of advantages to this being sort of a one stop shop for,\r \r you you know, package installation in my local work, package installation for for web assembly\r \r purposes, right, as well. Yes.\r \r\n\nSo it's it's a pretty incredible resource that we have as as well as all the documentation,\r \r citation,\r \r you know, and all sorts different things that we have around all the different packages,\r \r that are now on\r \r the our universe. So incredible resource. He's another one where, like you, Eric, I I have no idea when your own sleeps but I'm very grateful for the work that he's done for the community.\r \r\n\n[00:24:35] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 35,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Like I said, I inspected the, GitHub repo for the new front end and my goodness. If I could under if I was able to understand even 10% of all the JavaScript magic he did there, I'd be a lucky lucky person. But,\r \r yeah, I was even pulling up the I now have 2 packages on our universe, albeit they're both related to the,\r \r podcasting 2.0 ecosystem. But, boy, those pages look fantastic.\r \r Like, man, my goodness. I I I feel good about passing this off to somebody and showing it off to to friends and stuff. This this is top notch. I love it. Just love it. Me too.\r \r Sometimes, I'll catch myself\r \r saying when I read maybe some terse documentation.\r \r\n\nI'm not gonna say it's inspired by real life scenarios, but, you know, take that for what it's worth. And I'll kind of flippantly say to myself,\r \r who even wrote this stuff?\r \r Well, you know what? We're gonna answer that question literally in a much different context in our last highlight today\r \r because\r \r there is, of course, even in this advent of technology and most of us using a keyboard or a touch keyboard to write, you know, in the majority of our communication,\r \r there are still many instances where we are handwriting material.\r \r And there is a very important\r \r domain of research\r \r in forensics\r \r that are looking at more data driven approaches\r \r to helping identify\r \r potentially from a source of handwritten\r \r materials, maybe they're letters, maybe they're short notes, maybe they're whatever have you,\r \r I'm trying to use, you know, awesome algorithms\r \r to help link maybe certain\r \r writing sources to a particular author or a particular, you know, writer.\r \r\n\nThis last highlight\r \r is fascinating to me in a world that I definitely don't frequent in the world of forensics,\r \r but there is a major update to an r package\r \r called handwriter.\r \r This is maintained by Stephanie Reinders, and she is part of what I believe\r \r is the Iowa State University,\r \r the Center For Statistics and Application\r \r in Forensic Evidences or CSAE for short,\r \r mouthful, but they've been doing a lot of research in this space.\r \r And in particular, this r package that we're referencing here\r \r is a first step in a bigger pipeline that they are in the process of open sourcing, although they've got some manuscripts\r \r to show for it,\r \r where this package handwriter\r \r will take a PNG\r \r screen grab, if you will, of any handwritten content,\r \r and it's gonna apply\r \r some handy analysis\r \r methods\r \r to help identify\r \r certain features of this writing. And this is\r \r it's all about rabbit holes. I can only imagine how much research time is gonna spend into this, but I'll give a high level of the pipeline because there's no way we could do it all just this year, but it's got 4 major pieces of this pipeline.\r \r\n\nFirst of which is that let's say you\r \r are scanning a handwriting reference that has colored\r \r ink or whatnot.\r \r It's going to turn that image into literally great black and white or gray scale first, and then\r \r it's gonna take, you know, the the stroke width of each of the writing. And there's,\r \r we have a link in the show notes to the package site itself where they have a good example using literally the word c safe\r \r written in cursive\r \r where they will take this reducing the width of each of those strokes to 1 pixel.\r \r That's fascinating too.\r \r\n\nAnd then trying to detect,\r \r they call this the break phase next\r \r to compose it into small pieces, which in 2 of you might think are the individual letters\r \r in this writing.\r \r And they do this with a little graph theory to boot. They'll put nodes and edges\r \r that correspond to these different points in the in the detection of these units or breaks.\r \r And then they'll actually take measurements of the distances\r \r between these breaks,\r \r distances between the different letters\r \r to help figure out then, okay. Can we are there certain properties\r \r of this writing\r \r that then if they get additional sources, if they get similar writing style,\r \r you will see different versions of these or similar versions of these metrics\r \r as compared to, say, if you and I, Mike, wrote, like, the same, you know, same, like, short story on 1 page on a one piece of paper,\r \r it should detect our writing styles to be quite different. And I venture to say you probably have better handwriting than I do do because my handwriting's terrible. But, nonetheless,\r \r this package should be able to detect that if we gave 2 PNGs\r \r of our different sources that it would correctly\r \r identify us as being\r \r different riders.\r \r\n\nSo as I said, this is part of a larger,\r \r research pipeline that they also talk about\r \r in this, in this, package down site\r \r of how they integrate this\r \r with additional\r \r analytical tooling using some Bayesian methodology,\r \r some classical k means clustering\r \r to help really with a larger set of writing to be able to put this into distinct groups so that then you could link maybe potential\r \r sources to the same author.\r \r So as you can imagine, where this would really be important, especially in the world of forensics,\r \r is if there is an investigation and maybe one of the pieces of evidence\r \r is a writing that maybe a suspect had and then trying to link that maybe to that actual person as part of the evidence. I'm just speculating here because, again, not in my domain, but you could see how important this is in the role of forensics. So the fact that r itself\r \r is able to drive a significant part of this pipeline\r \r is absolutely fascinating to me. So when I pulled up this page the overnight,\r \r I I was I wasn't sure what to expect, but, boy, I can see that this is very important research.\r \r\n\nAnd, again,\r \r I I started to think it analyzing my handwriting because I'm not sure maybe I'd break the system on my bad handwriting.\r \r But nonetheless,\r \r this is, a pretty fascinating domain\r \r and certainly a big credit to that team,\r \r at CICE for really,\r \r putting all this out there. And if you're interested in this space, yeah, I would definitely recommend checking out the handwriter package.\r \r\n\n[00:31:19] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Well, Eric, I have seen your handwriting before and let's just say I am glad that we now have an r package\r \r for me to use to figure out what the heck you're saying.\r \r\n\n[00:31:33] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Oh,\r \r that cuts deep, Mike. That cuts deep. I'm just kidding. I'm just kidding.\r \r\n\n[00:31:39] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 39,
        "trans_speaker": "Mike Thomas",
        "trans_text": "One thing that warms my heart more than anything else in the world is seeing\r \r universities\r \r use\r \r R to this extent and create R packages\r \r to\r \r just further, you know, the specific research that they're working on.\r \r The fact that this Center For Statistics\r \r and Applications in in Forensic Evidence, c safe at Iowa State University\r \r has\r \r clearly what I think, you know, chosen to leverage r as a as a tool to to push their research in their field\r \r forward,\r \r it it makes me so happy. And like you, Eric, this is a domain that I literally know nothing about. Probably my extent of learning anything about handwriting\r \r processing in R is the old MNIST dataset,\r \r where you're trying to classify, figure out which number someone wrote down. You have this 60,000 row dataset of all the\r \r that you you might use. So if you have done that before and taken a look at m MNIST, this is gonna blow your socks off, especially if you are in the space of doing any sort of image processing or handwriting analysis\r \r or or stuff like that. There's a great and maybe we can link to it in the show notes, The the documentation\r \r here is fantastic\r \r and it's all in a GitHub repository\r \r as well. It is a GitHub Pages site which is fantastic\r \r and it is, you know, well beyond\r \r any package downside, let's put it put it that way, that I have ever created.\r \r\n\nSo it's it's absolutely beautiful.\r \r I'm not even sure that they're necessarily\r \r using PackageDown. I know they've got some CSS, some custom\r \r CSS going on and things like that in a docs folder just sort of in the main\r \r branch,\r \r but it's it's an absolutely beautiful\r \r really informative\r \r site. It is a fantastic example of\r \r really, you know, including as as much documentation as there is functionality and and covering\r \r all your bases. There is a how to guide which I would\r \r recommend\r \r being maybe one of the first places that you can take a look at the functionality of this package, you know, in terms of\r \r word and then just a few quick functions to be able to process that image and and take a look at the results And the depth of the analysis that, you know, techniques that are encapsulated in this package is incredible. As you mentioned, Eric, it's, you know, plotting all sorts of different vectors and and directions as well as, you know, going all the way into to Bayesian analysis too, I think is included in this package. I saw some commits that that have stuff to do with Python support as well.\r \r\n\nThere's all sorts of documentation in here for\r \r whether you're working on a Windows, additional information for Mac users as well. So it's it's a fantastic resource. Again, it really warms my heart to see a university\r \r adopting R this hard and really putting a ton of best practices\r \r And\r \r\n\n[00:35:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And we probably shouldn't be too surprised,\r \r this influential research is coming from such an esteemed institution as Iowa State because\r \r this is also the university that once had the esteemed Di Cook, presenting as a professor\r \r at the university and\r \r graduates such as the, the,\r \r the man that needs no introduction, Yway Siya, graduated from Iowa State. So, yeah, this is a a powerhouse in the world of our the art community and research. So credit to them for keeping innovation going.\r \r\n\n[00:35:36] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I shoulda\r \r known.\r \r\n\n[00:35:38] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Eric Nantz",
        "trans_text": "The more you know, Mike. The more you know. And, speaking of the more you know, there's a lot more you can know by learning and reading the rest of this our weekly issue. There's another\r \r fantastic,\r \r roundup here that Rio has put together with awesome packages\r \r updated or brand new and awesome great blog posts and many others. We're gonna take a couple of minutes for our additional finds here, and we're gonna go meta on ourselves a little bit here, Mike, because\r \r what I teased about maybe a couple weeks ago, a listener got in touch with us,\r \r Yan Chohan,\r \r who has put together a GitHub repository\r \r of using R to scrape\r \r the metadata\r \r associated with this very podcast, rweekly highlights. And we'll put a link to that GitHub repo in the show notes, but it's a very clever use of scraping XML, which, of course, is the\r \r language behind the r Wiki highlights RSS feed just like any podcast.\r \r\n\nAnd he's got a handy,\r \r little bit of repo set up there where you can see then\r \r a little screen grab of the plot of episode duration over time.\r \r It has a nice annotation apparently when I ramble quite a bit back in, sometime in in 2022\r \r which, who would have thought that. Right? But it's a great little time course. And, again, using openly available data as part of our RSS spec. So it sounds like he's got a lot more planned in this. So, again,\r \r huge credit huge credit, to Yan for putting this together,\r \r And we'll definitely be watching this space because I always love it when people can use\r \r awesome, you know, uses of our to analyze things based on what we're actually producing. That's that's not that's top level stuff.\r \r\n\nSo, Mike, what do you think about that? I couldn't agree more. That's awesome.\r \r\n\n[00:37:25] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 25,
        "trans_speaker": "Mike Thomas",
        "trans_text": "For his sake, I certainly hope\r \r that the XML is not too bad. I have been in situations where the XML structure is great and easy to parse, and I have been in situations where it's the complete opposite.\r \r So I I certainly hope,\r \r that it's it's nicely structured and\r \r really flattered, I guess, in a way. Appreciate the the work on that and excited to continue to watch,\r \r what he's able to to to come up with\r \r there. Absolutely.\r \r Any, football or soccer fans out there as we call it in the US,\r \r you may know that there's a couple big tournaments going on or at least at least one going on\r \r right now and and one starting up shortly. The the Euro Cup is going on right now and the Copa America starts very shortly. And Luke Benz has put together\r \r a really cool article,\r \r with a great what looks like GT table kind of heat map,\r \r of the expected, you know, probabilities\r \r of winning the tournament as well as some statistics like offense, defense, overall rating,\r \r things like that, for both the Euro 20 24 and the Copa America 20 24 tournaments,\r \r leveraging\r \r a a Bayesian bivariate Poisson model, I think, to model the likelihood\r \r of winning the tournament. So that is is really really cool work. I always enjoy sort of the sports analytics stuff. Sometimes that's the easiest way for me to learn new things because it's, you know, a use case that I have a lot of passion for. So,\r \r awesome write up. Appreciate Luke's work on that.\r \r\n\n\n\n[00:38:53] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I do spy. Like I said, a GT table front and center in in those, summaries, and it looks absolutely\r \r fantastic.\r \r I'm sure that would make the author of GT Ritchie own a very happy to see that. That is\r \r top level stuff. In fact, I don't know if, Luke, if you if you had a chance to submit that to the table contest, but that looks like a serious,\r \r you know, top contender entry my if I do say so myself, really. It's so much fun to use sports data to learn, you know, different techniques in the in the our ecosystem.\r \r So when I maybe get some more downtime again, I'm gonna get back to my world of hockey analytics and start turning loose because that was one of the very first\r \r types of data I analyzed\r \r way back in the early history of the art podcast as I was doing some fun stuff with ggplot2\r \r and scraping some CSVs. There were some from a Google group of years gone by. Oh, I can't reminisce too much.\r \r\n\n\n\n[00:39:49] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Mike Thomas",
        "trans_text": "One of those days. But in any event, yeah, great great, great analysis of the, the world football, if I do say so myself. And if you can't get enough, you know, forecasting the the Euro 2024 tournament, there's another blog by Akeem Zales that's also on the highlights this week, and that is a machine learning ensemble approach. So if you wanna take another look at the same problem and a different approach to it, check that one out as well.\r \r\n\n[00:40:13] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Oh, that is awesome. And, I shouldn't be too surprised\r \r that these made it because, Rio is a very,\r \r very big soccer fan, one of 2 huge soccer fans. I I should say 3 of yourself included on our our weekly team. So, yeah, representing Mike's representing that. You won't be able to see that on the screen, but I I see it. So awesome stuff.\r \r Awesome stuff. Well, yeah, we could go on and on, but we're gonna have to wrap up here as RealLife is calling us again. But we will leave you with, of course, how you can get in touch with us as well as the project itself. First of all, our weekly is driven by the community. We produce a Florida community,\r \r but we live off of your great poll request, your suggestions for additional resources to highlight\r \r on every issue. And that's all at our weekly dotorg,\r \r handy little poll request tab in the upper right corner,\r \r all marked down all the time. We dare say if you can't learn our markdown in 5 minutes, someone in the r community will give you $5.\r \r\n\nI won't say I got that, but\r \r he he knows what he's talking about. We'll put it that way. And, also, if you wanna get in touch with us personally for this very show, you have a lot of ways to do that. We have a contact page in the episode show notes in your favorite podcasting player. And if you're on one of those modern podcast players like Podverse, Fountain, Cast O Matic, many others in this space, you can send us a fun little boost along the way and show us your appreciation there.\r \r And also, we are on the social media spheres. I am getting a little bit more on Mastodon these days,\r \r with at our podcast at podcast index.social.\r \r\n\nYou'll also see that I did a little, plug for a table submission I just have at the table contest. We'll see what happens. But in any event, it was a fun to put put my hat in the fray on that contest.\r \r Also, I'm on the Twitter x thing at at the r cast, and I'm on LinkedIn. Just search for my name. You will find me there.\r \r Mike, where can listeners get a hold of you?\r \r\n\n[00:42:14] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 14,
        "trans_speaker": "Mike Thomas",
        "trans_text": "You can find me on Mastodon as well at mike_thomas@fostodon\r \r dotorg,\r \r or you can find me on LinkedIn if you search Ketchbrook Analytics,\r \r ketchb\r \r r o o k.\r \r\n\n[00:42:27] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Very good. Awesome. Well, we we we powered through it. We're gonna hope for the best in our next adventures the rest of this week.\r \r But until then, it's been great fun to talk about all this great art content with all of you, and we will be back with another edition of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_25_highlights",
        "chap_timestamp": 27,
        "chap_text": "CRAN deadlines dashboard",
        "chap_href": "https://www.rostrum.blog/posts/2024-06-12-cran-db/index.html"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "chap_timestamp": 17,
        "chap_text": "Fresh look for R-Universe",
        "chap_href": "https://ropensci.org/blog/2024/06/12/runiverse-frontend/"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "chap_timestamp": 24,
        "chap_text": "The handwriter package",
        "chap_href": "https://csafe-isu.github.io/handwriter/index.html"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "chap_timestamp": 0,
        "chap_text": "Scraping our podcast!",
        "chap_href": "https://github.com/iamYannC/r-podcast"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "chap_timestamp": 50,
        "chap_text": "Soccer Simulations",
        "chap_href": "https://lukebenz.com/post/intl_soccer_2024/"
      },
      {
        "ep_name": "issue_2024_w_25_highlights",
        "chap_timestamp": 32,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_24_highlights",
        "ep_date": "2024-06-12",
        "ep_duration": 20,
        "ep_description_short": "A thoughtful perspective on why it's not an either/or situation with popular data processing paradigms in R, another case of being kind to future you with your Git commit messages, and satisfying the need for speed in the evolving geospatial space. Episode Links This week's curator: Tony Elhabr - @[email protected] (Mastodon) & @TonyElHabr…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_24_highlights",
        "description_long": "\r \r A thoughtful perspective on why it's not an either/or situation with popular data processing paradigms in R, another case of being kind to future you with your Git commit messages, and satisfying the need for speed in the evolving geospatial space.\nEpisode Links\n\nThis week's curator: Tony Elhabr - @[email protected] (Mastodon) & @TonyElHabr (X/Twitter)\nTwo Roads Diverged: Opinions on \"dialects\" in R\nWhy you need small, informative Git commits\nMaking a Ridiculously Fast™ API Client\nEntire issue available at rweekly.org/2024-W24\nSupplement Resources\n\nWelcome to the {data.table} ecosystem project! https://rdatatable-community.github.io/The-Raft/posts/2023-10-15-introtogrant-toby_hocking/\nPinball machines per capita https://www.sumsar.net/blog/pinball-machines-per-capita/\nNew York R Conference Retrospective Panel https://www.youtube.com/watch?v=L8Ec4ZktjJQ\nigraph 2.0 https://igraph.org/2024/05/21/rigraph-2.0.0.html\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\n \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\n \nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nDevilSLAB - Final Fantasy VI - MkVaff - https://ocremix.org/remix/OCR00250\nIce Cap Zone (Pulse Mix) - Sonic the Hedgehog 3 - MkVaff - https://ocremix.org/remix/OCR04400 "
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://mastodon.skrimmage.com/@tonyelhabr"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://rdatatable-community.github.io/The-Raft/posts/2024-05-20-kelly_bodwin/"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://masalmon.eu/2024/06/03/small-commits/"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://josiahparry.com/posts/2024-06-06-designing-arcgisgeocode"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://rweekly.org/2024-W24.html"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://rdatatable-community.github.io/The-Raft/posts/2023-10-15-introtogrant-toby_hocking/"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://www.sumsar.net/blog/pinball-machines-per-capita/"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://www.youtube.com/watch?v=L8Ec4ZktjJQ"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://igraph.org/2024/05/21/rigraph-2.0.0.html"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://ocremix.org/remix/OCR00250"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "links": "https://ocremix.org/remix/OCR04400"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We are back with episode 168 of the R Weekly Highlights podcast.\r \r We're so glad you're here listening from wherever you are around the world. And this is the show if you are new to this podcast. This is the show where we talk about the terrific resources that have been highlighted in this week's our weekly issue, all available at rweekly.org.\r \r My name is Eric Nantz. As always, I'm delighted that you've joined us wherever you are. We have a lot of fun things to talk about, but\r \r this is a team effort after all. And I got my partner in our related crime here, so to speak. Mike Thomas is here. Join me at the hip. How are you doing today, Mike?\r \r\n\n[00:00:40] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Doing pretty well, Eric. Not to violate any HIPAA laws and knock on wood. I am currently trying to dodge pink eye in our household so far. So good, but, I've I've heard that it's it's not fun. This is our first go around with it. So please pray for me. But We, we we have you in our thoughts for sure as somebody who's had a whole smorgasbord of\r \r\n\n[00:01:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "illnesses, viruses,\r \r things, and that\r \r and the kiddos,\r \r daycare days. Yeah. You,\r \r\n\n[00:01:10] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 10,
        "trans_speaker": "Mike Thomas",
        "trans_text": "keep strong, my friend. Thank you very much. But, Eric, how was your weekend?\r \r\n\n[00:01:15] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 15,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. You know what? It's been a while since we did this. We're gonna dust off a segment I used to do in my in my live streams.\r \r Who's ready for story time with our\r \r\n\n[00:01:25] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 25,
        "trans_speaker": "Mike Thomas",
        "trans_text": "podcast?\r \r Beybey.\r \r\n\n[00:01:30] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Eric Nantz",
        "trans_text": "So it's story time with Eric now. So let's, buckle up for a few minutes here. So\r \r Friday night, I get a little opportunity to do a little, you know, open source development work on some of this podcasting database stuff. I've been pitching in with a podcasting 2 point o project. And recently,\r \r Dave Jones, who helps spearheads a lot of that effort, gave me access to some more\r \r lower level JSON files and object storage to help\r \r analyze some of the the data that's going into their database as kind of a more real time access of it. And these are these are actually massive JSON files. In fact, one of them is over 200 gigs worth. So\r \r I figured, okay. You know what? To help, you know, minimize the bandwidth cost just for once, I'm gonna download\r \r a snapshot of those locally\r \r on my, you know, somewhat beefy\r \r network storage down in the basement where I have, like, a group of 4 hard drives networked together, and that's where I do\r \r all my backup. So I figured, you know what? I'm just gonna throw it on there. That way, I can, you know, work with them in a prototyping way like any good citizen would do with bandwidth and everything like that.\r \r\n\nSo that was like, earlier in the week, and then Friday night rolls around. I'm gonna do a little hacking on it again, just kinda get to know those files a bit.\r \r Go to the path.\r \r My, laptop mounts. This is like a Samba share. But I I go to and it's run Linux, but Samba is the protocol. So in any event, I go to grab one of these files or always read it into R. It's kind of like a prototyping.\r \r And then I get a\r \r path file not found. And I'm thinking,\r \r what's this about?\r \r I know I downloaded earlier in the week, and it's alongside a bunch of my other kinda our open source, like big file stuff. And\r \r I go into the SSH\r \r session to my network storage that's running Linux. And\r \r I navigate to that area,\r \r directory not found.\r \r\n\nOh, no. Oh, boy.\r \r So I do a little poking around, and I realize\r \r that's not the only thing that I found.\r \r I am now not able to see some very, and I mean very important family media files, which if you guess\r \r are pictures and videos that I've recorded over the years.\r \r No. No. No. No. No. No. No. No. No. No. No. No. Now now I when I set this up many years ago, I did put in a couple backup strategies,\r \r one of which was to send my pictures\r \r over to\r \r Google Drive, albeit in an encrypted way\r \r so that I didn't feel like I was feeding their machine learning algorithms for image recognition\r \r and whatnot.\r \r\n\nAnd so I quickly dust off my notes on how to interact with that. I was using a service called Duplicate\r \r to get that.\r \r And luckily enough, I did get the majority of my pictures back, albeit\r \r they stopped working after 2023,\r \r which was odd because I didn't get an alert on that. So that's one downside. But what was not on that cloud backup\r \r were the videos.\r \r So\r \r back to this internal setup, I have what's called a\r \r pooled file system of all these drives put together.\r \r And then there was an weekly job I would run\r \r that was kinda like RAID. If you ever heard of, like, how network drives are backed up in, like, a mirrored way, RAID is one way to do it. This is a different take called SnapRAID\r \r where it would, every week,\r \r funnel everything into what's called a parity drive.\r \r\n\nAnd that way, if the worst happened,\r \r I could restore from that parity drive and get everything back. So I figured,\r \r oh, yes. I I did run that job. Right? Now I go to where that file would be stored. It's like this big compressed file.\r \r But then my heart sank because the last run of that, apparently, was in 2020,\r \r and I didn't know that.\r \r I still ran the restore anyway just to see what happens. And sure enough, I've got videos and pictures and other important files\r \r up to that point.\r \r So I am missing now\r \r 3 almost 4 years' worth of important content. So,\r \r of course, now I investigate,\r \r can I mount this drive somewhere else?\r \r\n\nCan I just take it out of this network storage and put it into, like, an enclosure,\r \r connect it to my laptop, see if I can somehow salvage the files from there?\r \r That's when I realized there's the problem. The hard drive is making this sequential kind of buzzing kind of sound\r \r and cannot be recognized by any OS.\r \r That screams\r \r hardware failure.\r \r So I have now sent this\r \r to a drive recovery vendor. I'm waiting to hear back for the evaluation if they can get everything back. But if they are able to get it back, I hate to say it's not gonna\r \r be cheap to get it back. But this is a very harsh lesson,\r \r folks. If you have a backup strategy, make sure to check that it's actually working.\r \r\n\nIf you learn nothing else from this 5 minute diatribe,\r \r look at your backup strategy. Make as many notes as you can because future self will need it when you absolutely positively least expect it like little old me here.\r \r\n\n[00:06:55] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 55,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Eric, I'm so sorry.\r \r For our dear listeners out there, I asked Eric how his weekend was, and he would not tell me because he wanted to get my live reaction\r \r during the recording. And my live reaction is is despair, but I am almost,\r \r also not entirely surprised because I feel like story time with Eric\r \r probably sways\r \r a little,\r \r towards the the bad as opposed to the good if we're taking a look at the\r \r distribution of sort of sentiment\r \r around story time with their stories. I am sorry to hear that. I hope that that hardware vendor can can help you out some way somehow and it's not super expensive but, yes, that is, I think something we all struggle with is is backing up and and storage of especially, like, family media and stuff like that. I don't have a good strategy for it.\r \r Yeah. Oh, that that hurts my heart. That hurts my heart because I know how much work you've invested into\r \r building out, you know, your your hardware and software\r \r infrastructure in in the best ways possible and using the the best practices. So,\r \r\n\n[00:08:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I'm so sorry to hear that. Oh, I I appreciate that. But life is so ironic. Right? Of all the drives to fail,\r \r the one that has a majority of these family files, files, that had to be the one. I've got other nonsense on there that I could live without. It's just out of convenience, but it had to be that one. So\r \r on top of, yeah, this vendor crossing my fingers, I will not say who they are because I'm not sure if it's gonna work or not. So I'm not giving any free advertising here. I hope this vendor actually pulls it off. But the other lesson is\r \r I was kinda living on borrowed time with some of the infrastructure around this. So I am building\r \r as we speak. The parts are coming in the next couple weeks. A brand new server that's gonna have a much better strategy around it. So there you go. That'll be some rabbit holes.\r \r\n\nI does not surprise me at all. Best of luck with that. Yes. Thank you, sir. And, you know, one way or another, I'll I'll, share my learnings.\r \r They're they're this machine will double purpose. It will not just be a storage piece. This may be a piece where I can do\r \r some local Weaver machine learning stuff, AI stuff, or whatnot because I'm gonna I'm gonna spec it out pretty well for those workflows and media production. So it'll be a fun journey nonetheless. Just not one I was quite ready to do until Sure. This, certain event. Well, once you, install the Microsoft operating system and and turn the the Microsoft recall\r \r switch on, you'll never have to, you'll never have to worry about backing up anything ever again because it'll just watch you all the time. You know what? Yeah. What better peace of mind than to send that over to whatever they're training on? Oh, my goodness. For those of you who aren't aware of what we're talking about, that, Microsoft kinda got in a bit of a kerfuffle when they announced this\r \r feature, if you wanna call it that, where they would have\r \r a background process on your win Windows installation\r \r literally every, what, I don't know, 30 seconds.\r \r\n\n\n\n[00:10:02] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 2,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Oh, no. I think it's less than that. I think it's, like, every second or every other second. It's gonna take a picture of what's on your your laptop screen.\r \r\n\n[00:10:11] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 11,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I\r \r wow. I mean, just wow. It is is hopefully, some of you may think, yeah, that might have some disasters associated with it and many reasons. So\r \r they are rolling it back a little bit in terms of how they're rolling it out. But, nonetheless,\r \r the the cat's out of the bag, as they say, of what they've been planning for for this. So I think,\r \r more to come on this side of it. But, yeah, of all the things I did not expect to see, that announcement was one of them.\r \r\n\n[00:10:40] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Likewise. Likewise. It just makes me wanna install Linux instead.\r \r\n\n[00:10:44] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Eric Nantz",
        "trans_text": "No. You're not alone. There's a lot of people making the switch after that kind of news, and Apple hasn't quite done themselves any favors either with some of their decisions. But\r \r Onto the r stuff. Yeah. Yeah. We've, digressed enough. But, in any event, we don't have hardware failures to talk about in these highlights. Thank goodness.\r \r And they have been curated this week by Tony Elharbor, another one of our awesome,\r \r curators on the rweekly team. He's been around for quite a couple of years now. And as always, he had tremendous help from our fellow rweekly team members\r \r and contributors like all of you around the world with your awesome poll requests and suggestions.\r \r\n\nAnd we lead off the show with really a testament\r \r and a glimpse into\r \r the vast variety that's available to us with the nature of open source\r \r and especially some of the fundamental issues that can occur,\r \r not just from a development perspective,\r \r but also from a social and other type perspective as well.\r \r And this blog post and our first highlight comes from Kelly Baldwin,\r \r who is a assistant professor of statistics at Cal PIE,\r \r That is California Polytechnic\r \r State University for those that are outside of the US and may not know where that is. But in any event, she leads off with framing this discussion\r \r on 2 paths, if you might say, in the R community with respect to\r \r a lot of the ways that we handle data manipulation,\r \r data processing,\r \r and what has been perceived to be\r \r these separate roads traveled, so to speak. So she frames this post\r \r in light of Robert Frost, the road west traveled\r \r story.\r \r\n\nAnd she also is upfront that this definitely has some opinions. Hey, Mike and our full opinions on this show too. But\r \r I, as we go through this, I definitely see exactly where she's coming from, and I think it's definitely an important discussion\r \r to have.\r \r What we're talking about here are 2 major frameworks\r \r that have kind of, over time,\r \r become pretty mainstream in terms of the art community's efforts for data manipulation.\r \r 1 is the tidy verse, which is well known by this point.\r \r Of course, the development of the tidy verse has been led by Hadley Wickham\r \r and his team of engineers at Posit.\r \r\n\nAnd then we have data dot table.\r \r Data dot table was around well before the tidy verse. Data dot table,\r \r for those that aren't aware, had its first major release in 2008.\r \r Yeah. That's, got a dozen in the history books on this,\r \r And it was originally released by the core developer, Matt Dowell.\r \r And there's a link in the county's post for a nice video of what inspired they are dot table\r \r in the first place.\r \r And it you know, from near the beginning, they do that table has been so influential\r \r for many\r \r in the industry and academia,\r \r all walks of the life, so to speak, in the r community\r \r for respect to its very great performance and importing large data files.\r \r\n\nIt's got its own, you might call, DSL or domain specific language for how you conduct queries and whatnot\r \r and how you do, like, group summaries or filtering\r \r or creating new variables.\r \r It's got a syntax that is unique to it. And once you learn the ins and outs of it, it can be\r \r extremely powerful.\r \r And then fast forward about 6 years later,\r \r dplyr,\r \r the one of the cornerstones\r \r of what became the tidy verse, was released in 2014,\r \r again, authored by Hadley Wickham. And this, a lot of people point to this as the start\r \r of the tidy verse because of this new,\r \r at least new to many people at the time,\r \r way of performing these, you know, fit for purpose functions that use the data frame as, like, the main input\r \r such that you could combine this with the Magritter pipe and do all these nice kind of flowing\r \r analyses of data manipulation,\r \r you know, new variables, summarizations,\r \r group processing,\r \r and whatnot.\r \r\n\nSo with this, you now have, you know,\r \r at at this is Kelly Podsits here, about 3 major choices\r \r for your data processing.\r \r You could stick with base r. Of course, base r, it's got, you know, plenty of ways to do these type of summaries,\r \r data dot table,\r \r and dplyr.\r \r And they're all going to look quite different from each other.\r \r There has been a bit of a misconception\r \r over the years\r \r that data dot table is\r \r almost directly linked to base are. That's not quite the\r \r perception over the years that it was so\r \r perception over the years\r \r that it was so tightly coupled with base are that it was somehow going hand in hand with that. No. No. No. That's that's definitely not the case. It's got its own, you know, framework. It's got its own syntax. It's got its own paradigms.\r \r\n\nAnd again,\r \r in my opinion,\r \r choice is great in this pay in this space. Now, sometimes the kinds of choices, well, which one do I go with? Well,\r \r we're not going to always use a cliche, it depends, but a lot of it does actually depend\r \r on what you want out of your data processing pipeline.\r \r But this shouldn't be a situation where you feel like you have to pick 1 and stick with it forever.\r \r Just like any project, you should have the ability to choose the right framework for your requirements or for your job, so to speak,\r \r and what's important to you.\r \r\n\nBut\r \r it's one she also talks in this post is that,\r \r yeah,\r \r sometimes people feel like they have to be loyal\r \r to a certain package through and through no matter what. No. We all greatly respect developers, but in the end, the choice is ours for what we choose in our data processing needs in this case.\r \r And you shouldn't feel bad about going from, like, a little bit of base r to, like, data dot table or maybe the tidy verse and kinda\r \r as you wish to be able to mix these together. You're not confined\r \r to one framework or the other all the time. This is entirely driven by choice here.\r \r And so she recommends that let's be pragmatic\r \r about this. Let's not try to get into these,\r \r you know, you might call camps or tribalism\r \r of having to really be gung ho about one framework and you're gonna fit this, you know, use this hammer on every job, so to speak, no matter what. Let's be pragmatic about it.\r \r\n\nBut then she gets to the rest of the the next part of the post where she talks about kind of what's the reason that this is coming about, that she wants to, you know, put this out in the universe, so to speak.\r \r Well, in 2018, Mike, there was a certain event on our well, at the time was one of the leading spaces for kind of social type discussions in the art community on Twitter back when it was called Twitter.\r \r There was what she calls the great Twitter war of 2018,\r \r and take that for whatever irony you wanna read with that. But, Mike, just what in the heck for those that weren't around? What was this all about here?\r \r\n\n[00:18:17] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. There were some,\r \r accounts\r \r on on Twitter and some folks that I guess\r \r decided to for whatever reason at that point in time get get fired up about whether or not you should be using data dot table or dplyr.\r \r It actually led as as Kelly, I believe, points out, to\r \r some positive conversations,\r \r between some of the the cooler heads and actually maybe the the more important folks on both sides of the fence including Matt Dowell and Hadley Wickham, I believe to the,\r \r development\r \r of the dtplyr\r \r package which is sort of the best of both worlds where you're allowed to write dplyr syntax that actually translates and executes\r \r data dot table code under the hood. So you you get your dplyr syntax, but you get your data dot table performance, which was was pretty cool. But, you know, 2018 on Twitter was a little bit of a different time.\r \r\n\nYour timeline\r \r was actually\r \r relevant to the people that you followed and the type of content that you wanted to see as opposed to nowadays.\r \r I don't think,\r \r I see any posts from any of my followers\r \r on there but I I guess I'll I'll digress. It it was, I would like to say, a better time for the data science in our community and it was a nice place to to come together as opposed to now. We have a few disparate\r \r places to to try to do that, Macedon being being one of those places.\r \r But for whatever reason, you know, most of the discourse, most of the time was great.\r \r And in 2018,\r \r a a few people decided to start, you know, throwing stones from the data dot table and tidyverse sides of the fence at each other,\r \r for some reason. But I I I think most of the the cooler heads out there either either stayed away and and just sort of watched with their popcorn and how silly everybody was being,\r \r or, you know, tried to,\r \r try to add their their 2¢ and make the conversation a little little more productive as I think some folks did.\r \r\n\nBut, you know, that's that's social media, I guess, for you. And,\r \r\n\n[00:20:21] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Eric Nantz",
        "trans_text": "for better or worse, Mike, for better or worse.\r \r\n\n[00:20:24] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Exactly. I think there was a lot of better, but that was one case of it it being worse. And, yeah, you know, I love\r \r the approach that that Kelly took to this blog post and I couldn't\r \r agree more.\r \r To me, not to draw too much of a parallel to, like, like, politics, but you don't always have to be in necessarily one camp or the other and just, you know, blindly believe\r \r and and associate with one side or the other. From a project to to project basis,\r \r data dot table may make more sense for your project in one project and then the next one that you go to tidyverse may make a whole lot more sense to use and that is\r \r okay.\r \r\n\nEveryone listen. That is totally okay.\r \r You know, now DuckDV\r \r maybe, you know, the better solution than either one of those for your next project. Who knows?\r \r Like the thing that we love and that Kelly loves about the ecosystem is that we have choices\r \r and and that's incredible.\r \r And you should use whatever choice you feel makes the most sense to you,\r \r at the time and for the particular project that you're working on. So,\r \r in my opinion, you know, this is a great reflection.\r \r Very happy to hear that, there's been some grant funding towards the data dot table project that's going to allow that open source project to progress. That's something that we don't see a lot of the time where open source developers and community actually get get funding for their work and and for all the hard work that has gone into this project because,\r \r you know, if you take a look at the history of data dot table and what we're going on going on 15\r \r year or yeah. Something like that. Right? Going on 15, 16 years of the data dot table project.\r \r\n\nThere's been an incredible amount of work that has has gone into it and helped it evolve and get to the place it is\r \r now. So it's it's fantastic to see a piece of software have that type of longevity\r \r and, you know, it it looks like that's only going to continue.\r \r\n\n[00:22:21] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Absolutely.\r \r And, Kelly, we'll be talking a lot about this topic more in-depth at both the USAR conference coming up in July as well as PASIT conference. So I have a talk about\r \r these themes. And\r \r what's interesting here is, as you mentioned, there is funding for this recent effort\r \r and, well, through, you know, a a coincidental,\r \r situation. I was able to hear more from Kelly herself in a recent\r \r meeting, but this funding is coming from a National Science Foundation\r \r grant,\r \r that was carried out, I believe, ill, back in 2023.\r \r In fact, we may have covered parts of this in our weekly highlights way back when the launch of what they call the data dot table\r \r Ecosystem Project.\r \r\n\nAnd this is being headed by Toby Hocking as well as Kelly's involved with this as well. We'll have a link to this in the supplements of the show notes here.\r \r But this is meant to not just look at data dot table from literally just the source code perspective, but to help fund\r \r the ecosystem\r \r around it, which is both technical and\r \r infrastructure\r \r and social and making sure\r \r that it is sustainable\r \r for the long term.\r \r Certainly, Kelly is gonna be speaking about these themes in her upcoming talks,\r \r but there is one huge difference. And when you look at the history of data dot table as opposed to the history of tidyverse,\r \r is\r \r that let's be real here.\r \r\n\nWho's funding the tidyverse? It is a dedicated vendor,\r \r ieposit,\r \r helping to pay engineers full time, open source engineers to work on this.\r \r Data. Table does not have that. It is enthusiastic\r \r But like many projects in open source, it is built on the community to help drive that innovation,\r \r drive that continued development.\r \r So I know part of the motivation of this grant is to help make sure that that ethos\r \r is sustainable for such an important piece\r \r of many, and I do mean many in the community that rely on data dot table\r \r for all sorts of uses. I mean, I just spoke of a couple of them, but I always scratch the surface.\r \r\n\nAnd I've had, like I said, great success with certain pieces of it in my workflows, and I don't feel ashamed about that. Like, Mike, you said, Mike, I wanna choose what's best for the job. And by golly, I'm not gonna have any regret because in the end, I gotta get my stuff done. Right?\r \r\n\n[00:24:55] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 55,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Exactly. Exactly. And it's like,\r \r I can't say enough. It's amazing that we have these choices. It's amazing that these choices are so robust and so powerful,\r \r and so well supported. So,\r \r you know, hats off to sort of a great perspective, I think, hereby Kelly. Fortunate enough to I believe have met Kelly at last posit conference. I think she was in our our shiny workshop which is really cool. That's right. So she she is absolutely awesome and I'm very happy to see this blog post from her.\r \r\n\n[00:25:33] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Well, we're gonna go back to the development side, Mike, a little bit because our next post is gonna talk about ways that you can at least\r \r help future you even more\r \r even when you're already buying into proper version control.\r \r And what we're talking about here is a latest post from Al Salmon who, of course, has been a frequent contributor to our weekly both as a curator and now contributor\r \r to many great highlights in this podcast.\r \r And she\r \r speaks about why you should invest in\r \r not just doing version control,\r \r but helping\r \r future you by making what she calls small and informative\r \r get commits.\r \r\n\nBecause\r \r I don't know about you, Mike, especially\r \r even now, sometimes\r \r when I'm in a tight bind and I realize, oh my goodness, I have about 10 files that\r \r I've gotta get committed now because the time's running out.\r \r I, I've I fall to temptation,\r \r hit all the checkboxes,\r \r hit stage, just say, get this a prod in my commit and be done with it.\r \r Yes. It still happens.\r \r Yes. I know better. And that's why this post is gonna help you figure out why what I did was such a big mistake.\r \r Because let's say you get to a point in time and you're either doing a code review, maybe a colleague's doing a code review for for example,\r \r and they see a line in your code.\r \r\n\nAnd they're thinking, well, Eric, why did you do that? Like, what was the motivation for that line?\r \r You don't have a comment around it because at the time, you're just trying to fix maybe fix an issue or something in your head, and then you didn't put it into prosperity and via commit or a comment.\r \r Well, of course, we get you can go back and look at the history of your commits. Right?\r \r And in fact, there is a concept\r \r in Git. They call it Git blame, but I I'm with my I'll hear. I hate that terminology.\r \r It's really not blaming anybody,\r \r but it's better to be called git explain. I like the way she phrases that because then in a platform such as GitHub,\r \r you could have the view of the code itself, I. E, the file, but then next to it, see which commit message related to that change.\r \r\n\nAnd you might see in that example that I gave that this mysterious line\r \r was part of like this massive 10 file commit and you just have something that says,\r \r get the prod or just get it done, get out of my hair or whatever you wanna call it.\r \r Well,\r \r that's not gonna help very much. But had you done small\r \r informative commit messages where you do, like, one file at a time or maybe a set of related changes even if they're spread across multiple files.\r \r That get blame methodology can be very helpful for you to go back in time and figure out what were you trying to fix. Were you trying to add a new feature? What was the motivation for that? A bit of like a a way to get a lens into your development journey\r \r of what happened there.\r \r\n\nSo, again, if you do what I said was a bad thing to do and just put all these files in one big commit, you're not gonna get any real benefit out of that.\r \r But like I said, had you done a small\r \r informative message\r \r of that particular change, and again, it might be one file, it might be related files,\r \r it's gonna make it so much easier for both you and collaborators\r \r to figure out just what was your motivation for that.\r \r So that's one reason to do it. But there is another reason,\r \r especially if you realize\r \r that over time, maybe it's only like a month later, maybe it's a long time later,\r \r Something\r \r is not working, and you've got to figure out just where\r \r it started to not work.\r \r\n\nThat's where Mike Sheehyah takes us onto another concept and get that I don't do enough of, but I can definitely say if you're behind on certain situations. Why don't you take us through that? Yeah. So my Elle talks about this tool that I admittedly\r \r\n\n[00:29:42] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Mike Thomas",
        "trans_text": "do not use, this this function I guess you might call it that get offers us\r \r called git bisect.\r \r And what git bisect allows you to do is to try to identify the particular commit in history\r \r where your software was was working.\r \r And it it'll make you try some commits to help pinpoint, you know, which commit exactly\r \r introduced the bug that you're now\r \r observing and it sort of breaks your code,\r \r into 2 sections sort of before,\r \r everything was working\r \r and then after sort of everything\r \r fell apart.\r \r And it will assume that all commits are up to that particular commit that you're bisecting on were good, and it's gonna make you sort of explore,\r \r commit by commit the the the following\r \r ones to to figure out exactly,\r \r what introduced the breaking change. And it's\r \r it's a really nice feature that sort of allows us to I don't know. It almost feels like the debugger in a way in in R where you're able to sort of go commit by commit very slowly and figure out exactly which one is the one that introduced that that breaking change. And and hopefully,\r \r if you made small commits,\r \r we're able to identify\r \r that git commit that that broke things as, you know, this small diff that that in Mel's example shows, you know, 2 changed files with 3 additions and 2 deletions.\r \r\n\nIf we're very unlucky,\r \r it's going to have a message like one of those that Eric writes occasionally and I have never certainly ever ever written a commit like that that says, you know, commit a bunch of files and it's at, you know, 6 o'clock on a Friday\r \r and the the diff shows a 145 change files with 2,600\r \r editions and 22100 deletions.\r \r We we certainly hope that's not the case but but maybe it is. But GetBisect\r \r can help you get to that point.\r \r You know, one nice additional thing that we have,\r \r in our ecosystem\r \r now\r \r is is both unit testing and and services like GitHub Actions and and formerly Travis to when you do make a new commit,\r \r you can test, you know, you can execute your unit test to make sure that everything continues to work, after that new commit has been introduced and and this is certainly something that I I think everybody\r \r that uses Git can be guilty of is is not making small enough commits. I have sort of this long standing issue where\r \r I know that I need to make multiple changes to the same file,\r \r and I will make the first change and forget to just sort of commit that small change and I will make 3 different like conceptual changes within the same file.\r \r\n\nAnd now I either am at the mercy of,\r \r you know, trying to undo those\r \r particular,\r \r you know, changes number 23\r \r and just revert back to to change 1 and and make my commit message\r \r small and and related to that. Or try to write some 3 part commit message,\r \r that, you know, sort of tries to explain that the 3 different changes that took place but it's it's not good in either way is is really ideal or easy. So the best thing that I could possibly do is to stop after I make that first change to the file,\r \r make my commit, and move on to the second change. But but sometimes, you know, when you're in the zone,\r \r it's hard. It's hard to stop and and lift your fingers up off the keyboard and and remember to do that instead of just knocking everything out at the same time. But\r \r Git blame is and it should be called Git explain. I agree as well. I think it's a fantastic tool when we do have to go back and,\r \r you know, try to figure out sort of sort of what went wrong,\r \r what is the the status\r \r of, our our software at the point in time that that things went wrong, what what does our repository look like, and how can we sort of pinpoint\r \r where things went wrong and and what led to that. I think GitLab is a fantastic tool. I admittedly don't use it enough, but I do know the people that do use it and rave about it,\r \r and find it very helpful to their workflows. So it's it's one that I think my Elle is,\r \r inspiring me to\r \r dive a little bit deeper into and to start using a little bit more. So I I certainly appreciate\r \r the overview here. I I appreciate,\r \r the introduction and to get bisect as well because I think that that is gonna be a new handy tool that I'll be able to use in these, you know, tricky,\r \r situations where where something breaks and it's not trivial to pinpoint\r \r where it took place.\r \r\n\n\n\n[00:34:19] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I really like your your relation earlier to the concept of a good bicep and debugging your code because it made me think of a debugging technique that Bicep kinda mirrors a little bit in that if you have a long r script, wherever it's a Shiny module or any any data processing thing, for example, and you know there's an error somewhere, maybe it's a function or whatnot, but you just don't quite know where it is,\r \r A lot of times, what people will do is they will\r \r comment out\r \r or start putting the browser at, like, a halfway point, and then they'll see, oh, wait. Is the error happening before this or after this? And if it's happening after somewhere,\r \r then you know that the rest of the code above it is working. And you kinda go in this I don't know what the proper term is, but you kinda go half by half or a certain percentage.\r \r\n\nAnd that's where get by site kinda starts you off with is you're gonna find that known point, at least that your conjecture\r \r is, and then you tell it, okay. Oh, yeah. This one works. I'm going to go to the next part, the next part, the next part.\r \r But none of this none of this is going to help you if you don't follow the advice from the start on these\r \r fit for purpose,\r \r you know, you know, targeted commit messages. And, again,\r \r yeah, Mike, I you've you've always been a pro with this. Like, you you don't need any advice here. But little old me, I I did some shortcuts even this year that I'm not proud of. So myel gives me a reality check that, you know, sometimes I need from time to time because I'm not perfect. What can I say? But if you wanna practice some of this in the confines of r, Nael has made an r package, which I'm going to butcher the name once again,\r \r of superlipopet\r \r or something to that effect\r \r where you can practice\r \r get concepts\r \r in r,\r \r albeit with your get client at hand\r \r to practice things like BISEC. Practice things like, you know, commit messaging\r \r or restoring or branching\r \r and things like that. So if this is all novel\r \r concepts too and you're wondering what's an easy way to kind of practice this about\r \r risking the destruction of a production code base, I recommend her pack as superwhippulpit.\r \r\n\nThat's the best I can do. But that's a that's a great package nonetheless.\r \r\n\n[00:36:39] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 39,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That's the best I could do as well. And that it's my first time taking a look at that package, and it's incredible. It's fantastic.\r \r Allows you to to practice all sorts of git commands including git bisect, which is is really really cool. I think that's really powerful because it's very difficult\r \r to practice Git in a in a sandbox, I guess, unless you're spinning up a brand new a brand new project, but then you don't really have any history to play with.\r \r So this is a great great reference here.\r \r\n\n[00:37:06] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And there's one other tidbit that I've seen both her mention, although be a not so much mentioned specifically, but then I see others in the community that I follow follow this trend as well is that\r \r at the beginning of a commit, they'll have a short phrase, maybe a one word phrase that describes the intent\r \r of that particular commit.\r \r It may be fix or feature or\r \r chore or things like this.\r \r I'm trying to opt into that a bit more because that's a handy way if you're looking at your history of your commit messages\r \r to isolate very quickly\r \r to distinguish between\r \r a new feature type of commit versus a bug fix commit versus,\r \r oh, I gotta rerun that r oxygen documentation\r \r again, regenerate the man pages as like a chore kinda commit because it's a chore to do. I guess that's where that naming comes from, Mike. But, have you have you done any of that in your commit messages?\r \r\n\n\n\n[00:37:59] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I haven't. We have some folks on my team who are are just fantastic developers who I have noticed recently\r \r do that,\r \r very much so in in all of their commits and are very consistent about it and it's,\r \r sort of a practice that I'm still\r \r maybe getting used to reading and and trying to decide whether that is something that we should try to adopt globally across the team,\r \r or not. You know, I think the\r \r idea of of creating issues and branches that reference those specific issues\r \r and, you know, obviously, your commit messages are are on that particular branch sort of lets me know\r \r exactly what is being accomplished\r \r here with maybe up without perhaps needing,\r \r all the way down to sort of the commit message\r \r level of granularity,\r \r letting me know sort of what's being worked on.\r \r\n\nBut I I think on some particular projects, especially, maybe where it's not as\r \r clear cut of an issue branching workflow\r \r and maybe we're we're making commits to a particular branch that are across a wide variety\r \r of, of types and use cases, you know, both development work, bug fixes, chores, things like that. I think that that might be\r \r possibly a great idea. So,\r \r it is something that I have have seen. I'm just not sure if I am all in on it yet, but I don't see any drawbacks to it.\r \r\n\n[00:39:22] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 22,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I've I've been seeing it enough where it's like I'm gonna start paying attention to it. And maybe for my next project, I'll give it a shot. But like anything I get,\r \r it's not just the the the mechanisms\r \r of doing it. It's the discipline to keep doing it. And, again, if nothing else to take away from this,\r \r be kind to future you, be kind to future collaborators,\r \r Small fit for purpose commit messages\r \r will help you. Even if it takes a while to get used to, you'll thank yourself later. And, yeah, that goes with testing as well. Don't ask me why I think testing is a good thing because I've I've been bit by that too. I'll be a nut with hardware failures.\r \r\n\n[00:40:01] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Mike Thomas",
        "trans_text": "When AI does finally get good enough, I will try to create a\r \r Mael hologramrubber\r \r duck on my desk that can just yell at me when I'm I'm doing the the wrong software development practice because I need this advice constantly and I'm very grateful\r \r to all these blog posts that she puts together to to remind me to, stay the course and\r \r continue to\r \r incorporate those best practices.\r \r\n\n[00:40:28] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 28,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Unlike some other things in AI, that is one that I would welcome to have next to me monitoring\r \r me through many points in my dev journey.\r \r\n\n[00:40:36] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Me too.\r \r\n\n[00:40:53] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I'm rounding out our highlights today,\r \r at the risk of dating myself with a reference\r \r here. I feel the need for something, Mike. You know what I feel the need of? The need for speed\r \r because it doesn't just apply to one aspect of data processing. It also applies\r \r to the way we consume\r \r data coming from these robust APIs\r \r and combining that with the\r \r very vast evolving\r \r ecosystem\r \r of geospatial\r \r data and performance.\r \r Our next highlight has the intersection of all these and definitely made me do a few double takes in terms of the metrics that we're about to talk about here. In particular, we're talking about this post that comes from Josiah Perry who has been a long time member of the r community, and his tagline lately\r \r is helping\r \r r be built and used better in production.\r \r\n\nAnd his blog post here is his journey on making what he calls a ridiculously\r \r fast API client in r.\r \r And his day job is working for a company called called Esris, who is specializing in putting on these certain services\r \r to query geospatial\r \r data from many different development frameworks. I believe they have some host of services as\r \r well. Well, as I'm guessing as part of his daytime responsibilities,\r \r Josiah has released a new r package\r \r called arc\r \r just geocode,\r \r all one word, the big name here, which is an r binding and our interface\r \r to what they call the ArcGIS world decoder service.\r \r\n\nAnd he says that this looks like an official\r \r package from his organization,\r \r Esri,\r \r in this space.\r \r And in his knowledge, up to this point, he's got some metrics to prove it. He claims that this is the fastest geocoding library available in the entire\r \r our ecosystem.\r \r In fact,\r \r he's claims that our just geocode\r \r is about 17 times faster\r \r when you do what's called a single address geocoding\r \r and almost 40 times faster\r \r when doing a reverse geocoding\r \r lookup as compared to other packages\r \r in the community already in this space.\r \r So let's dive into this a bit more.\r \r\n\nHis first reason for why this is important\r \r is that some I took for granted until a recent project, I talked about the onset with some of this podcast metadata JSON data\r \r is that parsing JSON data\r \r is not always fast, my friend. Not always.\r \r Many of us are using JSON Lite, the, you know, almost tried and true package offered by your own ooms for,\r \r consuming and writing JSON data in r.\r \r And it's it's it's been a huge help to me. Don't get me wrong.\r \r But it does have some performance issues, especially when dealing with long text strings in your JSON data and then bringing that conversion back to an r object\r \r and the other way around.\r \r\n\nWell, guess what? Another language that starts of r comes at a rescue in in Josiah's initiative\r \r because there is a rust crate, that's kind of their term for packages,\r \r called SERDAY or SERD, I'm not sure if I'm saying it right, that handles both the serialization\r \r and deserialization\r \r of structures and rust.\r \r And guess what? It is very tailor made to JSON data too. It just expects you\r \r at the onset\r \r to help specify\r \r for your given JSON type data you want inside your your session,\r \r the specific\r \r attributes of each variable or each field.\r \r So in his example, he's got an address structure, if you call it, with all the different fields that would come out of this JSON data.\r \r\n\nAnd most of them, big surprise, are strings,\r \r but it'll give you the ability and rust to really determine what's supposed to be a string, what's supposed to be an integer,\r \r different types of integers. You can go, you know, really specific on all these needs.\r \r Now that's great and all, but how does that help with r?\r \r Well, there is the package called extender,\r \r which is kinda like the RCPP, if you will, of Rust to r.\r \r We'll let you tap into a Rust crate\r \r and bring that into r and be able to go back and forth with our functions to basically call out to these lower level Rust parts of the paradigm.\r \r So this,\r \r Serde JSON crate\r \r is a massive speed improvement in general for importing JSON data, serializing JSON data\r \r over the community counterparts as he attests to in this post.\r \r\n\nBut that's not the only part. The other part\r \r is a feature that I should have known about in my research in HDR 2, but it just went over my head until this post,\r \r is that\r \r we often use HDR, HDR 2, and this is the regeneration of that, if you will, by Hadley Wickham\r \r to help in r\r \r perform these, you know, requests to API\r \r services. I get request, post request, and whatnot.\r \r And, usually, I do these requests kind of 1 at a time, if you will. Like, there's a get request. I'm gonna do that with specific set of config parameters,\r \r bring it back down and whatnot.\r \r\n\nWell, how in the world did I not know about this function, Mike?\r \r Rec perform\r \r parallel,\r \r\n\n[00:46:29] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Mike Thomas",
        "trans_text": "which lets you do it in more than one time. Oh my gosh. Where have I been, Mike? Did you know about this? Neither did I, Eric. I had no idea that this was part of the h t t r two package now, that we have the ability\r \r to send, I guess, paralyzed\r \r request to an API pretty easily and maybe point that function towards\r \r a connection pool or a few different nodes, few different workers,\r \r to be handling requests concurrently. This makes me think of, I don't know, potential integration with the crew package or something like that.\r \r Perhaps this is something that you could do on your your own machine and and leverage,\r \r you know, the the ability to parallelize your own machine\r \r and and send out a few different requests, at the same time which is is pretty incredible.\r \r\n\nAnd\r \r there's this Twitter thread that Josiah puts, earlier on in the blog post where he's, you know, he's he's showing off the fact that he was able to geocode,\r \r 2.6\r \r 1,000 addresses in in 3 and a half seconds. And and somebody asked, in as a reply\r \r to that particular screenshot that he put up, they said, isn't geocoding always bottlenecks by the server?\r \r And, that is true. But I guess when you have multiple servers to span the job across and we have this beautiful function request perform parallel that I imagine brings it all back together\r \r at the end.\r \r\n\nThat's that's a fantastic utility to be able to, you know, speed up,\r \r significantly and and this is something that I've dealt with in the past as well, geocoding.\r \r It takes time because you're typically going address by address and, you know, a lot of projects you'll you'll want to be geocoding your entire data frame which could get, you know, could get particularly long you know thousands tens of thousands\r \r hundreds of thousands of observations\r \r that you need to geocode\r \r so it's\r \r really interesting to me that we have the ability, you know, not only to leverage the speed of Rust,\r \r for this serializing\r \r and deserializing\r \r of JSON objects which is time intensive, but also,\r \r being able to just break the job out into across a few different,\r \r nodes here which is\r \r is pretty incredible, something that I didn't know about. Obviously, Josiah says that you need to be a little bit careful when you are doing anything like this especially when you're sending sort of paralyzed paralyzed\r \r requests\r \r at a different service that you don't perform,\r \r an accidental\r \r denial of service attack, you know, which is where you you make way too many requests all at once\r \r to the service\r \r and bring that down. So you don't wanna be the person that does that. So so certainly be be careful\r \r and perhaps, you know, use a small number of workers.\r \r\n\nIf you're just geocoding a couple thousand addresses, you don't need to spin up\r \r a few hundred workers or something like that to be able to do that just just\r \r spin up a couple and\r \r and maybe wait those extra few seconds that it's going to take, to be patient between, you know, spinning up a few workers and\r \r and many many workers. But it's really interesting because you will get, you know, these this great sort of orders of magnitude returns in performance,\r \r when you do\r \r add compute to the problem here as well as, you know, leveraging Rust for that that quick deserialization,\r \r of of JSON data. One thing that I will also shout out just because I was curious about this and, you know, we're\r \r finding all of\r \r these new, faster\r \r programming,\r \r software utilities out there when it comes to to data.\r \r\n\nAnd there is a DuckDb extension as well for handling\r \r JSON data and reading JSON data and so I would be interested\r \r to see how that compares to what Rust can do for parsing JSON data as well.\r \r\n\n[00:50:16] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Eric Nantz",
        "trans_text": "But both very fast, I'm sure. Yeah. They are. I'm experimenting that a little bit too actually in my DuckDV adventures and I'll definitely come back with my findings as I get that more polish. I'll be at the hardware catastrophe, put a stop on that for a bit. But,\r \r nonetheless,\r \r I'm really intrigued by the concepts that,\r \r Josiah,\r \r parts in this post here. And then at the end, he recommends\r \r additional packages in the community that if you're still not quite ready for the plunge to Rust for some of these efforts, if you're not ready to build, like, an internal\r \r JSON parser that depends on Rust, There are some additional JSON related packages in the r community that definitely\r \r take a look at. He recommends\r \r the RCPP\r \r SIMD JSON package as a great way for parsing data\r \r as well as the y y JSON package that comes from the affectionately known cool but useless on the our community. He's got a great package called y y JSON\r \r and also JSONify,\r \r which I don't have as much experience with. But you might wanna take a look at each of those too and see it for your parsing needs or writing\r \r serialization needs. If that just gets you good enough\r \r without while being able to stay in the confines of of R directly.\r \r\n\nBut, nonetheless,\r \r this is great learning for me personally as I'm starting to deal with JSON data more and more in my open source work as well as my internal\r \r day job stuff where we just built an API\r \r binding package.\r \r But we're running this in the day to day use with, patient level data set where there's, like, multiple visits,\r \r multiple, obviously, patients in a treatment group, and it's basically doing these get requests to this custom service\r \r 1 at a time\r \r for each of these calls. My goodness. I could do the rec perform parallel and probably speed that up a bit. So I'm gonna have to take a look at this and hopefully not make my IT admins angry when I start to paralyze this.\r \r\n\n[00:52:14] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 14,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Definitely do it on a, development cluster to start. That would be my recommendation.\r \r\n\n[00:52:19] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. Because,\r \r yeah. That that was another, story time from years ago when when I, was too greedy with multi cores, and I took down an entire HPC cluster. Don't be that person, everybody. Just don't be that person. I remember that story.\r \r Yes. Who lives in infamy. But,\r \r what lives in good ways, of course, is the rest of the our weekly issue itself.\r \r Tony's done a terrific job as always he does with the rest of the issue. We got so much we could talk about, but we're gonna have to wrap up here with our additional fines over this issue.\r \r And, Mike knows and many of you know I am a retro gamer at heart, not just with retro games, but also\r \r I have fond memories of going to the local arcade and putting some quarters on those awesome pinball machines\r \r that waste a lot of hours on that. Well, there is a fun post that combines\r \r things like, geospatial data, API calls, and some handy visualizations\r \r from Rasmus Bath. He calls this the public pinball machines per capita\r \r looking at where pinball machines are most distributed around the world.\r \r\n\nAnd and as post surprise, surprise, the United States is in the lead with this, but Europe is not far behind\r \r in some of their visualizations.\r \r But his post goes into how he attained this data,\r \r loading the packages. And guess what? It's coming from an API\r \r just like everything else.\r \r He's got some, you know, really elegant code to do this.\r \r Really modern code here. They was using HTR 2 as well\r \r and some great handy visualizations\r \r built in ggplot for the distribution\r \r of these, pinball locations\r \r and some word clouds too. So really, really fun stuff here. And,\r \r yeah, it makes me get the itch to get some quarters out and find that retro arcade\r \r to, you know, knock out some pinball action. So that was fun. But, Mike, what did you find? Very cool, Eric. I found an oldie but a goodie. I think at the the recent,\r \r\n\n[00:54:21] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Mike Thomas",
        "trans_text": "our conference that's held in New York by that under Lander Analytics\r \r hosts,\r \r there was a panel discussion about your favorite R package.\r \r And I believe it was,\r \r who's the author\r \r of the data science Venn diagram there? Drew\r \r Conway.\r \r He was being asked what his favorite R package was and and I think it was one, it was called iGraph and I think it's one that's been around for a long long time,\r \r for doing, I believe, network analysis type stuff\r \r in,\r \r r.\r \r And I saw on the highlights this week that r igraph has crossed the 2.0\r \r threshold.\r \r\n\nSo it's it sounds like, you know, similar to data dot table that this is another package that has had quite a life to it, continues to be very very well\r \r maintained, and it's it's just awesome to see a package like that be able to have the longevity it has.\r \r\n\n[00:55:13] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. IGraff, I have tremendous respect for. It is the engine behind many, and I do mean many, of the r packages\r \r that provide some kind of network visualization\r \r or processing.\r \r My exposure to this has been using some custom\r \r eye graph bindings inside a widget called Viz Network, which I have a kind of a love hate relationship with, but I've done enough customization to wrangle it to my particular needs. But, yeah, iGRAS been\r \r around a long time, and it is prevalent in additional languages as well. But, yeah, huge congrats to that team for the 2 point o release.\r \r And I know, yeah, my whole biograph stays around for a long time because it is a fundamental pillar\r \r in these, network visualizations. So awesome\r \r\n\n[00:56:01] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Mike Thomas",
        "trans_text": "awesome call out there. I grabbed 0.1 released in 2006.\r \r Even older than the data that table.\r \r\n\n[00:56:08] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 8,
        "trans_speaker": "Eric Nantz",
        "trans_text": "My goodness. Yeah. As if I didn't feel old enough in this post. Good grief. What are you what are you doing to me, man? I I I need to get a youth injection or something. But what makes me feel youthful is just seeing what's happening\r \r in this community. Again, really great developments happening. Really great showcases\r \r of data science, you know, providing good to everybody involved. So where can you see this all? Where we've been talking about here,\r \r so many of our great wings are available at rw.org.\r \r Many additional\r \r findings here, many additional\r \r developments of packages.\r \r\n\nWe need to touch on all the newer packages out there. There's so much happening\r \r in these spaces,\r \r but we invite you to bookmark that site if you haven't already to check it out on a weekly basis. And\r \r also, we love hearing from you in the community. There are many ways to get in touch with us.\r \r You can send us a contact or message on our contact page, which is in the episode show notes. So, again, keep those comments coming. We love to hear from you.\r \r You can also, in the modern podcast app, such as PowVerse, Fountain, Cast O Matic, Curio Castor, there's a whole bunch out there. You can send us a fun little boost along the way if you want to send us a message\r \r without any middle thing in between. And no harbor failures on that one either.\r \r\n\nBut and the other way you can contact us is on social media as well. I am mostly on Mastodon these days with at our podcast and podcast index on social.\r \r I am also on LinkedIn. Just search for my name there. You'll find me there and sporadically on the weapon x thing with FDR cast\r \r and a special little shot. I didn't get to it in my stories time. But I had the great pleasure of having a, little dinner with,\r \r the author of GT, Rich Yone, who was in town for a local conference. So great fun talking with him, all things are, and someone he's up to. So, Rich, if you're listening, thanks for coming into town even for a brief couple of days. A lot of fun learning from you. But, Mike, we're gonna listen to get a hold of you. That is awesome. I am so excited for POSIT conferences here to be able to see some see some community faces. But, folks, until then, can get a hold of me on mastodon@mike_thomasat\r \r\n\n[00:58:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "fostodon.org\r \r or on LinkedIn if you search Ketchbrook Analytics,\r \r ketchb\r \r r o o k, you can see what I'm up\r \r\n\n[00:58:28] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "trans_timestamp": 28,
        "trans_speaker": "Eric Nantz",
        "trans_text": "to. Yes. And, hopefully, I don't see any messages about any failures in your infrastructure.\r \r Let's call it that. Let's keep keep our fingers crossed. But, yeah, just don't do what I did. That's the best advice for today. But in any event, we thank you so much for joining us wherever you are and wherever you are in your our journey. We hope that we're a little bit of a help along the way. And one of the best ways also to help us out is just share the word. You know? If you got value out of this podcast, we'd love for you to share it around, tell your friends, and always great to expand our audience for those that are getting started with our we think our weekly is one of the best resources\r \r for anybody in this community. Am I biased? Absolutely. Yes. But, hey, I speak I speak the truth here, I think, in any event. We're gonna close-up shop here, and we'll be back with another edition of our weekly highlights\r \r next\r \r week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_24_highlights",
        "chap_timestamp": 20,
        "chap_text": "Story time!",
        "chap_href": "https://rdatatable-community.github.io/The-Raft/posts/2024-05-20-kelly_bodwin/"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "chap_timestamp": 21,
        "chap_text": "Two Roads Diverged",
        "chap_href": "https://masalmon.eu/2024/06/03/small-commits/"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "chap_timestamp": 33,
        "chap_text": "Small commit messages",
        "chap_href": "https://josiahparry.com/posts/2024-06-06-designing-arcgisgeocode"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "chap_timestamp": 52,
        "chap_text": "The fast arcgisgeocode",
        "chap_href": "https://www.sumsar.net/blog/pinball-machines-per-capita/"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "chap_timestamp": 51,
        "chap_text": "Pinball machines",
        "chap_href": "https://igraph.org/2024/05/21/rigraph-2.0.0.html"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "chap_timestamp": 15,
        "chap_text": "igraph 2.0"
      },
      {
        "ep_name": "issue_2024_w_24_highlights",
        "chap_timestamp": 18,
        "chap_text": "Episode wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_23_highlights",
        "ep_date": "2024-06-05",
        "ep_duration": 15,
        "ep_description_short": "How vintage features in R could introduce chaos in your quest for a tibble & data.frame function, and the awesome potential of integrating custom parameters and conditional processing in your next Quarto workflow. Episode Links This week's curator: Jon Calder - @[email protected] (Mastodon) & @jonmcalder (X/Twitter) Make your functions…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_23_highlights",
        "description_long": "\r \r How vintage features in R could introduce chaos in your quest for a tibble & data.frame function, and the awesome potential of integrating custom parameters and conditional processing in your next Quarto workflow.\nEpisode Links\n\nThis week's curator: Jon Calder - @[email protected] (Mastodon) & @jonmcalder (X/Twitter)\nMake your functions compa-tibble\nCreating R tutorial worksheets (with and without solutions) using Quarto\nEntire issue available at rweekly.org/2024-W23\nSupplement Resources\n\nInvariants: Comparing behavior with data frames https://tibble.tidyverse.org/articles/invariants.html\ngeoarrow: Extension types for geospatial data for use with 'Arrow' http://geoarrow.org/geoarrow-r/\nCustomize your R startup message https://drmowinckels.io/blog/2024/rproject/\nAbout Podcasting Episode 10: Podcasting and Data Science with Eric Nantz https://www.aboutpodcasting.show/episodepage/podcasting-and-data-science-with-eric-nantz-from-the-r-weekly-highlights-podcast\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\n \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\n \nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nChapter image credits\n\nIllustrations from the Openscapes blog Tidy Data for reproducibility, efficiency, and collaboration by Julia Lowndes and Allison Horst https://www.openscapes.org/blog/2020/10/12/tidy-data/\nIntroducing the Geoparquet data format https://getindata.com/blog/introducing-geoparquet-data-format/\nMusic credits powered byOCRemix\n\nSalut Voisin! - Final Fantasy IV - colorado weeks, Aeroprism - https://ocremix.org/remix/OCR04553"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://fosstodon.org/@jonmcalder"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://hugogruson.fr/posts/compa-tibble/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://nrennie.rbind.io/blog/r-tutorial-worksheets-quarto/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://rweekly.org/2024-W23.html"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://tibble.tidyverse.org/articles/invariants.html"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "http://geoarrow.org/geoarrow-r/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://drmowinckels.io/blog/2024/rproject/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://www.aboutpodcasting.show/episodepage/podcasting-and-data-science-with-eric-nantz-from-the-r-weekly-highlights-podcast"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://www.openscapes.org/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://www.openscapes.org/blog/2020/10/12/tidy-data/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://getindata.com/blog/introducing-geoparquet-data-format/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "links": "https://ocremix.org/remix/OCR04553"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with episode 167 of the R Weekly Highlights podcast. This is the weekly show where we talk about the awesome resources that are shared every single week on the R Weekly issue. My name is Eric Nantz, and I'm delighted you joined us from wherever you are around the world. And, yep, we are in June already. It's hard to believe, almost midway through the year.\r \r So as usual, I can't do this shindig alone these days. I am joined by my awesome cohost, Mike Thomas.\r \r Mike, how are you doing this today?\r \r\n\n[00:00:33] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Doing pretty well, Eric.\r \r I've been paying attention more and more to your favorite sport, hockey. I know your red wings aren't in it, but, Canada could have the cup coming home for the first time in a long time. Shout out Connor McDavid's goal the other day. That was incredible if you haven't seen it,\r \r for any sports heads\r \r there. And, my my local Boston Celtics are are in the basketball\r \r finals so that's pretty exciting over here. But other than that,\r \r it's all it's all data science all the time.\r \r\n\n[00:01:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That's right. And, yeah, the the the nation of Canada is gonna have this kinda carrot dangled in front of them once again for the first time since almost 2006\r \r for that team.\r \r Who knows? Who knows? They're going against a mighty tough Florida team that was there last year, and\r \r they got an education, and they've been on a mission ever since. So it'll be a it'll be a fun one to watch for all you hockey fans out there. But, yeah, congrats to your Celtics. I think it is their year. I would have put a lot of lot of stock into what they've learned over the years, so it should be a fun final. We'll see. We'll see. I gotta\r \r\n\n[00:01:38] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Mike Thomas",
        "trans_text": "see, any of the r, you know, sports\r \r probabilistic,\r \r you know, models\r \r\n\n[00:01:44] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Eric Nantz",
        "trans_text": "out there. I gotta I gotta see what they're saying. Yeah. It's good. I think it's gonna be kind of a toss-up depending on how hot that, certain Luca gets in the in the Dallas side. But it's gonna be gonna be fun to watch nonetheless. But\r \r in any event, we're gonna hear talking about all sorts of things of our data science today. And our curator for this episode or this issue, I should say, is John Calder, another great contributor in our Our Weekly team. And as always, he had tremendous help from our fellow Our Weekly curators and contributors and\r \r members like you all around the world with your awesome poll requests and suggestions.\r \r\n\nAnd we lead off today with,\r \r a great post about\r \r if you've been using, say, the tidyverse align your data science analytics and other work, and you've been starting to\r \r harness those principles and maybe a new package at your organization\r \r or making some functions that are consuming datasets as their main input,\r \r this first highlight today is a great primer\r \r for how you might wanna make your functions a little more compatible, so to speak,\r \r with the main building block of the tidyverse,\r \r data processing object type, albeit the Tibble.\r \r And this post comes to us from Hugo Gruson who is a\r \r research software engineer in epidemiology.\r \r\n\nAnd he leads off this, very succinct post with motivating the\r \r situation. 1st, a bit of those here that aren't aware,\r \r the Tibble is what you might call\r \r a reimagination\r \r or or a slight\r \r update on the typical data dot frame object and base r,\r \r which, of course, holds your rectangular\r \r style data.\r \r The TIBL does a little things under the hood to not so much replace data frame, but,\r \r add some either safeguards\r \r or more kind of quality of life enhancements on top of it. The biggest one that's obvious to you, especially you've been a veteran of r for a few years,\r \r is that if you have a large data frame\r \r and you print that in your console,\r \r oh, you're probably gonna have a wall of text just spinning down all throughout because it's gonna print that whole thing.\r \r\n\nWhereas a Tibble\r \r has a modified print method, whereas I'm gonna show you the first, like, 10 rows or so and then the names of the columns. So, hence, it's a good way to kinda get a quick\r \r glance at your dataset without\r \r overloading your console. That's just one of the minor differences.\r \r But we're gonna talk about some differences under the hood that could affect you if you're writing a function that takes a data frame or a tibble\r \r as input.\r \r And in case in point,\r \r there are, there is a big difference here. And that's the first part of this post here\r \r is that when you subset for a column and, like, a particular column of observations\r \r in a data frame,\r \r When you look at that under the hood,\r \r you will get a vector right away if you use the bracket notation\r \r of, like, the name of your data frame, the opening bracket, a comma to say get all rows,\r \r and then either the name of the column or the index position of the column,\r \r you will get a vector of those observations right away.\r \r\n\nWith a tibble,\r \r not so much.\r \r With a Tibble, if you do that kind of notation\r \r to grab a column out of it, you're actually gonna get a 1 column Tibble back\r \r instead of a vector.\r \r That can be a bit of a problem if you're gonna make a function that does some kind of, like, single column selection.\r \r And that function, like in the example here, a mean function\r \r is expecting a vector of observations,\r \r not a 1 column data frame.\r \r So his advice in this first example\r \r is that you can't rely\r \r on that single column subsetting having that default behavior of a data frame\r \r of what we call drop.\r \r\n\nDrop meaning, like, drop the data frame class and go straight to vector.\r \r Don't don't hedge your bets on that, so to speak.\r \r So in his example,\r \r he explicitly\r \r mentions or explicitly states a parameter\r \r in that bracket style subsetting of the column\r \r with drop equal true.\r \r Then you're guaranteeing that no matter if it's a data frame being fed into this function\r \r or a tibble, that you will get that one column back as a vector of observations,\r \r a vector of numbers instead\r \r of that 1 column data frame.\r \r I have been victim of this in the past when I was writing some packages that\r \r albeit didn't use Tibbles in their main package code, but then I was using Tibbles\r \r as a way to put some nice kinda convenience functions on top of the pipeline.\r \r\n\nAnd that drove me nuts when I just wanted one variable instead.\r \r And then suddenly these\r \r functions I was doing that was doing, like, p value derivations\r \r was just spitting errors at me because it was getting a data frame inside. Like, I couldn't believe it. Sure enough. I was I was running into that little mini inferno about the drop the drop situation. So\r \r sage advice here from Hugo on that because I think that trips up a lot of people when they're starting to make functions that are using Tibbles as an argument instead of just the data frame itself.\r \r But that's not all, Mike, because there's another concept that, admittedly, both you and I have never really paid a lot of attention\r \r to, but that could wreak havoc on your function as well.\r \r\n\n\n\n[00:07:24] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Mike Thomas",
        "trans_text": "No. You're exactly right, Eric, and and I just wanna go back to to your topic really quick. I think anybody who's ever\r \r probably ever developed in our package has been bit by this this drop equals true versus drop equals false behavior, you know, where with\r \r a sort of plain vanilla data frame, you're getting a vector out and with a Tibble, you're actually getting a data frame out, instead of, you know, the vector of the values of the column that you're you're looking for. So if you haven't been bit by it yet, it's this is one to, watch out for. And and another one to watch out for, Eric, as you're alluding to,\r \r is the concept of partial matching, which\r \r I must have seen, you know, somewhere along in my journey but I do not remember this and it's blowing my mind that this is even a thing.\r \r\n\nAnd what we mean by partial matching is when you're using the dollar sign operator on a data frame\r \r to extract\r \r a particular\r \r column\r \r from that data frame.\r \r And we'll use like empty cars as an example here.\r \r If you say empty cars dollar sign s,\r \r it will pull out the speed column because it's going to use partial matching to try to guess which column you were referring to.\r \r And you don't necessarily have to\r \r specify exactly the name of that column to get it out. To me, that's mind blowing. The the fact that we can do that, I'll be totally honest with you, I don't think I really like that. It does not feel safe to me. I'm surprised that it it still exists. I'm assuming it still exists and, you know, our 4 dot 4 dot o.\r \r You know, that the latest release, may maybe it's 441 that's out there now.\r \r\n\nI imagine that this was something that was implemented\r \r in the early early days of r, you know, thinking that that maybe it's a good idea. We wanna make, you know, this language and the syntax as user\r \r friendly as possible.\r \r But to me, oh, man, it gives me the heebie jeebies and and makes me feel like there's a lot of more opportunity for disaster to strike here than there is for efficiency\r \r to be gained.\r \r But, you know, the the idea along this section of Hugo's blog post here is is definitely do not rely on this partial matching,\r \r idea. I don't know too many people who who do rely on it but if you do, it's something that you should certainly watch out for. You can actually set some options if you'd like in your environment\r \r to ensure\r \r that that partial matching, you know, can't be can't take place.\r \r\n\nAnd one of these options is the warn partial match dollar argument,\r \r which you can set to true in your dot r profile file, for example,\r \r which will essentially\r \r ensure that you get a at least a warning,\r \r that a partial match is is taking place and that warning will appear in your console.\r \r You can do the same thing. You may wanna do the same thing in your your test that folder so that your your unit tests throw\r \r an error,\r \r or a warning at least give you that flag if there's partial matching going on that you're not necessarily\r \r expecting, which I think can be a great idea.\r \r\n\nAnd if you you do really need to support partial matching, obviously, this partial matching concept is is only implemented on the the vanilla data frame side and not necessarily implemented on the Tibble side, but you can,\r \r manually\r \r handle it. And Hugo gives an example here of using the the care match function, c h a r match function,\r \r to be able to sort of fuzzy match, partial match,\r \r a column name,\r \r that you're looking for and sort of have the same exact user experience as you would have\r \r with this partial matching against a a pure vanilla data frame,\r \r within a Tibble environment. So there's a nice little code chunk here if you're interested\r \r in doing that. But, again, you know, it's\r \r this is just my opinion only. You know, we're full of hot takes on this podcast and my hot take today, I guess, is\r \r be careful of any partial matching\r \r that's going on. And I think this is a great blog post in general to just warn you about some funky behavior that can take place between data frames and Tibbles that that you may or may not have been privy to. And it's it's definitely something that could easily,\r \r easily trip you up in a script that you're writing or a package that you're writing. So it's great stuff to look out for. Hugo also alludes to and provides a link to a longer vignette that contains all the differences,\r \r between Tibbles and data frames. And I think data dot frames and that,\r \r vignette is from the tibble Tibble package itself.\r \r\n\nOne of the fun pieces about this blog is, that it Hugo\r \r continues to use, the phrase compatible,\r \r which, you know, is a really nice pun that that rounds out this blog post, I think, beautifully. So a great top to bottom,\r \r summary of these sort of 2 funky behaviors\r \r between data frames and Tibbles. And I I definitely think it's a good reminder,\r \r warning to those of us out there to to be on the lookout, stay vigilant for, these differences.\r \r\n\n[00:12:34] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Absolutely. And even had I known about partial matching back in my very early days of of using r back in grad school,\r \r I probably wouldn't touch over 10 foot pole. I am just one of those people that\r \r on the side of caution, on the side of verbosity and specificity.\r \r And I'm gonna put the full name of that variable\r \r no matter how long it is because in the end, a, there are many ways in programming, not just in ARB, but in programming in general, to just\r \r whack yourself silly with, you know, user inflicted issues already.\r \r Last thing I need is partial matching to\r \r wreck havoc.\r \r\n\nAnd I do think it's kind of a you might say, I don't know, relic's the right word, but it's a it's a it's a snapshot in the history of r and s itself because\r \r let's think about what was not around when r and s were built. We didn't have\r \r modern IDEs\r \r and modern frameworks that would support auto completion\r \r in an intelligent way. Like, if you're looking at a TIP or looking at a data frame and you wanna get the name of that variable\r \r and you start typing the name of the data frame, dollar sign, and start typing the name of that variable,\r \r Our the modern editors like our studio and even some of the plugins you get in Versus code and whatnot will let you auto complete the name of that variable. So you don't have to very rely on partial matching\r \r in those situations because the ID is gonna give you a helping hand to help complete that that full name. And also within the tidyverts itself, packages like dplyr, tidy r, and many others\r \r under the hood,\r \r use a package called tidy select\r \r that will let you\r \r grab related variables based on maybe, like, the prefix of their name\r \r or maybe their position or other other ways to intelligently search for these. And, again, what you'll get back is the full name of the variable. It's just a convenience way for you to get there.\r \r\n\nSo, certainly, I think the modern tooling and the modern principles\r \r in the tidy verse hopefully make it that you don't have to support partial matching. But if you have some legacy projects where you do, this post has definitely got you covered on those as well. And then, also, Hugo throws some interesting nuggets at the end here with respect to testing\r \r if you have to really rely\r \r on data frames and Tibbles being, you know, jointly supported in your function,\r \r he has some ideas and some resources that you might wanna use to help make that testing more efficient.\r \r He has some plugs for both the Patrick r package, which lets you do\r \r parameterized\r \r tests with test that, which I didn't know about,\r \r as well as this auto test package.\r \r\n\nAnd that is basically a way to help\r \r scrape your r packages, like example code for, like, your functions.\r \r And then intelligently or dynamically, I should say, kinda change inputs that kinda do some, you know, test generation based on that.\r \r So 2 little nuggets there if you wanna really be robust with not just equipping your functions for the support of tibbles and data frames, but also helping yourself as a package author\r \r to test for these differences in a more systematic way. These two packages could help you out quite nicely there. So lots of knowledge dropped in the short post here.\r \r And rounding out our highlights today, we've got another great showcase of the power of the quartile\r \r documentation engine\r \r with a k a use case that'll be very nice for those of you in the educational sector or building\r \r maybe internal\r \r our trainings that wanna leverage this novel technology.\r \r\n\nAnd we have this highlight coming from the esteemed Nicole Arany who is a frequent contributor to the rweekly highlights\r \r in the past. And she talks about her solution\r \r that combines\r \r the concept of parameterized\r \r reporting in quartile\r \r with dynamic and conditional\r \r logic inside your quartile document itself\r \r to hide or show\r \r certain pieces of elements. And the use case here\r \r is as she wanted to\r \r create exercises\r \r and tutorial material for her students to work through in a workshop session. She's actually taught many workshops that have been shared in the art community. I still wanna thank Nicole once again. You know, I thanked her many times before for awesome workshop and machine learning at last year's our pharma. She did a tremendous job with that, and she built up the materials using quartile, so timely here as well. But in case of this example that she's talking about here,\r \r she had a set of goals that she wanted to achieve here is that\r \r the the document would have a series of questions that the users would have to, you know, write some r code or use r to help answer.\r \r\n\nAnd then a companion document to this that would have not just the questions,\r \r but the solutions\r \r to the exercises\r \r as well. Again, very,\r \r familiar concept to anybody in the educational sector.\r \r And\r \r this approach would not just work for web based formats but also work for static formats as well, such as PDF output. Hence, if you have to do hike a paper version for every reason, I've don't ask me about why I've been looking at static outputs recently. We'll save that for another episode.\r \r But in any event, the first part of this post talks about\r \r what are parameters inside a portal document.\r \r\n\nIf you used Rmarkdown before, this will actually sound pretty familiar to you because it works basically the same way.\r \r In your YAML of a portal document,\r \r you can have a field called params, and then inside it, you can have a series of 1 or many\r \r of these what look like key value pairs, only they're variables that you might give it a name like year. And then in colon, after the colon, you give the actual value of that. So you could define\r \r as many of these as you like.\r \r And then this sup this is supported both with the knitter engine as well as the Jupyter engine. So no matter if you're on the r or Python side, you can use parameters just as easily\r \r in each framework.\r \r\n\nAnd this has been a hugely helpful technique, especially if you're doing automated reporting,\r \r maybe on a ETL or another processing pipeline where you've got the same report, but it's changing like a subset of the data or it's changing a key variable,\r \r but yet the rest of the outputs are gonna be generated in a similar way.\r \r Parametized reports are a great way to, make that happen.\r \r So in the case of this tutorial\r \r example,\r \r she has a parameter\r \r called hide answers,\r \r and the default of this is true, meaning that in the document, it's gonna be one document.\r \r But here's the kicker\r \r is that in the document, she has\r \r put what a what we call these fenced identifiers\r \r around\r \r the type of output\r \r that will only be shown if one of these parameters is set to true.\r \r\n\nSo she has this\r \r in a very interesting way with both the answers being shown as well as\r \r if you're doing PDF output to only show\r \r when the output format is\r \r is PDF in the case of when she renders it.\r \r But this is all combined very nicely\r \r in her quartile chunks of the code\r \r where she's gonna dynamically\r \r put in whether to put in these fence identifiers\r \r of what they call content hidden\r \r based on an inline r code snippet, where if that parameter of hide answers is true.\r \r This is genius here. I love this technique. I, in fact, I was literally thinking to myself, how could I do this of a portal dashboard\r \r to do certain styling elements or certain pieces of the card, you know, styling\r \r if I had a parameter that was, like, longer length than another one. This is the key to make that happen. An inline\r \r little snippet that says, if params dollar sign hide answers,\r \r then put in this fence div of content hidden. And then you can still have the answer in one place. It's all in one document. She didn't make separate documents for this. Hence, we've we're applying the the dry principle here. Right? Don't repeat yourself. Don't make a separate document just for just for one snippet. This is this is terrific stuff. And then in the end,\r \r you see an example where one printout of the screenshot\r \r is asking the question\r \r and then another printout with hide answers false\r \r is showing the actual r code to help achieve that answer.\r \r\n\n\n\n[00:21:34] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. It it's pretty incredible. I would say that Nicola is probably one of the leading\r \r voices on\r \r all of the different gymnastics that you can do with with quarto and especially when it comes to, you know, not repeating yourself,\r \r making things as reproducible as possible and making things as easy on yourself as possible. And this is a another fantastic walk through and I I do just wanna before I forget, thank Nicola for these many quarto blog posts which have honestly helped me and saved me hours, in a lot of the quarto work that that we do at Catch Brook.\r \r So in the conditional content section of of her blog post, she leverages,\r \r again, one of these sort of fenced divs\r \r and you're able to specify,\r \r you know, when a particular format is being rendered to take this action.\r \r\n\nSo the best place to take a look at this is is in the blog post but within this fence div,\r \r she uses the dot content,\r \r hidden\r \r argument followed by the when format\r \r argument and specifies when format equals PDF,\r \r then the content is going to be hidden. So it's a pretty powerful little utility that we have in quarto to be able to take in a conditional action\r \r based upon,\r \r the type of format that's being rendered to. So very very useful,\r \r I think especially for folks who are rendering documents to different formats because let's be honest, you know, sometimes when you're rendering to HTML,\r \r some element, of your quarto document is going to look really nice and when it gets rendered to PDF\r \r either it's going to break or it's just going to look terrible because you know they're 2 completely\r \r different formats.\r \r\n\nMaybe you're taking advantage of you know some HTML content that you know really only belongs on a web page and doesn't belong on a static document or or vice versa when it comes to PDF. So this is a really powerful,\r \r little argument within this fence div that we can create that I think is excellent.\r \r And then maybe the last thing that I'll point out\r \r is,\r \r you know, that there are multiple ways to render\r \r your documents. One is from the command line, which is, you know, utility that that I'll use quite often as well. But if that render call gets a little bit lengthy, you know, for example maybe you have a few different arguments that you're trying to specify.\r \r You know, one maybe being the the output file name if you wanna rename that file, something different than the naming convention that you used for the dot\r \r QMD document.\r \r\n\nMaybe that's something that you wanna specify or if you have parameters, you can use the the, params\r \r flag\r \r of that command line call.\r \r Alternatively,\r \r you may wanna use,\r \r the quarto r package itself and leverage the quarto render\r \r function and specify\r \r these different arguments, you know, a little nicer than this this really wide,\r \r command line call that you might have to be making, if you are trying to set these different flags and specify these different arguments and output file names\r \r and things like that. So at the end of Nicole's blog post, before the additional resources, she has 2 code snippets for how she rendered, you know, the questions\r \r that she created as well as the answers document\r \r that she created in these 2 different,\r \r our calls using the the quarto render function from the quarto\r \r r package which you may be interested in in taking a look at. And the only difference between the 2 is the execute params, execute params,\r \r argument\r \r is specified such that, you know, for the questions hide answers parameter is set to true and for the answers,\r \r the hide answers parameter\r \r is set to false.\r \r\n\nSo that second time that she knits\r \r this document,\r \r the answers will be\r \r displayed. So, she'll create, you know, 2 different documents here which is is fantastic and a great, you know, top to bottom run through on how she went about doing this, all the different considerations\r \r and options and fence divs and parameter options that we have in quarto to make things as as flexible as possible,\r \r not only across, you know, 2 different outputs that she wants to create but even multiple document types. So great great walk through.\r \r\n\n[00:25:41] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And, like, echo your your your gratitude and thanks to Nicole for these terrific resources because I was able to use some of her previous materials as well that combined principles that we see in this post here\r \r for my recent,\r \r our consortium submissions working group,\r \r efforts where we have\r \r a document that we have to send as part of this bundle that we transfer to regulators.\r \r We call it an analysis dataset reviewers guide or ADRG.\r \r And I wanted to try something different with this. I could've taken the the typical route and just do a do a Word document, type it all for being was like, no. No. No. No. We're in 2024. Let's do something better here.\r \r So it's a portal document,\r \r but it's got 2 formats.\r \r\n\nBecause as much as I'd love to be able to submit the HTML format, we can't really put that in the bundle, so we do a PDF as well. But we do have conditional logic throughout some parts of the document that we know that for PDF,\r \r it's not going to quite render as nicely with the default font size. So I'll do some code chunk\r \r updates based on the output type.\r \r And then that way, I have a preview version of the ADRG linked on, you know, an HTML\r \r static site hosting area. And then the reviewers can look at that, you know, as as they give me comments and whatnot. But then the actual bundle that we transferred to them, which hopefully be this month, we will be able to supply the PDF version, and it's gonna look, you know, very good, very polished.\r \r But, again, the source is all from one place. We just have conditional logic on top, but still preserving the majority\r \r of that source going to both output types. So I do think this is this is a very novel concept,\r \r and parameters\r \r can you know, we're just scratching the surface of what is offered here. At the end of Nicole's post here, she has doing some terrific additional\r \r either blog posts from Mike Mahoney\r \r or JD Ryan's recent parameterized\r \r quartile reporting workshop as you gave for our ladies\r \r a while back. There's some great additional learning material,\r \r and I can't stress enough how awesome it is to have,\r \r like, a data frame of, like, parameter values in each row, maybe a different configuration of it. Just do a, per walk of that. For each row, run portal render. You got your outputs all generated within about 10 seconds. I did that yesterday, and it was a thing of beauty, my friend. Just a thing of beauty. Music to my ears, Eric. I I love nothing more than the per walk over that that nice little data frame with all your different parameter configuration. So thank you.\r \r\n\nYes. So so once you combine all this stuff, it's like, yeah, I always equate it to being like a a chef that can actually cook because I'm not a chef that can actually cook very well. But with programming, I like to think I can mix and match these quite a bit but I'm certainly not alone. We're learning from the call and many of the other\r \r thought leaders in this space here.\r \r And it never stops learning when you look the rest of the art weekly issue, and John has done a tremendous job for the rest of the issue here. So we'll take a couple of minutes to talk about our additional fines that caught our attention for the week.\r \r And going back to the concept of Tibbles and concepts of, like, the building blocks of the tidy verse,\r \r There were some some great posts that were\r \r illuminating a concept in tidy yard that I did not know was possible.\r \r\n\nThere are a couple posts here from Lael Lecri\r \r on the use of a Tidyr function called packing\r \r versus the concept of nesting, which we often hear about more fully\r \r with respect to creating your Tibbles.\r \r And if you're like me, when you first saw this issue or thinking,\r \r packing? What is that? Well, you can think of packing as, like, a slightly different take on how the data frame is being collapsed.\r \r Nesting is kinda like doing a row based collapsing. You're gonna have\r \r maybe a set of columns that become\r \r their own table, but it reduces the number of rows in your data frame as a result. We often do this in group by\r \r processing and whatnot.\r \r\n\nPacking is kinda taking the opposite approach.\r \r It's gonna keep the same number of rows, but then it's gonna make a table out of various columns,\r \r and then you can unpack it to make it wider again.\r \r And so there these two posts are gonna talk about the comparisons of the 2, when you might wanna use 1 versus the other. And in particular, I mean, I still have a lot to learn in this area here, but she did eliminate some interesting examples. If you have jason type data, why am I want to look at packing\r \r versus nesting and those concepts? So again, just an illustration that\r \r I always think I I know most of the tidy verse, but there's always something I don't know. So we're all we're all learning together on this. But, Mike, what did you find? So I found that the Geo Aero package, I think, has its first release on CRAN. It's version 0.2.0,\r \r\n\n[00:30:39] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 39,
        "trans_speaker": "Mike Thomas",
        "trans_text": "which I am super excited about because\r \r I am a huge proponent of, the arrow package and the parquet file\r \r format, and we are getting some utilities in R to be able to wrap the geoparquet\r \r project, which allows you to work with GIS data that's stored in in in parquet format for just huge efficiencies\r \r over, you know, traditionally, you know, large heavy datasets when we talk about geospatial\r \r data.\r \r One more blog I wanna shout out is a blog from Athanasia\r \r Mowinkle which is called\r \r Customize Your R Startup Message. And it's a really nice little walk through about how to give yourself,\r \r a little message if you'd like,\r \r when your R session starts up each time. So a really cute little fun one for anybody interested.\r \r\n\n\n\n[00:31:27] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. We we need a little variety in life. Right? I mean, I have all my my friends in the Linux community that do these fancy shell prompts and start up messages for their servers. I'm like, I need some of that for my artwork. So yeah. Well, that post is gonna gonna have me cover there. So yeah. And and awesome. Congrats to the Geo Aero\r \r team because, yeah, we're seeing immense immense, you know, innovations\r \r in the world of parquet with, spatial data. So this is just another tip to the hat, and, yeah, what a great time to be part of that ecosystem.\r \r And it's a great time to see the rest of our week as well and for you to get involved as well because this is not a project that's just run by a few individuals on the whims. This is based on the community, for the community, and by the community, if you will.\r \r\n\nSo the best way to help us out is to contribute to the issues directly via your\r \r suggestions for new resources,\r \r new packages,\r \r new tutorials, new workshops. We are fair game for all that. That will help your community.\r \r How you do that? Every issue at rwicky.org\r \r has a link in the top right corner for the upcoming issues draft. You can just click that, and you'll be taken directly to the poll request template\r \r where you can put in markdown syntax, that great link, that great resource that you found,\r \r all marked down all the time. We live marked down. We love it. Hence, Hence, some quartiles have been great with markdown as well. So all just a poll request away to get your resource in the issue.\r \r And, also, we love hearing from you and the community as well.\r \r\n\nWe have a few ways to get in touch with us directly.\r \r One of which is in this episode show notes. We got a link to the new ish contact page that you can send us a message on there. And I did hear back from a listener that wants to do some interesting,\r \r I guess, meta analysis on our past show notes. I'm gonna, you know, give that's gonna be exciting. So I'll definitely get in touch with you about that.\r \r And, also,\r \r you can also send us a fun little boost in the modern podcast app if you're listening to, say, paverse,\r \r Cast O Matic,\r \r fountain, many others in this space. So you can send a little boost directly in the podcast app, and we'll get that message directly to us about any third party middle person\r \r in between.\r \r\n\nAnd speaking of podcasts,\r \r I guess I had a busy, couple of months recently because I was on another show recently\r \r hosted by my good friend Barry at Pod home talking about my adventures of podcasting and data science, and I'll have a link to that in this episode show notes. That was that was great fun to join Barry on that on that episode.\r \r So I will link to that from the about podcasting show.\r \r That was great fun.\r \r And, also, you can get in touch with me on the social medias these days. I am mostly on Mastodon.\r \r We've got our podcast at podcast index.social.\r \r\n\nDoing a lot of fun dev work now behind the scenes with the podcasting 2.0 stuff and getting real gnarly\r \r with JSON data. It's been a fun learning adventure to say the least.\r \r I'm also on LinkedIn. Just search for my name. You'll find me there as sporadically on the weapon x thing with at the r cast. And, Mike, where can the listeners get a hold of you? Sure. You can find me on mastodon@mike_thomas@phostodon\r \r\n\n[00:34:43] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Mike Thomas",
        "trans_text": "dotorg,\r \r or you can check out what I'm up to on LinkedIn if you search Ketchbrooke Analytics,\r \r ketchbrook.\r \r\n\n[00:34:52] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome stuff. And, yeah, it's been a nice tidy episode that I think, judging by the fact that I have kids at home, I gotta get myself out of here. So we're gonna close-up\r \r shop here in this episode of our Wriggle highlights, and we thank you so much once again for joining us from RevAir\r \r around the world. And we hope to see you back here for another episode\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_23_highlights",
        "chap_timestamp": 17,
        "chap_text": "Compa-tibble functions",
        "chap_href": "https://hugogruson.fr/posts/compa-tibble/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "chap_timestamp": 9,
        "chap_text": "Tutorials powered by Quarto",
        "chap_href": "https://nrennie.rbind.io/blog/r-tutorial-worksheets-quarto/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "chap_timestamp": 51,
        "chap_text": "Packing & nesting",
        "chap_href": "https://rdiscovery.netlify.app/posts/2024-06-03_use-case-pack-nest/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "chap_timestamp": 31,
        "chap_text": "geoarrow lands on CRAN",
        "chap_href": "http://geoarrow.org/geoarrow-r/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "chap_timestamp": 6,
        "chap_text": "Customizing R startup messages",
        "chap_href": "https://drmowinckels.io/blog/2024/rproject/"
      },
      {
        "ep_name": "issue_2024_w_23_highlights",
        "chap_timestamp": 0,
        "chap_text": "Episode wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_22_highlights",
        "ep_date": "2024-05-29",
        "ep_duration": 17,
        "ep_description_short": "The recent patches in R that pave the way for a future object-oriented-programming framework to accompany S3 and S4, a treasure-trove of open spatial data ready for your mapping visualization adventures, and a collection of tips for the next time you refactor your testing scripts. Episode Links This week's curator: Jon Carroll -…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_22_highlights",
        "description_long": "\r \r The recent patches in R that pave the way for a future object-oriented-programming framework to accompany S3 and S4, a treasure-trove of open spatial data ready for your mapping visualization adventures, and a collection of tips for the next time you refactor your testing scripts.\nEpisode Links\n\nThis week's curator: Jon Carroll - @[email protected] (Mastodon) & @carroll_jono (X/Twitter)\nGeneralizing Support for Functional OOP in R\nGetting and visualizing Overture Maps buildings data in R\nWhat I edit when refactoring a test file\nEntire issue available at rweekly.org/2024-W22\nSupplement Resources\n\nOverture Maps https://overturemaps.org\nShiny Developer Series Episode 30 - The Connecticut COVID-19 Test Spotter App (Part 1) https://shinydevseries.com/interview/ep030/\nIntroduction to vvcanvas https://vusaverse.github.io/posts/vvcanvas.html\nHow to Split a Number into Digits in R Using gsub() and strsplit() https://www.spsanderson.com/steveondata/posts/2024-05-22/\nGet a Free New Logo for Your R Package in Our Hex Design Contest - https://www.appsilon.com/post/hex-contest\nop3r - R client to the Open Podcast Prefix Project https://rpodcast.github.io/op3r/\nSupporting the show\n\nUse the contact page at https://serve.podhome.fm/custompage/r-weekly-highlights/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\n \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\n \nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nLiquid Puzzles - Baba Is You - Gaspode - https://ocremix.org/remix/OCR04582\nBar Hopping - Streets of Rage 2 - Jaxx - https://ocremix.org/remix/OCR00437"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://fosstodon.org/@jonocarroll"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://blog.r-project.org/2024/05/17/generalizing-support-for-functional-oop-in-r/"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://walker-data.com/posts/overture-buildings/"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://masalmon.eu/2024/05/23/refactoring-tests/"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://rweekly.org/2024-W22.html"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://overturemaps.org"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://shinydevseries.com/interview/ep030/"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://vusaverse.github.io/posts/vvcanvas.html"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://www.spsanderson.com/steveondata/posts/2024-05-22/"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://www.appsilon.com/post/hex-contest"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://rpodcast.github.io/op3r/"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://serve.podhome.fm/custompage/r-weekly-highlights/contact"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://ocremix.org/remix/OCR04582"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "links": "https://ocremix.org/remix/OCR00437"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with episode 166\r \r of the R Weekly highlights podcast. If you're new to the show, this is where we talk about the latest happenings at our weekly every single weeki highlights podcast. If you're new to the show, this is where we talk about the latest happenings at our weekly every single week\r \r with,\r \r take on the latest highlights and other other great finds that are in the issue.\r \r My name is Eric Nantz, and\r \r I usually say every week as we usually do it. But, the universe kinda gave us a sign last week that maybe it was time for us to take a little week off. So I think I think we're better for it. But in any event, we are back this week, but I'm never alone on this. I am joined by my awesome cohost, Mike Thomas. Mike, how are you doing today?\r \r\n\n[00:00:38] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'm doing well, Eric. Yep. We did, record a great or we did, I shouldn't say record. We have a great episode last week. We just we just missed,\r \r the record in case\r \r you can't tell. But this week, we have pushed the button, so let's hope that it makes it out there to the universe.\r \r\n\n[00:00:56] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. And, as Mike can attest to, when he and I connected this morning, this was the very first thing yours truly did. So sometimes, yeah, the universe says\r \r may have gotten too comfortable before. So,\r \r you\r \r\n\n[00:01:10] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 10,
        "trans_speaker": "Mike Thomas",
        "trans_text": "know, the the bots can't automate everything. Mike, AI can't automate all this either, unfortunately. So Nope. That's right. Just add it to the collection of lost episodes out there. Highly Yeah. Valuable.\r \r\n\n[00:01:20] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Luckily, it's still single digits, and we hope to keep it that way.\r \r\n\n[00:01:24] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That's right.\r \r\n\n[00:01:26] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 26,
        "trans_speaker": "Eric Nantz",
        "trans_text": "But, you know, it's not lost. We got another fantastic issue to talk about today, and our curator this week was our another longtime member of the rweekly team, Jonathan Carroll.\r \r And as always, yeah, tremendous help from our fellow rweekly team members and contributors like all of you around the world with your poll request and other suggestions.\r \r And it's fun when you can lead off with,\r \r you might say, straight from the source, if you will, because we have a blog post\r \r straight from the r development blog itself\r \r on some of the latest patches and enhancements that have been made into base r to support\r \r a new frontier of object oriented programming systems.\r \r\n\nAnd if you're coming into base r, you may have noticed that there are\r \r 2 built in object oriented programming systems right off the bat with no additional packages needed.\r \r These are called s 3\r \r and s 4.\r \r They both accomplish similar things, albeit they go about it a bit differently.\r \r But you will find that, for instance, a lot of the tidyverse packages have been built upon s 3, whereas other packages in your ecosystem,\r \r especially those around the bioconductor side of things, have links to s 4. And we've covered in previous episodes of benefits and trade offs of each of those.\r \r But ever since about a year and a half ago, there has been a new effort,\r \r a joint effort, I should say, between the Arcore team as well as developers\r \r of, say, the tidyverse\r \r and other community related packages\r \r on a new object oriented programming system that is now called s 7,\r \r which right now is available as a standalone package that you can import into r.\r \r\n\nBut with the advent of s 7, it has provided\r \r the R Core team a time to reflect, if you will,\r \r on how to maybe help out packages like s 7 in the future become\r \r part of the base r installation.\r \r And they've identified\r \r a few key gaps, if you will, of ways to make this\r \r journey of incorporating\r \r into base r a bit easier.\r \r And this blog post in particular talks about a set of 4 different patches that have been landed\r \r ever since our version 4.3.0\r \r that are going to pave the way\r \r for an easier onramp of s 7 and perhaps other packages in the future\r \r to take advantage of some of these principles\r \r that have been built into R for quite some time,\r \r but to help give a more friendly interface around these.\r \r\n\nWe'll do a quick recap of each of these 4, but we're gonna, you know, buckle up a little bit. We're gonna get pretty technical here. The first one, probably the most technical here,\r \r is the concept\r \r of how dispatch works with respect to different object types and different operators.\r \r If you don't know what dispatch means in this context, it is really the concept\r \r ascending a generic, which is another word for function that's supposed to have, like, one name\r \r such as plot or summary,\r \r but take different actions depending on the type of object being fed into it.\r \r And so it'll say, hey. If I wanna do a summary of a data frame, it's gonna do, like, a quick five number summary of each, you know, variable in your data frame versus for a model object. It's gonna give you those model fit convergence\r \r statistics, those likelihood statistics,\r \r and other information.\r \r\n\nAnd typically for s 3,\r \r a generic will use the first argument that is passed into that that that that method call\r \r to help determine where it dispatches.\r \r S 4\r \r kinda takes a more general approach. It could be any number of arguments\r \r in that call that help determine\r \r which method gets dispatched to. S 7 is somewhere in between. It has this intricate kinda double dispatch system And\r \r even\r \r I'm not\r \r quite sure how that part works, but, luckily, for the rest Even I'm not quite sure how that part works, but, luckily, for the rest of this explanation,\r \r we really need to know that because\r \r now since version 4.3,\r \r they are now\r \r helping the situation\r \r where\r \r it's not always just like a summary or, you know, other function like that. A lot of the operator functions in r, such as like the plus or the multiplication\r \r or many of these others,\r \r actually are built on 2 arguments. Right? You don't see it, but the left hand and the right hand side of these operators are like the 2 arguments to the actual function itself.\r \r\n\nWell, before\r \r this patch,\r \r it would always\r \r if there was ever a mismatch in the types of arguments that are in these kinda operator type methods,\r \r r would warn you, hey. These aren't the same type, and it wouldn't dispatch anything that was based on those.\r \r Now since 4 dot 3, there's a new function built in the base r called choose ops method\r \r which is gonna let an object type\r \r declare\r \r that they are in fact based on a combination\r \r of different methods for that argument pair, not just one method.\r \r Where this is really gonna come into play\r \r is the situation where you have a pretty complex method\r \r that wants to\r \r do, like, these operator methods\r \r that is meant to do a unique thing,\r \r but be able to take an account that these argument types going in\r \r could be more than one type.\r \r\n\nAnd they use an example from reticulate\r \r in this piece, which I think is quite interesting here. But for those aren't aware,\r \r Reticulate is the RPAC is a interfaces with Python under the hood, and, hence, it's going\r \r to find a way for your r code to go to the appropriate Python method.\r \r But especially in the space of machine learning and other methods like that,\r \r sometimes these operators, they might wanna build a custom, you know, method on.\r \r They're gonna have different things inside each of the left and right side, if you will. So in the example they have in the post, it's based on TensorFlow\r \r where you might have an interesting object\r \r that's based on a tensor,\r \r tensor itself, which is a Python object, but you might wanna add to that, like, a simple array in Python or whatever.\r \r\n\nWhereas in for for r4.3,\r \r it wouldn't know what to do because these are 2 different object types. But now\r \r with this choose ops method,\r \r reticulate can say, okay. For this unique type of combination\r \r of an array and a tensor object,\r \r dispatch to this particular method.\r \r Now you may never really encounter this in your day to day development, but as a package author dealing with some more novel and more intricate class systems,\r \r this is going to be a big win for many people. So it's going to pave the way for more flexibility\r \r in these situations of building your own method\r \r on these, what you may call classical operator type functions.\r \r\n\nAnd speaking of those classical operator type functions,\r \r there has been one that's kinda had a unique, you might say, history\r \r and where it's invoked.\r \r And that, in particular,\r \r is the multiplication\r \r surrounded by percent signs.\r \r If you've done any, like, math in r or maybe in your graduate school or over class training,\r \r you probably use this when you had to multiply matrices together if you're learning the ropes of linear algebra and the whatnot.\r \r Prior to our version 4.3,\r \r this only worked with either s 4 objects or base r objects.\r \r Well, guess what? Now that in 4.3,\r \r there is a way to have now a new generic\r \r category called matrix ops\r \r where it's gonna have this built in operator as one of its first citizens of it, so to speak.\r \r\n\nBut package authors and developers of new object class systems\r \r could help put in new methods into this. And they say in the future, within base r, they're going to fold in the cross prod and the t cross prod,\r \r functions\r \r into this family.\r \r So they do admit this is meant for backward compatibility,\r \r but it's also\r \r intending this to let other packages have to do with operations\r \r that are more unique in this situation\r \r such as s 7 in the future, be able to do the appropriate\r \r classification\r \r of these methods.\r \r And, yeah, we're we're not quite done yet. We got 2 more to go.\r \r One of these\r \r is also\r \r filling a need that can be inconvenient or maybe it was a bit difficult in the past\r \r of trying to figure out for an object type what class it inherits from.\r \r\n\nThere is a function in base r called inherits where you put in as the first argument the object itself,\r \r and the second argument\r \r of the name of the class that is meant to check if it inherits from.\r \r Well, a lot of these class names that for an s three standpoint\r \r were kind of built in as an attribute\r \r and not really meant for human consumption. It was not meant to be very syntactically,\r \r you know, very easy to understand, apparently.\r \r Well, now\r \r in the inherits function ever since version 4 dot 3,\r \r you can now\r \r have arbitrary\r \r objects as that second argument that you're gonna use the check for inheritance of that first argument,\r \r which means you don't have to memorize or go in source code to figure out what is that name of that s 3\r \r object type that you're or class type that you're checking from.\r \r\n\nYou can now feed in a logical name of this\r \r or an object itself. So the example they have\r \r in s 7 where they define a class called class x,\r \r they give an object called class x of that new class,\r \r and then you can now use that as a second argument instead of a string\r \r trying to guess what that class type is.\r \r So that's also meant for use of s 7 to get into base r eventually,\r \r but there's no reason other packages can't\r \r inherit that same idea.\r \r Again, similar to the Python side of it where you might have in your reticulate\r \r package, build down reticulate,\r \r maybe a new class name that can be a lot easier to type for the user.\r \r\n\nLast but certainly not least,\r \r if you're familiar with s 4, if you ever explore that, the way to get into\r \r what we call slots of these objects in your creative s 4 has been the at sign. It's kind of been like the dollar sign to me when you would use that in, like, your data frame, dollar sign, name a variable.\r \r In s 4, it's been quite similar. You would have your object that was built in s 4, use the at sign, and then you would start typing in, like, the name of either the method or the slot that you want to get more information on.\r \r Well, this never worked for anything besides s 4.\r \r\n\nWell, now, ever since 4.3,\r \r now that can be used with s 3 dispatching as well.\r \r I still don't quite know in my day to day when I would would actually use this, but they do give justification for this by saying that s 7\r \r is taking bits of s 4, albeit these more formal definitions\r \r of slots and other formals that are going into these class types.\r \r And now, if you have that muscle memory of using s4 and this at sign to get into these different slots, you're going to be able to use this of s 3 and s 7 now as well.\r \r Again, not sure when I'll use that day to day, but, again, many of these changes\r \r are paving the way for an eventual future state\r \r of s 7 becoming part of the base r installation.\r \r\n\nSo I think it's one of those things we're gonna see the fruits of this labor more down the road.\r \r But if you ever had questions on what our\r \r our core project is doing\r \r to get this state ready. This blog post is definitely for you, especially if you want a primer on how these are gonna make your life at developing a new object oriented programming system or building a a PONCE S3\r \r or the new S7.\r \r\n\n[00:14:16] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Mike Thomas",
        "trans_text": "These are definitely, features that you wanna keep your eye on as you're developing your source code for that. Yeah, Eric. This is this is pretty exciting stuff and it's interesting to me to see how\r \r Posit and the RCCOR team are coming together on this initiative as well as some others, you know. It's really cool to have that,\r \r collaboration out there between, you know, the brightest minds in the some of the brightest minds in the R ecosystem.\r \r And if I understand it correctly, I think the the road map here is that this new framework is\r \r currently out there as an R package called s7\r \r for developers to, today if you want to,\r \r download, install, and kick the tires on it for a while.\r \r\n\nAnd then once the team feels that the package\r \r is stable across a wide variety of use cases, I believe the idea is to bring s 7 into base r.\r \r And I don't know if there's any specific timeline on\r \r that that we saw in the blog post.\r \r Not not yet. It looks like it's still got some work to do. Yeah. So I I would imagine that it's gonna be a function of how much use this s seven r package\r \r gets, and how many folks out there can download it and and try it out, and how many edge cases, they can find before they they finally feel that, s 7 is is stable enough\r \r to bring into base r. But, this is all, you know, I think extremely exciting stuff for those who are trying to, you know, sort of push the boundaries of what R can do. I I think,\r \r a lot of the\r \r power\r \r behind, this object oriented programming approaches\r \r is actually in making\r \r sort of the the end user's life easier and making the UX for, you know, our users that maybe don't necessarily need to know or care about,\r \r you know, methods, classes, object oriented programming,\r \r make, you know, their day to day jobs easier. Just like you said, Eric, we have these these generic functions,\r \r you know, summary. You can call that against a a data frame and get your your quantiles for each column, or you can call it against the model object. And each,\r \r you know, for for most\r \r authors of of our packages\r \r that contain predictive modeling frameworks,\r \r they all typically implement their own sort of summary generic or or print generic as well against the model objects that those packages offer. And the ability to sort of do that and custom tailor what the end user is going to see on screen is is really cool. It's really powerful. And for those of us in our early in our our journey or even, you know, intermediate in our our journey, the fact that we just sort of get that nice functionality\r \r for free,\r \r is is fantastic. And it it makes everybody's life easier. I think it contributes to some of the reasons why R can be a friendlier language for some folks to pick up. So, you know, the fact that we're getting some additional, you know, extension functionality, you know, beyond s 3, what s 3 can do in this new s seven implementation, you know, particularly with with sort of that second argument idea, I think is going to go a long way to continuing,\r \r to help, you know, those hardcore\r \r r developers make, everybody\r \r everybody else's life a lot easier. So we're very appreciative of that.\r \r\n\n\n\n[00:17:27] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. Exactly. And I'll admit my journey in OOP systems right now has been on a package, r 6, because I'm doing some shiny extensions\r \r as we speak. But it has been on my bucket list, so so to speak, to get into s 7. And our our good friend, John Harmon, has been doing some work of s 7 as well and some of his package development exploration. So it's it's on my to do list. But as you know, Mike, there's only\r \r so much time in the day.\r \r\n\n[00:17:52] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'm in the same boat, Eric. I have some\r \r grandiose\r \r ideas\r \r still sort of on the s3 object oriented\r \r side, but,\r \r we have this this credit scorecard\r \r package that\r \r leverages\r \r traditionally just a a GLM, a logistic regression model, but it's very possible\r \r to stick these scorecard models or wrap them around,\r \r other modeling types like XGBoost and something black box.\r \r But the methodology\r \r for for doing so, is is quite a bit different. So I'd have to to stand up a lot of\r \r different, I guess, object oriented approaches\r \r to ensuring that these generics that we've written, you know, fire correctly. So I have lots of ideas and plans as well, but it's only so much time as you said.\r \r\n\n[00:18:46] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 46,
        "trans_speaker": "Eric Nantz",
        "trans_text": "You know me, I love it when we have more open resources\r \r for both developers and users to kinda test their\r \r visualization muscle on, so to speak, and really generate some awesome insights.\r \r And our second highlight is highlighting just that. It comes from\r \r Kyle Walker who is a director of research for a winyan, if I'm pronouncing that right, as well as he has, apparently, his own consulting company for data science.\r \r And he highlights\r \r area that I did not know about until I read this post. So, again, I'm always learning when I read these.\r \r But, there is a project out there called the overture maps datasets\r \r initiative, which is\r \r a project not just from 1, not 2, but multiple\r \r big tech giants in the tech sector such as Microsoft, Amazon, and Meta,\r \r along with others\r \r to help produce\r \r both open and standardized\r \r geospatial\r \r datasets.\r \r\n\nMy goodness. Oh, this this looks really fun, and it's meant for developers to be able to use\r \r in the applications that they develop. Well, of course, nothing wrong of using this in r as well. Now how will we pull this off on the r side of things?\r \r Guess what? These datasets\r \r are written in what format, Mike?\r \r\n\n[00:20:06] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Mike Thomas",
        "trans_text": "My favorite format, Eric, parquet.\r \r\n\n[00:20:13] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Exactly. We've been harping on parquet for many months now on this show, but these datasets have been shared as objects and s 3 storage on AWS for public\r \r consumption with parquet.\r \r And just how can you import these into r itself? Guess what? The arrow package is your friend here\r \r because the arrow package will be able to import not just these parquet files that are stored locally on your disk. They can read from remote locations as well, such as these s three locations\r \r and not just read from them. It's not like you're, you know, behind the scenes, like, downloading in some temp area and then somehow importing all this into your system.\r \r No. No. No. No. These are kept remote,\r \r and this is really important example that Kyle outlines here because he found\r \r a unique data set with respect to building coordinates or topologies,\r \r and this data set has, get this,\r \r over\r \r 2,350,000,000\r \r That's a b. Building footprints around the world. Mike, have you ever had your hands on a data set this large?\r \r\n\n\n\n[00:21:22] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 22,
        "trans_speaker": "Mike Thomas",
        "trans_text": "How how big is the New York taxi dataset?\r \r\n\n[00:21:25] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 25,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Probably not that big. I don't think it's that big. Yeah. I think that's in the millions, but, boy, we're talking about 1,000,000,000 here.\r \r So you can imagine if you put that in your system, yeah, it's gonna probably blow up and smoke fire or whatever in your laptop or PC of choice. So you don't want that in your home memory. Guess what?\r \r IRL comes compatible with dplyr\r \r functionality,\r \r so you can use this to query for just the parts of data you need.\r \r And in particular, in the example that Kyle walks through here, he has an example of filtering the coordinates based on San Francisco, I e the state of California\r \r where he was able to grab the actual coordinates,\r \r from, I believe, another package to get the coordinates, right, the bounding boxes.\r \r\n\nAnd then\r \r once you have that well, of course, we're visual. Right? We wanna see what this looks like.\r \r The\r \r the package called rdeck,\r \r which is a wrapper\r \r on deck GL,\r \r gives you a way to have a 3 d\r \r based visualization\r \r of these buildings. And in the post,\r \r the code itself,\r \r really and really straightforward. Really not too much going on here\r \r other than setting your initial view\r \r and centering the coordinates, doing some zooming parameters,\r \r and then adding the layer, I. E, the Polygon layer\r \r for based on that data, the building\r \r topology from San Francisco\r \r and then being able to basically feed in variables for the various attributes, much like ggplot2 in a sense. And lo and behold, if you're looking at this in your modern podcast app, you'll see in the chapter image marker, you got a really nice looking topology layout of San Francisco\r \r that looks pretty darn cool if I dare say so myself.\r \r\n\nAnd so Kyle was curious.\r \r It looks like the u United States portion of this data has a little more fleshed out,\r \r building data, so to speak. He thought, what's it look like in the rest of the world just to kind of test that, you know, hypothesis out? He did the same kind of code, but instead of going to the US, he went to Sydney, Australia\r \r to see what kind of topology he would see here. And you do see that there's only maybe looks like about 15 or 20\r \r buildings that are represented here, which obviously we know Sydney is a big city. Right? So there's gotta be a lot more to it.\r \r But this just goes to show this iterative\r \r nature or might say the early stages\r \r of this initiative. So perhaps\r \r there will be others in the community that start contributing more data to the Australia side of things or other parts of the world. But in any event,\r \r you've got access to this really innovative set of data.\r \r\n\nYou do not have to blow up your hour session and import it in. Parquet is, again, we've been harping on this before. It's opening up a ton of possibilities\r \r for you as an R developer and R user\r \r to be able to do some really great insights\r \r without having side\r \r of\r \r side of things later on, this data set this set of data looks like a great source to draw upon. Yeah. Eric, I couldn't be more excited about this project. In the past, I've\r \r\n\n[00:24:45] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 45,
        "trans_speaker": "Mike Thomas",
        "trans_text": "leveraged typically the Google suite of APIs for\r \r geolocation\r \r types of of activities. Think if you remember my Connecticut,\r \r COVID 19 at home test spotter shiny app that I I shared on the shiny dev series, we use the Google Places API\r \r to allow users to search for particular places,\r \r in in the US and have, you know, that autocomplete that you're familiar with seeing, if you're ever been on Google Maps and ensure that the the particular place they selected is is a recognized location in Google's giant database. And it's a fantastic API, but there there can be some cost associated with that depending on your volume.\r \r And this new project, that's, as you mentioned called called Overture which is this collaboration between these powerhouses, Microsoft, Amazon, and Meta\r \r to open source these large geospatial datasets\r \r is is really exciting. And I I there talk about 5 different,\r \r particular\r \r geospatial datasets\r \r out there. One being administrative boundaries.\r \r\n\n2, land and water features,\r \r building footprints and roof prints, and then points of interest which I think are are like that places dataset that I was talking about, places API.\r \r And then last is transportation rare layers, like roads and public transit ways.\r \r One other feature that I hadn't,\r \r seen before is this deck.gl,\r \r library which is a relatively new, I think, framework for visualizing these very large datasets.\r \r And as you can see in the blog post, the output of, the deck dot gl\r \r maps is is beautiful. They have great visuals there, very modern looking,\r \r really really cool. And that rdeck package is just this great wrapper for the API that, as you said, the code here is is quite minimal. It's pretty incredible. There's some data prep work that goes on to to grab counties and to filter down, the buildings within a particular bounding box coordinates that we we care about,\r \r using, you know, the dplyr and arrow combination as well as the the sf package.\r \r\n\nAnd then there's this one call,\r \r a few lines. I think it's 1, 2 arguments really, to the rdeck\r \r package in order to sort of build that base map and then leverage this add polygon layer function\r \r on top of that to,\r \r really stick your polygons on top of there that are going to draw,\r \r the the different shapes on the map that you're looking for, all these different buildings and their their heights and the gradients and scales and things like that.\r \r And and that's about it. It's it's pretty incredible. It should feel pretty straightforward and and familiar to those who have done any geospatial analysis before.\r \r So the fact that we just continue to get these higher and higher performance tools for all of our data science work\r \r is super exciting.\r \r\n\nA great blog post, great walk through. I used, you know, you you we've talked about this a 1000000 times on the the podcast before and my love for Parquet k as well as the arrow package.\r \r I recently used DuckDV for the first time last week finally.\r \r I had a 25,000,000\r \r by 50 column SQL Server table that I wasn't about to to try to write summary queries\r \r against because I I tried to do that once and it it did not end well. Let's just put it that way. So I was able to to write that out to parquet using a a chunked approach,\r \r and the new I think, ADBC,\r \r that database connection\r \r for,\r \r for the Arrow framework\r \r and wrote that out to Parquet, and then I use DuckDV to query this this parquet file that ended up being, you know, I think around 1 gig for these 25,000,000\r \r rows by 50 columns sequel server table,\r \r and the the queries that I was running with DuckDV were taking like less than a second.\r \r\n\nIt was\r \r it was insane. It was incredible.\r \r So I can't I can't sort of recommend these frameworks enough for, you know, high performance,\r \r data analysis. And this is a fantastic use case of bringing a few different tools\r \r together, in terms of some of the Tidyverse ecosystem, the Arrow project, some of these other data visualization libraries, and then this new deck dotgl\r \r library, which is incredibly exciting. And, like I said, sort of the outputs here are are really visually appealing and nice. So it's a fantastic blog post,\r \r to to have out there. So thanks to Kyle.\r \r\n\n\n\n[00:29:07] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 7,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Absolutely. In fact, I've even just thought of a a use case for this myself in a rather geeky project where I'm starting to\r \r interface more with some interesting podcast metadata,\r \r and some of it is\r \r the location where downloads are occurring from. You know?\r \r Maybe I could use this to map out the downloads of our weekly highlights on a nice little map, so to speak. So I'm,\r \r you know, cover me intrigued then, and I I still think parquet is becoming the new CSV\r \r in a lot of our data science circles, and this is just yet more more credence to that. So, yeah, really, really fun to learn about the innovations in this space as well.\r \r And last but certainly not least on our highlights section today,\r \r we, in this,\r \r quote unquote loss episode last week, we we had a great discussion on ways that\r \r have been explored to help automate\r \r some refactoring of tests.\r \r\n\nWell, we're gonna make good on it because we have part 2 of that series here. We're gonna talk about the highlights here, and this comes to us from Al Salmon who, of course, was a former contributor here at rweekly and now is a research software engineer with rOpenSci and rhub and synchro as well.\r \r And this is part 2 of her quest\r \r to refactor\r \r test files in one of her packages.\r \r And, again, last in her her post last week, which, again, is on last week's our weekly issue,\r \r she had a fantastic,\r \r albeit\r \r quite in-depth\r \r system\r \r of using a combination of parsing our code\r \r and XML\r \r representation\r \r of code\r \r to find calls to certain expectation\r \r functions and be able to swap them on the fly by how having to do the infamous control f find and replace\r \r for all these hover instances. Well, we're we're getting a little bit more, human readable here, so to speak, in terms of automation versus,\r \r you know, some principles that I think\r \r on paper they make complete sense.\r \r\n\nBut, again, you got to put it into practice. Right? And, I already have\r \r one project where I put maybe half of these in practice, and I'm gonna go back and put the rest in practice. We'll kind of hit these 1 by 1 here, but a lot of these are gonna relate to not just test, but also your base r code as well for your package or other routine.\r \r Make variable names that actually make sense, and this also applies to your test suite as well\r \r because it may be tempting if you're, like, doing a similar expectation by just varying, like, 1 or 2 things,\r \r kinda reuse those variable names over and over again.\r \r\n\nNo. No. No. No. No. Don't do that. It'll make the bugging a lot worse, especially if most of those expectations\r \r pass\r \r except for one thing here and there. So\r \r having variable names that\r \r make make more sense to you when you read it,\r \r don't be afraid to make them verbose. I like long variable names if it helps my cognitive function. And so\r \r don't worry about, you know, trying to be with that. Again, you are probably the one that's gonna read this the most. So be nice to future you on this. And speaking of variable names,\r \r you, again, may be tempted to use the same ones\r \r across different tests if they're all doing the similar type thing.\r \r\n\nYou know, you might wanna change those up a little bit. So in her example here,\r \r she's got a function that has, like, 3 different modes of complexity,\r \r and she changes\r \r those inputs going into the expectations based on that mode, if you will. Easy, medium, and hard\r \r versus, like, x x x for all of them. So, again,\r \r tailor it to the way you as a developer can help move your debugging when these expectations\r \r are not passing.\r \r And then\r \r as you're developing these expectations,\r \r you may think about, oh, when I wrote this package,\r \r I had, like, all my objects created above, and then I put them, like, my processing functions below that or whatnot.\r \r\n\nMaybe for testing, you don't wanna do that. Maybe you wanna put\r \r the the objects you're creating\r \r related to the expectation that it's testing with\r \r and put those groups together instead of, like, all your objects in one part and then all your expectations\r \r in another part.\r \r Again, some of this is subjective, but, again, when you're debugging things,\r \r it may be much more straightforward to have these logical groupings of the object and expectation\r \r with each other\r \r instead of, like, everything in the preamble of your test and then every expectations\r \r all below it. So, again, these are all nice enhancements,\r \r but\r \r she's not done there. She's got a lot more here, Mike, that I think you could definitely relate to as a as a developer as well.\r \r\n\n\n\n[00:34:06] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Unit testing is a a funny thing, Eric, because\r \r some of\r \r the sort of best practices that you might think of in terms of how we like to author\r \r our code,\r \r can sometimes go by the wayside or or not necessarily make as much sense within a unit testing\r \r framework. And,\r \r you know, her her last sort of section\r \r here that she talks about or as you were discussing before is maybe not, you know, create all those different objects\r \r and then run your sort of expectations,\r \r you know, against those different objects that you previously created, but keep everything sort of logically together. So if you're about to execute a test using, you know, expect,\r \r equal or expect greater than or something like that,\r \r you should have\r \r the object that you're using in that test or objects that you're using in that test\r \r as close to that as possible.\r \r\n\nAnd and I think that that makes a lot of sense. You know, when I'm reading some source code\r \r of developers that I, you know, admire\r \r and and try to mimic, I think that that's something that I see, you know, quite often in their their unit tests within their test that folder is that everything is is sort of chunked up nicely into different sort of logical\r \r sections where they they have a per very particular thing that they are trying to test\r \r and, you know, they have that that very much segmented in one location.\r \r However, you know, sometimes\r \r you're trying not to\r \r recreate the wheel all the time as well and there may be opportunities\r \r maybe at the header of that file before you start executing any of your unit tests to create a particular\r \r particular object that you're going to actually pass and leverage in a lot of the different tests that you're running. So there's some trade offs here.\r \r\n\nA lot to think about. I I again,\r \r I say this I feel like every time I'll author a blog post but I feel like these topics aren't something that's talked about very often. So it's it's really nice to have someone out there who is talking about,\r \r her opinions and best practices, you know, most of which I I sincerely\r \r relate to. But these are a lot of things that I've had to learn the hard way, sort of, by trial and error,\r \r over the years and not necessarily had a lot of content out there to follow.\r \r So very grateful for Mel for for putting this together. And and maybe the last,\r \r point that she puts out is is try to use a a bug summary and not just maybe the issue number that you're solving as your test name. You know, if you go back and take a look at a test, you know, where sort of your test that,\r \r first argument there is just the string that says, you know, bug number 666\r \r is fixed as Mel uses for an example.\r \r\n\nShe certainly prefers that you you write that string to say something like, you know, my awesome function does not remove the ordering. You know, sort of,\r \r maybe providing the summary\r \r of that issue as opposed to just the issue number itself. So that when folks are going back to to understand it and look at the tests that have been written,\r \r It's very easy for them to be able to see\r \r exactly what's taking place in these tests, what has been solved,\r \r what maybe still is open and needs to test around that. And she recommends, you know, use that summary\r \r as that string, that first argument to your test that call,\r \r but but maybe you can have a comment within that that has a link,\r \r to the particular bug report or that git GitHub issue, so you have sort of the best of both worlds there. So a great great,\r \r blog post here again by Maelle. I really appreciate her covering a a topic that I think doesn't get enough attention, and I definitely learned a lot here. Yeah. Me as well. And I've been actually,\r \r\n\n[00:37:48] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Eric Nantz",
        "trans_text": "in the past couple weeks, I've been bolting on some really interesting unit tests for a shiny app I'm about to put in production. But guess what? As much as it may seem like a paradox, Mike, 90% of those tests have nothing to do with shiny. It's about the business logic, which again is a pattern that may not be as obvious as a Shiny developer. But guess what? Because the business logic is just based our code if your summaries or visualizations\r \r or over, you know, in this case, some Bayesian modeling.\r \r These are all things that we can take principles that Miles outlined here and as well as her previous posts on developing best practices. So I have her blog on one tab. I have the r packages\r \r tab on or open on another tab. The r packages book by Hadley Wickham and Jenny Brian. And so these have been greatly helpful. And, yes, there is some shiny test to match. I got the end there for what I call a more end to end user focused view of it.\r \r\n\nBut, boy, if I have confidence in the business logic and I organize these tests such that I know exactly\r \r where to go if something fails. And sure enough, I had some failures\r \r with a survival object outcome where I was like, wait. Why didn't it work for binomial and continuous? Why not for survival? Sure enough. I was doing a dumb thing in one of the inputs and the processing functions. But the expectation covered it, and I knew exactly where to go. So it does help future you. You've just gotta try it once. I promise.\r \r\n\n[00:39:13] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I couldn't agree more, Eric. Please please please write unit test for your business logic. It's the most important place to have them.\r \r\n\n[00:39:20] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Exactly. So I've got, members of of our developer team helping with some of those business logic. I gotta kinda help with the summary and visualization\r \r side of it. But in the end, we've got over 40 of these tests, and right now they're all passing. So yay for now.\r \r Hooray.\r \r You know you know what passes, though, as well. It passes the, the r curiosity test, if you will, is the rest of the rweekly issue because we got a lot of great content for you to continue your learning journey on with new packages, new blog posts, great new resources for you to dive into.\r \r So as usual, we'll take a couple of minutes to talk about our additional finds here.\r \r\n\nSpeaking of learning,\r \r this is definitely gonna be relatable to those who have\r \r children here in the US have started their summer breaks. Right? They're,\r \r they're not using their,\r \r their course web pages now to get homework and whatnot.\r \r But most of those schools here in the US build their learning systems on something called canvas.\r \r It's a learning management system.\r \r Mike, you're gonna know about this in a few years. Trust me on this.\r \r And most of their most of the teachers will use this to help bring out assignments\r \r or, you know, get in touch with their students, add resources, and whatnot.\r \r\n\nWell, if you are a maybe teaching a, who knows, maybe a stat or math course,\r \r and you wanna use r in it, but you wanna help use r to help automate some of your\r \r management of these resources, well, there is a package for you.\r \r This package is called vv canvas. This is a package to automate tasks in the Canvas LMS,\r \r and this has been authored by Ewin Tomer. And this is actually part\r \r of what was new to me,\r \r a verse of package is called the Vusa verse,\r \r which is a collection of our packages\r \r tailored to student analytics\r \r with respect to teachers using these in their courses and and other systems.\r \r\n\nSo this package basically builds upon the Canvas API\r \r If you wanna use r to help automate certain tasks, like creating, you know, assignments\r \r or\r \r finding metadata of assignments and whatnot.\r \r Looks really interesting if you're using this system with respect to your teaching.\r \r And as usual, as I say to many people,\r \r if there's an idea, there's typically a package for that. Well, little did I know there will be a package for the campus learning management system. So that was a new one to me. So maybe if you're one of these teachers that are on your quote unquote summer break and you wanna supercharge\r \r your, learning pipeline for administering your course and you use R, maybe this is for you. I have no idea.\r \r\n\nUnfortunately, as a parent, I can't leverage this API. They don't give me the keys for that. But, hey, if I was ever teaching, I would. I\r \r\n\n[00:42:10] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 10,
        "trans_speaker": "Mike Thomas",
        "trans_text": "have heard of Canvas before. You're right, Eric. I'm not quite there\r \r yet, but I am sure that sooner rather than later, if Canvas is is still around, I\r \r will be engrossed in it,\r \r once my daughter gets to gets to school. So\r \r very good to know. Very, very good highlight. I've got a couple for us. I will wanna shout out Stephen Paul Sanderson\r \r who has a bunch of little bite sized,\r \r posts which are are just fantastic little nuggets. One is called how to remove specific elements from a vector in r. He walks through,\r \r approaches using baser,\r \r d player,\r \r and, data dot table, I think. He has a a little,\r \r blog post how to split a,\r \r number into digits in r, which is fantastic. It's actually a use case that I had with with DuckDV,\r \r which has fantastic,\r \r function to be able to do so to split a a particular value by a delimiter into an array.\r \r\n\nAnd then it has a second function for picking the element of the array that you want but that's just a a tangent,\r \r based upon some rabbit holes that I had to dive down recently. So I want to shout out,\r \r Steve Sanderson for these great bite sized posts. Then I also wanted to shout out Epsilon for this contest that they are having,\r \r to win a, I believe, professionally designed HEX logo\r \r for your r package.\r \r You have until May 31st\r \r to sign up for this. So you have a couple more days left. You have to provide some details about your r package, package,\r \r name, purpose, functionality, and some links and, briefly describe the design that you're looking for, design concept, any preferences that you have for the logo, and you could win a professionally designed hex logo for your r package. And if you've seen any of Absalon's,\r \r I think\r \r newly sort of rebranded\r \r or redone,\r \r hex logos, I'm thinking about the tapper\r \r package which is,\r \r I believe\r \r is that on the Shiny for Python side? That's their Yep. Rhino That's their kind of rhino like wrapper. Yes. For building modularized,\r \r Shiny for Python applications.\r \r\n\nThese HEX logos look super clean, super modern,\r \r really really cool. So if you did win this, I have no doubt that that the design that your R package would get for its hex logo would\r \r be be very fresh,\r \r and would be, you know, sort of way ahead of of most of the competition in the R ecosystem. So very exciting stuff and and thanks to Absalon for running that contest.\r \r\n\n[00:44:38] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Because,\r \r Mike is designed a hex logo easy for you.\r \r\n\n[00:44:43] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Not necessarily.\r \r I spend way more time than I need to spend but it's it's maybe not necessarily,\r \r the time that it takes to actually do the work, but maybe the\r \r the finickiness that I have trying to get, you know, what I want in my head,\r \r sorted out.\r \r\n\n[00:45:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah.\r \r Exactly. And so I've I've massive respect for anybody that it can have such, you know, in, you know, such amazing design skills.\r \r When I look at these examples on the blog post here. Yeah. I,\r \r I got absolutely nothing on that on that route. So all my internal packages do have a HEX logo.\r \r They take me a long time to get across, and then in the end, they just\r \r well, you won't see them, so you'll never know. But,\r \r basically, I just find some random\r \r open source image. I use column phase hex make shiny app to throw it on there with a little metadata, and then I'm done. I'm like, you know what? It's an internal package, so be it. But, yeah, if you are, as as Mike you said, a package author and looking to have a great HEX logo, yeah, this contest is definitely for you. So you got a couple days left to sign up for that.\r \r But what won't have a deadline here is our weekly itself. It does not stop. Right? I mean, we are continuing, you know, hopefully for a very long time with sharing these great resources for you. And, certainly,\r \r when, your trusty hosts here know how to hit magic buttons, we come with a new episode for you every single week. But, of course, we love we love hearing from all of you too. So one of the best ways to get help with the project, first of all, it would be\r \r looking at r o q dot o r g. Looking in the upper right, there's a little poll request button right there for the upcoming issue draft. So if you see a great new package or great new blog post that you think should be\r \r highlighted or or be part of the next issue, It's just all markdown text. Very simple. Just give the hyperlink.\r \r\n\nWe give a nice little contributor guideline there right in the in the template so you can, you know, fill out that information.\r \r Again, very straightforward.\r \r If you know Markdown, you know how to contribute our weekly. It is just that simple.\r \r And as well, we'd love to hear from you as well. There are many ways to do that. We have a somewhat new contact page because yours truly forgot that we moved to a new host that my previous contact page was gonna be null and void. So I've got a new one up. The link has been updated in the show notes, so you'll get to that right there.\r \r That's actually some custom HTML in that, by the way.\r \r\n\nI'll be\r \r found a template online to do it, but credit to our podcast our podcast host called Pod Home for giving me the keys to be able to do that. So that was kinda cool in any event.\r \r You can fill out that as well as if you're on a modern podcast app, such as PowVerse, Fountain, Cast O Matic. There are many others out there. You can send us a fun little boost along the way right directly in your app itself,\r \r and these modern apps are gonna be where do you get to see those fancy chapter image markers\r \r on top of the chapters themselves so you can kinda get a little visual cue every time we dive into another topic.\r \r\n\nBut, of course, we are also available on these social medias. I am, Mastodon mostly these days\r \r with [email protected].\r \r And my quest to bring r to the world of podcasting 2 point o just hit another milestone recently.\r \r I have now open sourced a new package called 0p3r,\r \r which is a front end to the OP 3\r \r API service by John Spurlock that gives open podcast metrics.\r \r And, yes, now I can visualize our weekly highlights metrics\r \r with my same package with a little deep fire magic. So more to come on that as I dive into to more on this, escapade that I'm on. So, that was, that was from my interview,\r \r podcasting 2 point o. Adam Curry himself said, yeah. Yeah. It'd be nice if we did that OP 3 stuff in your dashboard. I'm like,\r \r duly noted. So new package as a result. Boardroom driven development nonetheless.\r \r\n\nBut I'm also on Twitter, x, whatever you wanna call it with that the r cast sporadically,\r \r and I'm also on LinkedIn. Just search for your my name and you'll find me there.\r \r\n\n[00:48:54] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 54,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Mike, where can the listeners get a hold of you? Eric, that is super exciting about your OP 3R package. Congratulations.\r \r I'm excited to\r \r to check it out and then install it, from GitHub and see what I can play around with. And it's a it's an API wrapper?\r \r API wrapper. Once again, I'm in the world of APIs now. Gotta love it. Gotta love it. I'm excited to to see how you went about, wrapping an API and and learning a little bit more about that because I know there's a few different ways to that folks go about doing that, some best practices out there and now that we have h t t r 2 and things like that. So,\r \r it looks like the thumbs up sounds like that's that's sort of the approach that you That's exactly what I built it upon. I've got some APIs. Very wild. Got some APIs I need to wrap. So, I will be taking a hard look at your repository. Thank you for your work there.\r \r\n\nFor folks looking to get in touch with me, you can do so on mastodon@[email protected]\r \r Or you can reach out, on LinkedIn if you search for Catchbrook Analytics,\r \r k e t c h b r o o k. You can see what I'm up to lately.\r \r\n\n[00:49:58] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "trans_timestamp": 58,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Very good. Very good. And, yep. So luckily, all things\r \r considered, I think we've got one in the can here. We're gonna hope so anyway. But, thank you so much for joining us wherever you are, and we will be back for another edition of ROV highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_22_highlights",
        "chap_timestamp": 45,
        "chap_text": "Generalizing OOP Support",
        "chap_href": "https://blog.r-project.org/2024/05/17/generalizing-support-for-functional-oop-in-r/"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "chap_timestamp": 46,
        "chap_text": "Overture Maps",
        "chap_href": "https://walker-data.com/posts/overture-buildings"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "chap_timestamp": 54,
        "chap_text": "Refactoring Test Files",
        "chap_href": "https://masalmon.eu/2024/05/23/refactoring-tests/"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "chap_timestamp": 58,
        "chap_text": "vvcanvas",
        "chap_href": "https://vusaverse.github.io/posts/vvcanvas.html"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "chap_timestamp": 27,
        "chap_text": "SP Sanderson's Tips",
        "chap_href": "https://www.spsanderson.com/steveondata/posts/2024-05-22/"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "chap_timestamp": 21,
        "chap_text": "Appsilon's Hex Logo Contest",
        "chap_href": "https://www.appsilon.com/post/hex-contest"
      },
      {
        "ep_name": "issue_2024_w_22_highlights",
        "chap_timestamp": 55,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_20_highlights",
        "ep_date": "2024-05-15",
        "ep_duration": 15,
        "ep_description_short": "An aesthetically-pleasing journey through the history of R, another demonstration of DuckDB's power with analytics, and how webR with shinylive brings new learning life to the Pharmaverse TLG gallery. Episode Links This week's curator: Sam Parmar - @[email protected] (Mastodon) & @parmsam_ (X/Twitter) The Aesthetics Wiki - an R Addendum R…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_20_highlights",
        "description_long": "\r \r An aesthetically-pleasing journey through the history of R, another demonstration of DuckDB's power with analytics, and how webR with shinylive brings new learning life to the Pharmaverse TLG gallery.\n\nEpisode Links\n\nThis week's curator: Sam Parmar - @[email protected] (Mastodon) & @parmsam_ (X/Twitter)\nThe Aesthetics Wiki - an R Addendum\nR Dplyr vs. DuckDB - How to Enhance Your Data Processing Pipelines with R DuckDB\nTLG Catalog 🤝 WebR\nEntire issue available at rweekly.org/2024-W20\nSupplement Resources\n\nEric joins Adam Curry & Dave Jones on Podcasting 2.0 Episode 179! https://podverse.fm/clip/dYmaWGIOc\nDuckDB quacks Arrow: A zero-copy data integration between Apache Arrow and DuckDB https://duckdb.org/2021/12/03/duck-arrow.html\nDemo repository for creating a Quarto workflow with {quarto-webr} and {quarto-pyodide} https://github.com/coatless-quarto/quarto-webr-pyodide-demo\nWhat's new in ShinyProxy 3.1.0 https://hosting.analythium.io/what-is-new-in-shinyproxy-3-1-0/\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\n \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\n \nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nGreen Glade Groove - Donkey Kong Country 2: Diddy's Kong Quest - TSori, dpMusicman, etc - https://ocremix.org/remix/OCR04437\nGerudo Desert Party - The Legend of Zelda: Ocarina of Time - Reuben6 - https://ocremix.org/remix/OCR03720"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://fosstodon.org/@parmsam"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://twitter.com/parmsam_"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://www.rostrum.blog/posts/2024-05-08-aesthetic/"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://www.appsilon.com/post/r-dplyr-vs-duckdb"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://pharmaverse.github.io/blog/posts/2024-05-08_tlg_catalog_webr/tlg_catalog_webr.html"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://rweekly.org/2024-W20.html"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://podverse.fm/clip/dYmaWGIOc"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://duckdb.org/2021/12/03/duck-arrow.html"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://github.com/coatless-quarto/quarto-webr-pyodide-demo"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://hosting.analythium.io/what-is-new-in-shinyproxy-3-1-0/"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://ocremix.org/remix/OCR04437"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "links": "https://ocremix.org/remix/OCR03720"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back of episode 165\r \r of the our weekly highlights podcast.\r \r If you're new to the show, this is the weekly podcast where we talk about the latest resources,\r \r innovations that we're seeing in the our community as documented in this week's our weekly issue. My name is Eric Nantz, and I'm delighted you join us wherever you are around the world and wherever you're listening to. And as always, I never do this alone. We're in the middle of May already. Time goes by fast, but I'm joined by my cohost,\r \r\n\n[00:00:32] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 32,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Mike Thomas. Mike, where's the time gone, man? It's crazy. I don't know. It is crazy. And, yeah, we gotta do the stats on how many episodes we're at together now at this point, Eric, but it's it's gotta be a lot.\r \r\n\n[00:00:44] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That's right.\r \r And now would never feel the same without you as is, I was thinking that you're sick of me.\r \r Not quite. Not quite. Not yet.\r \r You ought to you ought to give me more rants before that happens. But\r \r in any event, yep, we have a lot of great content to talk about. Before we get into the meat of it, I do wanna\r \r give a huge thank you\r \r to the, pod father himself, Adam Curry, and the pod stage, Dave Jones for having me on this past week's episode of podcasting 2.0,\r \r where I was able to geek out with them and, or as the chat was saying, nerd out,\r \r the, our language itself and the use of\r \r our end quartile to produce this fancy\r \r podcast index database dashboard. That was apparently\r \r more of a reality check than what Dave was expecting in terms of data quality\r \r of the podcast index database. But it was a ton of fun, And, apparently I've given him some things to follow-up on, which we may be touching on in one of our highlights here. But again, thanks to them for having me on, and I've been anointed the podcasting 2 point o data scientist. So I'm gonna take that and run with it. Pretty cool. Add that to your CV, Eric. I'm super stoked to listen to that episode. Today, I got a long car ride this afternoon and I will be tuning in. So,\r \r\n\n[00:02:01] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Mike Thomas",
        "trans_text": "very very excited to to hear about that.\r \r\n\n[00:02:04] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. And I'm actually gonna make sharing that even more efficient in this episode show notes. I will have a link\r \r not just to the episode itself, but to an actual clip of the episode with my segment on it. Again, one of these great features you can give in podcasting 2.0. So that's just a tip of the iceberg or some of the things that dev community is up to. But, nonetheless, we got some great art content to talk about here and our curator this week's for this week's issue was Sam Palmer,\r \r another great contributor we have in our our weekly team. And as always, he had tremendous help from our fellow our weekly team members\r \r world with your awesome poll requests and suggestions.\r \r\n\nAnd, Mike, we're gonna I guess guess this first high is gonna be a kind of a trip down memory lane, but I'll be at a visual aspect of it in ways I totally did not expect until we did\r \r research for this show. Oh, yeah. Exactly. So our first highlight today is coming from the esteemed Matt Dre who has been a frequent contributor to our weekly\r \r and past issues.\r \r And in particular, he's been inspired by a resource that admittedly little old me did not know about until now, but is called the aesthetics\r \r Wiki,\r \r which in a nutshell, what this is is\r \r a Wiki portal, but it's a very visually themed Wiki portal where it's got a collection of images,\r \r colors,\r \r links to musics and videos that\r \r help give you a vibe, if you will, of a specific maybe time period or a specific feeling in mind. And I met when I looked at this and I was going coming through some of the, you you know, the top Wiki pages,\r \r there was one about the y two ks issue from way back. And, I could I could definitely got the memory triangle. I'm looking at that Wiki portal,\r \r but I'm also getting vibes. And so this is gonna date myself quite a bit, so bear with me here. But, yeah, I had cable TV growing up and one of the, guilty pleasures I had was on VH one watching the I love the eighties, and I love the nineties series because it was\r \r such a fun trip down memory lane for each of those years of those decades. And I will still stand on my soapbox here. And at the eighties nineties were the golden age of video games, so take that for what it's worth. But in any event, I I definitely got those same vibes here. And apparently, Matt was inspired to think, you know what? On this Wiki,\r \r there's something missing.\r \r\n\nIt's the R language, of course.\r \r What could we do to visually depict certain, I would say,\r \r major stages\r \r in the evolution of our,\r \r for respect to this kind of theme on the aesthetics Wiki.\r \r So I'm gonna lead off with probably the most appropriate given yours truly is the old timer on this show\r \r with the first period that Matt draws upon is called base core.\r \r And the picture on the blog post definitely,\r \r gives you some vibes of\r \r there's a lot going on under the hood with our, but it's, you know, kinda scattered around. It it's it's got a lot happening.\r \r And he talks about some of the bullet points that inspired the imaging here\r \r because of if you know your our history, it actually came in the mid nineties.\r \r\n\nIt was derived from the s language and then to our from Rasa Hakka and Robert gentleman\r \r and then base core as we know it was founded in the year 2000.\r \r And if you have old r code laying around from that time period,\r \r I eventually gonna have 3 major operators in there one way shape or form.\r \r Bracket notation for referencing rows or variables,\r \r dollar signs for referencing variables inside a data frame, and the tilde's for your linear regression model fits and whatnot.\r \r He also mentions that if he was gonna put this Wiki together, he would have\r \r a link to the,\r \r writing our extensions PDF, which I've combed through a few times in my early career, but it's, not for the faint of heart if you're if you're new to the world on that.\r \r\n\nBut, yeah, the the the vibe of it is very, you might say, utilitarian,\r \r kind of mundane a little bit here and there, but the potential is there. So I really like what he put together there. And of course, in the in the blog post, it's in our post after all. He's got a code snippet that looks straight out of my early\r \r r classes and graduate school\r \r where you've got the assignment operator referencing\r \r rows with the double equal sign in the brackets,\r \r the dollar sign for referencing variable names\r \r and FL's\r \r aggregate, you know, bay from base are, and then finally ordering it by height. In this case, it's a data set of star wars worlds and characters. And in the end, you get a nice data frame of the average heights\r \r for those living in Tatooine or Naboo and others.\r \r\n\nSo\r \r I feel seen when I see that because if I look back in my old land drive here in the basement, I have lots of code that looks just like this. But our\r \r many\r \r other developments have happened.\r \r And the next period\r \r that Matt talks about will be something that I think will look pretty familiar to most users now. He calls it the tidy wave, Mike, and I would say it's anything but mundane.\r \r\n\n[00:07:28] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 28,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. No, Eric. That was a great\r \r trip down, you know, the the late nineties, early 2000\r \r of our the aesthetic\r \r or the fashion,\r \r that Matt matches\r \r to the the base core,\r \r time period is cardigans\r \r and a wired mouse with a ball in it. Man, if that doesn't sum up base score, I don't know what does. But on to the Tidy Wave as you'd say,\r \r he he talks about the history sort of starting in 2,008 and then later\r \r being popularized,\r \r mostly through the Tidyverse, sort of wrapping\r \r up a lot of,\r \r this different tidy functionality\r \r in 2016\r \r when that was originally released.\r \r\n\nThe key visuals here are the mcgritter pipe,\r \r the data placeholder\r \r as a period or a dot, and then the tilde,\r \r not being used for formulas but being used for Lambda functions\r \r in this iteration\r \r here. The fashion choices\r \r are Rstudio,\r \r hex stickers,\r \r and rapid deprecation.\r \r\n\n[00:08:33] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Where did you get that idea from?\r \r\n\n[00:08:36] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Every package is experimental. I feel feel like, you know, with the the little badge that it has,\r \r during this particular time period, but a lot of fun. Right? Absolutely. And you can see that the code snippet that we have here is leveraging a lot of dplyr\r \r verbs like filter, select, left join, mutate, summarize, and arrange.\r \r And the code\r \r arguably\r \r is a little easier to understand what's going on from from top to bottom and left to right.\r \r Looks a little more SQL ish than what you got in the base core,\r \r time period.\r \r And that brings us to this last new period, Eric, which Matt is calling v4punk.\r \r\n\n\n\n[00:09:17] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I love this because\r \r this is one of those situations where we are seeing another big evolution, but it's so fresh. May not fully grasp it yet. But the visuals of this\r \r have big roots into one of the most major developments in the our language itself of the last few years. And that is the introduction\r \r of the base pipe operator,\r \r which, again,\r \r one could argue that the tidy verse popularity you just summarized\r \r was a direct influence on this feature coming in alongside other languages having similar mechanisms.\r \r And in 2022,\r \r it was\r \r released fully, in support of our the the base pipe. So that is, of course, one of the key visuals here along with the underscore, which is not just for variable\r \r name separations\r \r between words,\r \r but as a data placeholder,\r \r similar to what you mentioned earlier with the period and the and the previous summary\r \r and a new notation for Lambda functions, which, admittedly, I'm still wrapping my head around, but it's the slash with the parenthesis afterwards. I\r \r admit, Mike, I have not actually written that one out yet. You're gonna have to pull the tilde for lambda functions out of my cold hands, so to speak, but I am warming up to it. It's just taking a while.\r \r\n\nSo the fashion here is this one's really funny. It's, you might call evil mustaches\r \r and posts on Fostodon and memes up the wazoo on various blogs.\r \r There there's a lot a lot going on here with the pallet being, you might say, very, you know, unified and pleasant, a rainbow pallet.\r \r And his nearest aesthetic that he finds on the Wiki that would correspond to it is and, again, I feel seen when I see this vacation\r \r dad core. Apparently, that's full of dad jokes and other visuals that those are kids probably put your kids through embarrassing moments or whatnot. Not that I've ever done that. But,\r \r the sample here\r \r is gonna look very similar to the sample you saw in the tidy verse sample above,\r \r but substituting for the base pipe, substituting for the new data placeholder and the new Lambda function notation.\r \r\n\nBut guess what? This is monumental, folks, because now,\r \r a very important feature in many languages is now\r \r in r itself. And who knows what the future holds here?\r \r But in any event, it's gonna be a wild time. I'm sure\r \r as more companies adopt new and later versions of r\r \r and say version 4 dot 1 and up going into production systems depending on your organization.\r \r But it is, a fast moving space and who knows what the rest of the future looks like. But, again, I can't stress how monumental it was for the r language to adopt\r \r this operator\r \r after this many years. It does show that the team is not resting on its laurels. It is definitely\r \r keeping up with the time, so to speak.\r \r\n\nSo it was this was this was a fun\r \r fun new take on the evolution of r itself, and, I can't wait to see what's next.\r \r\n\n[00:12:24] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Eric, it's pretty wild that in that last code snippet that uses entirely base r, looks so strikingly similar\r \r to the prior code snippet that was using all dplyr,\r \r verbs. It's it's pretty incredible, I guess, where we've come, you know. I don't know if this is a cherry picked example totally\r \r because, you know, you this works great until you get\r \r to a particular base art function that you wanna use that that maybe its first argument, right, isn't necessarily\r \r what's being piped\r \r into it. I know there's there's some placeholders to help you you get around that,\r \r but I do think that that maybe there's potential use cases that the Tidyverse can handle\r \r better than what we have access to in Base R, but, you know, there's also use cases here as Matt clearly demonstrates\r \r where you can just leverage what's straight out of Base R, and it's it's pretty wild. It's a pretty wild time to be in our developer.\r \r\n\n\n\n[00:13:23] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 23,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And even at the end of that last snippet,\r \r we see hot off the our version 4 dot forward presses the use of sort underscore by.\r \r And, again, we'll be very analogous. So we see in dplyr with the arrange function. So you're right, Mike. It is\r \r very mind blowing to me that after all these years, we have this\r \r capability\r \r that I think for those\r \r that are new to the language. And again, there will be opinions on this across the spectrum. So just take the Eric's opinion here. But when you look at the readability of this from a person new to the language,\r \r outlining all the steps that are happening in the state of manipulation,\r \r transformation\r \r of new variables,\r \r summarizing all that in a group format and calculating these derived statistics.\r \r\n\nI know for those coming from other languages, certain ones with proprietary name to it. This syntax is gonna feel more at home than what we saw in the in the good old days. But then again, I still have that old cold for a reason. It's always fun to look back. That's right.\r \r And next on our highlights\r \r very, hot and much talked about\r \r duck DB format for databases and how that compares to what you may have done in the past in tidy verse pipelines within particular,\r \r the deep wire package.\r \r And this highlight today is coming from\r \r Dario Ridicic who is a senior data scientist at Neos, and he's published this on the Epsilon blog\r \r talking about how you can take advantage of DuckDV to enhance your\r \r data processing pipelines in your ecosystem.\r \r\n\nWe have we have definitely mentioned DuckDV\r \r before, but if you're new to it and in particular,\r \r I mentioned being on the podcast in 2 point o show on Friday, I offhandly mentioned duct d b as someone else looking at for some of the podcast database and I, I had, Dave, scratch in his head a little bit. I'm running, oh, I gotta follow-up on this. So, Dave, this is for you.\r \r If you and those also that have not heard of DuckDB before, but\r \r this is a database\r \r system, but there are there are definitely different classes of database systems.\r \r One of which is the more traditional,\r \r there's a client interacting with a server process somewhere. And this is where if you heard of MariaDB,\r \r MySQL,\r \r Postgres,\r \r sequel\r \r and others.\r \r\n\nThese are very prevalent in the industry, but they often have a pretty heavy footprint,\r \r yet they are quite valuable in in the industry sector and other sectors as well. And then you have what are called in process\r \r database systems. These are ones that you can run directly on your computer\r \r as a file format,\r \r so to speak\r \r with where the data stored. And then there's some layer in your system is gonna interact with that.\r \r And the most historical one that's had the most popularity\r \r and still does to this day is SQL light.\r \r And that's where you just have to install a compliant front end on your system, have a SQLite database file on your system. And then you're able to read that into your preferred language.\r \r\n\nDuck DB is in that same space.\r \r So it does share some similarities of sequel light, but there are some interesting differences\r \r that may be worth your time to look at as you're thinking about, you know, database evaluations\r \r for different formats\r \r is that DuckDb is designed for\r \r data analysis, and the abbreviation here is OLAP for online\r \r analytical processing.\r \r This is massive if you're gonna have situations where in your database, it's not just querying for the existence of particular rows or existence\r \r of things. It's actually performing analytics on the fly\r \r much like we do in the tidyverse pipelines a lot where we're gonna aggregate by groups. Gonna derive mean\r \r values or\r \r or or medians or other statistics.\r \r\n\nAnd probably have to do that with complex, you know, indexing as well.\r \r DuckDV is tailor made for those situations.\r \r And so the other selling point of DuckDV these days that it is first completely open source, and that's of course a win for us and the data science community.\r \r And it is relatively dependency free,\r \r which means that it can be run on a variety of systems and architectures,\r \r including\r \r web assembly, which is some I'm very intrigued to buy for sure.\r \r Now it's not all roses and unicorns.\r \r There is some mention\r \r of disadvantages for DuckDV.\r \r\n\nI think it's more limited depending on your use case here. It's probably not the best for constant writing to the database file.\r \r But for most of my needs,\r \r I'm not usually writing a lot concurrently\r \r like I would say for an IoT device device or other digital device that might be hammering an endpoint multiple times per second. Most of the time in my day job, I'm analyzing\r \r these data from source and doing more complex\r \r operations.\r \r And you're not gonna get, like, the distributor set up like you would with a client server model for, say, postgres\r \r or Spark or other ways that you can have a database layer that's networked across multiple\r \r nodes on, say, a a VPS provider.\r \r\n\nBut, again, you're in a different use case already in that point.\r \r So and the upper part that is to keep in mind, it is still a fairly new project.\r \r They certainly had a lot of progress, but it doesn't have\r \r quite the maturity at a sequel light. But with that said, there is a lot of advancements\r \r happening in the community here, and I do think DuckDV, especially the integrations,\r \r what we can do with web assembly technology and other systems,\r \r even as lower scale as a Raspberry Pi, I think are really thought provoking on what you can do with this. But as an r user, you may be thinking yourself, I'm very comfortable with dplyr.\r \r What's in it for me to move to DuckDb?\r \r\n\n\n\n[00:19:48] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah.\r \r So in this benchmarking\r \r that that Damien,\r \r puts together here between dplyr\r \r and DuckDb.\r \r I believe\r \r he used,\r \r tried to aggregate about 38,000,000\r \r rows\r \r that was spread across 12 different parquet files. And if you're not familiar with the parquet file format, we've talked about it a lot on this podcast. It is, in my opinion, sort of the new CSV. It's it's columnar\r \r storage that makes analytics,\r \r very efficient. It compresses the data in a way that makes your files, these parquet files, much smaller than if you were storing them as something more traditional like a text file or a CSV, but we have plenty of other other links and episodes that that discuss that.\r \r So Damon used the, taxi\r \r data, the the very famous yellow taxi,\r \r the dataset,\r \r to be able to create sort of this large 38,000,000\r \r row dataset in 19 columns,\r \r that takes\r \r a a little less than 1 gig of disk space, I think 630\r \r meg, he said.\r \r\n\nAnd that's, you know, quite large for trying to do some analytics\r \r on natively.\r \r So one thing that he was able to do with with dplyr\r \r was to be able to,\r \r create this dplyr pipeline just using, 3 verbs here, 3 or 4 verbs. It looks like mutate,\r \r where he's creating a couple different date type columns, the ride date and the ride year,\r \r using lubridate\r \r to be able to parse those things, from a date time column. He's filtering,\r \r for only ride years in the year 2023,\r \r And then he he's grouping by these particular dates and taking a look at a few different median statistics, like the median distance, median fair amount, and median tip, as well as the the ride count, which is just a simple count. And he reproduces that same exact logic,\r \r using dplyr verbs\r \r again, but the second time it's against this this dplyr table connection,\r \r that connects via duckdb,\r \r the the DB connect, DuckDb\r \r driver,\r \r against these parquet files. Again, you're able to just have DuckDb sort of sit on top of and interact with these parquet files as opposed to DuckDV,\r \r being the database itself. You do have both options similar to SQLite. You can actually create a DuckDV database\r \r file if you would like. But you can also just use the DuckDB engine to operate against parquet files, which is what is going on here, and I think is is probably what you'll see more common out there in the wild these days and act in terms of, data storage\r \r as opposed to actually storing, you know, your your data\r \r itself as the stuck DB database.\r \r\n\nHe also demonstrates that you can if you didn't wanna write the dplyr code, you could write,\r \r an entire SQL statement that does this exact same thing,\r \r within the DB GetQuery\r \r function,\r \r from\r \r the DuckDb,\r \r package which would allow you to, you know, express your logic, all the CTL logic in SQL as opposed to dplyr.\r \r But now here's sort of the big results here. We're trying to look at this this little dplyr chain and how it performs,\r \r in in Raw dplyr as opposed to\r \r using the DuckDV engine under the hood. The dplyr approach takes almost 15 seconds to do this aggregation, which results in a data frame that I think is,\r \r they're they're showing about 16 different,\r \r observations here, 16 rows\r \r across these,\r \r 4 different,\r \r statistical columns\r \r that get computed,\r \r and then the DuckD\r \r b, as opposed to the 15 seconds that it takes in deep prior, the DuckD b approach takes less than one second.\r \r\n\nSo it's it's pretty incredible.\r \r Damien knows that they have, triple checked this statistic and that the numbers are correct, and DuckDb here is almost 20 times faster\r \r than dplyr, which is is pretty incredible and right that, you know, a lot of times when especially, you know, in the context of, Eric, a lot of what you and I work on in terms of Shiny apps and trying to make those UXs as\r \r seamless,\r \r frictionless\r \r as possible, you know, moving some of that ETL from something like, you know, raw dplyr or base our code,\r \r to leveraging, you know, DuckDB or Arrow\r \r can create these these drastic orders of magnitude gains inefficiency\r \r that that really make that user experience,\r \r tremendously better than it would be otherwise. You're not having to have people, you know, continue to wait around for something to happen for these ETL chains to run.\r \r\n\nSo this is a great great walk through, great use case. I would also recommend maybe a couple other,\r \r functions out there and some pieces of documentation out there. I think there's actually a function from the arrow package\r \r called to_duckdv,\r \r which allows you to sort of start with an Arrow object,\r \r but leverage the DuckDB\r \r engine,\r \r on top of Arrow to make that pipeline even faster and to allow Arrow and DuckDV to integrate seamlessly\r \r together, which is is fantastic.\r \r There's also a blog post\r \r sort of on that same,\r \r vein on the DuckDV website. I just realized it's from from 2021,\r \r but it had been, you know, getting shared around on on Twitter recently,\r \r which is called DuckDV Quacks Aero, a 0 copy data integration between Apache Arrow and DuckDb. So maybe I can share that in the show notes as well.\r \r\n\nBut it certainly seems like, you know, this is sort of the way of the future in terms of ETL. It's certainly the way that we're doing a lot of stuff at Catchbook right now for our ETL pipelines, and it's it's making a huge difference for us. So it's a really exciting time\r \r to be able to leverage and see all of these,\r \r really nice ETL data processing\r \r improvements and tools that we have now.\r \r\n\n[00:25:40] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And there was a situation actually came up at at the day job last week when,\r \r there was a user that thought that was Deepfire just having really bad performance on a certain situation. And, of course, they tried to get more details because we don't wanna just vague request like that. But, apparently, they were analyzing\r \r a 7,000,000\r \r row dataset,\r \r which, yeah, if you're just gonna ingest that in native our sessions without a helper like duct DB or even SQL life for that matter,\r \r it's going to be a long time to produce aggregations and summaries on that kind of set. And it didn't help that this set was in SaaS format, but that's another story for another day. But in any event, imagine\r \r if that dataset is getting split up into parquet files or intelligently by groups, And then you take the same kind of code that was demonstrated by Damien over here\r \r and to be able to run that very efficiently or Dario should back. Try that again. And imagine if you take the same code that Dario puts together in this post\r \r with those parquet files again, like you said, correct me. My I feel is that the new CSV,\r \r There's a reason I linked to those\r \r as extract downloads in my podcast index dashboard. I didn't wanna do CSVs anymore\r \r trying to push this as the other communities as well to look into this. But you are gonna get tremendous gains in these situations with with DuckDV\r \r on the back end. And one addendum that I would be interested in trying on, maybe I will when I get some spare moments,\r \r is it was, what, a week or 2 ago on this very podcast, we had covered the release of the Duck plier package,\r \r which again is a very similar vein to what Duck DB package itself is doing here, but it is a even more of a direct one to one replacement for dplyr.\r \r\n\nIt is still newer, so we're keeping an eye on its development.\r \r But you could probably leverage the majority of that same code\r \r into a duct flyer pipeline, and I would venture to say you're gonna get those same performance benchmarks because it's all Duck DB\r \r under the hood anyway. But we'll definitely have a link to Duck plier as an additional thing to explore here. But I see, again, massive potential\r \r in the spaces that you and I operate on in both of my day job efforts. But now, as I mentioned in my open source efforts of this podcast database,\r \r my portal dashboard\r \r kind of takes a quote unquote easy way out where I've through GitHub actions, I'm doing all the processing\r \r outside the dashboard and the dashboard is simply referencing them directly via RDS files that are being downloaded on the fly.\r \r\n\nI am waiting for the day where I can swift flip that up to do web assembly,\r \r DuckDV in inside that, and then I can do the real time querying, so to speak, in that dashboard as a Shiny Live app instead.\r \r It's coming, Mike. It's coming. I just need the time to do it.\r \r\n\n[00:28:44] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Mike Thomas",
        "trans_text": "And speaking of WebAssembly,\r \r we have one last highlight to wrap up the week that I think might just be on that topic.\r \r\n\n[00:28:51] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 51,
        "trans_speaker": "Eric Nantz",
        "trans_text": "So, yeah, it's not only on that topic. It is literally in my same industry about ways that I've been envisioning for\r \r ever since I've heard about this technology,\r \r where I think the potential is, and we are seeing that here. And in particular, this last highlight is coming from the pharmaverse\r \r blog\r \r and authored by Paolo Rucci, who is a data scientist developer\r \r at Roche.\r \r And for those unfamiliar, the pharma verse,\r \r if you're in the r community, you've like you heard of things like the tidy verse and whatnot. Well, this is a\r \r collection of packages that are helping\r \r make clinical\r \r pipeline\r \r analyses,\r \r data processing\r \r that we routinely do in life sciences\r \r much easier to do in the our ecosystem as ours now taking a much, stronger footprint\r \r in the life sciences industry.\r \r\n\nWell, one of the suites of packages and the pharma versus, you know, getting popular\r \r is the nest packages and others to help produce\r \r what one might consider the backbone of what we call a clinical submission to regulators\r \r for a given study,\r \r and that is the production of tables,\r \r listings, or graphs or TLGs for short.\r \r Traditionally, these have been done in a certain proprietary language, but that's not we're gonna talk about here because r has made tremendous strides in this space.\r \r And as a way to get new users or to show off the potential of what's possible with the pharmaverse in this in this, part of the pipeline,\r \r The pharmaverse has produced for a while now the TLG\r \r catalog,\r \r which has been a snippet for the common table listings and graph types that we often do in submissions,\r \r but with the r code to actually produce those and a snapshot of the output.\r \r\n\nWell, what, Paulo was talking about in this post is they have now\r \r integrated\r \r WebR,\r \r hence WebAssembly,\r \r into this portal site\r \r to not only show the code,\r \r but to let the users\r \r run the code themselves,\r \r change things on the fly,\r \r experiment with the existing syntax.\r \r My goodness. This is just a massive win for learning in this space. I am geeked out about this already.\r \r They had me there, but as the game shows will say, but wait, there's more\r \r because\r \r another popular part of the pharmaverse has been the teal framework,\r \r which is a way to bring interactive data exploration with these common summaries\r \r into a Shiny application with a set of reusable modules and packages\r \r to help with different analytical types, different parts of the processing,\r \r but teal is a great way to ingest these clinical data for review\r \r in your given systems to explore for new insights and whatnot.\r \r\n\nWell, guess what? With the advent of shiny live, Powell is also plugged in a way to run a teal application\r \r tailor made for each of these table summaries\r \r inside that same website, folks.\r \r This is massive. I cannot underscore how enthusiastic I am about this because\r \r think of the doors this is opening. Right? Is that\r \r there will be, many in life sciences that are new or newish to our for a lot of these clinical analyses.\r \r Anything, and I mean anything we can do to make this easier for them to transition,\r \r we need to take that and run with it as fast as we possibly can. This TLG catalog, I think, is amazing\r \r first step\r \r in this vision. So I whoever you're in the pharma industry or not, just take the ideas from this. Think about how this could be used in your use cases\r \r for whether you're teaching\r \r new users of r or you're trying to demonstrate to your leaders what is possible when you mirror the technologies of open source and web assembly together. This t o g catalog\r \r is a massive vision. I or a demonstration of this vision\r \r that I think can be applicable to many people. And, yeah, when I saw this, I'm like, I'm IMing some people at work. I'm like, you need to see this folks. This is amazing. So I'm definitely gonna be pursuing this very closely. But, again, what an excellent showcase\r \r of WebAssembly,\r \r quarto,\r \r and the pharmaverse\r \r all in one place. Absolutely massive, Mike. Can you tell I'm excited?\r \r\n\n\n\n[00:33:15] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 15,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I can tell you're excited, and it's hard to do it all justice,\r \r on audio format, but there's some great\r \r gifts as well that Pavel has,\r \r included\r \r and implemented into this blog post that really demonstrate\r \r exactly what's going on. And I don't know if the users sort of caught it, Eric, but\r \r what this means and what's being showcased here is not only the ability\r \r to create this this sort of shiny app, right, using web assembly and web are sort of in the browser,\r \r But also allowing users to be able to edit the source code for this app and actually change\r \r the underlying, you know, structure of this app\r \r within the browser\r \r itself, and actually see the changes in that app underneath the code\r \r immediately, which is fantastic.\r \r\n\nNo needing to install any dependencies on your machine. You don't even need to have R installed or Rstudio installed. This is all taking place in the browser,\r \r which is is absolutely incredible. I think, you know, again, it it just lends itself to,\r \r less friction for those trying to get started\r \r with our easy learning,\r \r the language language and adoption of the language. Hopefully, for those coming from from different languages to be able to to get started and and go from sort of 0 to 1\r \r with the only requirement being an internet connection that they need,\r \r which is really incredible.\r \r\n\nThe other thing that I would say is, you know, what this this whole,\r \r sort of WebR framework and WebAssembly framework where it has sort of my head spinning now at this point which is something that we talked about, I think, on recent episodes but I don't think it is quite fully implemented yet\r \r is the idea for, you know, packages that we develop\r \r and these pack beautiful package downsides that we create with them,\r \r for the examples\r \r that we have for the different functions, in the reference section of our packages\r \r to be able to to actually be run-in the browser instead of users having to install that package and run those examples, you know, within their own our session.\r \r\n\nWhat I saw recently, and I can't remember if it's the most recent version of quarto that got released or if it's the most recent version of our that got released that had these capabilities,\r \r but you can now use quarto or QMD\r \r files to create package vignettes,\r \r which is probably sounds like a very subtle\r \r thing, but my hope\r \r is that now that we're able to to leverage quarto\r \r for authoring,\r \r packaged vignettes which I'm super excited to move to just because I love quarto.\r \r My hope is that maybe that\r \r leads the way or blazes the trail for the integration of of WebR\r \r into these vignettes\r \r as well backed by maybe the shiny live quarto extension\r \r and allowing us the ability to to do what I just described\r \r So, you know, like you said, Eric, and like we've brainstormed,\r \r the possibilities here are endless\r \r with all these advancements in in WebR and WebAssembly.\r \r\n\nAnd\r \r you and I I'm not sure if you had met him before but but at least I was fortunate enough to meet Pavel at, Shiny Conf last year and and maybe he'll be there again this year, but,\r \r a brilliant data scientist and a very,\r \r very well done blog post from him and a great way to wrap up the week.\r \r\n\n[00:36:36] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. We we were able to connect as well at that same conference, and I've I've you know, I've had multiple conversations thinking about potential of this new technology, and that's why I'm so excited to be part of this space right now with my, our consortium effort with that pilot, Shiny app submission and WebAssembly.\r \r I think we're on to something here and,\r \r that that indeed what you mentioned with quarto, it is in as of quarto version 1.4 is indeed the version Atlanta support for package vignettes, and I\r \r cannot wait to try that. Even if it's a internal package, if I can pull that off, yes, that again is a massive win for learning.\r \r\n\nEven as something as I'm gonna call trivial, it's not so trivial. I have an internal package to import SAS data sets into our bet backed by Haven, but with little syntactic stuff on top. Imagine just having\r \r a a a vignette powered by quartile to help demonstrate what that code looks like and some of the post processing functions\r \r I have in store. But, yes, I think in in our industry, we we are ready to embrace\r \r technology like this.\r \r Admittedly, we still have a long ways to go to see where this impacts, like, actual\r \r submission pieces, hence what I'm exploring in this pilot.\r \r\n\nBut when you put this in front of people,\r \r I don't know how you can't\r \r be excited about the potential of this. And like I said, no matter what industry you're in, I hope you take some inspiration from parts of this because\r \r this is this is the time to try things out. I think this is that evolution in history\r \r that we're gonna look back on maybe 5, 10 years down the road and wonder how did we live without this.\r \r\n\n[00:38:16] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I hear you. I agree.\r \r\n\n[00:38:19] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Eric Nantz",
        "trans_text": "You know what else is hard to live about is our weekly itself. Right? I mean, if our week had been around when I was learning our oh, I would have learned so much faster. But we can't turn back time. But at least you can start with the present\r \r and check out the rest of the issue that Sam has put together of more excellent resources.\r \r So it'll take a couple of minutes for our additional finds here. And,\r \r yes, I am very, you know, much a fan of the web assembly frame, but I haven't forgotten about my explorations with container environments.\r \r And that's where this another mind blowing moment for me from this issue\r \r is that James Balamuda, who goes by the cultless professor on the various social handles,\r \r he has been the pioneer\r \r of that web r extension for quartile and whatnot,\r \r but he has put a spectacular\r \r demonstration on his GitHub organ profile here\r \r that has\r \r a, custom\r \r dev container setup,\r \r which for those aren't aware of dev containers are a way for you to bootstrap\r \r a container environment in versus code\r \r or get hub code spaces.\r \r\n\nAnd he's got one that's actually 2 of them that are tailor made for both building portal documents and with newer extensions such as the web r extension\r \r and the pile died extension if you're doing Python based,\r \r web assembly products.\r \r But also these dev container features have one that works in the traditional GitHub code space, which will look like Versus code in your browser. Again, you as a user don't have to install anything with this on your system. It's all in the cloud.\r \r And\r \r wait for it.\r \r There is a dev container feature for Rstudio\r \r server.\r \r\n\nLet me say that again. There is a dev container feature for Rstudio server. If you recall maybe a year or so ago, I was\r \r exploring my workflow for these dev container environments for all my our projects, and I would spin up\r \r RStudio container via custom Docker file. And I would, okay, get from the rocker project, add these dependencies, add these packages and whatnot. And, yeah, it quote, unquote works, but it is a bit of,\r \r manual setup nonetheless, even if you clone\r \r my repo.\r \r Oh my goodness. Do you know how much easier this is now with just one line in that devcontainer JSON file he can have in our studio environment in the browser,\r \r not on your system,\r \r all powered by the GitHub Codespaces.\r \r\n\nOh my goodness. I am playing with this as soon as I can.\r \r\n\n[00:40:54] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 54,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That is super exciting, Eric. I can't wait to play with it as well.\r \r You\r \r you know, I I don't need to say it again that I have been bitten,\r \r hard by the dev container bug, and we do all projects\r \r now on our team,\r \r within dev container environments just makes collaboration and and sharing that much easier. So this is a great\r \r great blog post, touching on that subject again. I can't get enough of that content, so that's a great shout out as well. Another thing that we do a lot of, so this spoke to me quite a bit, was that there is a new release\r \r of ShinyProxy,\r \r version 3.one.0.\r \r\n\nAnd for those who aren't familiar, ShinyProxy is a platform for\r \r hosting Shiny applications.\r \r It's it's clear fully open source,\r \r but you you host these Shiny applications,\r \r heavily\r \r via Docker such that\r \r each user,\r \r when they click on an app on your your ShinyProxy\r \r platform, it spins up a separate Docker container\r \r for that user,\r \r and that allows you to to leverage things like Kubernetes fairly easily,\r \r and it does allow for some, you know, additional security. You're able to deploy\r \r your Shiny apps,\r \r as as Docker images, which is is really nice in terms of reproducibility\r \r as well. But, you know, ShinyProxy is something that that we leverage pretty heavily both internally and for our clients. This was exciting to me and I know that there's some other folks out there that,\r \r leverage this project as well as it's it's one of, the the multiple Shiny hosting options that you could have. And the new features in ShinyProxy,\r \r 3.1\r \r are, as opposed to what I just said, you know, when a user clicks on an app, it spins up a a brand new separate container for them. In 3.1.0,\r \r we have the option for some pre initialization\r \r of that container or sharing of that container across multiple users. So,\r \r sometimes when a Docker container sort of is is spinning up depending on how large that image is, it can take some time to spin up and users may have to wait, you know, 5, 10, 15 seconds,\r \r something like that, for that container to spin up and for them to actually be able to see their application. So\r \r 3.1.0 provides some opportunities for pre initialization\r \r of those containers and actually sharing,\r \r containers across users such that an already running container can be leveraged, by a second user.\r \r\n\nThe other, big update is that, you know, up to now, ShinyProxy\r \r supported 3 different container back ends. That was Docker, Docker Swarm,\r \r and Kubernetes.\r \r Now there is a brand new back end, AWS\r \r ECS,\r \r which is pretty exciting. I think AWS ECS,\r \r allows you to or or maybe, they take care of some of the server setup,\r \r and scaling\r \r that you might have to have rolled your own, if you're using Docker, Docker Swarm, or Kubernetes. So it's nice that that abstracts it away from you. But as Peter Salomos notes in his, hosting data apps blog that that recaps this 3.1.\r \r O release. You know, one downside of of AWS ECS is that in most cases, it takes more time to start the container compared\r \r to other back ends. But now that we do have this this pre initialization\r \r and container sharing capabilities in 3.1.0,\r \r we might be able to reduce that startup time to something that's that's even less than a second,\r \r if we are able to take advantage of those new features. So, there's some additional stuff in there, but but really exciting,\r \r for myself and maybe those others in the community that that leverage ShinyProxy.\r \r\n\n\n\n[00:44:28] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 28,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. These are fantastic\r \r updates, and I can underscore the importance of that\r \r pre initialization\r \r feature because\r \r sometimes with whoever you're, you know, sending this to, you might have to,\r \r have to think about, okay, what are the best ways to enhance user experience. Right? And loading times is unfortunately one of them for better or worse. So be able to have that ready on the fly, I think, is massive.\r \r And for all the DevOps engineers out there that may have been, you know,\r \r what we call an r admin that's administering shiny proxy or maybe working with IT\r \r to support that. What I really appreciate,\r \r as you mentioned, Mike, with the ECS, you know, new back end implemented,\r \r If you're wondering how that might fit for some of the automation, like deployment pipelines,\r \r they linked to in this post\r \r a,\r \r a repo that has an example for Terraform, which is a very popular dev ops, you know, system configuration\r \r platform for automation. So I I I have a few HPC admins in my day job that would appreciate seeing that because that's Terraform all the things with Chef. So this might be something that if we do shiny proxy in the future, I'll be sending this their way. But, yeah, really, really exciting to see these updates for sure.\r \r\n\n\n\n[00:45:43] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I have somebody on my team who's big into Terraform. It's not something that I've stepped into yet, but it seems pretty awesome for sort of just writing maybe kind of like a a Docker file of your pipeline in terms of your entire setup. You know it's fairly\r \r easy to read, easy ish to read, and it's sort of just listing out the instructions of the infrastructure that you wanna set up. It's pretty cool.\r \r\n\n[00:46:06] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. There's a lot in this space that I've been, you know, trying to learn up on on my time. I've gone kinda far, but I've been learning up on Chef and Ansible\r \r and a little bit of Terraform, but, there's only so much time in the day. But, nonetheless, there is so much more we could talk about in this issue, but we would be here all day if we did. So we'll just invite you to check out the rest of the issue at rnp.org\r \r along with all the other resources that we mentioned in this episode as well. It's all gonna be in the show notes.\r \r And by the way, if you are listening to this show on one of those more modern podcast apps like pavers or found, you may have noticed we've actually upped the production quality to show quite a bit where now you get not only the chapters, which we've always done, we've got chapter image,\r \r images\r \r that will directly link to each of the highlights that we talk about. So I think that's pretty cool if you're taking advantage\r \r of the modern tooling here and also\r \r a big win for accessibility,\r \r each episode now has a transcript directly generated into the show, which,\r \r ironically, even Apple has adopted recently. So you should be able to get that in many of the podcast apps that you listen to this very show. And, we love hearing from you and the audience as well. But, of course, the art weekly project itself goes\r \r with the community. It's powered by the community.\r \r\n\nSo if you see a great resource you wanna share with the rest of the art community, we're just a pull request away. It's all at rwiki.org\r \r and click in the upper right for that little GitHub icon, and you'll be taken to the next week's issue draft where you can put in your link. And our curator of the week will be glad to merge that in after a review.\r \r And, also,\r \r we'd love to hear from you as well directly.\r \r There are many ways to do that. The fun way, of course, is if you're on one of those aforementioned podcast app, you can send us a fun little boost along the way, and we'll be able to read it directly on the show. And,\r \r it was fun to be on the Friday show because I I did get a few boosts sent my way because I was part of what they called the valued split at that point for that segment. So lots of fun shout outs about the r language and whatnot and are nerding out on that side of it. But, also, you can contact us on the various social media handles.\r \r\n\nI am mostly on Mastodon these days with at our podcast at podcast index dot social.\r \r I'm also sporadically on x Twitter, whatever you wanna call it, with at the r cast\r \r and also on LinkedIn. Just search for my name, Eric Nance, and you will find me there. Mike, where can the listeners get a hold of you? Sure. You can find me on mastodon@[email protected].\r \r\n\n[00:48:38] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Mike Thomas",
        "trans_text": "If you search for my name on LinkedIn,\r \r you will probably find way too many Mike Thomases and not be able to find me. So, you can see what I'm up to if you search Catchbrook Analytics\r \r instead. That's ketchb\r \r r o o k.\r \r\n\n[00:48:53] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Very nice. And, yeah. That will wrap up the episode 100 and 65. We had lots of fun talking about these highlights of all of you, and we definitely invite you to come back again next week to hear us talk about yet more our community goodness of our weekly. So until then,\r \r happy rest of your day wherever you are, and we will see you right back here\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_20_highlights",
        "chap_timestamp": 2,
        "chap_text": "R visits Podcasting 2.0!",
        "chap_href": "https://podcastindex.org/podcast/920666"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "chap_timestamp": 43,
        "chap_text": "Aesthetically-pleasing R Timeline",
        "chap_href": "https://www.rostrum.blog/posts/2024-05-08-aesthetic/"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "chap_timestamp": 34,
        "chap_text": "Another DuckDB Benchmark",
        "chap_href": "https://www.appsilon.com/post/r-dplyr-vs-duckdb"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "chap_timestamp": 43,
        "chap_text": "TLG Gallery powered by WebR",
        "chap_href": "https://pharmaverse.github.io/blog/posts/2024-05-08_tlg_catalog_webr/tlg_catalog_webr.html"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "chap_timestamp": 40,
        "chap_text": "Devcontainers for Quarto",
        "chap_href": "https://github.com/coatless-quarto/quarto-webr-pyodide-demo"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "chap_timestamp": 21,
        "chap_text": "ShinyProxy 3.1.0",
        "chap_href": "https://www.openanalytics.eu/blog/2024/05/07/shinyproxy-3.1.0/"
      },
      {
        "ep_name": "issue_2024_w_20_highlights",
        "chap_timestamp": 19,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_19_highlights",
        "ep_date": "2024-05-08",
        "ep_duration": 6,
        "ep_description_short": "Our take on the important conversations spurred by the recent R deserialization CVE, how simulations may save you from cracking open that probability textbook, and recapping the exciting 2024 Shiny Conference. Episode Links This week's curator: Colin Fay - @[email protected] & [@ColinFay]](https://twitter.com/ColinFay) (X/Twitter) Everything…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_19_highlights",
        "description_long": "\r \r Our take on the important conversations spurred by the recent R deserialization CVE, how simulations may save you from cracking open that probability textbook, and recapping the exciting 2024 Shiny Conference.\nEpisode Links\n\nThis week's curator: Colin Fay - @[email protected] & [@ColinFay]](https://twitter.com/ColinFay) (X/Twitter)\nEverything you never wanted to know about the R vulnerability, but shouldn't be afraid to ask\nCalculating birthday probabilities with R instead of math\nHighlights from ShinyConf 2024\nEntire issue available at rweekly.org/2024-W19\nSupplement Resources\n\nR-bitrary Code Execution: Vulnerability in R’s Deserialization https://hiddenlayer.com/research/r-bitrary-code-execution/\nCVE-2024-27322 Should Never Have Been Assigned And R Data Files Are Still Super Risky Even In R 4.4.0 https://rud.is/b/2024/05/03/cve-2024-27322-should-never-have-been-assigned-and-r-data-files-are-still-super-risky-even-in-r-4-4-0/\nSafety Radar for RDA Files https://github.com/hrbrmstr/rdaradar\nR's new exploit: how it works & other ways you're vulnerable (Josiah Parry) https://www.youtube.com/watch?v=WGvXEi4nG5k\nBogus CVE follow-ups https://daniel.haxx.se/blog/2023/09/05/bogus-cve-follow-ups/\nData serialisation in R https://blog.djnavarro.net/posts/2021-11-15_serialisation-with-rds/\nTapyr https://connect.appsilon.com/tapyr-docs/\nPodcast Index Database Dashboard (built with R and Quarto) https://rpodcast.github.io/pod-db-dash/\nEric will be a guest on the Podcasting 2.0 show this Friday! (10-May-2024 1:30 PM EDT) https://podcastindex.org/podcast/920666 \nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\n \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\n \nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nGreen Glade Groove - Donkey Kong Country 2: Diddy's Kong Quest - TSori, dpMusicman, etc - https://ocremix.org/remix/OCR04437\nSalut Voisin! - Final Fantasy IV - colorado weeks, Aeroprism - https://ocremix.org/remix/OCR04553"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://fosstodon.org/@colinfay"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://twitter.com/ColinFay)"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://aitap.github.io/2024/05/02/unserialize.html"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://www.andrewheiss.com/blog/2024/05/03/birthday-spans-simulation-sans-math/"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://www.appsilon.com/post/shinyconf-2024-recap"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://rweekly.org/2024-W19.html"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://hiddenlayer.com/research/r-bitrary-code-execution/"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://rud.is/b/2024/05/03/cve-2024-27322-should-never-have-been-assigned-and-r-data-files-are-still-super-risky-even-in-r-4-4-0/"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://github.com/hrbrmstr/rdaradar"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://www.youtube.com/watch?v=WGvXEi4nG5k"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://daniel.haxx.se/blog/2023/09/05/bogus-cve-follow-ups/"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://blog.djnavarro.net/posts/2021-11-15_serialisation-with-rds/"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://connect.appsilon.com/tapyr-docs/"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://rpodcast.github.io/pod-db-dash/"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://podcastindex.org/podcast/920666"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://ocremix.org/remix/OCR04437"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "links": "https://ocremix.org/remix/OCR04553"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We are back with episode 164 of the Our Week of Highlights podcast. This is the weekly show where we showcase the latest highlights and awesome resources that you can see every single week and the Our Weekly issue at rweekly.org.\r \r My name is Eric Nanson.\r \r Yeah. I'm on demand. I'm sounding a bit more like my normal self. So thanks to all of you for persevering through that last week if you're listening to\r \r that. But we have a lot to discuss today, and I'm not going to do this alone. And there's no way I could do it alone today because I have my awesome cohost with me, as always, Mike Thomas. Mike, are you ready for a jam packed episode?\r \r\n\n[00:00:38] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'm ready, Eric. The highlights are heating up. It's it's heating up here on the East Coast.\r \r\n\n[00:00:43] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And I don't know if you wanna hear this or not, but my Boston Bruins are heating up as well. Yeah. You know. Yeah. Yeah. At that point, you know, when you get to game sevens, they're a coin flip. But, yeah, once they got through that\r \r pesky, Toronto Maple Leafs, now they're gonna they're gonna give those, dreaded Panthers a run for their money, it looks like. So fun times ahead for you. We'll see. We'll see. Well, revenge in action because last year, they, they got a rude awakening and 7 games from them. So maybe\r \r the revenge factor strikes again like it does in pro sports. But,\r \r yep. But we don't have any revenge to conduct against each other. We're good friends as always. But, of course,\r \r this issue is, of course, not built by us. It is built by the R weekly team. And in particular, this issue was curated by the esteemed Colin Fay, of course, the architect of all things GOLM and many of our shiny awesome\r \r packages.\r \r\n\nBut, of course, he had tremendous help from our OurWeekly team members and contributors like all all of you around the world. Well, if you had to guess where we're gonna start, it's probably not so much a mystery because this has been making the waves for the past about 2 weeks now in the R community and even other tech sectors outside of R itself.\r \r We are, of course, talking about the recently disclosed\r \r critical\r \r vulnerability exploit or CVE\r \r that was disclosed with respect to the serialization\r \r of particular r data types with the RDS format.\r \r And we had a little bit of a mention of this last week because it was literally late breaking as we're recording\r \r in last week's episode. But if you're not familiar what we're talking about here, it was about,\r \r about near the end of April, April 29th, to be exact.\r \r\n\nA vendor called Hiddenware,\r \r who I've not heard of before this particular story,\r \r had this had disclosed the vulnerability\r \r called CVE\r \r 202427322.\r \r I don't expect you to memorize that, but all the links are in the show notes.\r \r But this is describing that an exploit that you can\r \r utilize in previous versions of R\r \r up to version 4.4, where apparently this has been patched,\r \r where you can inject arbitrary\r \r code to be executed\r \r into an RDS serialized\r \r file\r \r through means of clever uses of the headers inside that file\r \r and taking advantage of concepts like PROMISE for evaluation\r \r and the like.\r \r\n\nWe won't read that post verbatim here. You can look in the show notes for it.\r \r But as I expected, when this broke, I thought there would be some additional either fallout slash follow-up\r \r from the community, especially for those that are in tune with both the intersections of data science\r \r and infosec or information security.\r \r And this first highlight is one of those responses we're gonna dive into along with a bunch of related\r \r resources.\r \r And this post comes from Ivan Krivlov, who I believe has been featured in previous highlights.\r \r And his post\r \r succinctly titled,\r \r everything you never want to know about the r vulnerability,\r \r but shouldn't be afraid to ask. I think that's an awesome title\r \r because this is really going to break it down piece by piece\r \r in terms of what this practically means\r \r in terms of our day to day for the usage of R and just what is going on under the hood.\r \r\n\nOne thing that we're going to say right off the bat\r \r is that\r \r this\r \r specific instance in this CVE is just one example of how potentially, and I do mean potentially,\r \r someone could exploit certain features of the R language\r \r to, you know, do malicious things on a on a somebody's system and whatnot.\r \r But these are features\r \r of the language itself, and R is most definitely not alone\r \r in having these features in place. We'll get to that in a little bit.\r \r But in essence, Ivan starts off the post\r \r with kind of some background on the RDS and R data file formats.\r \r Where they are, their job is to directly represent\r \r the state of an art type of object.\r \r\n\nAnd I mean really\r \r represent it. In essence, serialize it such that it can be completely reproduced on another system or another installation of R via the loading functions for that particular object.\r \r Now these objects\r \r do, by nature,\r \r often contain code that needs to be executed on the system related to R itself.\r \r A good example that he calls out here is a lot of those model fit objects that you might pass around based on a linear regression fit or whatnot.\r \r It's gonna contain code VSA s three methods or others under the hood\r \r to do certain things with, say, the data that was supplied in that model fit, looking at model assumption, you know, model metrics and whatnot,\r \r that's by design, folks. That's always\r \r been there.\r \r\n\nSo, yes, what this vulnerability really is is just finding clever ways to inject\r \r additional\r \r execution of code\r \r in these places, in these serialized objects so that you could take advantage of it.\r \r But if you really wanna get really deep it, it's not that easy.\r \r He does have examples talking about the anatomy\r \r of a particular vulnerability like this, of how you might have to get into\r \r the source of R itself and how it serializes\r \r objects and try to interject things in between if you want to do something really\r \r nefarious.\r \r\n\nBut in the end, this is all things that have happened in other languages as well. And that's where he leads off with, at the end, you know, our friends in the Python community, this is something they've been dealing with for years\r \r with respect to an arbitrary\r \r serialized object called pickle,\r \r often used\r \r in machine learning model fits, prediction modeling in general.\r \r There's nothing stopping a nefarious person from injecting\r \r Python code.\r \r He got somewhat hidden in that object where if you don't know to look for it, you might miss it.\r \r But I'm going to take a step back here and think about an example that I've been telling people as they've been asking me about this.\r \r\n\nWe live in this era of digital communication. Right? And what is the most you know, one of the most direct means of communication these days\r \r is the good old email message. Right?\r \r You often have text and email, but you might also have something else with it called attachments.\r \r And I know in my organization,\r \r they put us through very rigorous training\r \r to say, did you get an attachment with someone you trust?\r \r If not, you might wanna think twice about opening that up on your system.\r \r And that's where I think the CV is bringing the light\r \r maybe something that I don't know if glossed over is the right word, just hasn't been talked about much, is that these\r \r serialized data objects\r \r have always had this capability.\r \r\n\nThe question is, do you trust\r \r the process that's building it and who is sending that to you?\r \r And with that, on top of Ivan's post, we've got other terrific resources here that I'll put in the show notes\r \r that really dive into the practicalities of what the CV really means.\r \r In particular, Bob Rudis has an excellent post on his blog,\r \r and he is very, opinionated on this. Although, frankly, I share his opinion.\r \r This probably never should have been a CVE in the first place. Again, this is not a unique problem to R.\r \r This is the language operating as, quote, unquote, its design.\r \r\n\nIt doesn't take away\r \r our responsibility\r \r as end users\r \r to be, you know, critical of when we're receiving these data objects,\r \r verifying the source. And in particular, he's got a proof of concept in his GitHub repository\r \r that will let you scan these data objects to look for potential vulnerabilities or potential\r \r nefarious code injections inside.\r \r That's just one example.\r \r And another great example linked to is Josiah Perry\r \r just has a very brief or to the point video on his YouTube channel\r \r about how you can take advantage of these exploits as well, again, using fundamental features of the language\r \r that are not gonna go away anytime soon, nor they should\r \r of you know, executing arbitrary code in s 3 methods\r \r and other, you know, methods that you get when you load a data object into your memory.\r \r\n\nAnd then a couple other things before I, well, glide down here\r \r is that the concept of CVEs in general, while, of course, I acknowledge they are hugely important\r \r in the realm of security,\r \r there's always more than meets the eye about this. So I found this great interesting post from Daniel Stenberg\r \r who has a interesting take on the CVE process and some of the nuances behind it in light of disclosures back a few years ago with respect the curl utility\r \r and other frameworks.\r \r Just something to have in the back of your mind as you see this reported in the general tech sector\r \r of these outlets that aren't really going really deep into this story. And that's what we're trying to do here. We want you to give you the resources to do more follow-up on your own and make your own call about what this means to you. We're just sharing what it means to us.\r \r\n\nAnd then lastly, if this whole data serialization\r \r topic is new to you, like it was to me even just a year or so ago.\r \r Another link I'll throw in the show notes is Daniel Navarro\r \r has an awesome blog blog post, easy for me to say, about how data serialization and r really works, in particular, the RDS format. So you can kinda see the nuts and bolts of how this works. So my takeaway is\r \r I think this v CVE, while I don't really agree with how it was disclosed and\r \r highlighting a feature of a language itself that's not in and itself a vulnerability.\r \r I am at least\r \r you know, happy is probably not the right word, but I am glad that it's bringing to light\r \r the the discussion that we've had internally in my company, but also others in the community\r \r about really being responsible about how we're using these data that's supplied to us or being built by these other processes.\r \r\n\nSo I think that's good that's good discussion to have. I've seen it on Mastodon. I've seen it on LinkedIn and other places.\r \r So maybe it is that wake up call that the community needed that the art language has grown enough in popularity\r \r\n\n[00:11:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "that now we really have to think critically about these methods that could potentially be used again for nefarious means. But, Mike, I've rambled enough. What's your take on all this? No. Eric, I share a lot of the same thoughts, and it's I'm glad that you pointed out Danielle's, blog post there because that was one that came across my mind when I was reading, you know, all the different blog posts around this topic because really what underlies\r \r the issue here is, you know, serialization and deserialization\r \r of of our objects and how that works. And I think\r \r a large, you know, sort of,\r \r point to projects like the the Parquet project was to try to get away from some of that serialization and deserialization\r \r of language agnostic\r \r or or yeah, language specific,\r \r I should say, you know, formatted objects like RDS files, like pickle files, and to try to be able to store data in more of an agnostic way, that doesn't involve serialization that allows users,\r \r to be able to to to work with that data no matter, what language they're in. But obviously, we don't have something like that when it comes to something like a model object, right, or storing, you know, pretty much anything else, you know, in an RDS file or and I believe on the Python side in a pickle file, you can pretty much store anything you want\r \r in those files, which is incredibly useful,\r \r when it comes to doing things like machine learning and and having to, you know, deploy\r \r a machine learning model. Right? You want don't wanna have to retrain that model,\r \r as part of your production process. You wanna\r \r train that model, store it as a some sort of single object that makes it very easy to make predictions, to load and make predictions against. And that's where a lot of the times we'll use RDS files\r \r or or pickle files on the Python side.\r \r\n\nBut, you know, I certainly share your sentiment that if nothing else\r \r this\r \r CVE\r \r brings to light, you know, the point that\r \r you need to trust the sources of your RDS or your pickle files,\r \r completely.\r \r And, you know, if someone I I thought of this this sort of use case here that I think I've seen before, you know, in, like, a GitHub gist, you're you're trying to solve a problem.\r \r You're you're diving deep into to GitHub and to Stack Overflow,\r \r places like that, and you finally, you know, see somebody who has a reproducible example\r \r with some code, but in order to run that code, right, they they've also attached a file. There could be a CSV,\r \r could be an RDS file, a pickle file, something like that. And you you need to have that file to be able to run their code. Right? They weren't able to create, like, a full reproducible example for for whatever reason just based out of code where they they sort of simulated that data. You they're providing you this file that you're going to need to run that gist or run that example.\r \r\n\nAnd\r \r maybe in the past,\r \r you know, depending\r \r on where that file was was located, depending\r \r on, you know, who the author is of that that gist. If it's a\r \r repository of someone, you know, well known that you trust, maybe it's in the Pandas project or the DeepLiar project and it's posted by, you know, somebody from somebody from Posit or or Wes McKinney or something like that,\r \r maybe you're you're likely to trust that file and to download it and run it against that code.\r \r But if it's,\r \r you know, that that gets into a very sticky situation. And I think\r \r it's just a good time maybe to remind your team in situations like that that they need to exercise extreme caution when opening and opening any file. Right? And and the the open source community,\r \r I think relies on a lot of trust\r \r for better or for worse. Right?\r \r\n\nAnd,\r \r you know, I guess this is just a good time for us to sort of step back\r \r and remember\r \r that,\r \r you know, there there could be bad actors out there and that we we have to deal with a lot of skepticism,\r \r in order to ensure the safety of the data products that we're creating and deploying to production.\r \r So, you know, like I said, if nothing else, you know, this is maybe a good time to to do that step back\r \r and to think twice. You know, admittedly,\r \r when this came out, you know, the the fact that that NIST, which I believe is, like, the government,\r \r entity, National Institute, Institute National Vulnerability Database is the NVD,\r \r place where this got posted to. And NIST is the big, you know, cybersecurity\r \r risk management,\r \r you government entity out there. So whenever you see something come across NIST,\r \r you know, and I'm thinking of, like, you know, a lot of the organizations\r \r constantly watching what NIST is publishing.\r \r\n\nSo if this came across their desk and, you know, NIST is sort of blasting this this new R vulnerability,\r \r It's something that we need to pay attention to and we need to engage in communication with those stakeholders to to really bring all sides of, you know, the the discussion to the table so that we can sort of understand, you know, exactly how this impacts us, what what's the messaging that needs to take place, What are any changes,\r \r if any, you know, that need to take place?\r \r And, you know, I think, again, sort of some of the the blog posts from from Bob's, sort of some of the blog posts here that we're we're reading from Ivan, you know, may just\r \r reiterate the the need that the the messaging, and the conversations, and the reinforcement of, you know, best security practices is is maybe more important here than actually making any changes to your R infrastructure.\r \r\n\nSo admittedly, you know, when I I did see this initial\r \r blog post come across from Hidden Layers\r \r and, you know, this new entry in the national vulnerability database\r \r come across,\r \r it was, you know, it was sort of big scary news a little bit. I put out a LinkedIn post, you know, talking about that we're we're sort of advising our clients to up to to our 4.4.0\r \r for new projects that they have and just to exercise that caution on RDS files or RDA files or any sort of, you know, pickle type file that, you know, you don't know exactly where it originated from. I I think those two pieces of advice are are still, you know, solid pieces of advice But in terms of, like, going backwards and and blowing up any processes that you had in place that maybe don't have anything to do with with the RDS or RDA files or something like that. I I don't think there's a need for that,\r \r at all. But obviously, a lot of opinions on this subject. I'm glad that we're getting a lot of opinions on this subject and folks are taking the time to really dig in here,\r \r but but this is sort of a a great blog post from Ivan to provide that perspective. It comes with a lot of links,\r \r a lot of citations, and I sincerely\r \r appreciate his work on this post.\r \r\n\n\n\n[00:18:16] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Likewise. And, yeah, there's been there's been a a few others as well, and Bob's been quick to acknowledge others in his blog posts that have really been looking at these issues, you know, for a long term. But now ever since this came out, they were looking at even more. So Conrad Rudolph's another one. I call Davydov is another one if I'm saying it correctly. They've been on Mastodon looking at different proof proof of concepts of how this exploit\r \r could be utilized. But, again, the message is\r \r is that the language itself\r \r is still\r \r doing what it expected, that that it it hinges on this type of feature\r \r in terms of, you know, serializing\r \r data objects as efficient ways of transferring and whatnot.\r \r\n\nBut I do like your your callout about other formats that are taking shape in the community, such as parquet and the like.\r \r And with respect to putting on my life sciences hat for a second, there was questions I would get about,\r \r what does this mean in terms of if we use r for clinical submissions and whatnot?\r \r Well, guess what? It's very strict guidelines with respect to regulators that we transfer data\r \r in a very specific format that is not a serialized\r \r object. They have very rigorous\r \r procedures in place to eliminate\r \r the hint of any file being transferred that is, quote, unquote, executable in that sense. So we wouldn't even be bothering with these formats in a clinical submission as as of now.\r \r\n\nBut the other piece that I thought about, and I may mention this at the end of the episode, is I've been been working on a side project\r \r with a portal dashboard and GitHub actions that does\r \r duplication analysis\r \r but, and also a data quality check. But then I'm sending extracts\r \r of, like, each of the, quote, unquote, failed quality checks\r \r in 2 file formats, RDS\r \r and parquet.\r \r But the key point is that if someone is wants to inspect that themselves and maybe they are our user as well and they wanna see the RDS file for that particular step of, like, looking at duplicate\r \r IDs in a database or whatever.\r \r\n\n1st, they got a choice of which data format to pick from. But second,\r \r if they wanna see how I produce the RDS file, guess what? It's all in the open. Right? That's the nature of open source. I have all my my my GitHub action, our script,\r \r all in there that's run every week, and they can see for themselves\r \r what algorithm I'm using, how I'm serializing at the RDS,\r \r and, hence, transparency\r \r when it is available, I think, is paramount in these situations. So\r \r I think, you know, leaning on that but also leaning on the practical,\r \r you know, you know, practical, you know, thinking process, thought process\r \r of, you know, being critical about your data sources\r \r and then being transparent to your customers or your other colleagues about how this is being produced.\r \r\n\nI think that is being brought to the forthright\r \r foreflight here, so to speak.\r \r And I hope the discussion keeps going in this direction\r \r and not just tunnel vision on this very specific CVE itself because that's missing the point.\r \r This when we bring back the point to the general use of open source, the use of these serialized formats in general,\r \r again, nothing new in this ecosystem.\r \r It just so happens that it got popular enough that it became the light. So I guess that's that.\r \r\n\n[00:21:38] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Or if, in Bob's take, you know, I think there's some sort of a conference coming up and somebody may have been looking for a little clout, heading into that conference. So who who knows? A lot of a lot of different possibilities\r \r out there, and I would\r \r definitely,\r \r sort of recommend\r \r that folks take the time to read up on this across all these different perspectives\r \r and and form their own opinion and and figure out how to,\r \r best\r \r communicate this and and make any changes necessary within your own organization.\r \r\n\n[00:22:16] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Well, Mike, let's lighten up the mood a little bit, shall we? Because, we're gonna we're gonna go back to school a little bit. But\r \r I hear there's a way we can even circumvent some of those hard math details in our next highlight here. And this is coming from Andrew Heiss who has been a frequent contributor\r \r to the our weekly highlights in in many episodes ago.\r \r And he has this great post on how you can take advantage of a method I've been utilizing in my day job for years,\r \r of simulation to help calculate probabilities where you might have had to rely on those,\r \r you know, famous or infamisimally or prospective math formulas\r \r that you might have seen in grad school. So what are we talking about here is that this is motivated by situations\r \r where maybe you're asked or you're teaching a concept\r \r that has to deal with some very, you know,\r \r intricate concepts and probability.\r \r\n\nI don't know about you, Mike, but I remember in my stats or math coursework,\r \r whenever you got the probability,\r \r you always were hit to that problem of you got, like, 1 or more of these urns of red, green, or yellow balls or whatever. Nice. And you gotta pick pick which what's the probability of getting, like, at least one of each color or 2 colors and not that one and whatnot.\r \r That's where Andrew in this post starts with, you know, a little refresher\r \r on how to use common\r \r metrics\r \r to represent\r \r the pool of choices from these balls and these earns\r \r and choose k, you would often call it. So the formulas are all there.\r \r\n\nYou I remember in the old days, I used the old TI 85 to calculate all this.\r \r Shout out to all the TI 85 nerds out there.\r \r We may or may not put games on it, but that's what I'm sorry for another day. But in any event,\r \r guess what? You can do this in r itself. There's the choose function. Right? There's choose, and you can say out of 40 balls, choose 5. What are the number of possibilities\r \r you can get there? And then, of course, you can do that for your answer. It gets a little more complicated when you get to more nuanced questions of\r \r maybe at least one red, blue, or green ball. Then you can see in the post here, there's lots of different\r \r combinations they have to sort through in your numerator and denominator.\r \r\n\nAnd, yes, you can use r for it, but, again, you've got you've got a lot going on there.\r \r Well, Andrew mentions way back in his training in 2012, he had a professor\r \r that kind of mentioned a comment at the end of one of his lectures\r \r that, you know what? You could get a similar answer as what you're doing in this math probability\r \r through simulation.\r \r And, of course, I'm sure if I had heard that at the time, I probably would have had that light bulb moment in my head too of like, hey. I wonder if I could circumvent some of this gnarly\r \r math formulation. And sure enough,\r \r you certainly can.\r \r\n\nSo Andrew\r \r dug up some old some of his historic r code. Again, credit to him for being transparent on this of a 4 loop that he created to simulate that earned problem of choosing\r \r at least one color probability of choosing at least one color out of that.\r \r And it's a pretty intuitive for loop. Right? You'll see it in the post, but when you read it, you grok what's happening there without the need of those fancy combination formulas.\r \r Now where does this mean practically? Well, he was inspired\r \r by a post he saw on Blue Sky\r \r of someone asking in their household.\r \r\n\nThey have an n o six. They have all their birthdays inside a 6 month interval.\r \r How likely or unlikely is that in practice?\r \r That's an interesting birthday problem, if I dare say so myself.\r \r So the rest of this post goes into all the different ways that we can address this.\r \r And one neat way to address this first\r \r is taking advantage of a unique\r \r geometric representation\r \r to see just how this shapes up in terms of how the months are related to each other.\r \r And he mentions creating a radial chart of sorts,\r \r taking advantage of a newer GEOME that's supposed to ggplot23.5.\r \r And there's code here in the blog post\r \r to do this.\r \r\n\nI believe it's called GM radio\r \r or if I recall correctly. Yep. Oh, cord radio. Yep.\r \r Yep.\r \r And there's some great visuals here,\r \r for his household\r \r where these birthdays fit birthday months fit in this spectrum. And if they're in a 6 month window, they're going to be all within\r \r a half circle radius of each other or half circle on the on the perimeter,\r \r if you will. My geometry is rusty, folks. Bear with me here. But it gets even more gnarly of that when you start thinking about,\r \r well, now let's try to generalize this a little bit. And what happens in the case where a birthday is from a previous year,\r \r but it's still within that 6 month window? How do you navigate representation on that?\r \r\n\nSo he's got some examples of how you do a clever use of additional segments to go from the previous year to the January 1st date of the new year and visualizing that. So there's great code in ggplot2\r \r that walked through how he is able to accomplish this visualization\r \r and how it handles birthdays outside that 6 month scope and wealth within it. And like I said, with years overlapping and whatnot,\r \r but that's just the visualization\r \r part. Now, the actual\r \r calculation of the probabilities at hand,\r \r this is where\r \r I've always said dates, times, time zones are hard. And this is another situation here because you can't quite get away with representing the birthdays\r \r on this perfect circle because\r \r in calendar years, we got different days a month. We got the leap year to deal with and whatnot.\r \r\n\nSo there's a lot of custom code that's needed\r \r to derive\r \r things like the distance between the the earliest date and the latest date,\r \r accounting for year transitions,\r \r trying to transform this into a pseudo circle representation.\r \r There's a lot of interesting code here that's doing a hybrid of, you know, per map reducing\r \r and arithmetic with respect to these birthday dates, sometimes having to multiply\r \r time spans by 2 and whatnot to make this happen.\r \r And then once you get through kind of the algorithm side of it,\r \r now you gotta actually perform the simulation.\r \r\n\nAnd, again, taking into account leap years and whatnot.\r \r So he does come up with a function that takes advantage of some of the algorithms he develops early in the post\r \r to start simulating this. And, again, at this first glance, from a uniform type setup,\r \r assuming all birthdays could be, you know, occurring equal on equal days in the calendar.\r \r On the surface, that seems like a a gen like a reasonable assumption.\r \r Actually, not so much.\r \r And this is where at the end of the post, he discovers that there are sources from the CD and the Social Security\r \r Administration here in\r \r the US that actually keeps track of daily births in the United States from in fact, in 538, that portal\r \r had a story in 2016 about the patterns in this. And guess what? They put their CSV files on GitHub that they use to assemble all this. So guess what?\r \r\n\nNow instead of assuming that it's a uniform distribution of these birthdays falling on any of the 365\r \r days of the year, we can actually sample from this known set\r \r of prior birthdays to get a more accurate representation\r \r of that distribution\r \r in in daily practice.\r \r He does this nice visualization\r \r of the kind of a heat map here\r \r showing that there are indeed\r \r portions of the calendar\r \r where birthdays are more common,\r \r such as, like, not many are current around Christmas and New Year's. Yeah. I wonder why, but that's an interesting thought exercise for everybody.\r \r But it it's right there. Yeah. You can see it's clearly not uniform.\r \r\n\nSo he's able to update his probability\r \r functions\r \r to utilize this type of distribution approach to sample from here.\r \r And then in the end, we get a nice little bar chart at the end or a lollipop chart, depending on how you wanna call it, where you look at, depending on the household size,\r \r the decrease in probability that all these birthdays occur\r \r in a 6 month window.\r \r To no surprise, when you have less number in the household, like 2 or 3,\r \r although, actually, 2, looks almost a 100%\r \r confident\r \r that you'll have birthdays that fall in the 6 month time span. But as you get the 3, 4,\r \r 5, 6, you start to see that kind of exponential decay, if you will,\r \r of seeing how unlikely it is to when you have a larger household, such as, like, 6.4%\r \r for an 8 person household.\r \r\n\nBut in the end,\r \r what is not in all the functions that he produced here to derive this answer?\r \r No call outs of probability formulas.\r \r No calls to that choose function.\r \r It is all based on a rigorous set of simulations.\r \r I admit there's a lot going on in this post here,\r \r but in the end, the approach is what I wanna take away from here is that when you're in doubt to find that maybe close form solution\r \r or that neat probabilistic,\r \r you\r \r know, derivation\r \r or formula calculation,\r \r simulation is your friend here. And with the computer technology we have and modern systems\r \r and whatnot.\r \r\n\nYou can get a great approximation\r \r to these answers even for fun problems like this birthday problem. So, again, felt like I was going to school here, but it was a great way to tie in multiple things that I do in the day to day. But explain in Andrew's a really great,\r \r\n\n[00:32:04] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Mike Thomas",
        "trans_text": "technique here. Well, I felt like I was going to school too, and I think it's fitting because I believe Andrew is a professor and he is also a machine\r \r because,\r \r this is a a lengthy phenomenal\r \r blog post with, you know, looks like it might be authored in in quarto or something like that with\r \r fantastic narrative,\r \r inline code,\r \r all these beautiful gg plots. You know, that's sort of what really stands out to me. It's just really the attention to detail on a lot of these gg plots\r \r as well. And\r \r I\r \r too, Eric, like you,\r \r really wish that I had been taught probability and statistics,\r \r with the concepts of of simulation,\r \r instead of the more theoretical approach that I was taught with. I think my grades probably would have been a little bit higher in that class if that had been the case, but, you know, what can we do now? It eventually\r \r clicks fortunately,\r \r and I\r \r imagine that Andrew's\r \r students are probably pretty grateful\r \r of his very practical and applied\r \r approaches,\r \r to explaining and demonstrating concepts\r \r like this. I I too thought it was pretty interesting,\r \r the idea that, birthdays maybe\r \r are not sort of normally\r \r distributed.\r \r\n\nAlthough,\r \r it looks like the difference between his simulation when he made that assumption that birthdays are normally distributed across the year,\r \r versus, you know, when he went to using the data from 538.\r \r The differences there are are pretty marginal, you know, with his household size of of 6.\r \r You know, assuming that there was a uniform distribution of birthdays, I think his simulation returned like a a 17.8%\r \r chance of all 6 of those birthdays occurring within the same 6 month window.\r \r And when he used that 538 data to simulate from, the percentage actually jumped or the likelihood actually jumped from 17.8\r \r to 19.3.\r \r\n\nSo a a little bit higher probability with 6 folks in your household that they will all have a a birthday within sort of a same 6 month window. I I thought that was, you know, fairly interesting. And really, it's the\r \r approach here. It's the practicality.\r \r It's the the tools that he's giving us to to execute the same type of analysis that I think are super useful. So I would recommend that that anybody\r \r who is maybe, having a difficult time or or just needs a refresher\r \r on, you know, sort of basic probability and statistics\r \r via simulation,\r \r check out this blog post. It's fantastic\r \r top to bottom.\r \r\n\n\n\n[00:34:38] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And I dare say it's also kind of a little gateway, if you will, to the concepts of Bayesian statistics as well with this idea of you may not know in real life what that distribution of outcomes or that set of data you're dealing with.\r \r When in doubt, you'll take what you do know,\r \r try to use that as prior information. Again, I'm using this on purpose, but these are things that again, when I was in school, I didn't know heads or tails about Bayesian probability. I was over in the Bayes theorem, which we just glossed over in 1 week, and then suddenly I'm off to the next convergence stuff.\r \r That is a fascinating\r \r world that we often\r \r dealing with with respect to the multitude of data sources we have.\r \r\n\nAnd it is very difficult to assume one type of specific recipe, if you will, for how these are being created in the real world. So simulations\r \r combined with Bayesian\r \r methodology,\r \r I think they put so much in the hands of you, the data scientist or statistician,\r \r to come up with meaningful answers\r \r in light of not knowing what is the real source of truth here. So, again, it's a great it's a great, you know, pseudo, you know, gateway to to that side of the world. And, yeah, I probably would have had a little better grades if I had something like Andrew as a professor, but we don't have that time machine yet, Mike. And, I dare say we ended up pretty well nonetheless, but, you know, hindsight is 2020.\r \r\n\n[00:36:02] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 2,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I think so too, Eric.\r \r\n\n[00:36:14] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 14,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And lastly on the show today, we're gonna talk about we referenced this a little bit last week, but we had the good fortune, both Mike and I, of attending\r \r the recent, shiny conference, 2024,\r \r that was held by Absalon.\r \r And our last highlight today is a little, very nice and insightful blog post that they had that they wrote earlier this week on their particular highlights from the conference. And trust me, as someone who's been on the other side organizing\r \r these type of events, it is always great\r \r to reflect back, and\r \r I think what they share is what I share as well.\r \r\n\nThe content that we saw at Shining Conf was absolutely amazing from top to bottom\r \r across many different spectrums of innovation on Shiny itself\r \r the respect to doing data for good, which is a track that was led by our good friend, John Harmon.\r \r And then our shiny life sciences track, I had the pleasure of leading that track and having a lot of great content as well\r \r and amongst much more about Shining and Enterprise as well.\r \r They first mentioned, you know, talk that we actually talked about in the highlights last week, the tailoring Shiny for modern users. There's a shout out here in the post about that.\r \r You gotta listen to last week's episode for our take on that particular talk.\r \r\n\nBut, also,\r \r one of the keynotes that gave a lot of attention there were a few keynotes, actually.\r \r But Joe Chang, of course, the CTO and author of Shiny himself,\r \r talked about the async interest session concurrency in Shiny with extended\r \r task. This has been in the works for a long time,\r \r but when the recording comes out, you'll definitely wanna watch this talk because\r \r if you've been down the promises train that was talked about years ago in one of the, Rstudio conf keynotes,\r \r You know that wasn't for the faint of heart. This is really trying to put async\r \r within Shiny apps in a much more accessible way to developers.\r \r\n\nAnd there's a lot to come in this space, I'm sure, as more teams adopt this.\r \r As well as, of course, the keynote that I was fortunate to recruit,\r \r George Stagg from from the Pasa team to talk about reproducibility\r \r of WebAssembly and WebR.\r \r And boy, oh, boy, there's some nuggets at the end of that talk. And when they come to fruition,\r \r oh, boy, the game is going to change in respect of reproducibility\r \r and package versions\r \r and the like. There's some big, big stuff happening in this space. So that was really fun to have charts talk about that as well. We're also fortunate to have Pedro Silva from Appsilog, give his keynote on the past and future are shiny\r \r and and so much more. And, apparently, there is an announcement that they're gonna have a new open source package in the works with respect to, I believe, something to do with Rhino.\r \r\n\n\n\n[00:38:58] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 58,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That's, that's a tease here. So I think it's already I think it's about a time between when we're recording today and when this blog post came out, I think it's already out. It's\r \r a new package called Tapyr, t a pyr,\r \r from Appsilon, which is sort of their Rhino approach to Shiny for Python. So it's building modularized\r \r Oh. Shiny for Python applications.\r \r\n\n[00:39:21] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Nice. Nice. So they they put the t's out and, apparently, it was announced after the fact. So, yeah, congratulations to them for that\r \r monumental achievement.\r \r And there were some fun stuff in in the conference as well. In fact, they had a little\r \r are which package are you quiz, which is a fun one to take. I remember taking that, and I I actually forgot my answer already. But I think it has something to do with data modeling or something like that, which probably isn't too surprising for me. Although I thought it might be a shiny thing, but I got gross. I'm a I'm a complicated case. Do you remember what you got on that score, Mike?\r \r\n\n[00:39:55] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 55,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I don't quite remember what I got. I might have missed that,\r \r I might have missed that game, but I would be very interested to see what I would come up with. Yeah. You have to try that out after this episode for sure. It might be a more complicated case, Eric.\r \r\n\n[00:40:08] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 8,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Yeah. We're we're we're we're, we're complicated folks, aren't we? But,\r \r but in the end, this was,\r \r I believe, the first of the shining conferences that had the multiple tracks. So, again, there's always pros and cons of that approach, but in the end,\r \r really excellent content nonetheless. And, hence, when the recordings come out, you might be able to catch up with what you missed. But, overall, that was a fantastic event, very well attended, and the engagement from the audience was top notch,\r \r\n\n[00:40:37] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 37,
        "trans_speaker": "Mike Thomas",
        "trans_text": "from top to bottom. So, Mike, what are your impressions of what you saw there? Yeah. That was fantastic. I mean, you covered a lot of the the ones that were big highlights for me between Joe Chang and and George Staggs.\r \r Another one that really resonated with me because I really appreciate\r \r someone who is actually\r \r trying to take an applied approach to quote, unquote\r \r AI was Tanya Casarelli's,\r \r best practices and lessons learned. I guess it was a real world use cases for AI in Shiny,\r \r which was just a fantastic talk and great to see a practitioner out there actually, you know, putting, you know, fingers to keyboard\r \r to spin up solutions that are helpful, for her clients with, you know, AI and Shiny as opposed to just a lot of those vendors out there that are just sort of yell AI at you with,\r \r with no\r \r sort of, you know, execution plan behind it. But I'll digress, you know, it resonated a lot with me because I have to give a very similar talk\r \r on applied AI use cases at a conference in August. So I may study up on on her materials again\r \r and rewatch\r \r it in on the recording in the RingCentral platform which folks who attended,\r \r have the ability to do.\r \r\n\n\n\n[00:41:54] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 54,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome. Yep. And like I said, watch out for those recordings. But, yeah, there was, I think, something for everybody. And, again, excellent,\r \r job by Epsilon, and congrats to them. Hopefully, they're getting some well deserved rest after that because I know after the our pharmas that I've helped organize in the past along with an excellent team, we're like, okay. We can exhale now, and then\r \r give us a couple weeks before we think about the next year. So\r \r in any event, what you do have to think about is where do you find content like this every week? Well, it's our weekly dotorg, of course, and we got more than much more than what we just talked about here. Collins put together a fantastic issue, and we'll talk about some additional fines over the next couple of minutes here.\r \r I'm gonna I'm gonna I'm gonna give a little plug to Collins organization, ThinkR, on their blog. They have a great blog post. If you ever felt a little intimidated or don't know where to start with\r \r after you find that awesome JavaScript library online, but yet you're not quite sure how to put that into your Shiny app, they have a great,\r \r example here about taking\r \r the Sweet Alert 2 JavaScript\r \r library and putting that into a Shiny application, which to no surprise is powered by Golem.\r \r\n\nSo this is a great, you know, compliment to what you might find in the existing, like,\r \r engineering production grade shiny apps book that I think R and Colin Fay have authored.\r \r If you want a kind of a quick take and you found that Sweet Alert 2 utility,\r \r how do you bundle the dependencies together? How do you inject that into your golem app manifest?\r \r And how do you build, you know, easy functions on the other side of things to call that JavaScript\r \r and passing the data back and forth.\r \r It can definitely be very helpful to see how this works in the day to day because\r \r in the end, you're probably if you're in the shiny space for more than a little\r \r bit, you're gonna be asked by a customer or maybe even yourself\r \r to bling it up a little bit, give a little more pizzazz with that awesome utility. And you're like, wait a minute. There's no package for that. What do I do? Well, this approach is a is a great way to call that out. And I didn't know there was a new Sweet Alert 2 library. I've been using Sweet Alert via Dean Nitelli's\r \r shiny alert package, so maybe I need to throw him a note to see if he's interested in something like this. But in the event, as a shiny nerd, that was right up my alley.\r \r\n\n\n\n[00:44:10] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 10,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Me too, Eric. That was a great find. One that was also right up my alley was a blog post from Athanasia\r \r Moical\r \r on the different IDE's that she uses. And,\r \r she flip flops sort of back and forth between RStudio and Versus Code in a way that is\r \r resonates very much with myself. She's Rstudio.\r \r Typically, for anything R related,\r \r if there's a a git conflict, you know, that's when she'll spin up a Versus Code window to be able to solve,\r \r those different git conflicts. And then for just about every other project or language, she'll use Versus Code. And there's just some great comparisons\r \r across the different features in RStudio,\r \r Versus Code. And also, you know, she talks about her her journey,\r \r you know, in her early days. She actually started out in MATLAB,\r \r as well as, like, the the Vim editor.\r \r\n\nAnd it really compares, you know, the features that she experienced\r \r along that journey,\r \r to the different tools that she was using across the different tools\r \r that she was using. And, it's a great rundown, resonated\r \r a lot with me because I think there's a lot of folks out there that are, you know, seeing some some of the different ways that you can do\r \r different things across different IDEs,\r \r even though a lot of the times it's it's just a matter of of preference. You can pretty much accomplish all the same stuff,\r \r depending on on which IDE you're in. It might just be, you know, different keyboard shortcuts. It might be, you know, different options to to set up, and and click on. But it resonated a lot with me and for any folks who are trying to navigate which IDE\r \r is best for them on their project. This might be a nice blog post to read.\r \r\n\n\n\n[00:45:49] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And being, in my opinion, having the awareness of each of these out there, but then knowing what are the best use cases for your environment or your projects is hugely important.\r \r I have an aspirational goal. I want to be just as fluent\r \r with using, say, the combination of Vim or Neovim with the r plug in\r \r as much as I am fluent with RStudio and Versus Code. That's my aspirational goal. I don't know if I'll ever get there, but, boy, I'm gonna keep trying more than ever. I've seen it. It's it is cool. It's very cool.\r \r Yeah. There's I've seen some screen cast by some good friends, and I'm like, how did you pull that off? Whether it's VIM or Emax or stuff.\r \r\n\nSome good cred there, I must say. But, you know how you get good cred, you read the rest of our weekly, I tell you, because it's gonna give you a boatload of additional\r \r insights that we couldn't cover today. So, again, if you don't know where it is, I'm gonna tell you again, it's rweaker.org,\r \r and we love hearing from you in the audience.\r \r We have a few ways to do that. We have a contact page in the episode show notes,\r \r Also, we have a modern podcast app, like, say, Poverse, Fountain Cast O Matic, CurioCast. So there's a bundle of others. You can send us a fun little boost along the way, and we'll get that message directly sent to us. And we'll be able to read it right here on this very show.\r \r And, also, we are sporadically on social media as well.\r \r\n\nI am mostly, I'm masking on these days of at our podcast at podcast index dot social.\r \r Speaking of podcast index,\r \r yours truly has a good fortune of joining\r \r Adam Curry and Dave Jones on the podcasting 2 point o show this Friday\r \r to talk about a quartile dashboard that I built with our quartile\r \r to visualize the podcast index database\r \r duplication analysis\r \r and quality checks with the point blank package. So if you wanna hear me talk about that, tune in this Friday around 1:30 EST.\r \r But in any event, I'm also on the, LinkedIn as well and also on Twitter with at the r cast.\r \r\n\n[00:47:48] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Mike, where can they find you? Eric, if I was in charge of editing this podcast, I would insert some celebratory\r \r applause.\r \r That is awesome. I'm very excited to listen to that that episode, and I'm sure that the folks,\r \r working, you know, on that project are are super,\r \r appreciative of the work that you put into building that quarto dashboard.\r \r Is that publicly available for folks to check out? It sure is. Oh, man. We'll put a link in the show notes. Put a link in the show notes. I would love to take a look at the final final product. I think I've seen some draft iterations as you've been working on it but I'd love to see the final products. That's awesome. Folks can find me on mastodon@[email protected]\r \r or you can check out what I'm up to on LinkedIn if you search for Catchbrook Analytics,\r \r k e t c h b r o o k. That's where you'll be able to to check out what I've been up to lately.\r \r\n\n\n\n[00:48:37] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "trans_timestamp": 37,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome stuff. And, yep. So we're gonna\r \r wrap up here on this edition of our weekly highlights, and, hopefully, you've been able to take away some good insights from us. We knew that this was a very important week for our show because of the big story that was at the top, but, certainly, give us feedback if you enjoyed the discussion or if you have other things you want us to discuss. In any event, we'll close-up shop here, and we'll see you back here for another episode of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_19_highlights",
        "chap_timestamp": 38,
        "chap_text": "Behind the R CVE",
        "chap_href": "https://aitap.github.io/2024/05/02/unserialize.html"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "chap_timestamp": 15,
        "chap_text": "Simulations to the rescue",
        "chap_href": "https://www.andrewheiss.com/blog/2024/05/03/birthday-spans-simulation-sans-math/"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "chap_timestamp": 13,
        "chap_text": "ShinyConf 2024 Recap",
        "chap_href": "https://www.appsilon.com/post/shinyconf-2024-recap"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "chap_timestamp": 34,
        "chap_text": "Integrating JS into Shiny",
        "chap_href": "https://rtask.thinkr.fr/pimping-your-shiny-app-with-a-javascript-library-an-example-using-sweetalert2/"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "chap_timestamp": 10,
        "chap_text": "IDE Roundup",
        "chap_href": "https://drmowinckels.io/blog/2024/ide/"
      },
      {
        "ep_name": "issue_2024_w_19_highlights",
        "chap_timestamp": 31,
        "chap_text": "Episode Wrapup",
        "chap_href": "https://rweekly.org/2024-W19.html"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_18_highlights",
        "ep_date": "2024-05-01",
        "ep_duration": 55,
        "ep_description_short": "Why R 4.4.0 may reduce your trips to a certain kind of stack overflow, a call to update your favorite Shiny application code snippets, and how the steller ASTHOS Profile Shiny dashboard has your hosts blown away and fighting the urge to refactor their applications UIs! Episode Links This week's curator: Eric Nantz: @[email protected]…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_18_highlights",
        "description_long": "\r \r Why R 4.4.0 may reduce your trips to a certain kind of stack overflow, a call to update your favorite Shiny application code snippets, and how the steller ASTHOS Profile Shiny dashboard has your hosts blown away and fighting the urge to refactor their applications UIs!\nEpisode Links\n\nThis week's curator: Eric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nWhat's new in R 4.4.0?\nIt's time to add bslib to your shinyapp snippet\nTailoring Shiny for Modern Users\nEntire issue available at rweekly.org/2024-W18\nSupplement Resources\n\nFull R 4.4.0 changelog https://cran.r-project.org/doc/manuals/r-release/NEWS.html\nR-bitrary Code Execution: Vulnerability in R’s Deserialization https://hiddenlayer.com/research/r-bitrary-code-execution/\nASTHO Profile dashboard https://astho.shinyapps.io/profile/\n{plotcli} command-line plots for R https://github.com/cheuerde/plotcli \nFritz Leisch (1968-2024) https://www.r-project.org/doc/obit/fritz.html\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\n \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\n \nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nTrippin' on the Bridge - Streets of Rage - lazygecko - http://ocremix.org/remix/OCR00993\nYou Are Not Confined - Final Fantasy IX - Sonicade - https://ocremix.org/remix/OCR01064"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://www.jumpingrivers.com/blog/whats-new-r44/"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://www.garrickadenbuie.com/blog/shiny-new-bslib-snippet/"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://lindsayjorgenson.github.io/Tailoring-Shiny-to-Modern-Users/#/tailoring_shiny"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://rweekly.org/2024-W18.html"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://cran.r-project.org/doc/manuals/r-release/NEWS.html"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://hiddenlayer.com/research/r-bitrary-code-execution/"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://astho.shinyapps.io/profile/"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://github.com/cheuerde/plotcli"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://www.r-project.org/doc/obit/fritz.html"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "http://ocremix.org/remix/OCR00993"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "links": "https://ocremix.org/remix/OCR01064"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back of episode 163 of the Our Weekly Highlights podcast. This is the weekly show showcasing the latest innovations and terrific resources that have been highlighted\r \r at ourweekly.org.\r \r My name is Eric Nanson.\r \r If you couldn't tell already, your your trusty host here is feeling a little bit under the weather here, but I'm gonna power through this because it's always exciting to talk about awesome art content with my trusted cohost right here virtually,\r \r Mike Thomas. Mike, I hope you're doing better than I am these days.\r \r\n\n[00:00:34] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I am, Eric. My allergies are in full bloom.\r \r Had a little bit of a tough time on the the golf course on Sunday,\r \r both allergy wise and\r \r golfing wise. But, we'll not talk about the latter.\r \r And but everything else is is going pretty well. I'll tell you what\r \r also bloomed was\r \r engagement on my LinkedIn post on dev containers. So keep gonna keep rolling on that topic. It seems like it's something that people enjoy hearing about. Yeah. I'm really excited to see see how much that took off, and I am\r \r\n\n[00:01:07] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 7,
        "trans_speaker": "Eric Nantz",
        "trans_text": "super thrilled that it's helping your team, you know, enhance your work flows. And, you know, once you once you go that route, it's very hard to go back because it just makes things so much easier to get effective collaboration in your dev environments because\r \r ain't nobody got time for package mismatches and all that fun jazz. Right? No. And system dependencies, system libraries, and stuff like that not being installed.\r \r\n\n[00:01:30] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. It's it's really changed the game for us from a collaboration standpoint. It it makes collaboration\r \r pretty much frictionless, which is amazing.\r \r\n\n[00:01:39] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 39,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And, yes, we are here to talk about our latest issue. And let's see who was that curator. Oh, yeah. It was me before I got this bad cold. So luckily, I was able to knock out some\r \r awesome resources here.\r \r Really terrific stuff we're gonna be talking about today.\r \r And as always, I have tremendous help from my fellow curators and contributors like all of you around the world. I will be honest. There weren't any poll requests this time, but luckily, many of you have submitted your websites to rweekly.org,\r \r so you're able to grab that content dynamically and put it into this issue.\r \r\n\nSo without further ado, here we go with a very important\r \r highlight to start with because\r \r version r4.4.0,\r \r codenamed puppy cup, has been released as of last week. And as always, it's always a big event whenever a new version of r has been released, and\r \r a great summary of the big\r \r changes has been put together\r \r by Russ Hyde, who is a data scientist at Jumping Rivers. And Russ leads off this post on the latest updates of 4.40 with a very\r \r interesting example\r \r on a concept that I don't take as much advantage of, although it can be very important, especially in situations where you don't quite know\r \r how to get to the right answer, so to speak.\r \r\n\nAnd this example is, of course, based on recursion.\r \r And, again, this is a paradigm often used when we're trying to get a close approximation\r \r to a type of solution.\r \r But, again, the path to that made me unclear, so to speak. So we may have to\r \r approximate running a function over and over again\r \r and then maybe build some either stopping rules or other criteria to say,\r \r how close are we? Are we close enough?\r \r And the example in the post that Russ puts in here is having to do a finding zeros in a mathematical function, such as, like, the sine curve and whatnot.\r \r He has a nice example of, like, if you're gonna build this function from scratch, how you might how you might approach it. He is quick to mention that there is a a built in function in R that would be better for this, but he calls this a bisect function\r \r and it's got some mathematical operations under the hood. But at the end, you'll notice\r \r it calls BISECT again right at the end of the code. So\r \r this is gonna keep running until\r \r it hits the right criteria\r \r for, say, getting that answer\r \r in a tolerance limit. Now beforehand,\r \r you might not know how many times this is gonna have to be called. You hope it's not very much, but it could be it's gonna be called quite a bit,\r \r perhaps 1,000\r \r or even 1,000,000 of times.\r \r\n\nAnd what happens when that happens?\r \r You fall victim\r \r to a Stack Overflow error.\r \r And there's probably a generation of listeners on this show who may think a Stack Overflow is a website to get programming help, but this is actually a CS term\r \r when you have these function results that are built on top of this stack,\r \r usually based in c or whatnot.\r \r But in r, you may have encountered this unwillingly if you accidentally put recursion in your paradigm, and it just ends up blowing up the stack, and then r will literally crash saying, you know what? I got too much in this stack. I don't know what to do with myself kinda thing.\r \r In version 440 of r, there is now a new function called tail call,\r \r which is gonna be basically a drop in replacement for that last call to your function at the end of the original function\r \r where instead of, like, doing, in this case, the bisect call again at the end, you're gonna put bisect\r \r into this tail call function.\r \r\n\nThe motivation for this is that r is only going to keep track of that last call that ended up knee being necessary for the solution\r \r instead of all those intermediate calls beforehand. Hence,\r \r you could have a recursive function ends up being used, say, 1,000,000 of times,\r \r but that call stack is only gonna retain what it needed at the end, so to speak.\r \r Now I admit, I don't do recursion very much, but I can definitely see how useful this will be in situations\r \r where you're probably gonna need some additional iterations\r \r before you get to that elegant solution that you're trying to solve.\r \r\n\nSo they do mention it is experimental because this is a brand new function, so, hopefully,\r \r it'll work well for your use cases and recursion.\r \r But certainly a welcome feature for those of you in the approximation realm.\r \r And I deal with this a lot in simulations as well, so that will be a very\r \r nice usability enhancement for my recursion workflows.\r \r But of course, there is much more here, too.\r \r And also new to R is the introduction of a nice and elegant way\r \r to deal with those null values and conditionals. And, Mike, why don't you tell us about that? Yeah. This is something that's been in Arling for quite a while now,\r \r\n\n[00:06:33] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Mike Thomas",
        "trans_text": "that I've seen,\r \r you know, in a lot of source code that I've taken a look at online but maybe not realized,\r \r and and haven't used it myself\r \r either and and not realized that it's not in base r. So it's this\r \r operator and if you want to write it, it is 4 characters,\r \r percent sign,\r \r pipe pipe percent sign.\r \r And essentially\r \r what it does is it evaluates the left hand side\r \r of that pipe\r \r and it says if that left hand side is null\r \r return what's on the right hand right hand side of the pipe. So it's it's a sort of a shorthand for is dot null,\r \r essentially for evaluating maybe conditional,\r \r if statements, flow control type statements, and just making, your code a little bit more concise that you don't have to write out that full is null, you know, else statement if you want. So\r \r especially if if you're someone maybe developing in our package or something like that where you are trying to test to see if a particular element is null and if it is, you want to return maybe a message or a different object or something like that just because you're trying to program defensively, which is something that we all try to do,\r \r in all of our work, I think this this shorthand operator could potentially\r \r be your friend there and may reduce the need to import Arlang, although I haven't written an R package where I don't have to bring in our where I haven't brought in Arlang in quite a long time.\r \r\n\nBut maybe it'll still be useful, you know, in your local scripts if if you don't need Arlang as well and you just wanna have this particular operator handy. So very excited to see this operator come into Besar.\r \r I think it's,\r \r I think it's a good\r \r a good decision by the ArcCorp team. I know it's probably not a trivial thing to add, you know, an operator\r \r to base r, and that's probably, actually a fairly big decision at the end of the day. But I believe that its use is is so widespread probably at this point that it makes sense for them to have done that. So that's a a nice little inclusion that we have in our 4 dot 4. One additional\r \r thing that is introduced as well is this new shorthand hexadecimal\r \r format, which I guess is common in in web programming. And and you can think about, you know, specifying\r \r your your hex codes for your colors. Right? Maybe in your ggplots or something like that. And most of the time, if we're we're trying to specify a particular hex code, we have to write it out all 6 digits out, you know, except maybe in the case of,\r \r some hex code that has a repeating pattern, you know. I think of black and white. It's just f f f and and 0.\r \r\n\nRight? Sometimes you don't need to write those\r \r all the way out. But, I guess the the shorthand\r \r allows you\r \r to translate a code like 112233\r \r to just,\r \r you know, pound sign 123 or hashtag 123 for the kids out there.\r \r So it's interesting,\r \r that that we now have this shorthand textadecimal format.\r \r There's some additional,\r \r improvements around parsing and formatting complex numbers if you're someone that leverages complex numbers in your R code,\r \r I can't say that that I'm one as well. And then probably the the last one which may be\r \r arguably the most useful\r \r is this new sort by function,\r \r sort underscore by. And it allows you to essentially sort a data frame typically based upon 1 or more columns,\r \r that you could specify in a list if you have multiple columns or you can just provide that one column to the sort by function.\r \r\n\nAnd,\r \r you know, I I think it's it's really interesting that we have that now. It's it's going to make,\r \r everybody's life easier to to sort of data frame in base r,\r \r\n\n[00:10:18] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 18,
        "trans_speaker": "Eric Nantz",
        "trans_text": "by 1 or more columns. So nice little handy improvement as well. Yeah. There there is much more to it. So Russ links, and we'll put a link in this as well to the full news file of the the all the updated changes.\r \r And he also concludes we're we're just talking about containers earlier, Mike. A great way for you to try r 44, if you don't wanna put it on your system right away,\r \r is to leverage Docker containers.\r \r Then he's got a simple example of pulling that,\r \r into into your system,\r \r and it's very easy to do, 2 lines in in each of those cases.\r \r And you may wanna look at this sooner or later because\r \r I you you can't write this you can't script this, so to speak, but literally the morning after I released our weekly,\r \r this updated issue,\r \r A news item that's been making the waves, and we'll probably have a lot more to say possibly next week on, is that for possibly the first time ever, there has been a critical vulnerability\r \r exploit discovered for the r language\r \r with respect to potential malicious\r \r code that could be inserted into what's called the RDS file format, which for those that aren't familiar, is a way for you to serialize\r \r our objects into a binary type format that's tailored to what R can use to import and export.\r \r\n\nNow there's a lot you know, I think there's a lot of information that's still going to be shared, without throughout the community on this.\r \r But if you're in an organization or you help consult with an organization,\r \r it may be worth informing them about this in case they wanna update their r version of 44\r \r now that that's been released. And that's important because r44\r \r event has been set to fix this vulnerability.\r \r So it would only be previous versions of r that could be potentially vulnerable to this.\r \r Like I said, I imagine we'll have more to say about this in the coming weeks because there's still a lot to digest here, but that is something for awareness. If you were you're on the fence about updating, that might, push you onto that edge sooner than later.\r \r\n\n[00:12:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "No. That's a great call out, Eric. And, yes, I I agree that I think we'll probably be hearing more about this story and maybe it's Genesis\r \r within the next week. Perhaps, something that we can talk about in more depth in the highlights next week, but I I guess it's good to see that this has been, you know, detected.\r \r This has been, you know, run up the food chain where it needs to be run up to and folks are investigating and it sounds like it's been remedied actually in in r4.4.\r \r So I think now it's it's sort of about spreading the word, maybe doing some sort of, you know, post mortem analysis to see if there's any other places within r that could potentially be impacted by this vulnerability or the way that r sort of serializes and and deserializes,\r \r data\r \r and, it's it's very interesting you know to to see this come across.\r \r\n\n\n\n[00:13:21] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And for our last couple highlights here, we're gonna visit our friendly, old Shiny Corner here because we got 2 terrific highlights having to do with Shiny itself that we'll touch on here.\r \r And actually, both of these are fresh off\r \r some presentations that were shared at the recent Appsilon Shiny conference. So lots of momentum from that. And first, we're going to dive into\r \r a very nice kind of usability\r \r enhancement for you as you bootstrap these Shiny apps and you want to take advantage of the latest and greatest\r \r best practices.\r \r\n\nAnd in particular, we're going to talk about a post by Garrick Aiden-Buie, who is a software engineer on the Shiny team at Posit.\r \r And he mentions in this post that a big initial focus in his 1st year with the team\r \r has been, you know, enhancing the bslib package,\r \r which Mike and I have been singing the praises of for over a year now, I believe, of this package. But for those that aren't aware,\r \r bslib kinda started off as a way to bring in the modern bootstrap styling into your Shiny apps without it affecting the Shiny core package itself. So this is an additional package that you'll load with your Shiny apps. And with it came some really nice new\r \r takes on layout functions, such as page sidebar and other,\r \r layouts that are very well tailored for dashboards and much more, as he\r \r says. Well, it's one thing to be a SLIB out there. It's one thing to have these examples out in the community, you know, say, with the package vignettes, the package website, and whatnot.\r \r\n\nBut there has always been a feature that many have taken advantage of in their development environments to quickly get Shiny apps up and running with a traditional sidebar layout, and that's the use of snippets.\r \r So in in RStudio Workbench or RStudio IDE, for example,\r \r there are a handful of built in snippets,\r \r including one to get a Shiny app off the ground.\r \r But you'll notice\r \r that this Shiny app is using the traditional Shiny package itself with its sidebar functions.\r \r And what Garrick does in this post is shows you how to quickly update that to take advantage of bslibs\r \r page sidebar\r \r layout so that you can get started right away with using bslib in your app. And it is super helpful, especially if you're going to be building these\r \r on a routine basis\r \r and you want to be able to not have to refactor your code after you get that initial snippet off the ground and say, oh, wait. No. I I wanna pivot the BS flips thing for this. So great. Yeah. Now you can have this\r \r snippet added in your Rstudio or update your snippet, I should say, in your Rstudio IDE's available snippets.\r \r\n\nBut there is more.\r \r This was an intriguing thing I've seen from somebody at Pasa themselves\r \r is that he also calls out a simple way for you to update or add a new snippet\r \r in your Versus Code snippets as well, which I know has been used heavily in a lot of Shiny app development these days. We in fact, at the recent Appsilon Shiny conference, we had a lot of people spreading enthusiasm\r \r about using Versus Code for more complicated setups. So Garrick has an example at this post\r \r of how you can add this snippet that looks very similar\r \r to the one that you would add in our studio's\r \r snippets feature,\r \r just a little bit more quoting around it. And let's say JSON, you know, syntax. But once you have it, then you can get that same functionality in in Rstudio or Versus Code. So take your pick. You're gonna have a nice snippet that you can use to get yourself started with BS Lib right away, right on the right foot.\r \r\n\n\n\n[00:16:57] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 57,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah, Eric. That's a great find, and\r \r snippets are something that I feel like I was very late to the game taking advantage of. But nowadays,\r \r you know, especially when I'm creating, like, small reprexes\r \r or examples or stuff like that for clients, you know, the the little Shiny app snippet that I get in R Studio is so much faster. It probably saves me a minute or 2 of actually creating that that UI in that server and loading\r \r Shiny at the header. So this is fan and I haven't really explored the concept of, like, creating your own snippets, but this is just a really nice simple walk through by Garrick on on how you could go about doing this in either RStudio\r \r or Versus Code. So it's definitely something that I need to start taking advantage of a little bit more because it is such a time saver. It's such a no brainer.\r \r\n\nAnd as Garrick sort of outlines in this post here, it's easy. It's it's not difficult at all to get up and running with. So,\r \r fantastic\r \r walkthrough by Garrick. And, you know, just like you, Eric, I am all bslib all the time when it comes to Shiny apps these days. So having some shorthand that actually\r \r sort of skeletons out the bslib app as opposed to having to edit what gets returned from the old Shiny app snippet,\r \r to conform to a bslib type structure\r \r is just going to additionally save that amount of time and and make my workflows more efficient.\r \r\n\n[00:18:20] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. You're you're right. I've been late to the snippet game as well, but I think to myself, what are on top of, like, getting the app, you know, boilerplate going,\r \r I have a bunch of widgets that I use every single time in my apps. In particular, I've always been a big fan of the ones such as picker input from Shiny Widgets, for example. I should have a snippet just to get one of those off the ground very quickly. I mean, there's you could take this to many different levels. But, yeah, anything to save you time to get this off the right way and then kind of reducing that manual effort of maybe just copy and pasting that snip that thing from one app to another. Oh, I gotta change the input and the ID and all this jazz. This can be a very efficient way for many aspects of Shiny development to to streamline your workflow.\r \r\n\n[00:19:05] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 5,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Absolutely.\r \r\n\n[00:19:21] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And our last highlight for today, again, we're gonna stay in the shiny corner for this. But Mike and I both agree we are blown away in very positive ways from what we're seeing\r \r in this summary here. And this is actually a presentation that was given at the aforementioned\r \r Appsilon Shiny Conference.\r \r And this was given by Lindsay Jorgensen,\r \r who is a director of business intelligence\r \r at Athos and as well as John Coene, who, Mike and I know very well, has been a prominent member of the shiny community\r \r all of these years.\r \r He actually is the CTO of the Y company that he cofounded earlier this year. So that's a new venture\r \r on his part. But they co presented\r \r a presentation called Tailoring Shiny for Modern Users.\r \r\n\nAnd the motivation for this was in this organization,\r \r as ASDOS,\r \r they have, which stands for Association of State and Territorial Health Officials,\r \r they usually they conduct on a regular basis a longitudinal type census\r \r every 3 years, and they started this back in 2007\r \r to help get some information with respect to potential funding and other projects\r \r that are happening at the state level for these different agencies.\r \r The results of these are very instrumental, apparently, for monitoring trends,\r \r advocating for additional funding,\r \r informing their future strategies, and much more.\r \r\n\nSo lots of data to deal with. And, of course, what's a good way to deal with these data? Let's throw this into\r \r a dashboard for end users to review.\r \r And the previous generation of this dashboard was built with Tableau where everything was in\r \r a kinda one interface layout,\r \r And certainly it looked functional. I never used it, but it definitely looked functional.\r \r But everything, like I said, is in kind of the single view\r \r and may or may not leave a little bit to be desired.\r \r Well, fast forward to the way they approach refactoring this with usability in mind and design in mind. So they took a step back\r \r and they modernized the user interface approach with this, I'll call, 3 column type layout,\r \r Where on the left, they've organized the inputs and not just, like, throwing all the inputs top to bottom\r \r in a a huge sidebar they have to scroll down on to actually see everything.\r \r\n\nThey've sub you know, they kinda compartmentalize\r \r these in different unique tabs at the top\r \r to get you focused on a few key inputs at a time and be able to click through these,\r \r different, like, tabs or organization\r \r so it's not overwhelming you right away.\r \r And then in the middle is like the main content. In this case, it's a lot of interactive\r \r additional context for that result. Maybe it's links to additional information or other\r \r information that would be useful as you're reviewing those visual\r \r results.\r \r And they have this kind of unified approach for the different tabs representing different analysis,\r \r you know, results\r \r all within the same application.\r \r\n\nBut, Mike, I when you look at this, there is almost no way you can tell this is a shiny f. This just looks absolutely fantastic.\r \r And on top of that, they even looked at accessibility\r \r as a first class citizen, so to speak, and how they built the colors of this as well. There's just so much going on here. It's just amazing stuff.\r \r\n\n[00:22:47] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Mike Thomas",
        "trans_text": "This is one of the best\r \r designed,\r \r like, websites in general, you know, information\r \r based\r \r websites, dashboards, whatever you wanna call it\r \r that I've ever seen, shiny or not.\r \r It's it's so clean. It's so thorough. It's incredibly thorough. You know, just some of the concepts that get employed here around displaying\r \r information and and trying to minimize clutter, you know, when there's sort of long\r \r explanations they cut it off after after 4 lines with an ellipse but have a hyperlink to to read more where that will open up, you know, sort of a longer form screen to to read more context\r \r on that text. They have definitions which are, you know, expandable,\r \r and nicely collapsed. Like you said, these these Highcharts driven charts are are beautifully\r \r tool tipped on top that that have a really nice,\r \r really nice encapsulation of all the information that they're trying to display. One of the coolest things for me, Eric, that we talked about preshow a little bit was on some of these, charts pages,\r \r you know, they allow you to sort of add filters\r \r dynamically where you can, you know, click a single button that says add a filter,\r \r you select, I believe, the column that you want to use for filtering and then you select the different,\r \r value or values,\r \r within that column that you want to filter down the data to and and that, you know, results in filtering the information that gets displayed\r \r in the chart. But instead of having, you know, a bunch of different filters\r \r on screen already\r \r across all the different columns that are probably\r \r represented in the underlying dataset,\r \r that would probably clutter the screen\r \r with the idea that maybe the user only wants to to leverage 1 or 2 columns for filtering context.\r \r\n\nYou know, don't\r \r create that clutter right off the bat and allow the user to select\r \r as many filters\r \r as they want. It's a few extra clicks, but I think I'm sure that they paid a lot of attention to user experience and really got to know the audience that's gonna be using this this app and understand that, you know, maybe they're only using a couple filters,\r \r and and maybe it's it's certainly gonna change from user to user,\r \r then it would make sense to to go with that approach. But, again, you know, that approach just makes everything super clean\r \r on screen and it\r \r I'm still blown away. I think I'm probably gonna it's gonna be very difficult for me to navigate away from this app today and actually start doing my work,\r \r as opposed to just playing in here,\r \r and desperately, you know, begging John and Lindsay for the source code behind this app.\r \r\n\nBut,\r \r it's it's one of the most\r \r beautiful apps I've I've ever seen. So I'm very grateful that they, you know, at least shared this app with us. I I think if nothing else, you know, and we don't get access to the source code or anything like that, the design ideas behind this are are just\r \r fantastic.\r \r And as I told you earlier, Eric, it just makes me want\r \r to go into all of our Shiny app projects and just immediately\r \r refactor them and bring in some of these principles because\r \r I feel like our work is light years away from what they've put together here. It is the the best way that I can describe it is just so clean.\r \r\n\n[00:26:02] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 2,
        "trans_speaker": "Eric Nantz",
        "trans_text": "It's so clean, so organized,\r \r and they're it's the perfect balance of making sure the user is seeing what they need to see first,\r \r but then letting them opt into additional context, additional information\r \r without thinking like, oh, they might want this. I'm gonna throw it on there. I'm gonna throw it on this other side. I'm gonna throw it on this footer. Like, it it will just drive you nuts. And, yes, I have seen many dashboards that were built with Shiny or things like Power BI\r \r that just become so cluttered\r \r with everything in your face, so to speak.\r \r\n\nThis, the organization at the top nav bar, but then within these sidebars,\r \r not overwhelming us of all the inputs at once. I mean, these are it is just it takes so\r \r it it just means that if you pay attention to detail on this early on, I mean, you're just gonna set you up for so much success for a wider range of customers or audience for your app\r \r and really taking advantage of these modern principles.\r \r Are quite overwhelming.\r \r Even though they're meant for statisticians, I don't think a statistician should have to suffer, so to speak, from information overload. So there are definitely\r \r techniques from here I wanna take into my production apps. Now the one thing they have open sourced,\r \r is this concept of what they call the data stories feature, where in the app itself,\r \r you will see this gallery of these different kinda more long form articles,\r \r but they're very nicely organized,\r \r kinda like a scrolly teletype setup a little bit. But then as you scroll,\r \r you get this nice interspersed set of narrative\r \r with the aforementioned visualizations\r \r and really a great way to kind of break apart visually, so to speak, these different sections. So there is an example repo for that that we will link to in the show notes if you wanna take advantage of that feature in your development. But, yeah, I'm gonna have to fight the urge to refactor all my apps now. But I do think I will refactor some of my apps. Just kidding.\r \r\n\n\n\n[00:28:01] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'm in the same boat, and it looks I this is deployed on Shiny apps dot io. One of the interesting things is that there is a,\r \r you know, extension on that Shinyapps.ioURL,\r \r where it's backslash profile.\r \r Makes me\r \r wonder if they're using some sort of a multi page\r \r approach here with brochure or maybe John didn't John have a a project called Ambiorix or something like that that Yeah. He does. That's right. Was leveraged here to have that sort of multi\r \r page\r \r possibility.\r \r So that would be interesting as well to see if there's any of that employed. But for how big this app is and where it's deployed on Shiny apps dot io, it's quite performant.\r \r So I'm sure they paid a lot of attention to\r \r trying to minimize the overhead on the on the back end as well. So very, very impressive.\r \r\n\n\n\n[00:28:49] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. And,\r \r I'll I'll put this out there, and I don't know when it will be yet. But I did, I was very enthusiastic about what I saw here, and I did get in touch with Lindsey, and she does seem receptive to being to joining me on a future shiny dev series episode. We're hopefully be able to dive into a lot of the technical bits on this in the future because I think it's a excellent story to tell, not just the the journey to get here to these principles, but actually how she pulled it off. So\r \r stay tuned for that. I don't know when yet, but you will know when when it's ready for that.\r \r But there's a lot more to stay tuned for because the rest of the Wiki issue has a boatload of additional resources,\r \r whether it's new tutorials,\r \r new packages, and updated packages. And I dare say this might be my biggest\r \r package section update yet because I got a lot to choose from here and a lot of great innovations across all different areas of of our and we'll take a couple of minutes for our additional finds in this in this segment like we always do.\r \r\n\nI've been, you know, a very big proponent, especially on my interactions of HPC systems,\r \r being on the command line, so to speak, you know, getting down and dirty with my data, quick inspections, you know, like Ed or tail of the last few rows.\r \r And I've I've been, you know, very enamored by some of these tools in the Linux community\r \r that let you profile performance of your system. There's something called HTOP\r \r and VTOP, etcetera. You can see, like, in real time\r \r your system performance and these nice line charts and stuff.\r \r Well, if you want that similar situation with R,\r \r guess what? There is a brand new pack that's released to CRAN\r \r called plot CLI,\r \r which has been authored by Klasheuer.\r \r\n\nHopefully, I'm saying that right. And like I said, it just hit CRAN recently.\r \r And this is going to take\r \r a very\r \r traditional type ggplot\r \r and convert it to a special object that you can print in the terminal and get nice coloring and symbol representation,\r \r which if you can't get to, like, say, a POSIT or RStudio IDE or a Versus Code instance,\r \r this might be a great thing to do if you're on that lower level, so to speak, with that HPC system\r \r and wanna look at a quick visualization.\r \r So I'm really excited about that.\r \r And, Mike, what did you wanna talk about? Oh, very cool find, Eric.\r \r\n\n\n\n[00:31:05] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 5,
        "trans_speaker": "Mike Thomas",
        "trans_text": "You know, not to be,\r \r morbid here sort of at the end of the show, but I think it it certainly warrants\r \r talking about,\r \r there is\r \r Fritz Leisch,\r \r passed away recently, and and Fritz was a member of,\r \r really the the core\r \r our project\r \r team.\r \r He helped\r \r cofound CRAN, if you can believe that, with Kurt Ornic,\r \r and that was, I think, around 1997.\r \r Yeah. He worked at Vienna University of Technology,\r \r and then moved to the University of Munich. I was a professor in computational statistics\r \r and became the head of that department actually\r \r in 2010 before moving back to to Vienna in in 2011 to to to work at the University of Natural Resources\r \r and Life Sciences.\r \r\n\nSo a very impressive career. One of his also additional contributions, I mean, this this almost sounds\r \r sounds made up, is that he actually developed the sWeave system that allows you to combine our and LaTeX\r \r into a single document which obviously is sort of, you know, the the core engine and how the Knitter project sort of came about and was built on top of, and now we have quarto sort of on top of that. So and I'm imagining that that also predates things like Jupyter Notebooks.\r \r So that idea\r \r of, you know, creating sort of reproducible\r \r research that encompasses both\r \r your your code and your narrative and your figures and your tables and your output like that,\r \r is is largely, I have to imagine, due to Fritz's work which is incredible.\r \r\n\nYou know, they also note that\r \r that led to, you know, the ability to create our package vignettes\r \r which obviously is something that's super powerful, I think, in the our ecosystem because it provides us with a way to give end users\r \r documentation\r \r that is does not necessarily exist or is not as thorough,\r \r or or beautiful, in my opinion, as what some other languages offer in terms of documentation around their packages.\r \r So, you know, he they say that in his, professorship, he he taught generations of of students,\r \r at bachelor, master, and PhD level,\r \r introduced\r \r 100\r \r of, R users to to proper R development\r \r workflows,\r \r and he is going to be extremely missed by the our core team and the our community,\r \r and we're incredibly grateful for his contributions\r \r to the our ecosystem\r \r and really allowing us what allowing us the ability to do what we do on a daily basis. So,\r \r definitely some sad news, but I guess maybe a time to reflect and and be grateful for the legacy that he leaves behind.\r \r\n\n\n\n[00:33:53] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Yeah. Thank you for that, Mike. Very well summarized. And, again, our our deepest condolences to his family and close friends and, yeah, the rest of the our core team. But I I mentioned this before either on this or my, older podcast.\r \r My dissertation was written in s sweep. It was revolutionary\r \r to me how I could literally without having to do the old copy paste method, I could get that plot, get that table\r \r into my LaTeX file. And\r \r just think of what's been built on top of that paradigm, as you said. That that cannot be understated,\r \r and we're really fortunate that we've been able to take advantage of these ideas,\r \r that that he's created,\r \r since the very beginning of our basically. So it is so many so many innovations that he's brought to the project that brought to the community.\r \r\n\nIt yeah. I definitely am very appreciative of everything he's accomplished. And, you know, it's always\r \r a it's always a time to reflect back and really appreciate what we have. And the innovations have to start somewhere. And he was one of those instrumentals to get the R project going.\r \r So definitely thank you for\r \r mentioning that. And\r \r also, you know, we always love to hear from all of you as well with respect to the R weekly project and this very podcast here. And again,\r \r one of our favorite parts of this job is to be able to showcase what all of you are building in this community and extending some of those great ideas. And if you want to get in touch with us, there's a few ways to do that. You can use the contact page directly in this episode's show notes. And also, if you want to contribute to our weekly itself, we have a link to contribution\r \r in terms of a poll request\r \r to the upcoming issue draft. You just click the right hand corner at the top. You'll get directly linked to GitHub for a poll request template,\r \r all marked down all the time. You know how it goes. I don't have to keep saying it anymore.\r \r\n\nAnd if you have a modern podcast app,\r \r such as, Podverse, Fountain Cast o Matic, and CurioCaster,\r \r you can send us fun little boosts along the way to give us a little encouragement and show your value of liking the show.\r \r And, also, you can get in touch with me on social media these days. I am on Mastodon at @[email protected].\r \r I'm also on LinkedIn under my name, Eric Nantz. You'll see, tweets are posted from time to time\r \r and sometimes on that x thingy at @theRcast. And, Mike, before my voice completely goes haywire, where can the listeners find you? You're hanging on pretty well, Eric. Yeah.\r \r\n\n[00:36:19] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Mike Thomas",
        "trans_text": "You can find me on mastodon\r \r at [email protected],\r \r Ketchbrook Analytics, k e t c h b r o o k. There's too many Mike Thomases out there, so you're better off looking that way. I'm gonna need to recharge my batteries now, so we're gonna close-up shop here on episode\r \r\n\n[00:36:41] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Eric Nantz",
        "trans_text": "163. We thank you so much for listening, especially to my horrid voice here. And, hopefully, I'll be back to normal shape and as well as to talk to you about awesome new resources for our next episode,\r \r which is coming up next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_18_highlights",
        "chap_timestamp": 10,
        "chap_text": "R 4.4.0",
        "chap_href": "https://www.jumpingrivers.com/blog/whats-new-r44/"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "chap_timestamp": 21,
        "chap_text": "{bslib} Shiny snippets",
        "chap_href": "https://www.garrickadenbuie.com/blog/shiny-new-bslib-snippet/"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "chap_timestamp": 21,
        "chap_text": "Tailoring Shiny for modern users",
        "chap_href": "https://lindsayjorgenson.github.io/Tailoring-Shiny-to-Modern-Users/#/tailoring_shiny"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "chap_timestamp": 20,
        "chap_text": "plotcli",
        "chap_href": "https://github.com/cheuerde/plotcli"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "chap_timestamp": 30,
        "chap_text": "Fritz Leisch (1969-2024)",
        "chap_href": "https://www.r-project.org/doc/obit/fritz.html"
      },
      {
        "ep_name": "issue_2024_w_18_highlights",
        "chap_timestamp": 5,
        "chap_text": "Episode wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_17_highlights",
        "ep_date": "2024-04-24",
        "ep_duration": 50,
        "ep_description_short": "Bringing interactivity to a staple graphical display in the genomics space, how one team is taking the box approach to sharing and developing modular R code, and a set of intriguing benchmarks with the newly-releaed duckplyr that have your hosts thinking of many possibilities. Episode Links This week's curator: Jon Carroll -…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_17_highlights",
        "description_long": "\r \r Bringing interactivity to a staple graphical display in the genomics space, how one team is taking the box approach to sharing and developing modular R code, and a set of intriguing benchmarks with the newly-releaed duckplyr that have your hosts thinking of many possibilities.\nEpisode Links\n\nThis week's curator: Jon Carroll - @[email protected] (Mastodon) & @carroll_jono (X/Twitter)\nInteractive volcano plots with the ggiraph R package\nModular R code for analytical projects with {box}\nKicking tyres\nEntire issue available at rweekly.org/2024-W17\nSupplement Resources\n\nHow to interpret a volcano plot https://biostatsquid.com/volcano-plot/\nSource code behind Tim's {duckplyr} and {data.table} benchmarks https://git.sr.ht/~tim-taylor/duckplyr-benchmarks\nAttach to a DuckDB Database over HTTPS or S3 https://duckdb.org/docs/guides/networkcloudstorage/duckdboverhttpsors3\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\n \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\n \nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nSnow Cone Heaven - Ice Climber - Mazedude - https://ocremix.org/remix/OCR01176\nCleaning Out Axis - Batman (NES) - Midee - https://ocremix.org/remix/OCR03008"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://fosstodon.org/@jonocarroll"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://tomsing1.github.io/blog/posts/volcano_ggiraph/"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://owenjonesuob.github.io/posts/2024-04-16-modular-r-code-for-analytical-projects-with-box/"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://www.hiddenelephants.co.uk/Blog/kicking-tyres.html"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://rweekly.org/2024-W17.html"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://biostatsquid.com/volcano-plot/"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://git.sr.ht/~tim-taylor/duckplyr-benchmarks"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://duckdb.org/docs/guides/networkcloudstorage/duckdboverhttpsors3"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://ocremix.org/remix/OCR01176"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "links": "https://ocremix.org/remix/OCR03008"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We are back of episode\r \r 162 of the Our Weekly Highlights podcast. This is the weekly show where we\r \r showcase the latest, awesome resources that you will see every single week in this particular week on rweekly.org.\r \r My name is Eric Nantz, and I'm delighted you joined us from wherever you are around the world.\r \r And, yes, I am never doing this alone as you know by now. I am joined at the hip here virtually by my awesome cohost, Mike Thomas. Mike, how are you doing today?\r \r\n\n[00:00:30] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Doing well, Eric. It's a good time to be a Boston sports fan.\r \r The the Celtics\r \r had a big win in the playoffs recently, and we have playoff hockey going on as well. And,\r \r I think the the Bruins took down the Leafs earlier this week or over the weekend.\r \r\n\n[00:00:44] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Game 1, they did, but it was a tough one last night. Oh, I missed it. Yeah. Well They fell last night? Yeah. There was a there was a one goal difference. But,\r \r Boston and Toronto, they don't like each other, and this is probably gonna go the distance if I had to guess. So buckle your seatbelts wherever you are.\r \r But, of course, you had to bring that up.\r \r My beloved wings\r \r lost on a silly tiebreaker to not make the playoffs. So I'm still wincing from that. But, nonetheless,\r \r we're not gonna we're not gonna, you know, complain too much here because we got some fun rweekly content to talk to you about today, and this issue has been curated by Jonathan Carroll, now one of our long time contributors\r \r to the rweekly project. And as always, yeah, tremendous help from our fellow rweekly team members and contributors like all of you around the world with your poll requests and suggestions.\r \r\n\nAnd we lead off with a visit to our visualization corner once again,\r \r and we're gonna talk about what is a very common and fundamental\r \r visualization that we often see in genetic and biomarker analyses\r \r and give it a little interactivity boost to make the experience even better for your collaborators.\r \r And this post comes to us from Thomas Sandman, who is a computational biologist.\r \r And he leads off with this situation where he wanted to share\r \r a very,\r \r powerful visualization\r \r called volcano plots to a collaborator.\r \r Now, what is a volcano plot, you might ask? Well, this is the plot where you can look at if you're comparing, say, 2 different groups in your experiment or your design.\r \r\n\nMaybe it's, in the case of life sciences, it might be a treated set of patients versus a controlled set of patients.\r \r And with these biomarkers, you are measuring\r \r boatloads of genetic quantities such as gene expression\r \r for their genetic microarrays, you might call it. And then you're gonna do some inferences on these. But you're often gonna have\r \r 1,000 upon 1,000 of these genetic markers.\r \r So you don't really know, you know, right away which one of these is gonna show a, you know, positive or negative trend either way.\r \r So the volcano plot's job is on the y axis. You will see\r \r often a log adjusted p value of the inference method.\r \r\n\nAnd then on the x axis, you'll see the fold change of the gene expression, which is like a ratio\r \r of the gene expression values from 1 group over the other.\r \r And, again, the shape, as you see, this does look literally like a volcano erupting on each side. It's a very, very intriguing visualization.\r \r I remember being blown away about that many years ago in my previous life as a statistician\r \r analyzing gene expression data.\r \r But, nonetheless, you can create these, as you can guess in R, quite, quite efficiently with the, always,\r \r you know, ready at your at your visualization hip here of ggplot2.\r \r\n\nAnd he has a great example\r \r after downloading some, gene expression data\r \r to do this volcano plot where you see, as I mentioned on the y axis, the log transform\r \r p values. And on the x axis, the fold change, also log transform.\r \r And he colors it by the different groups in the experiments. And you can see above a certain threshold,\r \r the red dots with\r \r the the gene expression fold change going in the positive direction\r \r versus the blue dots going in negative direction.\r \r Now that's great, but what if your collaborator or yourself wants to get more information\r \r on individual points in this?\r \r\n\nThat's where interactivity\r \r comes to play. In particular,\r \r you can opt into interactivity\r \r quite efficiently\r \r with the g\r \r g I raf or g giraffe, depending on your pronunciation\r \r of it. That package\r \r has been mentioned quite a few times on the highlights over the years. That package is authored by David Goel, who is also the architect of the Office verse,\r \r family of packages that we often see in our enterprise work. But ggiraffe,\r \r the way that works is that all you have to really do is replace the geom point in your red regular ggplot2call\r \r with the geom point interactive\r \r function.\r \r\n\nAnd with this, you supply a tooltip\r \r where when the user hovers over a point, you can supply metadata,\r \r if you will, on that particular point. And in the case of this plot,\r \r Thomas is supplying\r \r the p value,\r \r the log fold change,\r \r and the gene name itself. So, again, you can quickly see as you hover over that plot right in the blog post\r \r each of these, you know, specific genes and their fold change and p values.\r \r Now that's pretty good in and of itself. That might get you all the way there.\r \r But this is where this gets pretty intriguing, actually, because what if this plot\r \r is gonna be part of a larger report? I remember making these reports routinely with our markdown or even the predecessor to that s sweep in the in the early days.\r \r\n\nBut these plots, when you add these interactive elements,\r \r can take up a bit of size in terms of the\r \r HTML\r \r that's used to produce these plots when you add these tooltips in.\r \r So this comes now the very clever part of this post\r \r where Thomas is combining g g I f or something else\r \r and making the plot even more efficient for these reports. What what kind of trick has he done here? This this is pretty interesting where he combines the gg raster package with the ggiraffe\r \r\n\n[00:06:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "package, and, you know, essentially, what he's able to do here\r \r is to leverage this function called GeonpointRAST,\r \r to actually initially plot the points\r \r on the chart that you will see, but those points are not interactive. It's this,\r \r raster rasterized image which does not encode the position\r \r of each point separately. So it's sort of less overhead on the page in and of itself. And then on top of that,\r \r he overlays\r \r transparent\r \r interactive points for the significant,\r \r genes.\r \r And you could see that's where he leverages the Geon Point interactive function,\r \r but the the the alpha there is set to 0 such that there's no color.\r \r\n\nYou can't actually tell\r \r that those points are plotted unless you are hovering over them. So it's a very clever way to, I think, reduce the overhead\r \r on the page. And the use case here would be particularly\r \r if you, had a lot of plots on the same HTML page and it was, you know, slow maybe for users or, you know, the tooltip wasn't responsive because, you know, there's a lot of overhead potentially on those pages. So I thought this was super super clever. I see some use of,\r \r the poor man package to do some filtering,\r \r which is interesting as well to only show tool tips\r \r for the points that meet a certain significant\r \r threshold,\r \r which is really interesting. So sort of the grayed out portion of the bottom of the graph, you're not gonna get tool tooltips for,\r \r because, you know, the idea would be that users only necessarily care about those that are at or above the level of significance.\r \r\n\nSo a really really clever use case here for doing that. I think the code is very familiar to those who have experienced\r \r with ggplot. It's it's really not a very big step to go from ggplot to the ggiraffe\r \r package. And this gg raster package is one that I had not necessarily leveraged before but, it's very very very interesting to me and very,\r \r I don't know, kind of incredible how well these two packages work together, the gg raster package and the ggiraffe\r \r package,\r \r for being able to essentially, you know, plot\r \r the the points visually, sort of, in a static way on the page and then adding the interactivity,\r \r in a way that, you know, does not duplicate,\r \r the effort. So,\r \r great, great blog post top to bottom. I think for those either in the, you know, just interested in data visualization, I don't think you necessarily have to have the background in life sciences.\r \r\n\nI certainly, you know, am not super well versed in in gene expression data or anything like that, but I still took a lot out of this blog post. So a great job by by Thomas and, great start to the highlights this week. Yeah. It's a really clever way of inter of, blending in these different elements, and it's also underscoring,\r \r\n\n[00:09:16] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Eric Nantz",
        "trans_text": "trend we're seeing in almost any industry you can think of.\r \r HTML\r \r for reports is the way for the future. Right? So anything we can do\r \r to optimize the display of these, to be able to share these in self contained ways, and to minimize the footprint, so to speak. I mean, let's face it. I can in the before times, well caught. Did you ever wanna up you know, open a PDF that's like 30 megabytes?\r \r Yeah. Probably not your most, pleasant experience. But being able to have these reports done efficiently, I'm really,\r \r really impressed by the things we can that are at our fingertips.\r \r\n\nAnd, again,\r \r you as a a developer and R and programming these analyses and visualizations,\r \r you're not really stepping outside of a comfort zone here. You're just leveraging\r \r 2 additional packages that are in the same vein as your ggplot 2 type syntax. So it's a great way both, you know, from a cognitive standpoint to opt into this, and the result is absolutely fantastic.\r \r I've always been very impressed by ggiraffe\r \r and kind of its place\r \r in the visualization\r \r community. It often doesn't get enough love, but I think, you know, posts like this are definitely gonna show just just what it's capable of.\r \r\n\n[00:10:31] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 31,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Absolutely, Eric. And I wish that you would tell my clients that\r \r HTML reports should be the only, sort of format that they\r \r should be interested in, but I'll digress.\r \r\n\n[00:10:42] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Oh, don't get me started on the whole slide stuff. We're still in a PowerPoint world on that one, but, let's let's keep it positive, Michael. Let's keep it positive.\r \r And coming now speaking of, you know, efficiencies that we can gain with our code in general, our next highlight here has a very interesting take on how they're approaching modularity and their codevelopment\r \r across different projects\r \r and within the same project.\r \r This next post here comes from Owen Jones, who is a data science engineer\r \r at the UK Health Security Agency.\r \r And this post is all about how his team\r \r has been leveraging\r \r the box package\r \r as an alternative to other means and r of\r \r distributing and hosting reusable code,\r \r code bundles,\r \r modules, whatever you wanna call them, and to gain efficiencies in their projects.\r \r\n\nSo he mentions at the top that, you know,\r \r warms my heart to see a team that's using R for almost all of their data analysis\r \r and processing needs. And they definitely recognize a point where,\r \r hey. This project is doing this thing. This other project is doing the similar thing.\r \r Let's be efficient. Let's reuse that code and not duplicate it every time on the same project. So they're already on the right track from a cognitive standpoint,\r \r hopefully,\r \r beyond the path of minimizing technical debt and also enhancing collaboration.\r \r Now, if you're listening to the show and you've been in the art community for even just a little bit, you're probably thinking or even screaming at your, you know, podcast audio right now saying,\r \r this sounds like a package, and I would definitely agree with you. I think packages are\r \r a wonderful way to distribute shared\r \r functionality\r \r of\r \r data processing\r \r or other operational there is a bit of additional, you know, overhead or skill set that there is a bit of additional,\r \r you know, overhead or skill set that you need to be effective with packages. And, plus,\r \r if you have an update to make, you gotta update that package and then reinstall it or redistribute\r \r it amongst your different teams. These are all valid points. I definitely acknowledge it takes some discipline when you're in the the package mindset.\r \r\n\nNow their approach, again, this is where things get interesting is they are leveraging the box package.\r \r And you may have heard of box more recently because box is actually a fundamental piece\r \r behind the Appsilon team's Rhino package for, building,\r \r Shiny apps in an enterprise fashion.\r \r Now Box\r \r and this is where Eric's gonna have some takes here. Mike might have some takes on this too.\r \r I think they take some getting used to just like our packages would just in different ways. But I will say, if you are familiar with Python, especially,\r \r your box is gonna seem pretty familiar to you because in Python, you're probably used to, at the top of your Python script,\r \r importing, say, all the functions from a given, you know, package, whatever you wanna call it, or importing specific functions,\r \r possibly even renaming them\r \r and being very explicit of what your global environment in that Python session is going to have from these modules. Well, Box basically gives the same thing in the context of our code. You'll have this preamble at the top of your script saying which\r \r function,\r \r which piece do you wanna use from another script.\r \r\n\nThat, hence, you know, be very tailored, so to speak, of what's going into\r \r your environment.\r \r I will admit that's still not, like, comfortable to me yet, but I can see\r \r that perspective for sure.\r \r And what,\r \r what, Peter\r \r oh, no. Shit. What Owen has done in his post is also talk about how they're organizing\r \r the way they use these modules.\r \r He defines 3 different types of these modules within the box framework. 1 is a general bucket. This is the stuff that's gonna be used across different projects.\r \r He cites connections to an AWS Redshift data warehouse.\r \r That makes complete sense to me. Having those be able to reuse\r \r across different projects.\r \r\n\nAnd then within a project, they'll have a specific set of modules, and they call them project modules. Put them in a specific subdirectory\r \r that will be, you know, as the name says, specific to that particular project.\r \r And then lastly,\r \r a section called local modules.\r \r This category is meant for, you know, kind of tying it all together in that specific project, maybe more for utility purposes\r \r and whatnot.\r \r Now with Box, the other interesting piece of this is that\r \r much like in the our session,\r \r when you, say, call library dplyr, for example, it is\r \r searching for where dplyr is installed via what's called the library path.\r \r\n\nAnd that's where you typically can see what these are in your R session when you do the dotlibpaths,\r \r function call.\r \r Box has a similar mechanism where you can define the box path,\r \r which is can be 1 or more paths to where these\r \r scripts that are containing these box modules are stored. That can also be set for an environment variable.\r \r In that case, they kind of do some custom manipulations of that for a given project via the dotrprofilefile,\r \r which again, this is where either at a project level or your main R session level,\r \r you can add code that will be run at startup automatically when you launch your r session.\r \r\n\nSo they're putting these box configurations\r \r in a dot r profile file, which is similar\r \r to what, say, the RM package does to tell\r \r our hey. Don't look at the default library path. Look at this RM specific library path for packages. So I did find it interesting that they're using that technique to customize the box set. And then the other little interesting bit here is that I mentioned they have a category for these general\r \r box modules that they'll use across projects.\r \r Well, they make a clever use of the get submodule\r \r technique\r \r that says for a given project, we are going to clone\r \r the upstream repository of that general box module,\r \r but in a subdirectory\r \r of the project git module.\r \r\n\nSubmodules will take a bit of getting used to. I've used them a couple of times, especially in my blog down,\r \r you know, blog down sites where I have the\r \r Hugo theme as a submodule\r \r for the repository\r \r so that I could, like, you know, keep up to date with the developer of that theme from time to time, or I could just keep it as static as is and not touch it ever since. They're using that similar technique with these general purpose box modules.\r \r That's quite interesting to me, and I think that technique can be used on a variety\r \r of situations.\r \r\n\nSo it was cool to see how Box can be used in, like, a day to day concept.\r \r I will admit I'm personally not not convinced yet to change my workflow, but, nonetheless,\r \r I can see for a team that's still not quite comfortable with package development or package basics,\r \r but yet are familiar with other languages and how they import dependencies,\r \r I can definitely see how this could be a useful fit for them. Curious, Mike. What's your take on this approach here?\r \r\n\n[00:18:24] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Eric, I think this is super powerful\r \r depending on sort of\r \r how\r \r related,\r \r projects are within your organization from project to project.\r \r And I I think if you have\r \r a lot of projects\r \r where there's there's some overlap, right, maybe a little bit of overlap but not not sort of full overlap from project to project to the point where\r \r maybe you you wanna build,\r \r an R package that you know, contains a bunch of functions that you think are are going to be you're gonna use 80, 90% of them, you know, from project to project,\r \r then I think this may be the way to go when you're just trying to borrow sort of bits and pieces,\r \r from different places from from project to project where the the Venn diagram still has overlap from project to project but maybe a little bit, a little bit less where you're just trying to take a little bit here and there. And you're exactly right. It's it's sort of a very Python,\r \r type of mindset that you would have when leveraging the box package. I think it'll be very familiar\r \r to Python folks.\r \r\n\nOne of the third reasons why,\r \r they wanted to or Owen's team\r \r wanted to,\r \r leverage the box package as opposed to construct in our package and this reason is super relatable.\r \r It's that they would have to choose a package name\r \r and he admits that that is that is super hard that choosing a package name can be really difficult, which I will totally totally agree with.\r \r Although,\r \r I think, personally,\r \r that's sort of one of the the fun parts for me about developing R packages is I get to try to use that other side of my brain and then come up with an R package name that I think is is clever,\r \r and hopefully not one that, you know, a month from then I want to change and, because I, you know, at 3 in the morning I thought of a way better package name. You know, occasionally\r \r that may happen, may not happen. But I really do think,\r \r the use of Box can be incredibly powerful if it fits your use case. I I really appreciated the way that Owen,\r \r spelled out the different sub, the different module types\r \r in terms of general modules,\r \r project modules, and local modules because I think that makes a ton of sense in how to do that. I'm not personally familiar with git submodules. It sounds like something that I should\r \r get up to speed on because I can I can see from his explanation here how it would make a lot of sense to to leverage this git sub module technique,\r \r when you're employing, right, functions from these these quote unquote general\r \r modules and you have sort of multiple repositories\r \r potentially\r \r that you're interacting with pulling code from\r \r into the context of the current project\r \r that you're working on? So I think if you\r \r have the ability, capacity, you know, resources, understanding\r \r to leverage these 2 together,\r \r get sub modules in the box framework. I think it can be a really powerful way to develop within your team and and to share, resources,\r \r code,\r \r snippets, things like that, functions,\r \r that you want to leverage from project to project without\r \r introducing, you know, some of the the opinionated overhead that comes with developing in our package. And, Eric, as we always like to say, it's great to have options.\r \r\n\nAnd I think that this is another fantastic\r \r option and this is\r \r one of, you know, I don't I don't wanna\r \r speak out of turn here if I'm not correct, but this is, like, one of the most comprehensive or or best showcase blog posts that I've seen around the box package,\r \r at least recently.\r \r So a huge thanks to Owen for spelling this all out for us in a a really, really nice way.\r \r\n\n[00:22:09] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I I fully agree with this. I've been looking for\r \r additional\r \r practical day to day kind of treatments of box or narratives around it.\r \r I mean, like, yeah, we've seen all the stuff from Rhino. We we see why they are using box and and the Rhino framework. But in terms of data analysis, data science in general, I still wasn't quite absorbing it. But this this really hits home, you know, why this is important to them and how how they're leveraging it. Definitely, the principles here I see, you know, no matter which route you take, whether it's box or the package route, because you could think of the submodules\r \r as their way of,\r \r let's imagine I have a Shiny app as a as a project, which I typically do, and I'm using RM for it. And I have as one of my RM package dependencies,\r \r an internal package that's doing a lot of the heavy lifting for analysis.\r \r\n\nSo the sub module is kind of like if I have a separate git repo for that, I'll call back end package.\r \r I make an update in it. But then in r m, I have to opt in to upgrading the package version in r m for that overall app library.\r \r This, the sub module approach is saying, okay. Maybe the team on the that other team has made an update to that general module.\r \r They go into their project modules or they do, like, a get sub module fetch or or pull or whatever, and then they'll get that updated sub module in their project. So it's it's similar to that. And, obviously, people are gonna have preferences, you know, maybe one way or the other or some combination of both for how they keep their dependencies for a project updated.\r \r I do think it's quite elegant, though, because like I said for my Hugo,\r \r blogs, for the my original r podcast site and for my shiny dev series site, I did make use to get submodules\r \r to help keep upstream with the themes that I was using.\r \r\n\nAnd there were times that themes changed quite a bit, but I was like, do I really wanna opt into it yet? So I I got to chose when choose when to opt into it. But then when I did, I just gonna get some module fetcher or whatever, and I was off to the races.\r \r Yep. And you you mentioned lots of powerful ways or powerful ideas from that previous post, Mike. We're gonna really harness on the power aspect in this last highlight highlight here because there's been a lot of momentum in the recent weeks about DuckDV\r \r and the R community.\r \r\n\nAnd this last post is gonna\r \r have somebody who was admittedly a bit skeptical about this and some of their eye opening moments as they kick the tires quite literally on this. This post comes to us from Tim Taylor, and this is normally the part where I talk about their background or what their role is. I actually don't know, Tim, if you're listening, what your what your, day to day is like, but I will say you are\r \r 2 for 2 because you have done 2 blog posts. And now this is the second one featured on our weekly highlights. Your last one on indentation\r \r and our scripts was on just about a year ago on this very podcast. So kudos to you. You're batting a 1,000 on that one.\r \r\n\n\n\n[00:25:18] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 18,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. No.\r \r All I can see is that Tim is a proud dad, enthusiastic\r \r R user, and when he has time,\r \r a climber,\r \r with a fondness for for coffee and cake. So,\r \r we'll have to to track down some more about him unless sort of it's intentionally\r \r that way. But, yeah, it his last blog post on this hidden elephants,\r \r blog site that he's developed\r \r was exactly\r \r one day off,\r \r a year apart. So he is batting a 1000 annually here on on our weekly highlights as well for these blogs.\r \r\n\n[00:25:52] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Well, kudos to you again on that one. But, yeah, this is quite a departure from indentation\r \r because, like us, he has seen\r \r this amazing momentum that DuckDV has had in the community, in particular,\r \r the Duckflyer\r \r package release that was announced about a week or so ago,\r \r and\r \r he he is intrigued. He's still skeptical, but he wanted to see just for his own his own, you know, curiosity\r \r how the recent duct plier package would stack up with data dot table, which, again, has been renowned for many years on performance on large datasets.\r \r So he decided to take matters in his own hands and download a set of parquet files\r \r that corresponding to the New York taxicab\r \r trip dataset, which has been used in quite a few examples talking about high performance and databases and the like.\r \r\n\nAnd he implemented\r \r a few benchmarks\r \r to compare the 2 packages. The, again, duck plier and data dot table. And he implemented a series, I believe, 4 benchmarks,\r \r and using a series of group summary type operations.\r \r Pretty intuitive stuff if you've done any kind of data analysis looking at, like, medium medium pickup times and other,\r \r another similar analysis like that.\r \r And then he shows us the results. In this table here, he ran this in in two scenarios for each benchmark. 1 was using a year's worth of data and one using a quarter year's worth or 3 months of data.\r \r And you see here, when you look at the median timings, in this case, it was 5 reps, so little caveat there.\r \r\n\nThe ratio of improvement of duct plier performance, the data dot table performance in terms of these run times\r \r is between 5 and even up to 70\r \r times\r \r improvement.\r \r Holy jumping. That gets your attention.\r \r And he even admitted he was shocked at this as well.\r \r That that is amazing. Wine to said he needed some wine to take in these results. Yeah. I I probably would need to take a walk away from my desk and be like, what did I just see? Like, that's\r \r amazing.\r \r And so he dives into a bit more about how he, performed this. And by the way, there is a repo. We have all of his, code to set up these benchmarks. So I'll have a link to that in the show notes as well.\r \r But\r \r I think, again, trying to read between the lines here, what Doug Plyer and ductedbee are doing\r \r is a lot of, quote, unquote, lazy evaluation\r \r in terms of not doing the crunching\r \r until you absolutely have to, but it has certainly been optimized\r \r for performance like I didn't even dreamed of.\r \r\n\nAnd, apparently, it's also being very optimal for joining operations as well.\r \r Tim makes, some caveats in the post that there may not be a quite direct apples to apples comparison, so to speak, with the duct flyer and data dot table code because he had to modify the data dot table way of doing things\r \r to not be as,\r \r in, quote, unquote, lazier of our,\r \r approaches.\r \r I'll have to dive into that a bit more,\r \r but he is very upfront that he wants to keep running these benchmarks\r \r as new versions of Datadot Table and Duckplier are released just to kinda see the improvements that we're seeing in performance for each of these\r \r frameworks. But\r \r he seems to be convinced that this is something he's gonna be paying attention\r \r to in his future analysis, and frankly, I am very intrigued as\r \r well. And as I was reading through this prepping for this show, I did have one moment.\r \r\n\nImagine\r \r something I read about a week ago. I'll put this in the show notes as well. With DuckDB,\r \r there is a way that you can read as a read only source,\r \r a DuckDb database\r \r stored in an http endpoint or an s 3 bucket.\r \r You combine that with the forms that we're seeing here.\r \r Oh my goodness. I'm thinking shiny live web assembly with Duck DB with a big day. Oh. Oh. The plot thickens.\r \r I am very intrigued to explore this, and this really hit home that\r \r you could see some massive performance wins in this space. So,\r \r yeah, I was skeptical as well. I remember first hearing about DuckDB and Duckflyer,\r \r but my goodness, this is a heck of a job to convince me that I need to watch this space very closely.\r \r\n\n\n\n[00:30:26] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 26,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'm in the same boat, Eric. You know, I saw LinkedIn that you were, interacting with some DuckDV content recently and I follow them and I'm always,\r \r I'm very excited to see\r \r they're developing. It seems like at the speed of light, like, there's new functionality coming out in DuckDV.\r \r I've seen people say that DuckDV has sort of native,\r \r like,\r \r similarity measurement type functions that you could use for, you know, text embeddings and and things like that. And it's it's crazy that something like that, you know, functionality exists in\r \r within DuckDV, but it's it's like there's no end to the possibilities\r \r when it comes to it. And it's sort of really just exploded here,\r \r in the last, I don't know, 12 months something like that\r \r or may maybe more.\r \r\n\nSo it's really interesting and, you know, I think,\r \r Tim, you know, is quick to say at the end of this blog post as well\r \r that, you know, the current performance of data dot table is still very, very good.\r \r And it's it's always been more than just about raw speed. You know, there's people that love the syntax\r \r as well,\r \r and, you know, it's it's sort of Swiss army like functionality\r \r he mentioned. So, you know, even though this this benchmark is against data dot table and I feel like lately we've seen, you know, whether it be Arrow or or DuckDV or something like that, everybody's always benchmarking it against data dot table to show,\r \r you know, how much it can outperform\r \r data. Table maybe because, you know, that was the the prior sort of fastest game\r \r in town. You know, I would have liked to have seen, you know, a benchmark against sort of just raw dplyr\r \r code as well or or base r as well to just get that sort of full comparison and maybe not single out a poor data table so so much, because we do try to support that effort as well. But it's like, you know, like you've said, Eric, it's incredible. It seems, you know, as\r \r the the size of the data and maybe complexity of the operation\r \r increases,\r \r you know, the gap between DuckDBS performance and, you know, take your pick data. Table, whatever, it just seems to widen,\r \r which is is pretty incredible that we're getting, you know, 60, 70 x improvements,\r \r in the timing for some of these queries against, you know, the very famous New York taxi trip dataset, which is is pretty big. You know, Tim notes that\r \r it resulted in a data frame at times occupying\r \r 15 gigs of memory,\r \r in his r session, and and duck duck plier was able to perform all 4 of the queries that he wrote in, like, a little over 2 seconds, which\r \r is is it's incredible. And like you said,\r \r it definitely opens up the possibility\r \r for leveraging DuckDb and and WebAssembly\r \r WASM to be able to to run these things\r \r completely client side,\r \r on a page that doesn't necessarily have, you know, your traditional server behind it, leveraging Shiny Live,\r \r you know, connecting to to s three sources, HTTPS sources,\r \r and\r \r yeah, it's\r \r the the possibilities are are just endless here, and I'm so excited to continue to watch this space and see what happens\r \r in the next next year, 2 years, things like that. Maybe I've spun up, you know, my last digital ocean droplet here in the next next year or 2, because we'll just be deploying everything on on GitHub pages.\r \r\n\nBut we'll we'll have to see. We'll have to see. It's really, really exciting time to be in the data\r \r\n\n[00:33:50] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Eric Nantz",
        "trans_text": "space. Konas Otterberg and myself, man. I'm really intrigued by where I can where I can take these efforts.\r \r And\r \r there's gonna be a lot of fast moving pieces in this, so we'll be watching this space quite closely. And where you can watch this and many more developments is, of course, our weekly itself where we have so much more than just these highlights that we share in every issue, such as new packages,\r \r updated packages,\r \r and awesome showcases of our in the real world and tutorials.\r \r Almost there's always something for everybody.\r \r So we'll take a minute for our additional finds here, and I'm gonna gonna plug our our first highlight author, once again,\r \r Thomas Sandman. He has another post on this issue\r \r about querying JSON files\r \r with AWS\r \r Athena and this Noctua\r \r r package. Now this\r \r is pretty sophisticated stuff, but imagine\r \r you have data collected as JSON files, which, of course, is quite common in the world of web technology and web development,\r \r that you could, with this athena,\r \r service and with the Noctua package,\r \r treat those as if they were a DBI compliant data source and be able to leverage, say, dplyr code\r \r to do manipulations,\r \r do summaries, and whatnot.\r \r\n\nSo, as I think about ways I can\r \r store data interoperability\r \r wise between R and other frameworks that they all can access it efficiently,\r \r I'm definitely gonna keep an eye on this space. So that was,\r \r\n\n[00:35:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "a lot of moments on that post Laurent by Thomas. So definitely check that out. No. That's a great find, Eric. Yeah. There's there's a lot of actually additional highlights from the Datawookie\r \r blog by Andrew Collier.\r \r And, one that I'll I'll point out, which is a nice short and sweet one, it resonates with a lot of what we do is is on model validation, and it looks like, he has a model developed to try to estimate,\r \r stock market returns or financial portfolio\r \r returns as well and has 3 different methodologies\r \r for trying to evaluate\r \r whether the model he developed is a quote unquote good model. So it's an interesting one to to check out if you're in the model validation space.\r \r\n\n\n\n[00:36:00] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 0,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Nice. Yeah. I'll be checking that out as well. We're dealing with models left and right around here like everyone else.\r \r Very cool.\r \r And, of course, the rest of the issue is just as cool, so we invite you to check it out. The issue is always linked in the show notes, and John did another wonderful job curating this for us. And,\r \r again, our weekly is powered by all of you in the community. So the best way to help our project\r \r is to help send us a poll request for that new blog, that new resource, that new package,\r \r all marked down all the time. Details are at r wicked dot org. The upper right corner takes you directly to the upcoming issue draft. And, I think, yours truly is on the docket for next week's issue, so I can definitely use all the help I can get. So definitely help out your humble host here if you can.\r \r\n\nBut we also love hearing from you in the audience as well. You can send us a note on our contact page. This is directly linked in the show notes.\r \r Also, you can send us a fun little boost if you're using a modern podcast app like Paverse,\r \r Fountain, or Cast O Matic, Curio Castor. There's a whole bunch out there. And so you'll see details about that in the show notes as well. And we are still randomly walking those social media pathways.\r \r I'm mostly on Mastodon these days with at our podcast at podcast index.social.\r \r I am also on LinkedIn under my name, Eric Nance, and from time to time on the x thingy at the r cast. Mike, where can the listeners find you?\r \r\n\n\n\n[00:37:26] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 26,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Sure. You can find me on mastodon@[email protected],\r \r or you can check out what I'm up to on LinkedIn by searching Catch Brook Analytics,\r \r ketchbrook.\r \r And I wanna shout out Matan Hakim for his message on mastodon\r \r after I put out a little post,\r \r on Llama 3 saying that they did not\r \r have Catchbook Analytics in the training data when we asked them who Catchbook Analytics was, and he recommended,\r \r that they the developers, I guess, meta, of Llama 3,\r \r should have used the Our Weekly Highlights podcast as training data, which would have enabled them to, definitely spell Catch Brook Analytics because it's something that I apparently do at the end of every single episode. So sorry to the listeners for that, but not sure if it's gonna stop.\r \r\n\n[00:38:15] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 15,
        "trans_speaker": "Eric Nantz",
        "trans_text": "No. No. We we we keep we keep consistency on this show. So, yeah, Nada, get on this, buddy. We got we you gotta update your training data.\r \r\n\n[00:38:23] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 23,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That was awesome. Seriously.\r \r\n\n[00:38:25] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "trans_timestamp": 25,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. Yes. Well, our weekly itself shouldn't be hard to spell. Again, we're at our weekly dotorg for everything, so definitely bookmark it if you haven't.\r \r But, of course, we very much appreciate you listening from wherever you are around the world. It's always a blast to do this show, and we'll keep the train going as they say.\r \r So that will put a bow on episode 162,\r \r and we'll be back with episode 100 63 of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_17_highlights",
        "chap_timestamp": 36,
        "chap_text": "Interactive volcano plots",
        "chap_href": "https://tomsing1.github.io/blog/posts/volcano_ggiraph/"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "chap_timestamp": 0,
        "chap_text": "Modular code with box",
        "chap_href": "https://owenjonesuob.github.io/posts/2024-04-16-modular-r-code-for-analytical-projects-with-box/"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "chap_timestamp": 21,
        "chap_text": "Kicking tyres with duckplyr",
        "chap_href": "https://www.hiddenelephants.co.uk/Blog/kicking-tyres.html"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "chap_timestamp": 1,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_17_highlights",
        "chap_timestamp": 7,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_16_highlights",
        "ep_date": "2024-04-16",
        "ep_duration": 2,
        "ep_description_short": "Another way to hop on LLM train with the chattr package, a clever use of defensive programming to get to those warnings in your tests faster, and a major milestone for the R-Hub project. Episode Links This week's curator: Tony Elhabr - @[email protected] (Mastodon) & @TonyElHabr (X/Twitter) Chat with AI in RStudio Test warnings faster R-hub…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_16_highlights",
        "description_long": "\r \r Another way to hop on LLM train with the chattr package, a clever use of defensive programming to get to those warnings in your tests faster, and a major milestone for the R-Hub project.\nEpisode Links\n\nThis week's curator: Tony Elhabr - @[email protected] (Mastodon) & @TonyElHabr (X/Twitter)\nChat with AI in RStudio\nTest warnings faster\nR-hub v2\nEntire issue available at rweekly.org/2024-W16\nSupplement Resources\n\nR/Pharma 2023 presentation by Edgar Ruiz (GitHub Copilot in RStudio) - https://youtu.be/-Fjb8LZmTSI\nThe 2024 Appsilon Shiny Conference is just days away! https://www.shinyconf.com/\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info \nGet in touch with us on social media\n \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter) \nMike Thomas: @mike[email protected] (Mastodon) and @mikeketchbrook (X/Twitter) \nMusic credits powered byOCRemix\n\nMemories of a Master - Street Fighter II: The World Warrior - Captain Hogan - https://ocremix.org/remix/OCR02268\nHiggins Goes to Miami - Adventure Island - virt - https://ocremix.org/remix/OCR00461"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://mastodon.skrimmage.com/@tonyelhabr"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://blogs.rstudio.com/tensorflow/posts/2024-04-04-chat-with-llms-using-chattr"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://mm218.dev/posts/2024-04-12-testing-expensive-functions/"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://blog.r-hub.io/2024/04/11/rhub2/"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://rweekly.org/2024-W16.html"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://youtu.be/-Fjb8LZmTSI"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://www.shinyconf.com/"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://ocremix.org/remix/OCR02268"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "links": "https://ocremix.org/remix/OCR00461"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with episode a 161 of the RWKUHollwitz\r \r podcast. And depending when you're listening to this, you might get this a day earlier than expected because yours truly has the, day job going on. We have a couple on-site visits, but, nonetheless, we're gonna get an episode to you very quickly here. My name is Eric Nance. And as always, I'm delighted that you join us from wherever you are around the world. And I'm joined at the hip as always by my awesome co host, Mike Thomas. Mike, how are you doing today? Doing well, Eric. Happy tax day for those in the US.\r \r\n\n[00:00:33] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Having a pretty exciting day today because we're bringing on a new team member at Catch Brook Analytics, and if you're a small team, you know how big of a deal it is to to bring on an additional person. So very, very excited about that. But, yeah. Looking forward to a great week.\r \r\n\n[00:00:47] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Congratulations,\r \r Mike. I know a lot of stuff goes on behind the scenes to make those those acquisitions happen, so to speak. And sounds like you're you're gonna be teaming up quite well. And as always, if you wanna see what Mike's up to, yeah, I saw that in his LinkedIn feed. So definitely check that out.\r \r Thank you. Nonetheless yep. Nonetheless, we are gonna get on the business of our weekly here, and we our issue this week has been curated by Tony Elharbor,\r \r another one of our longtime contributors to the project. And as always, he had tremendous help from our fellow our our weekly team members and contributors like all of you\r \r around the world.\r \r\n\nAnd as you recall, Mike, this is something we talked about last year, I believe, is that there was a pretty big splash across the entire tech sector with\r \r large language models and artificial intelligence.\r \r And the Pazit group themselves had made a big splash when they announced\r \r how they were integrating chatgpt\r \r with their RStudio environment.\r \r And that's just one piece of the integration here because there is a lot more details, as they say. And that's the subject of our first highlight, which is\r \r all about the chatterrpackage,\r \r which is coming from the author of this post as well as the author of the package,\r \r our posit software engineer, Edgar Ruiz. And he tells us all about\r \r how you can chat with AI and large Angular models directly in RStudio itself via\r \r the Chatter package.\r \r\n\nThen on the 10, the easiest way to interact with it is once you install the package\r \r and you link it to the model of your choice, and more on that a little later, you will, by default, be able to bring up a handy little shiny gadget\r \r in the panel of your\r \r rstudio IDE.\r \r And it will look very familiar to those who have used things like chat GPT and other\r \r models online. You give it your prompt,\r \r hit enter, and then you're going to get some feedback back. And\r \r it does do some nice things under the hood that's tailoring it to, say, getting, say, our code for maybe you're developing a package or you're new to a certain package and you want a little snippet. It'll make it super easy for you to copy paste those snippets\r \r directly into your source prompt\r \r and actually going the other way as well.\r \r\n\nPerhaps you're like me, and you like the right markdown for all your expirations of, like, your data analysis and exploring a package.\r \r Maybe you write that question in your markdown file itself.\r \r And also, the Chatter package also has some nice interactions with the\r \r Rstudio add in feature\r \r where you could highlight that, say, text. That would basically be a prompt if you, like, manually typed it in.\r \r Send that directly to Chatter, and then it'll act as if you just prompted it directly. So nice little bidirectional\r \r communication\r \r on that front as well. So very nice kind of user experience on that front.\r \r\n\nNow the parts that I've been pretty intrigued by,\r \r especially as this\r \r technology starts to hopefully get more mature, although it still seems like moving at a breakneck pace,\r \r is that across multiple industries, across many of the people I listen to, there is a lot of interest in, you know, having the ability to self host your large language models\r \r and, hence, potentially being able to leverage the same technology\r \r without it leaving your company's firewall. And in my industry, that is a big, big deal because, we could get in big hot water if we if we transferred some confidential stuff in the OpenAI\r \r suite just on its own.\r \r\n\nWell, that's where Chatter has probably my favorite feature\r \r is the ability to integrate with not just the OpenAI type models of Chat, GPT, and the like, but also\r \r self hosted models.\r \r In particular,\r \r they give first class support\r \r for the chat LOM\r \r models, I believe.\r \r And some of these are coming from Meta\r \r themselves.\r \r And in fact, in particular, it's called Wama GPTJ\r \r chat. Again, some of these are being contributed by Meta and their research group. But with that framework, you can plug in different models that you can download that are freely available.\r \r They talk about WAMA itself, GPTJ,\r \r Mosaic pre chain transformers. Some of these I'm very not familiar of, but the whole idea is that once you install these on your system, you just set a little configuration\r \r in the Chatter package to map to those models.\r \r\n\nAnd then lo and behold, you'll be able to communicate directly\r \r in your network or even on your your computer itself without it again leaving the confines of your firewall or your own setup to go to another service.\r \r I do think that as this technology, yeah, gets more mainstream in industry,\r \r having that flexibility is going to be immensely important.\r \r And I'm very happy to see that even this early version of Chatter\r \r is bringing support for the local model execution,\r \r and they do encourage others to give it a try. And if there are models that they've seen online that are not supported yet, they are inviting,\r \r you know, issues to be filed on their issue tracker. And I'm sure Edgar and the team would love to pursue that further. But overall,\r \r certainly, as developing your R code, developing your package or data analysis,\r \r having a helping hand is never a bad thing. And Chatter gives you the flexibility of going straight to OpenAI\r \r or straight to your local system instead. So we're really happy to see it and can't wait to see where it goes.\r \r\n\n\n\n[00:06:26] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 26,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Eric, this is super exciting and I'm glad that you brought up the the point about the need\r \r for leveraging,\r \r sort of in house LLMs.\r \r You know, I think that in sort of non corporate settings, a lot of the times, right, or if you're just looking for help in your code, potentially, you know, you can leverage something like OpenAI or some of these these models where you are sending information to a third party service. Essentially, anything that you type is is probably gonna be captured and and used to retrain that model, if not for other purposes. And and, you know, that's okay a lot of the time. But if you are asking a question that's sort of specific to, you know, the the IP of your own organization or company, right, it's probably not a very good idea to do that. Your,\r \r your your information security team is probably not gonna be too happy if you start doing that.\r \r\n\nSo the fact that we have the ability to integrate here in our studio with some of these, you know, sort of, in house LLMs, you know, that that are open source and we can install and host ourselves\r \r is fantastic.\r \r I wasn't necessarily familiar with all of them. I do know that the Mosaic,\r \r pre trained\r \r Mosaic is a company that I believe was,\r \r you know, leading in this space and they were acquired by Databricks\r \r not too long ago.\r \r Then, I guess, the one other thing that I do wanna point out is if you are,\r \r someone who's sort of like me, who's been using Versus Code a little bit more, lately than RStudio, that's okay. You don't have to just be in the RStudio\r \r IDE. You know, this article highlights Chatter's integration with with RStudio's\r \r IDE.\r \r\n\nSpecifically, you know, all the screenshots are sort of Rstudio native, but,\r \r you know, this will all work outside of Rstudio as well, you know, for example, in the terminal. So it's a great walk through on on getting set up and and getting started. I think it's it's hugely helpful, you know. I have sort of mixed feelings as I'm sure you do about Eric. You do, Eric, about large language models and their utility.\r \r You know, I think I was probably a little bit more\r \r pessimistic about them when they first came out and I think they're growing on me a little bit to be honest.\r \r 1 I listened to a great podcast this weekend,\r \r that was with the chief operating officer of GitHub.\r \r\n\nAnd\r \r long this is just sort of a side story, but I live in this this very rural farm town in Connecticut as you know, Eric.\r \r Not much around. We're not we're not close to to any cities or anything like that.\r \r And the chief operating officer of GitHub\r \r lives 4 minutes away from my house and I never knew.\r \r Wow. In a small world. I sent him a little LinkedIn message\r \r to see if we're gonna get together sometime but I haven't heard back yet so I I don't blame him. But, no. It was very interesting and one of the points that he was talking about which I hadn't necessarily considered before is you know we talk a lot Eric about you know maintaining open source software and how it can be thankless sometimes. Right? There's not a lot of payoff there. But he was thinking about a world where, you know, somebody opens an issue in your, you know, open source repository that you have and maybe, you know, Copilot or or some sort of LLM is able to\r \r immediately\r \r show you some code to solve that issue. And obviously, you can go in and edit it, but any time savings that we can provide to open source maintainers,\r \r I think could be a huge benefit to the whole community and especially, you know, the many folks that work on open source that really don't get much back for it.\r \r\n\nSo I I thought that was interesting.\r \r They're growing on me. I I love seeing this article come out because I I think that this integration is very timely and looking forward to continuing to watch, you know, how this space evolves.\r \r\n\n[00:10:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Certainly, I've been pessimistic just like you have, and I do think depending on the context,\r \r there there are ways that\r \r if you're expecting too much, it's not\r \r you're gonna be you're gonna be disappointed if you think it's gonna solve all your woes of development and also coming up with a magical algorithm to save your company's bottom line. Yeah. Yeah. We're not there yet.\r \r But, however, I can definitely see\r \r the point of bridging that gap between doing\r \r so many things manually,\r \r such as looking up the concepts of a different language as you're folding maybe a custom JavaScript pipeline\r \r or custom, like, Linux, you know, operation into your typical data workflow.\r \r\n\nHaving that helping hand to be able to guide you with additional development best practices or snippets that get you\r \r started quickly, I think, is still\r \r the the the type of low hanging fruit that I think cannot be understated how valuable it is to get that extra helping hand. I think over time as these models get, you know,\r \r more updated, more trained, hopefully, with best practices for training those that we're all going to benefit from. But again, to me, the flexibility\r \r to be able to pivot to the direction that you choose,\r \r I think, is is definitely paramount here. And, yeah, for you Versus Code fans,\r \r guess what? The Versus Code, extension for R does indeed have support for RStudio add ins. So you should be able to use Chatter\r \r kind of out of the box even in your Versus Code setup. I haven't tried it yet, but I've been able to use add ins in the past with things like Logdown\r \r and other packages that had these nice little add in integration. So, yeah, who knows? Give that a try, listener out there, if you're a Versus Code power user because, I would imagine Chatter is gonna fit right in there.\r \r\n\n\n\n[00:11:54] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 54,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. It's a fantastic project and appreciate, you know, all the work that a lot of folks, it seems especially at Guru Ruiz, have put into this.\r \r\n\n[00:12:01] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. You can definitely see it. And in fact, he actually gave a a talk at the 2023 r pharma conference about some of his developments. So I'll have a link to that in the show notes.\r \r Now we told you how, you know, using things like large diameter miles can make things a bit faster for your development. Well, another thing that you want faster, especially when things go haywire, is if you're in the package development mindset\r \r and you're starting to do the right thing. If you've been listening to us and others in the community,\r \r you write your function. You know that function is important.\r \r\n\nMake a test for that, folks. It'll\r \r save you so much time and effort in the long run.\r \r Well, you may be in situations\r \r where you're writing a function\r \r that definitely has a lot going on, so to speak. Maybe it takes a lot of time to execute.\r \r Maybe it's impact it's interacting with some, you\r \r know, API that needs a little time to digest things.\r \r And you wanna still keep in the workflow of being able to test this efficiently,\r \r especially when things go haywire.\r \r And our next highlight here comes from Mike Mahoney, a PhD candidate who has also had definitely more than a few contributions to our weekly in the past where he talks about some of his recent explorations\r \r in helping to decipher\r \r the ways to fail fast\r \r in your test with respect to custom warnings and errors.\r \r\n\nAnd what we're talking about here is that typically speaking, when you have a function that's depending on some kind of user input,\r \r you probably wanna have some guardrails around it to make sure the inputs are meeting the specific needs of that back end processing.\r \r And if you detect that something's out of line, you will often wanna send a message to the user\r \r or in some cases, even a warning\r \r or an error right off the bat to the user that something is not right. They're gonna have to go and try it again.\r \r Well, maybe it is more of a warning concept or maybe they'll still get a result, but it may not be quite what they\r \r expect. And what Mike does in his example here, he has a little mock function that is intentionally meant to take a while,\r \r but he's making clever use of the rlang package\r \r to not only display the message to the user,\r \r but also attach a custom class to that message.\r \r\n\nI glossed over this years ago when I got familiar with\r \r Rlang and CLI, but this is a handy little feature because if you\r \r attach a class to this type of message or warning or error\r \r in your test to determine if that said warning or error actually fires,\r \r instead of having to test for the verbatim text of that message that it was showed to the user,\r \r you can test for that class of a message, which might be handy if you have more than one of these in a given function.\r \r Now that on its own, he's got an example where he builds a test to do that in his test suite.\r \r But there's one bit issue that, again, if you have an expensive function you're going to run it into,\r \r is that the function is still going to try to go through the rest of the processing even if your test for that warning is successful.\r \r\n\nWell, how do you get it so that you wanna, say, escape the hatch, so to speak, when that warning occurs?\r \r That's where the the rest of the example that Mike puts together here. He develops a nice little trick that's making use of the try catch function,\r \r which comes in base r, and it's a way for you to evaluate a function.\r \r And if you detect that there's an error, you can tell what to do in that post processing.\r \r So what Mike does in this example is he takes the detection\r \r of that warning condition in his function, which, in this case, is making a huge number\r \r with, going above the machine integer max.\r \r\n\nAnd then in his try catch block,\r \r he's got, okay, he expect an error that\r \r that error being actually\r \r a warning message instead of a typical error. So he does a little clever thing here, and this is not modifying the function itself. It's modifying the test that declaration of that function.\r \r So the function itself still has that nice, succinct syntax of if the integer is too big, send the warning, carry on. But it's in the test that block that he switches it a bit and says, I'm gonna expect that error for that warning condition.\r \r And that way, that the warning does indeed output as I expect. It's just gonna get out, and then I get on with my day, so to speak.\r \r\n\nNow this may not be a one size fits all for everybody because maybe there are cases where\r \r you're still gonna wanna test if that function does perform successfully.\r \r But I could definitely see as you're in, like, the iterative development workflow\r \r that you'll want that flexibility to say, okay. I just wanna test for my air conditioning first\r \r and then not get bogged down with the execution time in that iterative process. And then when I feel like I'm confident enough, then start building in the rest of the testing suite. Again, testing and development practices can be a highly personal thing,\r \r but I just love the use of these\r \r built in features of r to kinda make your day to day a bit easier\r \r in your testing suite. So a short example here, easy to digest,\r \r but I think it's got immense value,\r \r especially if you're in your early days of building that really\r \r\n\n[00:17:44] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Mike Thomas",
        "trans_text": "extremely clever by Mike and I appreciate him putting this example code together to demonstrate this this use case. It sort of reminds me,\r \r about a concept that maybe my Elle, Salmon was the the author behind, but just the concept of thinking about an early return as opposed to return right at the end of your function, you know, if some condition\r \r is met then, return early instead of executing all the rest of the code. So, great example here by Mike. I really encourage folks to to check out the example code. It's sort of hard to do it justice\r \r in a in a podcast. But this is really easy,\r \r base our code for the most part, a little bit of our lang and test that that you could run natively if you wanted to and and see, the time difference here that Mike expresses.\r \r\n\n\n\n[00:18:29] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I'm again, great nugget of wisdom here that I'm gonna be taking into my\r \r packages that I have to deal with either launching, say, a complicated model\r \r or interacting with an API that I have no control over,\r \r who maybe those engineers didn't exactly make it efficient on the back end. So if I wanna fail, I wanna fail fast, and hence, it's gonna be a nice little snippet that I can take into my dev toolbox to make it fail fast and still keep that function pretty pure in the process.\r \r And speaking of making things easy for you, again, going back into the package development mindset,\r \r you've done that awesome work. You've got that package ready to go.\r \r\n\nAnd then you're at that point of, am I really ready for CRAN yet?\r \r It can be a daunting task, but there are there's been an existing resource for us in the R community for over 8 years\r \r that has been immensely helpful as another sanity check to our package,\r \r especially with respect to different environments and different architectures.\r \r Well, what we're the project we're talking about has been the Rhub project,\r \r which has been led by Gabor Saasardi, a software engineer at Pozit.\r \r I believe Ma'al Salmons also contributed heavily to this project as well. Well, they have a very big milestone right now in our last highlight here because they are officially announcing in their blog post is that they are moving to R hub version 2.\r \r And, like I said, the impact that Rhub has had on the community itself cannot\r \r be understated\r \r with respect to package development\r \r and helping authors really get to the nitty gritty of how their package is gonna work across different architecture.\r \r\n\nAnd this has a rich history. As I said, this was actually a project funded\r \r by the R Consortium,\r \r which I've spoken highly about\r \r all the way back in 2015.\r \r So it has been standing up for years.\r \r Now why is this version 2 so exciting? Well, they are making\r \r major\r \r pivots to their infrastructure\r \r where a lot of this has been, in essence, self made or homegrown\r \r in terms of\r \r architectures for containers and servers.\r \r Now they are piggybacking\r \r off of GitHub actions\r \r to help automate many of these same checks\r \r and more that they've been doing in our hub over the years.\r \r And if that doesn't sound familiar, there has been another project we've been speaking highly about called r Universe that is also heavily invested in the GitHub Action route. So now that's 2\r \r major, major influences in the development,\r \r community for r that are making a big headway here.\r \r\n\nNow you as the end user, I. E. The package author wants to leverage this version of rhub. What do you have to do?\r \r The good news is there's always been a package called rhub literally in our ecosystem itself.\r \r You just gotta update that package to the latest version that they're announcing here. And then I believe you might have to reregister\r \r for interaction with the service. But if you've done it before,\r \r it should be a fairly seamless operation.\r \r And then the mechanism to you as the end user is exactly the same. You're gonna be able to supply\r \r or request that your package be checked in a more custom way. More on that in a minute. But we have a special configuration\r \r file that goes to your GitHub repository.\r \r\n\nAssuming your package source code is on GitHub,\r \r it'll be like a YAML file that in your main branch of the repo and optionally any custom branch\r \r that on every push to that said branch, it'll trigger in GitHub actions\r \r these other rhub version 2 checks. So then you can check the progress on that in the GitHub actions dialogue much like you would in any other GitHub action.\r \r I've been in I've been living in GitHub actions over the years, so it's becoming much more comfortable to me, albeit still not 100% yet. But again, they're taking all the hard work for you. You just got to put this configuration in your repo and the R Hub package itself will let you do that very quickly.\r \r And like I said, there are opportunities if you don't want to host your package itself on GitHub\r \r and still want to take advantage of something like GitHub Actions,\r \r there is a mechanism, a path forward for you as well\r \r where you can leverage\r \r the custom runners that the R Hub team has put together\r \r that are hosted under the R Consortium\r \r itself\r \r as these on demand runners, which would be similar to what you saw\r \r in the previous version of RHub.\r \r\n\nBut this is useful if you want to keep your package outside of GitHub\r \r and still want to leverage these kind of checks.\r \r There are a couple of caveats, though. Once you opt into this kind of check,\r \r obviously, the checks that are being run-in this Rhub, GitHub, Org under the R Consortium\r \r are still going to be public. So if you're okay with that, great. But, that's just something to keep in mind.\r \r With that said, I do think that this is gonna help the team immensely\r \r with their back end infrastructure.\r \r And, hopefully, you as the end user will be able to seamlessly opt into this, especially if you've already been invested in rhub. It should be a pretty seamless operation.\r \r And if you're new to rhub, it sounds like this is gonna be even faster for you and even more reliable\r \r and, hopefully, you know, get you on your way with more efficient package development.\r \r\n\nSo big congratulations\r \r\n\n[00:24:09] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Mike Thomas",
        "trans_text": "to Gabor and Myo and others on the rHub team for this, terrific milestone of version 2. Yeah, Eric. This is super exciting. You know, we've talked about this before, but the the need to be able to check your package and ensure that it it works and doesn't throw no any warnings or or notes or anything like that,\r \r across multiple different\r \r operating systems and setups ups that are that differ from your own, right? Which is really sort of before this, one of the only places that you could check,\r \r your package is is fantastic and it's it's super powerful.\r \r It looks like the rhub check function\r \r is a really nice interactive function, tries to identify the git and Github repository,\r \r that belongs to the package that you are trying to check. And then it has this whole list of it looks like about 20 different platforms that you can check your package on. And you can check it against as many, I think, of those platforms as you want. Just entering into the console,\r \r sort of the the index number for each platform, comma separated,\r \r that you want. One of the interesting things, Eric, I don't know if you know the answer to this, but if I'm looking at, you know, checks 1 through 4 here on Linux, Mac OS,\r \r Windows,\r \r It's it's it says that it's going to check that package against our and then it has a little asterisk, any version. So does that mean that,\r \r deeper within your your, maybe, YAML configuration file for your GitHub actions check, you're able to specify the exact version of r that you want, or is this sort of choosing the version of r for you?\r \r\n\n\n\n[00:25:45] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 45,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I'd imagine it's probably choosing for you, but I wouldn't be surprised if deep in the weeds you are able to customize that in some way. I just haven't tried it myself yet. Got it. No. Because that would be interesting because I have a sort of a use recurring use case where I feel like we need to check\r \r\n\n[00:25:58] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 58,
        "trans_speaker": "Mike Thomas",
        "trans_text": "against\r \r maybe 3 versions, you know,\r \r the the latest major release of our probably the next beta release as well that's coming and then and then the previous,\r \r major release as well because we know some folks in organizations sort of lag behind. So we wanna make sure that everything's working across,\r \r past, present, and future, if you will.\r \r So I wonder if I'll have to dig a little bit deeper into it. Maybe next week, I can could share my results on, the ability to specify particular\r \r r versions here. Anybody on Mastodon that wants to chime in, feel free as well. But, yeah, this is fantastic and, you know, there are as you mentioned, some of those limitations of your package being public.\r \r You know, if you do want to keep your package private and you have it in a private GitHub repository, you just wanna use the rhubsetup\r \r and rhubcheck\r \r functions instead of the rc submit function, and that should be able to keep all of your your code private for you and take care of that. But this is really exciting stuff,\r \r from the R Consortium and or from the R Hub team, and really appreciate all the work that they have done,\r \r to allow us to be able to\r \r more robustly,\r \r develop software, check that our software is working, and build working tools for others to use.\r \r\n\n\n\n[00:27:16] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I'm working with a teammate at the day job that we're about to open source a a long time package in our in our,\r \r internal pipeline\r \r and hopefully get it to CRAN. And they were asking me, yeah. What's this rhub check stuff? I was like, oh, you're asking me at the right time. They just released version 2. So we're gonna have a play with that ourselves probably in the next week or 2 and see how that turns out for us. But, yeah, we're gonna be putting that on CRAN. So between that and our universe, I think we're gonna be in good hands, so to speak, to prepare for that big milestone for us. That's exciting. And I do wanna point out that there is also it looks like a a very new, but a nice place to potentially ask questions as you kick the tire on this is a discussions board in the GitHub repository\r \r\n\n[00:27:58] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 58,
        "trans_speaker": "Mike Thomas",
        "trans_text": "for our hub. So definitely check that out.\r \r\n\n[00:28:01] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. This is, again, very welcome to get that that real time kind of feedback, you know, submitted.\r \r So definitely have that. Check out the, of course, the post itself, and you'll get a direct link to it.\r \r Having this dialogue early is going to be immensely helpful to Gabor and the team to make sure everything's working out correctly\r \r and, of course, the help with the future enhancements to our hub itself.\r \r And you know what else can help you all out there is, of course, the rest of the rweekly issue. We got a whole smorgasbord of\r \r package highlights, new updates,\r \r and existing packages, getting major updates,\r \r tutorials,\r \r great uses of data science across the board. So it'll take a couple of minutes for our additional finds here.\r \r\n\nAnd as I've been leveraging different, you know, data back ends for my data expirations,\r \r especially with huge datasets,\r \r I've been looking into things like, you know, of course, historically SQLite,\r \r DuckDB now, you know, Parquet. It's all it's all coming together as they say.\r \r Art Steinmis has a great post on our weekly, this issue,\r \r about the truth about tidy wrappers. It's a provocative title, but if you ever want a technical deep dive into kind of the benefits and trade offs of performance\r \r and other considerations\r \r with some of these wrappers that you heard about that say, let you use dplyr with, say, you know, relational databases,\r \r parquet files, DuckDB.\r \r\n\nThis post is for you. It is a very comprehensive treatment,\r \r lots of example metrics so you can make an informed decision\r \r as you look at the datasets you're analyzing in your particular project\r \r and seeing if it's a right fit to stick with the wrappers\r \r or to go full native with the respective database engine. So really, thought provoking read, and great post by Art on that one. And, Mike, what did you find? No. It's a great find, Eric. I found\r \r\n\n[00:29:56] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Mike Thomas",
        "trans_text": "a blog post by Hadley Wickham, announcing Tidyverse Developer Day 2024.\r \r\n\n[00:30:01] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Woo hoo. Yeah. This is exciting. It seems like it's been a little while since they had a Tidyverse Developer Day.\r \r\n\n[00:30:12] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 12,
        "trans_speaker": "Mike Thomas",
        "trans_text": "On August 15th. And\r \r if you're curious about what Tidyverse Developer Day is,\r \r it's just a really open communal day of folks, sitting and learning together\r \r and coding to try to promote contribution to the Tidyverse codebase.\r \r They're going to provide everyone with food and all you need to do is is bring your laptop and your,\r \r you're yearning to learn,\r \r so to speak.\r \r So it looks like,\r \r anyone can attend\r \r if this is regardless of whether you've ever created a pull request before\r \r or as Hadley says or if you you've already made your 10th package. So we're welcoming beginners to intermediate to advanced folks. Anybody that's interested\r \r in sort of the concepts of maybe con just contributing to open source or contributing to the Tidyverse,\r \r specifically.\r \r\n\nI'm sure that they will have,\r \r many sort of issues already labeled and and ready to go for sort of, low level beginner stuff to probably more advanced stuff if you really wanna get into the weeds of the tidyverse.\r \r It's gonna cost $10 and and they say that really that's just because,\r \r they don't want people, you know, sort of just a lot of people taking a ticket and and not necessarily showing up. They're trying to encourage, you know, some commitment to the folks that actually say that they're going to,\r \r register\r \r for this. And and I think they're looking forward to, this day. And I'm going to to try to make it if possible. I'll have to see if the logistics\r \r all line up. But this is super exciting. Just another thing that I love about open source. The fact that, you know, they're going to have a day dedicated to this, a very open sort of forum for folks to help contribute to code that's going to get used by, you know, 1,000, if not tens or 100 of 1,000 or millions of people around the world. Pretty exciting.\r \r\n\n\n\n[00:31:56] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I've never actually been to a developer day myself, but yet I've interacted with many people that have in the in the earlier years of the rstudio conference, and everybody was so immensely, you know, enjoying the experience.\r \r And it helps them get over that hump of package development,\r \r you know, contributing to open source. It's a friendly, welcoming environment.\r \r Yeah. Like I said, I've heard great stories from many many in the r community\r \r of all types of experience levels getting such tangible benefits\r \r and, of course, helping open source along the way. So I highly recommend if you have the capacity to join join that effort as well.\r \r\n\nAnd, yeah, as we're recording, Mike, I'll do one little mini plug here. We are only a couple of days away from the 2024\r \r Shiny conference hosted by Absalon starting this Wednesday.\r \r Hopefully, by the time you're hearing this, it'll still be a day or so left and you can still register.\r \r We'll have a link to the conference site itself if you haven't registered yet. I am thrilled to be chairing the life sciences track, and I'll be leading a panel discussion\r \r about some of the major\r \r innovations in life sciences these days are shiny.\r \r I'll be joined by Donnie\r \r Unardi, Harvey Lieberman, and Becca Krause. They are an all star team, if I dare say so myself, of practitioners in life sciences that are pushing Shiny to another level, and I'll be thrilled to, you know, dive into some of these topics with them. You know, super exciting that Shiny Conf is this week, we are looking forward to it. It's it's finally arrived. We have a little app showcase,\r \r\n\n[00:33:27] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Mike Thomas",
        "trans_text": "that's taking place on Thursday that we're excited for, but mostly excited for all the other fantastic content that will be, presented\r \r during the conference. So really appreciate Absalon putting that on, I think, with some help from Pazit and others as well. Of course, we hope that you enjoyed this episode and also our weekly\r \r\n\n[00:33:46] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 46,
        "trans_speaker": "Eric Nantz",
        "trans_text": "is meant for you in the community and is powered by you in the community.\r \r The best way to help the project is to send your favorite resource or that new resource you found. We have a poll request away. It's all available at rweekly.org.\r \r Click that little right hand ribbon in the upper right. You'll get a link to the upcoming issue draft.\r \r All marked down all the time. You know marked down. I'm sure you do. If you haven't, it'll take you maybe 5 minutes to learn it. And if you can't learn it in 5 minutes, my good friend, Eway, will give you $5.\r \r Just kidding.\r \r\n\nHe did tell me that one. So, luckily, I didn't need I didn't need 5 minutes to learn it, though.\r \r Oh, I love it. I love it. And, of course, we look forward to you, continuing listening to this very show. We love hearing from you as well.\r \r We are now about two and a half weeks, I believe, into our new hosting provider, and everything seems to be working smoothly again.\r \r But,\r \r I'm really excited for the directions I can take this platform in the future. In fact, I'm hoping I can share some really fancy stats of all of you based on some of the new, back end stuff I've been able to integrate with with this new provider. But, nonetheless, we love hearing from you.\r \r You can get in touch with us with the contact page, direct link in this episode show notes. You can also send us a fun little boost along the way with one of these modern podcast apps you may have been hearing about.\r \r\n\nWe have a link to all those in the show notes as well.\r \r And, of course, we love hearing from you directly on our various\r \r accounts online.\r \r I'm mostly on Mastodon these days with\r \r at our podcast at podcast index.social.\r \r I'm on LinkedIn as well. Just search my name. You'll find me there. And, occasionally,\r \r on the weapon x Twitter thingamajig@drcast.\r \r And, Mike, where can our listeners find you?\r \r\n\n[00:35:29] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. You can find me on Mastodon as well at [email protected],\r \r Or, you can check out what I'm up to on LinkedIn if you search for Catchbrook Analytics,\r \r ketchb\r \r r o o k.\r \r\n\n[00:35:43] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome stuff. And, again, Mike's always got some cool stuff cooking in the oven, so to speak. So it's always great to see what you're up to. And with that, we're gonna put this episode out of the oven. We are done for today. We're gonna wrap up this episode of our weekly highlights, and we'll be back with another edition\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_16_highlights",
        "chap_timestamp": 23,
        "chap_text": "AI chattr",
        "chap_href": "https://blogs.rstudio.com/tensorflow/posts/2024-04-04-chat-with-llms-using-chattr"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "chap_timestamp": 22,
        "chap_text": "Test warnings faster",
        "chap_href": "https://mm218.dev/posts/2024-04-12-testing-expensive-functions/"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "chap_timestamp": 8,
        "chap_text": "R-Hub version 2",
        "chap_href": "https://blog.r-hub.io/2024/04/11/rhub2/"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "chap_timestamp": 24,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_16_highlights",
        "chap_timestamp": 42,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_15_highlights",
        "ep_date": "2024-04-10",
        "ep_duration": 16,
        "ep_description_short": "The Nix and R train rolls on with automated caching, a collection of big improvements landing in webR, and how hand-crafted visualizations bring fundamental dplyr grouping operations to life. Episode Links This week’s curator: Jon Calder (@jonmcalder) (X/Twitter) Reproducible data science with Nix, part 11 – build and cache binaries with Github…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_15_highlights",
        "description_long": "\r \r The Nix and R train rolls on with automated caching, a collection of big improvements landing in webR, and how hand-crafted visualizations bring fundamental dplyr grouping operations to life.\nEpisode Links\n\nThis week’s curator: Jon Calder (@jonmcalder) (X/Twitter)\nReproducible data science with Nix, part 11 – build and cache binaries with Github Actions and Cachix\nwebR 0.3.1\nVisualizing {dplyr}’s mutate(), summarize(), group_by(), and ungroup() with animations: Visually explore how {dplyr}’s more complex core functions work together to wrangle data\nEntire issue available at rweekly.org/2024-W15\nSupplement Resources\n\nBruno’s unit test involving {tidyselect} https://raw.githack.com/b-rodrigues/nixpkgs-r-updates-fails/targets-runs/output/r-updates-fails.html\nCachix https://www.cachix.org/\nR/Medicine Call for Abstracts Open https://www.r-consortium.org/events/2024/04/05/r-medicine-coming-june-10-14-2024\nSurvival analysis for time-to-event data with tidymodels https://www.tidyverse.org/blog/2024/04/tidymodels-survival-analysis/\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @[email protected] (Mastodon) and @mike_ketchbrook (X/Twitter)\nMusic credits powered byOCRemix\n\nSun Ra - Ragnarok Online - Anthony Lofton, Joshua Morse - https://ocremix.org/remix/OCR01811\nChopinesque Kirby - Kirby’s Dream Land - Bladiator - https://ocremix.org/remix/OCR01257"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://www.brodrigues.co/blog/2024-04-04-nix_for_r_part_11/"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://www.tidyverse.org/blog/2024/04/webr-0-3-1/"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://www.andrewheiss.com/blog/2024/04/04/group_by-summarize-ungroup-animations/"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://rweekly.org/2024-W15.html"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://raw.githack.com/b-rodrigues/nixpkgs-r-updates-fails/targets-runs/output/r-updates-fails.html"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://www.cachix.org/"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://www.r-consortium.org/events/2024/04/05/r-medicine-coming-june-10-14-2024"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://www.tidyverse.org/blog/2024/04/tidymodels-survival-analysis/"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://ocremix.org/remix/OCR01811"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "links": "https://ocremix.org/remix/OCR01257"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back at episode 160 of the our wicked highlights podcast.\r \r My name is Eric Nance. And, hopefully, if you're able to listen to this, then the world is still spinning after the,\r \r little bit of an eclipse event we had here in this side of the world. But in any event, we are happy that you join us from wherever you are around the world.\r \r And as always, this show is our weekly take on the latest highlights that have been featured in this particular week's our weekly issue.\r \r And as always, I am never doing this alone, and he also survived the eclipse as well. My co host, Mike Thomas. Mike, how are you doing today? Doing pretty well, Eric. Yeah. We caught,\r \r\n\n[00:00:40] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Mike Thomas",
        "trans_text": "it here in Connecticut on the East Coast in the USA.\r \r I think, like, 95%\r \r of of total coverage. We weren't in the, line of totality\r \r as you are, but it was still still a pretty cool experience.\r \r\n\n[00:00:54] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 54,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I was here in the, Midwest. Got the lucky straw on this one, so had to take a very long trek. I mean, only a few steps to field in our neighborhood to check it out with a few, friends and and kids around. So, yeah, all in all, a good time.\r \r Temperature goes way down. You in about 3 minutes, it looked like we were in twilight zone. But, hey, I won't complain. It was a a ton of fun, and the world has still survived. So didn't have any, like, y two k issues from yesterday or anything like that. Internet is still on. It is still on. We're still recording here. And, thankfully, the Internet's on because that means that y'all can see the latest Our Weekly issue, which we're going to be talking about now,\r \r which has been curated by John Calder, another one of our\r \r long time contributors and curators on the project.\r \r\n\nAnd as always, he had tremendous help from our fellow Rwicky team members\r \r and contributors like all of you around the world.\r \r Well, one of the rweekly highlights, especially in the last few months, if we didn't check-in with a good a good friend of the show who is continuing\r \r his journey with Knicks and r. And, of course, I am speaking about\r \r Bruno Rodriguez and his latest blog post on his blog,\r \r which is part 11.\r \r Yes.\r \r 11 of this series of reproducible data science with Nix.\r \r And this is gonna have a lot of aspects that I think you as a user and as a developer\r \r will both sympathize with. And I think open your eyes. There are a couple really interesting things that we can do\r \r with this ecosystem.\r \r\n\nHow does this part of the journey begin?\r \r Starts innocently enough\r \r with\r \r a package that Bruno has released years ago called chronicler.\r \r And he gets an email from the crane maintainers\r \r saying that there's been a failure in the build.\r \r What does this mean? So, of course, he checks out the CRAN package results.\r \r And this is where things start to really get out here because\r \r there is only\r \r 2 instances\r \r of r on Linux, and in particular, the Fedora distribution of Linux,\r \r that have the failure of the checks, yet\r \r Debian\r \r as well as, of course, the Windows and macOS\r \r test\r \r results all pass.\r \r\n\nNow that is a head scratcher in and of its own because intuitively would think\r \r if there was a failure,\r \r a, would happen everywhere,\r \r and, b, even if it was isolated to Linux, that would hap but not all the Linux distributions that is checking. But that is not the case here.\r \r And so Bruno starts a little detective work. Right?\r \r And then he realizes,\r \r well, what would have happened on that particular day of the failure?\r \r Sure enough,\r \r there was an update to one of the dependencies.\r \r I would say a dependency of a dependency\r \r of his Chronicler package because it's not that obvious.\r \r\n\nBut in particular, the tidy select package, which for those aren't aware,\r \r is what powers now many of the tidyverse packages,\r \r functions that have to do with helpers in your select calls,\r \r like maybe select one of of the starts of a string or things like that.\r \r Well, it just so happened that tidy select got a new version\r \r on this day or at least the day before\r \r that this failure came to be.\r \r Now, again, you're wondering\r \r why on earth\r \r would this only affect\r \r one of the Linux variants.\r \r Turns out that Fedora\r \r is compiling the packages from source on each of these test runs, whereas\r \r the Debian distribution,\r \r and Debian is actually\r \r the base of the very popular Ubuntu distribution,\r \r that is using binaries of packages when they're available.\r \r\n\nBut for Fedora, they're not as available, these binary\r \r versions of packages. And, hence,\r \r a, you know,\r \r recently updated version of tidy select landed on the Fedora version,\r \r and there was an update in the tidy select,\r \r functions\r \r where an error message, in this case for eval select,\r \r was giving a more targeted message in terms of where that was actually happening in a select operation versus a subset operation.\r \r And Bruno, you know, listening to the advice of many package authors,\r \r has a very sophisticated automated testing suite\r \r where he is able\r \r to pinpoint one of the errors where this was failing\r \r because he was\r \r on the actual context of the error message or one of these select calls. We'll actually have a link in the show notes to this exact test because I I was just doing a bunch of testing for an internal package myself. So I'm always curious what others are doing in this space. And sure enough, yeah, that test was being triggered.\r \r\n\nBut because the other versions of Linux were not updated with the new tidy select binary yet,\r \r those pass the flying colors because that error message was the same as what he had built it on.\r \r Well,\r \r okay. Now what?\r \r Now what could we do differently here or at least what he could do differently here?\r \r Well, now that he's narrowed down where this failure occurred,\r \r where could Nix come in here?\r \r Well, he has a development environment\r \r that's powered by Nix now for building his packages. And, of course, for those who haven't heard the previous episodes, we've been talking about his Rix package,\r \r a way to help our users bootstrap these Nix\r \r like manifest to bring in dependencies of our packages\r \r and be able to constrain those particular versions and whatnot.\r \r\n\nWell, he wondered, you know, would this happen on nix? Well, what's interesting enough, and this is another nugget for me, especially some I'll get to in a little bit,\r \r is that the packages\r \r in NICS that are that are literally corresponding to our packages themselves\r \r are actually\r \r not updated\r \r until\r \r a new release of our hits.\r \r This is actually kind of marrying a lot of what many of us in the life sciences industry deal with in terms of our internal R installations\r \r where there's a central library of packages, but they don't really get updated\r \r until a new version of R is released and deployed in production, and then we refresh the library\r \r with those. And, apparently,\r \r these stable\r \r releases on next follow that same paradigm,\r \r which that that's kind of food for thought for me as I think about ways of making\r \r environments a little more hardened as they say. But that's, again kind of a digression here.\r \r\n\nSo\r \r Bruno, what he wanted to do here is that, well, what what can he do to catch this more in real time\r \r with Nicks?\r \r And, of course, he has these nice mechanisms in place based on his learning\r \r to update what are called expressions in next to cat to bring in more up to date versions of packages. And he was able to do that with tidy select\r \r and then be able to then replicate the error on nicks that he was getting on that cran check Infidora.\r \r So with that, of course, now he's updated his unit test for chronicler\r \r to account for this new message.\r \r\n\nThat could be it right there.\r \r But Bruno, like me, likes to, go go a bit further deep in this and think about what is there a way to have\r \r these more up to date versions of packages\r \r kind of add availability\r \r whenever he needs it instead of, like, custom doing this for\r \r one off packages here and there like you did with this tidy select situation.\r \r Well, another thing that we've been plugging a lot is using automation when you can. Right?\r \r And\r \r so Nix can be incorporated quite nicely in GitHub actions,\r \r which is, of course, a great way for you to run, like, your CICD testing suite and whatnot\r \r for package development.\r \r\n\nBut could you also combine this with bootstrapping\r \r environments of our packages,\r \r much like how we often do with r env in a lot of our GitHub actions where we use r env to take in the versions of packages we we use for a given project. And then to get an actual look at that lock file,\r \r install everything, and then be just as if we are on our development machine, give or take a few differences,\r \r with that particular environment.\r \r There is a way to, of course, do this on Nick's, but he had to do a little bit of magic along the way.\r \r Well, him and his colleague,\r \r Philip Bowman\r \r have started a GitHub organization\r \r with their fork\r \r of the Nix packages\r \r repository, which basically contains all the expressions for every\r \r package that's built in the Nix ecosystem. And, yes, this includes\r \r r itself\r \r and the packages within r that are built with these next expressions.\r \r\n\nSo in theory, you could take this, clone it, update the expression to get, like, a more up to date version of the package.\r \r Well, as that version gets up to date, guess what it's gonna have to do? There are no binaries of that new version available at that time,\r \r which means you're compiling from source.\r \r And yes, if you ever compiled stuff in the tidy verse from source and you're on Linux,\r \r get yourself a coffee or a favorite water beverage, you're gonna be there a while.\r \r Ain't nobody got time for that. Right, Mike?\r \r\n\n[00:10:38] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Nope. No. Especially when it comes to, you know,\r \r trying to install the tidy verse or something like that. You know, that's\r \r a suite of packages all getting built from source for sure. You're gonna have to,\r \r take a walk.\r \r\n\n[00:10:51] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 51,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Take a walk. Get get those steps in, but you don't wanna do that over and over again because you can only do so much walking in the day probably. But\r \r there there is a happy medium here. There is a happy ending to this. And that is\r \r you can actually, in the Nix ecosystem,\r \r have your\r \r own binary\r \r cache of binary versions of packages. And that is using this service\r \r called cachex,\r \r which I had never heard about until this post. But, basically, one of the things I've been benoming\r \r in my early days of my next journey\r \r is the fact that I was having to compile some of our packages from source. And I was living that that\r \r very, time\r \r this the time sync situation that we were just referencing. But, apparently, with cache x is that you can hook that up to your maybe GitHub action that Bruno is working on here. And in essence, there's some clever manipulation\r \r of how this is triggered.\r \r\n\nHe's got a process now where every day,\r \r maybe it's multiple times a day,\r \r that then there is a push to this repo that's gonna do the caching.\r \r And then that is gonna automatically\r \r build these packages if they're new and then push them to this custom cachex\r \r binary cache\r \r such that if he builds an expression from this point on with next and then he is able to reference this custom cache\r \r in his kind of preamble for the expression,\r \r it will figure out that, a, is this version of, say, tidy select\r \r available on the\r \r custom cache that Bruno set up? If yes, it's gonna pull down that binary version right away.\r \r\n\nAnd if it's not in the bind not in that cache x, it's gonna look for most likely where it will be is the default Nix repository for binary cache. If it's a package that hasn't been updated in months, it's probably gonna be there in the next stable repository, and it's gonna pull from that binary cache. So in essence, he's got his he's got a workflow now where he can pull these binary versions\r \r either from his custom cache\r \r or from the default NICS cache.\r \r That to me is massive, folks. That is absolutely massive because this was arguably\r \r one of the biggest deterrents I've seen thus far in my limited experience of Knicks that may have just been solved for this quote unquote developer setup.\r \r\n\nI'm really intrigued by this because\r \r this may be something I want to plug in to my package development because now I actually have 1 or 2 open source packages under my name that are starting to get used by some people that I'm I'm working with. I wanna make sure that I'm up to date\r \r on these issues, albeit they're not on CRAN yet. But at the same time, if they ever to get on CRAN, I want to harden my development set up for this.\r \r So this is an amazing approach that, again, everything's in the open. They got links, and Bruno's got links in the to the GitHub repository\r \r where this cache is being built and this other custom repository that's doing kind of the triggering\r \r of all this. I think there are a lot of principles here that we all can take from a developer perspective\r \r to give ourselves extra peace of mind\r \r for these cases where Kran might have some mysterious errors in these checks. And, of course, they're not gonna tell you how deep the rabbit hole goes of which dependency of a dependency actually caused a failure. It's on you as the as a package maintainer to figure that piece out.\r \r\n\nBut this may be a step in the right direction to be more proactive\r \r in figuring that out. And so I'll be paying attention to this work flow and maybe grabbing some nuggets of this as I continue on my,\r \r albeit it's still baby steps, but I've been\r \r venturing and running NICS on a virtual machine,\r \r trying to start bootstrapping our environments, bootstrapping my other tools of choice from a developer perspective.\r \r And this one, I'm definitely gonna keep an eye on as another way to augment my, my potential workflow here. So again, this post had a mix of everything. The detective work to figure out just which dependency caused this error,\r \r fixing the annoyance of having to compile all this manually every single time. And lo and behold, we got some really fancy GitHub actions and caching to to thank Bruno for. So kudos to Bruno for this immense\r \r rabbit hole journey here in this part of the next journey.\r \r\n\n\n\n[00:15:19] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. It is a little bit of a rabbit hole, Eric, but I I think there's a lot in here that\r \r might be useful to to those using Nix and maybe those even not using Nix or those maybe on their journey\r \r as well. You know, one thing that sort of stood out to me is for anyone that has a unit test,\r \r in their their R package or their,\r \r you know,\r \r our repository and that unit test is is maybe running up programmatically or on some schedule or something like that, you should probably be aware that in the latest version of the tidy select package,\r \r if you have a dplyr select call and\r \r write your that the error message that's going to get returned if one of the columns in that select statement doesn't exist. It used to say can't subset columns that don't exist. Now it says can't select columns\r \r that don't exist. So if you have an expect error\r \r call in your unit test and you're looking specifically for, that keyword subset,\r \r that's not going to to fire anymore. So that test is actually gonna fail\r \r because it that that rejects\r \r those strings will not match essentially so you may need to go in and update your unit test and take a look at the unit test that you have across your different R packages and repositories to to make sure that you are not too going to get bit by this issue the same way that Bruno did,\r \r and it was really interesting to me as well,\r \r how, you know, the binaries\r \r I guess of the\r \r the the release before,\r \r I guess, the 1.2.0\r \r release of Tidy Select, which is now, quote unquote, the old version,\r \r were the versions of Tidy Select getting installed, on Debian and Windows and and Mac,\r \r you know, for these crayon\r \r package checks, but it was compiling from source\r \r on fedora so that's you know there's there's all these these funky things\r \r that take place you know that we I think we see all the time\r \r that are huge head scratchers for when your your packages are going through these automated tests across all these different\r \r operating systems,\r \r when when they're trying to pass their crayon checks.\r \r\n\nRight? They'll pass 9 of them and then the 10th one will fail. And it'll probably make you wanna throw your computer out the window half the time.\r \r But, you know, it just sometimes takes a little investigative work like like Bruno did or maybe,\r \r you know,\r \r diving into your your r four d s Slack community or your Mastodon community,\r \r and trying to figure out,\r \r collectively\r \r what's going on here. And hopefully, it didn't take Bruno too long to to figure that out. But, you know, as you you mentioned, I think, Nick's actually is going to\r \r allow him to\r \r easily, you know, handle these types of situations\r \r in the future,\r \r where his unit tests need to ensure that they're running against the latest versions\r \r of all packages or or maybe, you know, on some OS's,\r \r it'll be, you know, building the the latest binaries versus on other OS's, the latest,\r \r packages\r \r compiled from source.\r \r\n\nSo, you know, I think\r \r one avenue again to to try to do some of this stuff, you know, might be having all sorts of different docker images,\r \r to handle all these different edge cases and and use cases and operating systems. But it seems like Nix actually might be a more streamlined,\r \r and efficient workflow to be able to to make those switches\r \r a little bit quicker and run those tests, within different environments a little quicker\r \r to to spin up VMs or something like that or install, you know, all sorts of different versions of our locally and all sorts of different versions of our packages locally and and you know just sort of cross your fingers that, you know, that your package checks would succeed on other operating systems that you didn't really necessarily have any access to.\r \r So you know that's really interesting and then and then maybe the last thing I'll point out here that I thought was interesting and and useful you know one a lot of times when we're you know, running GitHub actions. Right? It's it's running on some piece of compute that we we don't have full access to. So it's we're relying really on a YAML file at the end of the day and maybe this goes back to who was it? Yaron Ooms that authored that blog post a couple weeks ago about like,\r \r you know, workflows\r \r in our Oh. And Oh. You know, that's not repeat yourself. Miles Macbain. Miles Macbain. Oh. Miles Macbain. That's exactly who it was. Yeah. Oh, my goodness. This sort of brings me back to that where you know eventually\r \r you get to try to just do everything with it a YAML file and it would drive you crazy but,\r \r we're at the mercy you know with GitHub actions actions, you know, for better or for worse a lot has been abstracted for us which is awesome but we're at the mercy of, a YAML file. Right? To be able to handle,\r \r you know, setting up that that piece of compute, that runner and GitHub actions, installing the dependencies\r \r on there.\r \r\n\nAnd, you know, one thing I think that can be be tricky sometimes is is maybe authenticating\r \r it into different services that you wanna leverage. And that was my first thought here when I was taking a look at the this cache x,\r \r this cache utility here\r \r that allows you to to cache, different,\r \r packages,\r \r within sort of your next environment. But one of the interesting things is that you don't need to authenticate\r \r to cache x to simply pull binaries.\r \r All Bruno had to do was was really just these two lines of YAML specifying\r \r the cache x GitHub action version that he wants to use and then he has a particular name I assume you know he's logged into the cache x platform\r \r and and developed his own cache. That's that's b dash rodriguez,\r \r and that's where his cache lives, and that's all he has to specify in his GitHub action to be able to pull,\r \r binaries from that cache. So I think that's\r \r incredibly powerful,\r \r really nice that how\r \r simplified sort of this workflow is to be able to set up, your cache x cache,\r \r it within a GitHub Actions workflow. So fantastic blog post from start to finish. It really walks us through sort of the entire problems problem space and and how he was able to solve it.\r \r\n\nAnd another feather in in Nick's cap, I would say.\r \r\n\n[00:21:37] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 37,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. I totally agree. And I'm, again, very much anything that can make your development life easier to be proactive on these issues happening,\r \r you've done that hard work of building those unit tests. You're doing what you need to do in terms of giving yourself some sanity, hopefully, as dependencies get updated. But, be able to put this in action\r \r first when you need it in an ad hoc way, be able to just pull this environment down within probably a matter of a minute versus, like, an hour like it would be by default.\r \r I mean, they they can't underscore the time savings you get from the caching mechanism,\r \r But also there is a lot to glean from these repositories that you mentioned, Mike, that\r \r Bruno and Philippe have set up for these GitHub Action workflows.\r \r\n\nI I was in GitHub action nightmares,\r \r a couple weeks ago, debugging things. And I remember\r \r with a quartile compilation, I just I just I almost just threw my keyboard out the window. I just could not figure out what the bloody heck was happening. So, yeah, there is a danger sometimes\r \r of having the abstraction too high up versus what lower level it's doing. And the other piece of advice I'll give\r \r is that, you know, it may seem intimidating to be like, these these kind of actions are doing such magical things with these YAMLs.\r \r You know what's behind these actions most of the time? It's shell scripting. It's just doing stuff on Linux and then be able to troubleshoot that.\r \r\n\nSo, like, I went into the GitHub action source of some of those quartile actions, and I figured out, okay. So these kind of quartile commands with this Boolean check if, like, I have this render flag enabled or not. Then I realized, you know what? Okay. I can take matters in my own hands. I can do my own custom rendering.\r \r It's not as intimidating as it sounds. It's just the bugging can be a complete nightmare unless you know where to look. So I'm sure I'd imagine Bruno's had a few of those experiences\r \r too like all of us.\r \r\n\n\n\n[00:23:29] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Definitely. And GitHub actions has its own sort of cache as well which That is true. Has bit me a couple times not to speak ill of GitHub actions because I do I do love it.\r \r But, yeah, it's it's caches everywhere.\r \r\n\n[00:23:43] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. Caches,\r \r unfortunately, is not the kind of cache I could buy things with. But, you know, nonetheless,\r \r it's all everywhere. Right?\r \r Speaking of major updates that we're seeing in the ecosystems\r \r these days in terms of the tooling we use, another one I've kept my very close eye on with a lot of influential projects I'm trying to bootstrap right now is we are happy to talk about a new release\r \r for WebR itself.\r \r When this blog post comes from the tidyverse blog and authored by the WebR architect and brilliant,\r \r engineer George Stagg, who is in this blog post\r \r getting us through, you know, or talking us through a few of these major updates that we see in the WebR ecosystem.\r \r\n\nAnd I'm going to speak to a few of these. And I know some of these I'm going to be able to benefit one very quickly, I would imagine.\r \r But the first major of note is that now they are basing WebR on the latest stable release of R itself because\r \r in essence, they have to bootstrap R with a couple of the custom shims\r \r under the hood to make it seem like you're installing a package from a default repository where instead you're installing it from WebR's\r \r binary package repository. So they always have to, in essence, patch R to make all this work. And now they patch the latest stable version of R, which, of course, will be great for\r \r consistency with maybe your typical environment that you're building these analyses on. And another\r \r great feature that I think the users are going to definitely notice\r \r is some improved air reporting too.\r \r\n\nWhereas in the past, you might see a custom, like, uncalled exemption\r \r if something crazy was happening in the WebR process\r \r with respect to maybe an error in the r code itself.\r \r Well, now you're gonna be able to see the actual error in the JavaScript console whenever WebR is running,\r \r which, of course, is going to help you\r \r immensely with the bugging\r \r to narrow down, oh, did I get the JavaScript code wrong that I'm using WebR with, or was it in my R code itself? So\r \r that, again, for usability,\r \r a massive improvement for the quality of life.\r \r And speaking of quality of life enhancements,\r \r ones that you'll they'll hopefully be able to see and interact with\r \r is big improvements to the graphics engine.\r \r\n\nBecause now the graphics that are drawn with WebRx,\r \r they call it the canvas function,\r \r they're gonna be captured in that R based session\r \r in a similar way so that it's consistent with other output types that you would see in a normal installation of R,\r \r which is leading to more streamlined, you know, interaction with these graphics.\r \r And, also, along those lines,\r \r graphics that you create in Base R have had massive improvements to the rendering engine. And the blog post, when you see this linked in our weekly, you'll see\r \r very sharp looking images\r \r that they're able to produce when you evaluate that code. Even as I'm talking now, I'm running through these snippets, and they look very nice. Great anti alias text.\r \r\n\nThe symbols with the r logo look really sharp.\r \r Everything looks as if you were in your native r session. Again,\r \r just massive\r \r amazing improvements\r \r under the hood to make this, you know, very seamless and attractive to the end user.\r \r And it doesn't just stop\r \r with graphic objects.\r \r There has been a lot of under the hood enhancements\r \r as well as some new user facing\r \r enhancements\r \r that the R objects that are created in these WebR processes\r \r are going to be\r \r more easily converted back and forth between their JavaScript counterparts and their R counterparts.\r \r Where does this fit in the big picture?\r \r\n\nThe big thing for me is the data frame and r that is literally the fundamental building block of pricing 99%\r \r of my analyses.\r \r Now, of course, in r, you have your columns and you got your rows. Right? That's not always what JavaScript treats data as, especially if you're familiar with d 3.\r \r It is definitely a different type of layout you often see where it's basically the column is\r \r given\r \r a name. It's like a named vector of things in a row wise type fashion layout.\r \r But there are functions now in WebR\r \r to go back and forth\r \r between\r \r these JavaScript\r \r notations\r \r and the R native\r \r kind of representations.\r \r\n\nIn fact, there's a handy function\r \r called\r \r 2d3,\r \r where you can simply take that data frame in the R process, put it into a format that you could feed in any of your custom d three visualizations.\r \r These things are massive for that interoperability\r \r between maybe using r to do the heavy lifting statistically.\r \r But if you're familiar with JavaScript and you wanna keep with those JavaScript visuals,\r \r have at it. Have your d three magic and be able to get that that construct of the data as you need it. So,\r \r again, great way for you to take maybe baby steps if you're new to R, but you're familiar with JavaScript, a way to get the best of both worlds. Really,\r \r really a big fan of that.\r \r\n\nAnd then some really fun plumbing type enhancements here that I'm paying a lot of attention to\r \r is that with collaboration,\r \r you named dropped them earlier, Mike, your own ooms as well as,\r \r Utahn.\r \r They have\r \r new system libraries\r \r in the WebR process and as well as a custom WebR Docker container. Hey. Containers again for you.\r \r Which they've included some new numeric libraries\r \r as well as the ImageMagick\r \r image manipulation\r \r suite.\r \r And wait for it. There is now a Rust compiler configured\r \r so that if your R package involves Rust in some way, you're not gonna be able to compile that into web assembly 2.\r \r Absolutely amazing stuff.\r \r\n\nAnd to really, you know, you know,\r \r intrigue you even further,\r \r embedded in the post\r \r is a Shiny Live powered web app\r \r from your own himself\r \r on using that magic package that he's created in the past. But now in the blog post where you can absolutely distort or make fun of this random cat image.\r \r And I'm literally doing it right now as I speak.\r \r It is so responsive so quick. I can't believe this is happening, Mike. This is just amazing.\r \r\n\n[00:30:30] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Mike Thomas",
        "trans_text": "It's as if the shiny apps running locally. It's insane. It's actually, like, faster. I mean, the the fact that you can put effects\r \r on this image to like negate it and you know you totally changing how it's visually\r \r represented is awesome. You can upload your own image which is what I've done. I uploaded an old hex logo and I'm just messing around with it right now, rotating it, blurring it, imploding\r \r it\r \r you know it's it's pretty cool it flipping it reversing it\r \r yeah It's it's it's awesome. I cannot believe how responsive it is.\r \r\n\n[00:31:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. This has come such a long way. I mean, even it was maybe, what, 4 or 5 months ago that would take a good minute or 2 for these things at Boostramp, and here we are. We got this as if it was plugged into the blog post directly. Like, this is this is magical stuff.\r \r So I'm really, really intrigued by by where this is going. And, again, we're seeing more in the community leverage Rust. So I'm sure there's going to be a lot of grain enhancements with this. And speaking of packages themselves,\r \r there is now additional,\r \r refresh, if you will, on the packages in in the CRAN ecosystem\r \r that are now supported in WebR,\r \r that total is now bumped to 12,969\r \r or about 63%\r \r of the available CRAN packages that are now supported natively\r \r in WebR.\r \r\n\nAnd like I mentioned before, what George and other engineers have to do with this WebR binary cache of packages\r \r is they have to compile them in a special way so that they're supported by web assembly.\r \r So not everything is there yet, but that's a massive jump compared to where we've been even just like I said a few months ago to what is supported in webr. That is absolutely amazing.\r \r\n\n[00:32:18] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 18,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. I couldn't agree more, and this is just, you know, more exciting improvements. I think, you know, probably the biggest thing for me as a,\r \r you know, practitioner, somebody who who's very\r \r data,\r \r hands on in most of our projects as well as as you talked about, Eric. The ability\r \r to to switch back and forth, between JavaScript\r \r sort of data frame objects, you know, especially,\r \r I guess, particularly in this case,\r \r we're talking about raw objects\r \r of typed array\r \r array buffer and array buffer view those are the types of raw vector\r \r objects that may now be used to construct our objects\r \r and like you said you can go back from an our data frame\r \r to a Javascript\r \r object\r \r with the either 2 object function\r \r or if you want to go more the d3 route that would be the the 2 d three function in Javascript so\r \r that's exciting because to me that makes it feel you know much more\r \r our framework as well. It kinda feels a little,\r \r I've been watching a lot of the observable\r \r project\r \r and they have some some excellent,\r \r utilities, blog post documentation around how to sort of convert back and forth between either pandas data frames, our data\r \r frames, and you know the JavaScript data frames that really power the visuals,\r \r on that platform. So this sort of reminds me of that in terms of how easy it is to go back and forth between the 2, and I think that that ease of use is really going to go a long way towards helping people get up to speed and build\r \r tools,\r \r within\r \r the WebR framework. So very very excited.\r \r\n\nThanks to to all who work on this. There's a fantastic acknowledgment section\r \r at the bottom of this and and a lot of familiar names there of folks who are are working hard to continue to drive this this forward and, you know, especially thanks to to George Stagg for sort of spearheading all of this and putting the blog post together.\r \r\n\n[00:34:15] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 15,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And and and any package authors out there that are saying, hey. You know what? I know my package is not crayon. Can I do this a web assembly?\r \r Oh, yes. You can. They actually have a r WASM\r \r package to help you compile your own r package into WebAssembly\r \r and be able to manage a repository for that. And, yes, we were talking about GitHub actions earlier. Another, you know, nugget at the end here is that they have put links to their reusable GitHub Actions that you could get inspiration from or just leverage yourself\r \r so that your package is compiled.\r \r\n\nAnd, yes, you can also,\r \r check out we talked about this before. The R Universe project is offering WebR binaries of packages\r \r on any of the packages that they host too. So there is\r \r not just that binary,\r \r repository that WebR is hosting themselves.\r \r You know, our universe is another great inspiration or a great source of this as well. So\r \r lots to choose from in this space.\r \r\n\n[00:35:15] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 15,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. Absolutely. Don't blink.\r \r\n\n[00:35:25] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 25,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Don't blink. You might miss it. Just like how you might miss some very snazzy visuals that we're gonna talk about on our last highlight today.\r \r And as you know, Mike, you and I can probably sympathize, especially\r \r early on in maybe a data science journey or you're leveraging\r \r Are you hearing about things like the tidyverse, you know, suite of packages for the first time, and you're trying to get a handle on a lot of these operations\r \r that occur\r \r when you want to manipulate your data frames like adding new variables,\r \r doing transposing,\r \r you know, doing group summaries.\r \r\n\nA lot of people, myself included, do like to have a nice visual to accompany\r \r maybe the text around just what those particular functions are doing.\r \r Well, we're happy to share that Andrew Hice\r \r has authored a latest blog post\r \r on visualizing\r \r many of the important\r \r dplyr functions\r \r with both,\r \r single group as well as multiple group processing.\r \r And not just having static pictures, folks,\r \r he has handcrafted\r \r some absolutely amazing animations\r \r to go with this. I can I can imagine\r \r he is making heavy use of this in his statistics,\r \r lectures and his coursework?\r \r\n\nBut, yeah, of course, we're we're in an audio podcast talking about visuals here, but boy oh boy,\r \r you look at these and how he made them, first off, is that\r \r he tried to leverage what Garrigade and Bowie, from has built\r \r with his custom visuals in the tidy explain package, but he was running into a couple limitations.\r \r I'll be especially around the group processing.\r \r So Andrew is showing his, graphical editing shops here,\r \r has built custom Adobe Illustrator\r \r powered visuals and after effects.\r \r But guess what? He's actually shared the the files that if you have the software,\r \r you go import this in and try it yourself.\r \r\n\nI I'm not an Adobe customer, so I can't exactly run this myself. But, hey, it's there if you have that\r \r same software.\r \r But throughout the blog posts, he's got not just the narrative of what a function does such as mutate.\r \r You can simply hit play in the blog post and then see\r \r literally the transformation\r \r of that data with this nice transition kind of layout from left to right with new variables or new records\r \r being colored the same as the new code snippet that's being shown on the right\r \r side. It is very easy to digest.\r \r It does as a mutate with summarize,\r \r and then where it really starts to shine is the grouping visuals. Or now, if you're grouping by a categorical variable,\r \r he's able to separate these blocks out logically\r \r and then really show the impact of that operation\r \r and then be able to ungroup that at the end to get that\r \r original setback\r \r or things like that. And also custom mutations within groups. So he's got the code snippets\r \r alongside the visuals. Again,\r \r really great to digest visually\r \r what is happening here. And, boy, I wish I'd had this when I was learning the manipulation\r \r in the old days. But, of course, in my day, not to be that guy saying get off my lawn, we didn't have Dplyr back then. We had Plyr midway through my hour journey, and that did not have nearly the resources\r \r that dplyr has both under the hood as well as in\r \r educational materials.\r \r\n\nBut, again, the visuals really do a terrific job of really isolating the key\r \r incremental\r \r steps\r \r in these operations, which I think you can see it in a pipeline operation\r \r just with the text.\r \r But seeing that visual paired with it, you really start to see what is the impact\r \r of each of those statements.\r \r So there is a whole lot to digest here. We definitely invite you to check out the post because our ramblings can only do us so much justice,\r \r But, kudos kudos to Andrew\r \r for handcrafting\r \r all this from the ground up. It is truly amazing stuff.\r \r\n\n[00:39:28] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 28,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. This is fantastic. You know, I think I know Andrew\r \r is a professor, and this is just go I wish I had him as a professor because this I know. Is just going to go, such a long way towards\r \r building his his students understanding\r \r of, you know, especially,\r \r you know, I think I think mutate,\r \r isn't\r \r isn't too difficult to wrap your head around. It's a little straightforward, but once you start getting into\r \r grouping by aggregation,\r \r summarization,\r \r doing a mutate on a grouped data frame, joins,\r \r things like that, It it, you know, takes it to an additional\r \r level of, you know, abstraction\r \r that can be difficult to wrap your head around when you're when you're a beginner.\r \r\n\nAnd back in my day, Eric, it was, Excel pivot tables. That's how I first got my my start in, you know, understanding some of these concepts and then I had to bring it over, to the our side and I was like, wow. Hey, you know, this is a, maybe a hot take a little bit but\r \r what has a better expressive syntax to tell you exactly what it's doing,\r \r than dplyr\r \r and the tidyverse.\r \r I don't think there's anything else out there.\r \r Sure surely a whole lot better than Excel.\r \r I I can at least tell you that much in in terms of just being able to to look at the code, you know, I think SQL is probably a close second, but to be able to look at the code and understand sort of exactly\r \r what's going on and, you know, these examples applied to data,\r \r I think are fantastic. These these visuals go such a long way towards building that understanding\r \r as well because you can\r \r he's really representing sort of the the action\r \r taking place here, whether it be grouping, summarization,\r \r or a mutate.\r \r\n\nSo,\r \r yeah. Hats off to him. I would say that that\r \r his work\r \r doing this, he may not realize just how\r \r impactful this might be on his\r \r students or, you know, folks learning r who stumble across this blog post. So if you if you know someone,\r \r who's who's trying to learn r having a tough time,\r \r you know, first point them to the Tidyverse. That would be my recommendation\r \r to wrap their head around dang data wrangling, but I think this is going to be a fantastic blog post to to point people to\r \r as well, to help them get up to speed, to help them sort of get over the hump, right, in building their understanding of data manipulation in R. So I I really just can't understate, you know, I've said it a few times now, but I can't understate sort of the importance\r \r of this and, how useful\r \r I think this type of visual\r \r instruction can be.\r \r\n\n\n\n[00:42:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And another thing I wanna say is critically important, especially in this new age of, I don't know how new it is per se, but really\r \r someone I've been gleaming in the community of really openly\r \r sharing our our wins and our key learnings\r \r to educate\r \r ourselves and others\r \r is that you may be wondering, oh, wow, Andrew. You did such amazing work with this. I wish I could use this in my materials. Guess what? You can, folks. These are all Creative Commons license,\r \r which means he's got links to, like, the finished products,\r \r both the video form and animated GIFs and static images of all this. So if you wanna leverage this in your materials,\r \r have at it. Right? I mean, that is a huge service that Andrew has done here. He could have easily kept this under his own, like, private coursework, you know, materials,\r \r but he's sharing it with all of us. So I think that is\r \r a massive win for\r \r all of us kind of in this educational space. So even our organization is trying to help teach others\r \r that are new to R how some of these operations work.\r \r\n\nYou better believe I'll be,\r \r drawing upon some of this when I get questions about how some of these, you know, group processing and deep wire works and the like. It's\r \r just amazing\r \r amazing work, Andrew, and even more amazing that you are so willing to share this with everybody. It's a new it's a new age, I would say.\r \r\n\n[00:43:29] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Mike Thomas",
        "trans_text": "And has the time to author all of this content out there. I don't know how he does it, but thank you so so much.\r \r\n\n[00:43:35] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 35,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I I whatever you're you're, either ingesting or whatever life hack you've done, please pass it our ways because we we would love to have it. I respect the It's gotta be those damn cold tubs. I still gotta do that.\r \r Yeah. Yeah. I think we're late on that, aren't we?\r \r But, you know, what you're not late on is that if you boot up our week without org, you're never going to be late and seeing the latest and greatest from the R community\r \r showcased by the R community.\r \r Great new packages,\r \r new announcements,\r \r and new blog posts, much like what we talked about here. And we'll take a couple of minutes to share some of our additional fines from the issue. And for me, it's a plug, especially for those in the health and medical industries.\r \r\n\nThe Our Medicine Conference is back for another year, and they have just opened up their their open\r \r call for talks. And that conference is taking place on\r \r June 10th or 14th this year.\r \r And on top of having the call for abstracts and and talks open, they've announced that they have keynotes lined up from Stephanie Hicks and Gunilla Bosch,\r \r talking about some really innovative work in medical research and genomic analysis.\r \r Always stuff that I resonate with, especially in the early part of my career\r \r where r was immensely helpful as I was doing a lot of genetic\r \r the to the post from the Arkansas Museum of all the details. And it's always been a really\r \r top notch and well run conference. It's been a great kind of companion in arms, so to speak, with\r \r our pharma conference that I'm a part of. But, yeah, they all are very complementary of each other and really great to see these resources shared in the community.\r \r\n\nMike, what did you find?\r \r\n\n[00:45:27] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Mike Thomas",
        "trans_text": "No. That's awesome, Eric. I found a fantastic\r \r blog post, I think, authored by, Hannah Frick, who's a member of the Tidymodels\r \r team at Posit, and she's been instrumental in incorporating survival analysis\r \r into the tidy models ecosystem.\r \r So there is now support for survival analysis for time to event data\r \r across tidy models,\r \r which is is really really fantastic and exciting for those of us, which,\r \r I know you as much in life sciences as, believe it or not, me,\r \r in financial services and and credit risk, use\r \r these time to event survival analysis types of models because,\r \r they handle, you know, leveraging longitudinal data.\r \r\n\nThey, you know, have a good setup to be able to introduce\r \r hierarchical models\r \r as well, with mixed effects models or or Bayesian type models\r \r that, you know, are and these these longitudinal,\r \r types of data sets, as well as these hierarchical types of data sets,\r \r we see them all the time. I mean, that that those things are present in a lot of the data sets that we work with in a way that machine learning just can't necessarily\r \r handle.\r \r Right? So survival analysis is really a great tool to be able to use in those particular\r \r use cases.\r \r\n\nThere's a fantastic\r \r amount of links in here.\r \r There's also an additional blog post that walks through a very hands on,\r \r data use case, a a case study here called how long until building complaints are dispositioned.\r \r That's now on the Tidymodels website. It's it's linked at the very bottom of this blog post, and that's, sort of how I I came across this Our Weekly Highlight as well, because I saw that one, I think, come across Mastodon.\r \r And it's just a great, great walk through and and use case of all the different functionality that we now have around survival modeling,\r \r within the Tidymodels framework. So super excited about this. Thanks to all the folks that worked on this, and thanks to to Hannah for putting this blog post together.\r \r\n\n\n\n[00:47:31] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 31,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I'm diving in. I'm gonna dive into this case study after this because, I'm starting to get back into the time to event mode now with some custom analysis and clinical operations. And this could be a very nice way to\r \r benchmark newer models and take what I've been learning over the years of tiny models and apply it directly\r \r to time the event. It has been requested for a long time, and it is gratifying to see the tiny models team has taken this head on, and now we've got a boatload of additional\r \r capabilities to choose from. So, yeah, kudos to everybody on the team for that.\r \r\n\n\n\n[00:48:06] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. No trivial effort, I'm sure, because survival analysis modeling\r \r has a lot of different nuances\r \r for machine learning, but you can still borrow a lot of practices, you know, that we might traditionally associate with\r \r machine learning, like, hyperparameter\r \r tuning and things like that, and and leverage those within survival analysis workflow. So,\r \r it was no trivial effort, I'm sure, but extremely powerful,\r \r when brought together. And I'm very grateful for the fact that they have.\r \r\n\n[00:48:35] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 35,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. Absolutely.\r \r And I'm also grateful for hey. Hey. Our weekly even existing. So we can see this on a weekly basis and be able to talk to all of you about it. But it is, like I mentioned, powered by the community, and we always are appreciative of all of your help. And the best way to contribute to our weekly is send us a poll request with that awesome new blog post, that great new package you discovered,\r \r that great new resource that you think deserves the attention of the community. Is just a poll request away at the top right corner of r o k dot\r \r org. You'll see the frame little Octocad image there. Just click on that, and you got yourself a pull request template right there. It's all marked down all the time. I live in markdown. I live and breathe markdown now. I wish I could write my emails in markdown and have them render in real time, but that thing happened in Microsoft Outlook anytime soon. But I digress. At least, so every week, it does. So you can have that at your at your at your fingertips.\r \r\n\nAnd as well as we love hearing from all of you in the audience as well, you got a few ways to get in touch with us. Got a handy little contact page linked in this episode show notes\r \r and as well as you can send us a friendly little boost along the way if you're on those awesome modern podcast apps like Podverse, Fountain, Cast O Matic, CurioCaster.\r \r I could go on and on. They're all linked in the show notes if you wanna get a nice selection of all that. And, yeah, this is now gonna be the 2nd episode. Our new podcast host, and everything is yours truly\r \r botching his end of the recording. Let's hope that this one goes more smoothly this time around. Did some testing before this, fingers crossed. It'll sound as clear as we've always been, but, we are on a new host. So if you have any trouble\r \r finding the show, we have updated all the links at rweekly to our new podcast\r \r landing page, so it should be a seamless transition.\r \r\n\nBut as always, don't hesitate to get in touch with me if you have any difficulties.\r \r And the best way to do that, you can find me on Mastodon these days. I am at our podcast at podcast index on social.\r \r I'm also on LinkedIn,\r \r with show announcements and the like. And on that Twitter x thingy jingy at DR cast. And, Mike, where can the listeners find you?\r \r\n\n[00:50:41] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Sure. You can find me on mastodon don@mike_thomas@fossedon,\r \r dot org, or you can find me on LinkedIn by searching Ketchbrook Analytics,\r \r k e t c h b r o o k,\r \r and see what I'm up to lately.\r \r\n\n[00:50:57] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "trans_timestamp": 57,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome stuff. And, yep. We we were on the other side of that major eclipse event, but the the community train never stops over the our ecosystem. And as always,\r \r we thank you so much for listening to us wherever you are around the world, and we will be back with another edition of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_15_highlights",
        "chap_timestamp": 51,
        "chap_text": "R and Nix \"cache\" in",
        "chap_href": "https://www.brodrigues.co/blog/2024-04-04-nix_for_r_part_11/"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "chap_timestamp": 58,
        "chap_text": "webR 0.3.1",
        "chap_href": "https://www.tidyverse.org/blog/2024/04/webr-0-3-1/"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "chap_timestamp": 25,
        "chap_text": "Visualizing dplyr operations",
        "chap_href": "https://www.andrewheiss.com/blog/2024/04/04/group_by-summarize-ungroup-animations/"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "chap_timestamp": 52,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_15_highlights",
        "chap_timestamp": 34,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_14_highlights",
        "ep_date": "2024-04-03",
        "ep_duration": 5,
        "ep_description_short": "Taking the tradition of spring cleaning your R session to a nefarious direction, how a little R and automation crafted together helps with bill payments, and the tried-and-true method of simulation in action to investigate time-to-event inference statistics. Episode Links This week’s curator: Ryo Nakagawara - @R_by_Ryo) (X/Twitter) &…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_14_highlights",
        "description_long": "\r \r Taking the tradition of spring cleaning your R session to a nefarious direction, how a little R and automation crafted together helps with bill payments, and the tried-and-true method of simulation in action to investigate time-to-event inference statistics.\nEpisode Links\n\nThis week’s curator: Ryo Nakagawara - @R_by_Ryo) (X/Twitter) & @[email protected] (Mastodon)\nI Made R Text For Me\nStop Jenny committing arson\nThe log-rank Test Assumes More Than the Cox Model\nEntire issue available at rweekly.org/2024-W14\nSupplement Resources\n\nLinux Unplugged episode 156: The xz Backdoor Exposed https://www.jupiterbroadcasting.com/show/linux-unplugged/556/\nPushbullet https://www.pushbullet.com/\n{rpushbullet} R interface to the awesome Pushbullet service https://github.com/eddelbuettel/rpushbullet\nMike’s PDF quarto reports in devcontainers GitHub repo https://github.com/ketchbrookanalytics/quarto-pdf-dev\nAligning Beliefs and Profession: Using R in Protecting the Penobscot Nation’s Traditional Lifeways https://www.r-consortium.org/blog/2024/03/27/aligning-beliefs-and-profession-using-r-in-protecting-the-penobscot-nations-traditional-lifeways\nUsing Data to Protect Traditional Lifeways https://www.youtube.com/watch?v=2PjOSBHRm74\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media \nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @[email protected] (Mastodon) and @mike_ketchbrook (X/Twitter)\nMusic credits powered byOCRemix\n\nHeart’s Lullaby - Final Fantasy V - RebeccaETripp, Gamer of the Winds, Rahul Vanamali, Teil Buck - https://ocremix.org/remix/OCR04572\nTails and the Music Maker - Picolescence - zircon - https://ocremix.org/remix/OCR02176"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://mstdn.social/@R_by_Ryo"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://brendenmsmith.com/posts/text%20in%20r/"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://www.rostrum.blog/posts/2024-04-01-perpetual-restart/"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://fharrell.com/post/logrank/"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://rweekly.org/2024-W14.html"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://www.jupiterbroadcasting.com/show/linux-unplugged/556/"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://www.pushbullet.com/"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://github.com/eddelbuettel/rpushbullet"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://github.com/ketchbrookanalytics/quarto-pdf-dev"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://www.r-consortium.org/blog/2024/03/27/aligning-beliefs-and-profession-using-r-in-protecting-the-penobscot-nations-traditional-lifeways"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://www.youtube.com/watch?v=2PjOSBHRm74"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://ocremix.org/remix/OCR04572"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "links": "https://ocremix.org/remix/OCR02176"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2024_w_14_highlights",
        "chap_timestamp": 3,
        "chap_text": "Clean those environments x100",
        "chap_href": "https://www.rostrum.blog/posts/2024-04-01-perpetual-restart/"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "chap_timestamp": 40,
        "chap_text": "R helps pay the bills",
        "chap_href": "https://brendenmsmith.com/posts/text%20in%20r/"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "chap_timestamp": 19,
        "chap_text": "Time-to-event stats and simulation",
        "chap_href": "https://fharrell.com/post/logrank/"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "chap_timestamp": 27,
        "chap_text": "Additional finds"
      },
      {
        "ep_name": "issue_2024_w_14_highlights",
        "chap_timestamp": 1,
        "chap_text": "Episode wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_13_highlights",
        "ep_date": "2024-03-27",
        "ep_duration": 0,
        "ep_description_short": "How a recent pivot in one of the most popular testing frameworks in R unlocks mocking once again, bringing robust grammar checks to your R development environment with rspell, and flex your Shiny and HTML design muscles with flexbox. Episode Links This week's curator: Batool Almarzouq - @batool664 (https://twitter.com/batool664) (X/Twitter) Update…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_13_highlights",
        "description_long": "\r \r\n\nHow a recent pivot in one of the most popular testing frameworks in R unlocks mocking once again, bringing robust grammar checks to your R development environment with rspell, and flex your Shiny and HTML design muscles with flexbox.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq - @batool664 (X/Twitter)\nUpdate on mocking for testing R packages\n{rspell} Are you writing in a foreign language? The RStudio spelling dictionary setting is not sufficient to correct grammar errors. Try the {rspell} package to grammar-proof your notebooks and documentation straight on RStudio without copying-pasting.\n3MW (Aligning content with flexboxes)\nEntire issue available at rweekly.org/2024-W13\n\nSupplement Resources\n\ntestthat 3.2.0 re-introduced mocking after it was removed in 2019. The PR with Hadley's commentary https://github.com/r-lib/testthat/pull/1739#issuecomment-1428027869\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @[email protected] (Mastodon) and @theRcast (X/Twitter)\nMike Thomas: @[email protected] (Mastodon) and @mike_ketchbrook (X/Twitter)\n\nMusic credits powered by OCRemix\n\nKannonball - Donkey Kong Country 2: Diddy Kong's Quest - The Good Ice - https://ocremix.org/remix/OCR04571\nThe Art of Zoning Out - Pokemon Scarlet - timaeus222 - https://ocremix.org/remix/OCR04570"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://blog.r-hub.io/2024/03/21/mocking-new-take/"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://rfsaldanha.github.io/rspell/"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://3mw.albert-rapp.de/p/weather-ui-flexbox"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://rweekly.org/2024-W13.html"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://github.com/r-lib/testthat/pull/1739#issuecomment-1428027869"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://ocremix.org/remix/OCR04571"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "links": "https://ocremix.org/remix/OCR04570"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back up to a 158 of the R Weekly Highlights podcast.\r \r If you're new to the show, this is the show where every single week, we talk about the latest awesome highlights that are featured in this week's our weekly issue available at ourweekly.org.\r \r My name is Eric Nantz, and I'm delighted you joined us from wherever you are around the world.\r \r It's been a, you can tell spring is definitely more in the air, and I woke up to, a big old windstorm over here blowing over trash cans and everything around our house. Hopefully, you're safe wherever you are, but not in any event. I never do this alone. I'm joined at the hip here. Hopefully, he doesn't blow away with the winds either by my co host, Mike Thomas. Mike, how are you doing today?\r \r\n\n[00:00:44] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Eric, I'm doing great because I finally got my devcontainer\r \r and Versus Code set up for quarto\r \r rendering to PDFs.\r \r\n\n[00:00:53] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Flawless victory.\r \r Oh, listeners, if you only knew the struggles Mike has had on this\r \r effort, even I tried to take a look at it and I was scratching my head. So I'm really happy you solved that. But, man, what a game changer that is. Installing Windows fonts and everything.\r \r Oh, the pain. You don't wanna know. Yep. Yeah.\r \r I I really don't. Yep.\r \r\n\n[00:01:15] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 15,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Blog post, I I guess I owe the the world a blog post on this. I would love to see it. Yeah. We can never have enough content about using\r \r\n\n[00:01:23] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 23,
        "trans_speaker": "Eric Nantz",
        "trans_text": "struggling through the container setup because it is never easy the first time\r \r around. Awesome stuff. Well, congrats on that. And, hopefully, you don't have too much debugging as we record this issue. But, nonetheless,\r \r we have a fantastic issue today, and it was curated by Batool Almarsakh,\r \r now a long time member of the r Wiki curation team. And as always, she had tremendous help from our fellow r Wiki team members and contributors like all of you around the world with your awesome poll requests and suggestions.\r \r And, yeah, we're gonna lead off here with a concept that actually was touched on, you know, a bit earlier episodes of this podcast, but there's been some great,\r \r I would say, revisions in kinda how we go about this. And we're talking about the use of the mocking principle\r \r for testing your R packages.\r \r\n\nAnd in particular, this post is coming from,\r \r well, you guessed this. She returns once again to the highlights, Myel Salman, and this time from her post on the rhub blog\r \r on some of the latest developments that have happened in this space of automated testing within the R ecosystem\r \r and how mocking has just become a bit easier to do, you might say.\r \r And first, a little history lesson.\r \r So it was back in 2019\r \r or so\r \r that the test that package, which at the time had been experimenting\r \r with implementing mocking with a with underscore mock function,\r \r decided to pull the plug on that a little bit.\r \r\n\nThey noticed that they weren't too happy with the implementation of it, and they weren't quite sure of the best use cases for it.\r \r And as a result, there were some packages that sprung up in the our ecosystem\r \r to help fill this now gap,\r \r such as mocker and mockery.\r \r And the approaches that they took apparently caught the eye of Hadley Wickham himself\r \r because in the latest release of Testat 3.2\r \r that we covered in a previous episode,\r \r the mocking system has returned\r \r with now new functions\r \r that replicate that existing functionality.\r \r But in Hadley's words, in a much better implementation\r \r that they can scale up and make sure that it's robust in the future.\r \r\n\nSo Ma'al\r \r now has written this post\r \r as a revision to an example that they did back in 2019\r \r that is now taking advantage\r \r of TestDAT's new functionality.\r \r And in my crack research, if you will, before the show, I did dig up the very poll request\r \r that ended up bringing the mocking support back in the test net. We'll have that linked in the show notes if you want to hear the dialogue or see the dialogue between Hadley and other developers on this great development.\r \r So how do you end up doing this in your test suite?\r \r So in the post that or an example that they draw up here, Mahal first\r \r leverages to use this package to actually create a very simple\r \r prototype package that illustrates this point.\r \r\n\nAnd then the,\r \r the base example of this is a little callback to what you just said earlier, Mike, about your adventures with Windows fonts. They have a little fun function here called\r \r is encoding a pane.\r \r Guess where it's a pane, folks. It's a pane on the Windows system. I hey. I didn't write it. The Mal wrote this one,\r \r but it's a simple function that runs the base sys.info\r \r function to determine\r \r what operating system the r session is running on. And, of course, if it comes back as Windows,\r \r yeah, encoding is a pain. We all have been there. It's a very simple function.\r \r But\r \r here's the thing, though. Let's say this package is going to CRAN or another, you know, other system\r \r and you want to run your automated test, but you're probably going to run this either on a GitHub action, you know, container or whatnot.\r \r\n\nAnd most of those are not running Windows with the exception of, say, the CRAN wind builder service.\r \r So what do you do when you want to test this function\r \r but don't want it to actually do the check itself?\r \r And that's where this new enhancement to test that comes in.\r \r In particular, they,\r \r leverages the function\r \r local mocked bindings\r \r inside the test that she\r \r crafted here\r \r where she basically\r \r makes a fake version\r \r of the sys.info\r \r function\r \r but gives it a simple return value, you know, hard coded, if you will,\r \r so that when these tests are run,\r \r it's not going to call the actual base r installation sys.info.\r \r\n\nIt's gonna call this what you might call the mocked version\r \r of sys.info.\r \r So this technique, yes, this is a bit of a contrived example,\r \r I'll be it. You know, there can be panes of windows on various things. We won't get into that here. But it does illustrate the point\r \r that if you want to temporarily, for your test purposes,\r \r inject your own\r \r return value\r \r or circumvent what the function actually would do\r \r and put in your own return value instead for the sake of the test.\r \r The mocking principle with local mock bindings is going to be\r \r a very helpful way to make this happen without a bunch of refactoring\r \r of your basic\r \r code in your package.\r \r\n\nAnd she does have link to the manual page for local mock bindings if you want to see where this fits in terms of test stats, you know, you know, baseline functionality.\r \r But that's not all you can do\r \r with with the mock bindings functions. And, Mike, why don't you take us through another revision that Mau does here with what she calls revisiting their escape hatch example.\r \r\n\n[00:07:17] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I remember this example\r \r fondly, I think, from\r \r in our weekly\r \r post, from from Elle on this very same topic. You know, it's probably a year or so ago. Now, at this point and and I thought it was really fascinating. And sort of the example is that there's a function in the r directory of your your package, so it's gonna be one of your package functions. And, you know, it it has this check sort of at the top of the function to see if, the user has an Internet connection. There's a function from the curl package\r \r called has_internet,\r \r which, I guess, detects\r \r whether or not, you're connected\r \r to the Internet. So, you know, imagine that you want to write a test to ensure that, that function is is firing correctly. You know, for example, say that, in your r function, you're returning a message letting the user know that there's there's no Internet, so they should make sure that they connect to the Internet in order to run this function. Right? And you wanna make sure that that message is is firing correctly.\r \r\n\nWhen you go to run these automated\r \r tests in something like GitHub actions, you're probably not gonna be able to shut the Internet off,\r \r right,\r \r during that action. So\r \r this is where this local mock bindings can really come in handy,\r \r where you are essentially forcing the result of of this function,\r \r that that is called is InternetDown, this example function that they have, to be true. So you're you're essentially setting that and then your function is going to return that message that you would expect,\r \r and you can match that up in in an expect underscore message call from TestThat,\r \r and then life is good, essentially. But, you know, sort of before we had this local mocked bindings,\r \r ability in the TestThat package, it was very difficult to do this, sort of very hacky. Maybe you don't even maybe you don't even write the test because it's it's difficult to actually test.\r \r\n\nMaybe you're using the with our package too to to try to control some of this stuff, but I think, these these new local mock functions actually make it\r \r make our lives even a little bit more streamlined than having to use with our to to handle our environment to do something like that. So I'm really excited. That was a great example.\r \r It sort of brings me back to when I was, writing unit tests for a recent package\r \r that was unzipping files in a different order than I was expecting them to be unzipped in in my GitHub actions call. And I it was my first attempt at trying to to be a good, software developer using the with r package in my tests and,\r \r shot me in the foot. But that's the story,\r \r for for a previous time and maybe another time if anybody wants to hear it again. But at the end of this blog post, Mel, provides some some great additional examples\r \r where and this is another one that resonates with me.\r \r\n\nYou know, mocking might allow you to simulate having an older version of a package installed. So, you know, what if somebody has, you know, a version of r that's like 3.5? Or or I guess in the example of a package, what if they have a version of dplyr, as my\r \r an example with here? That's that's version 1.0.0.\r \r Maybe you have some code that is dependent on,\r \r a a particular version,\r \r a particular package being installed, so you can pretend that, in another example here, provides, you know, pretend that Arlang isn't installed. You can use local mock bindings to do exactly that.\r \r You know, you can create OAuth tokens or simulated OAuth tokens. You can create a fake GitHub URL for a project. The the sort of the possibilities here are endless. I really appreciate all the different real life examples and links that Mael has provided here.\r \r\n\nAnd it's it's a fantastic blog post showcasing this new, you know, albeit fairly straightforward,\r \r\n\n[00:10:56] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Eric Nantz",
        "trans_text": "function, local mock bindings, I think really powerful. So I'm excited to, leverage this new functionality and test that. Me as well. I was telling you in the preshow, I'm working on an internal package that's wrapping an API for\r \r scoring some health outcome measures.\r \r And this will be, you know, a great example of leverage a lot of the principles here with other, you know, best practices of API,\r \r package\r \r wrapping development.\r \r And, you know, this is yeah. These principles are really cool. And, yeah, that real life example about the package version,\r \r literally as you were talking about that, I just thought about a situation that I get confronted with for teams that are wary of building\r \r internal frameworks that are depending on what we call our central R library of packages, the ones that our IT group freezes until R is upgraded itself.\r \r\n\nWell, of course, let's say we upgrade R. We upgrade to this new version, say, 3.2 or whatever.\r \r And then those same tools that we're working on, say, you know, 3.0 or whatever have you,\r \r they wanna make sure that with that upgraded base library that's coming in a new version,\r \r will their internal tools still work as expected?\r \r Boy, oh, boy. If they wanna put some automated tests here, it seems like the mock bind the mock bindings with package versions\r \r would be a huge way to go. So thank you, Myelle, for putting that in front of me and seeing this great example from the pool package because\r \r that comes up time and time again when people are wary of, quote, unquote, the fast pace of our package versioning.\r \r\n\nYou know, it's not really that fast paced, but I digress. But either way, there are lots of there's lots of, great principles here that I think you can take wherever you're building\r \r wrappers to APIs\r \r or wrappers to system processes\r \r or other the the possibilities are endless as you see here.\r \r\n\n[00:12:45] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 45,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Absolutely. I agree. And,\r \r yeah. I mean, a lot of, a lot of throwbacks for me here not only to old blog post but the old situations that I've I've dealt with sort of this this\r \r overarching\r \r idea of how to\r \r really set, you know, minimum versions of R and minimum versions of packages\r \r as well for the R package that you're developing is that I think a really sort of complicated\r \r process as well. So maybe maybe some of these functions can help us,\r \r help us in that\r \r\n\n[00:13:18] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 18,
        "trans_speaker": "Eric Nantz",
        "trans_text": "journey.\r \r Yeah. You know, Mike, it's always good to have a helping hand now and again. And another area where I definitely need some help is if I'm drafting that very comprehensive report\r \r and I get it ready to send out, but, you know, I need that double check. Right?\r \r Misspelled check because, yeah, the fat fingers here often do misspellings in my documents.\r \r And also, it's not just a spell check. Right? Sometimes we need a little help with our grammar because as much as we learn about\r \r ours in our school education, we sometimes forget some of those rules. But that's where the magic of technology can help us. Right? And our next highlight here, we we highlight,\r \r if you will, this great capability\r \r where maybe what we see built in to an IDE isn't quite enough, but we want to tap in some more power or recite the grammar checking. And in particular, we're gonna be talking about this, I believe, a new package in the R ecosystem\r \r called Rspell.\r \r\n\nRspell has been authored by Rafael\r \r Saldanha\r \r who is a postdoc at INRIA, a French National Research Institute.\r \r And what is rspell for here? Well, rspell,\r \r the main objective here is to help plug in potential gaps that might happen in IDEs such as Rstudio\r \r for being able to do not just spell checking\r \r but grammar checking as well.\r \r Because some in the community and, like, the tech world at large will rely on services such as Grammarly or others\r \r that help with their document writing or even email proofreading and whatnot.\r \r Well, some of those are not really, you know, at this point integrated into, say, deposit or Rstudio IDE.\r \r\n\nSo where Rspell comes in is that it is,\r \r wait for it, a wrapper package to an API\r \r called the language tool API,\r \r which apparently does have a free tier. I did some digging on this. So it looks like this is leveraging the free tier of that API\r \r where then the user can simply select some text in the document they're authoring. It could be a markdown file, a markdown file, or a quartile markdown file, what have you, even just the documentation in their R script or whatnot.\r \r And then it will have a command or a function called check selection.\r \r And then the console will\r \r display any potential grammar errors after sending that,\r \r to the API for checking.\r \r\n\nAnd, of course, who wants to do that always in the click and drag approach? There are some nice keyboard shortcuts that you can add in your Rstudio preferences\r \r as an add in as well\r \r that you could\r \r key bind all that.\r \r And this is another major selling point. It will have support for multiple languages,\r \r and it will be smart enough to detect if your default language in POSIT or Rstudio\r \r has been set, it's going to automatically leverage that particular language\r \r when it sends these grammar checks to the language tools API.\r \r It'll also respect any definitions that have been made for, you might say, exceptions\r \r in the user's\r \r dictionary\r \r set in Rstudio as well.\r \r\n\nAnd then also it may be able to just say, I want to see the errors. Don't worry. Modify them. Yeah. Let me be the judge of that. You can do that with an argument ask modify equal false in the check selection function.\r \r Where I see this is honestly not just with the RStudio ID. I think this can be a great help for any development environment that you're leveraging with R. Why not put this in something like Versus Code or or Emax or N VIM, whatever have you? Like, this is giving you the power to do those grammar checks\r \r in a in a custom fit for purpose package that can be independent\r \r of, say, the ID.\r \r\n\nSo really great niche that's being filled here by by Rafael's\r \r Rspell package. And certainly, I think it's going to be a huge win for those of us that are not exactly using, you know, the\r \r Office type document, you know, software for our\r \r our document writing.\r \r It's always like a pain in the rear end for me to write something in Microsoft Word anymore. I love to do quartal and R Markdown\r \r all the way, and now I can have my nice grammar checks in there too just like anything else.\r \r\n\n[00:17:43] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes, Erica. I couldn't agree with you more. I have a very hard time, like, authoring anything or putting any sort of text on screen in Microsoft Word as opposed to if I'm in in quarto, in in IDE, like Rstudio or Versus Code, I can I can write away? I don't know what's wrong with my brain that that's the case, but that's just, I guess where I'm at these days. And and this language tool API is is really really interesting and really useful. We author, you know, some pretty long,\r \r quarto documents that are either, you know, model validation reports or, you know, RFP responses,\r \r things like that. So so we do,\r \r you know, have a need for\r \r grammar checking, you know, on these these large pieces of text. And, I think that this package is actually going to be be useful sort of immediately for us. You know, one thing that I think is fascinating is the ability to select some text with your cursor, it sounds like, and run this check selection command at the console. That that to me is fascinating.\r \r\n\nYou know, I was taking a look at some of the, limitations\r \r that that you have. And and even on the the free plan,\r \r it's, I don't know, it seems, you know, pretty friendly,\r \r in in terms of how many requests you're able to make. 20 per minute.\r \r Number of characters you're able to,\r \r make in a request per minute, 75,000\r \r free. You know, maximum number of characters per request, 20,000\r \r free. It's pretty incredible. And even if you go to the the premium version, which which scales that up, you know, about fourfold across all those different metrics,\r \r I think it's like, you know, $39 a month for a 100 API calls per day. It seems seems pretty reasonable. It seems like a really fascinating tool. I know Grammarly has been, you know, one of the the larger\r \r name, larger brand resources out there for grammar checking. But, you know, something that has a beautiful API that we can really easily bring into our software development workflows, like this language tool.\r \r\n\nI don't know. It seems pretty powerful\r \r to me. I don't know if there's I'd be curious to see if in Versus Code there's any extensions\r \r that,\r \r you know, are sort of higher level, more powerful grammar checkers than just sort of, you know, the spell check that you get out of the box, you know, that look something more like this language tool API\r \r or like Grammarly. Not a 100% sure there, but but it might be interesting to check out. But regardless, I think this is a a phenomenal solution. In the meantime, it looks like there's about 80 different languages\r \r that are supported in this Rspell\r \r package, and,\r \r I I really don't see how this can't be a benefit for everyone out there who's authoring any sort of scientific,\r \r report\r \r documentation.\r \r\n\n\n\n[00:20:24] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I I wholeheartedly\r \r agree. And I was looking under the hood a little bit at this, at this package, and,\r \r this is another one of the newer ones that is leveraging the h t t r 2 under the hood that recently had its 1 dot 0 production release. So if you're wanting to see another example in the community\r \r that's leveraging, you know, Hadley's new HTTR 2 package,\r \r this will be a great one to take a look at for inspiration.\r \r And I think, again, my my biggest win here is the\r \r democratization,\r \r if you will, of being able to leverage this wherever your development is happening. I think that's gonna be a huge help for everybody.\r \r And, yeah, I'd imagine in the world of Versus Code, there's basically an Accenture or just about anything these days.\r \r\n\nBut this means that you get this power of powerful, grammar checks wherever you are. And I'd imagine that as over time this package is more widely used, perhaps there will even be more features under the hood. So congrats again, Rafael, for this excellent release.\r \r You know, whenever you get Mike and I together on any show or podcast,\r \r event of where Shiny will enter the picture here in respect to our application development, our interfaces that we're trying to make a little more robust with some\r \r nice aesthetic stylings in HTML and CSS and whatnot.\r \r And one of the areas that in my day to day life is shiny in the early days\r \r that I definitely have one of those kind of love hate relationship with\r \r was the grid system.\r \r\n\nHow many times did I try to get the column width right between these rows and columns that are just scattered across my dashboard?\r \r Now things are looking better\r \r in the Shiny space, of course, with the advent of Versus Lib and whatnot.\r \r And sometimes you might need to still get a little lower level with some of your CSS styling.\r \r But our last highlight today\r \r is coming from the esteemed Albert Rapp on how you can take advantage of now a very popular technique in the world of web development and styling,\r \r in particular, the Flexbox,\r \r capability\r \r within CSS.\r \r\n\nSo, Mike, is Flexbox gonna gonna take me away from my column with woes, you think?\r \r\n\n[00:22:47] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I think it will, Eric. And I think it's already probably being leveraged pretty heavily in packages like bslib that are are trying to alleviate some of the\r \r alignment issues or hurdles that we had to overcome\r \r in the past. You know, I I remember fondly with that that grid system, especially in Shiny,\r \r you know, doing things with columns and a fluid row to try to align things that probably should have been aligned, like in a div with some CSS\r \r manually because it wasn't perfect. And I think I think Albert is walking us through sort of best practices\r \r around alignment, you know, using this this new sort of Flexbox\r \r framework. And he has this weather app,\r \r which looks like a, you know, phenomenal\r \r mobile application. It looks like something straight out of my iPhone,\r \r that he has been developing. I think just mostly sort of a UI for,\r \r and and showcasing, you know, different aspects of of UI development and HTML\r \r and CSS to to bring sort of best practices to the design\r \r of this weather app. So, you know, we're walking through a use case here where he's trying to accomplish\r \r a few things. The first one is at the top\r \r of the app, UI,\r \r there are sort of 4 icon elements. One is a time stamp for for what the current time is that you you might can imagine see on your on your iPhone.\r \r\n\nThen he has a,\r \r icon that represents sort of your your service, your your vertical bars, you know, can you hear me now?\r \r And then there is a WiFi logo, and then finally followed by a battery logo. And when the way that he puts these together is actually in a nested div, where at the top level of the div is the time, and then there's a a a div, you know, the nested portion\r \r that contains those 3 other icons, your your signal, your WiFi, and your battery\r \r status.\r \r And when he initially tries to do this this nested div without the flexbox,\r \r what happens is the time stamp is above\r \r the other 3 icons below it. And he really wants to align those, really nicely horizontally.\r \r\n\nSo the way that he's able to do that is in that the style argument of this main div,\r \r he has two arguments to the CSS function.\r \r The first is is a margin function, which, you know, doesn't have any impact, essentially, here. But the the second argument here is display equals flex.\r \r And that is how you implement Flexbox,\r \r you know, instead of grid, and that is all that was necessary here to align\r \r these necessary here to align these four elements, horizontally instead of, you know, part of\r \r the div being stacked on top of the rest of the div. So that was a really clever,\r \r sort of simple implementation and and really powerful to see how that plays out.\r \r\n\nThe second thing that he wants to do is he actually wants to,\r \r have the timestamp be on the left side of the screen,\r \r and then the other three icons be on the right side of the screen, be pulled to the right side of the screen, instead of them all aligned, you know, one right after the other. He wants this large space in the middle of\r \r the screen, between these icons.\r \r And the way that he's able to do that is is, again, you know, just essentially\r \r adding,\r \r this argument to the CSS function that that ends up, you know, being supplied to the style argument of the main div.\r \r And this additional argument is called justify_content\r \r and that equals,\r \r in quotes, space\r \r hyphen between.\r \r\n\nSo that's how he creates space between the top level of that div, which is just the time space,\r \r and then the the nested portion, the sub div, which are those 3 different icons. And it's it's beautiful the way that it plays out. It it creates the perfect amount of space,\r \r such that the timestamp is pulled to the left side of the screen and the other three icons are pulled to the right side of the screen, but they are all, again, on the same horizontal\r \r plane, which is fantastic. And the last,\r \r thing that that Albert does here, Eric, is centering this big icon that's that's below,\r \r these these top of your screen icons. This big cloud icon that's right in the middle of the screen, which I I believe, you know, sorta tells you what the weather is today. So I don't know if you wanna take a stab, Eric, at at,\r \r Albert's approach to centering that icon with some margin elements.\r \r\n\n\n\n[00:27:01] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And, first,\r \r it it gets wonky in the beginning here. Right? Because when you start just doing your your grouping with the div, which again is\r \r a I cannot undersell the technique of if you just think of these divs as, like, these virtual boxes of stuff and then be able to do whatever the heck you want with that and then have it only affect that particular, you know, grouping\r \r versus the rest of your app, that's just such a a game changing technique if you're new to this world of web styling. It took me\r \r a long time to grasp, but now in my apps, I'm dipping all sorts of things so that I get that flexibility.\r \r\n\nBut, yes, going back to this example when he first implements this grouping,\r \r and then you see that everything is all jumbled on this canvas. And it's not even fitting in this very nice styled\r \r cell phone like, you know, rec you know, vertical rectangle background. Been there. How the heck how the heck do we get this so that instead of spreading it out, like, on the column like fashion,\r \r it's spread into a row like fashion?\r \r And that's where in the Flexbox\r \r nomenclature,\r \r there is yet another\r \r argument or parameter called flex direction\r \r where now you can say, you know what? I want\r \r this text, all of or all these elements representing both the text and the image\r \r to be stacked on each other in this column wise fashion and not splat across this entire row by default.\r \r\n\nSo wave forty decides to use the flex direction, set it to the value of column.\r \r And now look at that. It's looking much better. Now you see the text\r \r and the symbol embedded into the cell phone background.\r \r And now, yeah, maybe it's still a little not quite there yet because you want to do some additional moving around.\r \r And that's where the margin arguments come in where you can define,\r \r you know, if it's intelligent enough to space it on, like, the margin left and margin right being auto. So it kinda,\r \r based on your screen resolution, will fit it appropriately\r \r into that container. And sure enough, once you do that,\r \r now you're really seeing\r \r a very fantastic\r \r looking layout already.\r \r\n\nThe city name at the and the quote unquote the top row. You got the degrees and, and the weather status on the next row.\r \r And then the actual icon indicating the weather.\r \r Front and center, literally center\r \r with a good size.\r \r And then there's placeholders from additional metadata, but they're nicely justified in the lower left.\r \r So\r \r really, really top notch styling here. Again, the key nuggets here are just taking advantage of Flexbox and the various parameters that you have at your play here.\r \r And one quick tip, it's been mentioned in his previous blog post, and other people have mentioned this as well.\r \r It's one thing\r \r to run this, you know, like recompile your app, if you will, see the layout on your, you know, browser window and kind of rinse and repeat, right, like we typically do with programming.\r \r\n\nRemember, with web development\r \r and that fancy schmancy browser you're running in, you've got those developer tools. Right? And then you can do the inspect capability\r \r and drill down to that very CSS that's outlining that but to your element that you select with your cursor.\r \r And then in real time, you could change like the margin was. You could change the flex directions,\r \r and you'll see that happen in real time. And that can be a nice time saver if you know you're gonna need to experiment a lot with this and you just wanna quickly see the impact of about rerunning your Shiny app, it's another technique that took me years to master between what Albert mentioned in his previous post\r \r and what, our good friend, David Grandgen, has taught me with his various web development. In fact, Mike, you and I were TA ing his posit workshop last year,\r \r learning about the ins and outs of Shiny UI design.\r \r\n\nThose nuggets,\r \r they add up to really minimizing your\r \r iteration time or really getting you to the point you need to be at. So looks like there's more to come in this space for his next, installment when he wants to, you know, make things even more polished here. It looks like that's coming soon. But in any event, if he had told me this was a professional weather based app that was in its early stages, I would say, yep. It sure is. How much is it? Nope. It's all free of charge, folks. It's all part of learning here. So congrats, Albert. A fantastic post as always, and we look forward to the next stage of this.\r \r\n\n[00:31:41] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Absolutely. No. I remember my first, foray into looking, popping open that developer tools pain and wondering what the heck have I gotten myself into.\r \r Why would I ever want to\r \r even, you know, attempt to mess with what's going on in here because it all looked so foreign to me but now I am grateful for whoever created that developer tools, you know, concept and technology because it allows us to iterate\r \r so much faster across the styling of our apps.\r \r\n\n[00:32:10] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 10,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And it's easy to get overwhelmed when you look at that at the first glance because there are so many different tabs of functionality or respect to even just seeing what are the actual requests that the page is generating and that almost like a like a Systrace\r \r log on Linux. It looks very, you know, overwhelming.\r \r But then when you get to the meat of what you want, which typically for me is either, like I said, the CSS tweaking\r \r or the JavaScript console, and I wanna look at inspecting some variable values and whatnot. Those are the 2 I'm in right now, but I know there's so much more in that in that council space.\r \r I would be remiss to not offer up my little conflict and my inner geek, if you will.\r \r\n\nYou know, I I ragged on the grid system as kind of being a bit painful over the years.\r \r But when I think of grid, I think of my favorite movie Tron. They were in the grid, man. They were in the grid. Flexbox just doesn't quite have that same ring to it. So I I'm gonna have to reconcile that in my head sometime.\r \r\n\n[00:33:07] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 7,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Favorite movie?\r \r\n\n[00:33:08] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 8,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Tron. It's my favorite. Memorized it. Good to know.\r \r Yeah. Yeah. That's a that's a way to get Greek cred with me. Anybody that likes Tron as much as me is as a friend already. So\r \r but, maybe Flexbox will grow on me in that sense, but we're not quite there yet.\r \r But in you know what's there, Mike. We got a fantastic rest of this issue of our week that Patul has curated for us, and we'll take a couple of minutes to talk about our additional finds here.\r \r And, yeah, I kind of alluded to my, you know, my, tech and gaming roots here. And so this post really caught my eye from Rasmus Bath. He has a post on modeling\r \r his pinball scores.\r \r\n\nThose of you that rep the arcades back in the old days, remember those awesome pinball machines that you would sink your quarters into.\r \r Highly addictive\r \r and the bling you would get by hitting all those sensors\r \r and seeing the score rack up. There's nothing like that that rush, you would say.\r \r And, apparently, what Rad Rasmuth has done here is he had downloaded\r \r a virtual version of a pinball game called fishtails,\r \r I believe.\r \r And he tabulated all of his scores\r \r that he got from that virtual game and has made a nice little jiggy pot out of it. And, yeah, it definitely looks like a somewhat random distribution,\r \r but the fact that you could do a data driven analysis on that, yeah, huge win in my book. Took me back to the days when, myself and a few of my winter skis friends\r \r were doing a virtual racing league, and we had to do screenshots of the race times to collect our data. But 2 of us did it, and we had tons of fun doing it. So awesome post from Rasmus, and, yeah, now I got the use to play pinball again.\r \r\n\n\n\n[00:34:50] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That's really cool. I found a,\r \r incredible set of slides,\r \r authored by\r \r Michael Friendly for his PSYCH 6135\r \r course on visualizing\r \r uncertainty.\r \r And just fantastic\r \r resource\r \r for doing exactly that in your statistical,\r \r analysis\r \r and journey. You know, I think it's really important to to not just communicate point estimates, but to communicate,\r \r the uncertainty that you do have around those point estimates, so people can make, you know, better risk based decisions.\r \r It's a great walk through\r \r of the functionality of packages like ggdist\r \r and tidybayes.\r \r\n\nAnd,\r \r it's just a phenomenal resource, one that I am definitely going to to save,\r \r in my notes for the future because it's spelled out really nicely for us. So definitely wanna highlight that as well.\r \r\n\n[00:35:42] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I love seeing these these awesome visualizations\r \r in this space because in my line of work,\r \r Uncertainty\r \r is not just a buzzword. We really have to account for and then be very clear\r \r to our stakeholders,\r \r our leadership,\r \r when we're looking at these different, say, study designs, just the uncertainty we might have with that particular outcome,\r \r that particular time point. You know, we've got to make sure we're transparent about it. So anything we do to communicate that uncertainty in a more concise way is a huge win in our book. So really great great post by Michael Friendly there, set of slides. I'll be definitely checking that out. And we want you to check out the rest of the rweekly issue. Like I said, a ton of amazing content here.\r \r So much to choose from, from the world of package development, you know, data science and the industry,\r \r academic research, calls to action.\r \r\n\nIt's all right there. And\r \r everything is available at rweekly.org.\r \r Everything is there. All the back issues are there. And as well as hearing from you because one of the easiest way to help with our weekly\r \r is to send us a poll request of your favorite resource, new package, new blog post.\r \r We love to see it. We'll have it featured in the next issue. So it's just a poll request away.\r \r If you can write markdown, you can contribute to our weekly. It's that simple.\r \r Very easy to get set up with. And, also, we love hearing from you in the audience as well. Got a little contact page directly linked in this episode show notes on your favorite\r \r podcast player of choice. Speaking of those podcast players, if you have one of those modern ones out there like Podverse, Fountain, Cast O Matic, CurioCaster, I could go on and on. There's a Honeywell boost functionality\r \r you could have to send your hosts, yours yours truly, and Mike here. A fun little boost to read along in the show if you wanna send us a message. So\r \r all right there. And, also, we're on the social media sporadically.\r \r\n\nI am on Mastodon mostly these days. So that our podcast at podcast index dot social.\r \r I'm also on the weapon x thing, that the r cast, and I'm on LinkedIn from time to time as well.\r \r And, ironically,\r \r you this will have happened since I've recorded this. But literally in a couple hours after finishing this recording,\r \r I'll be taking a part in the, latest Epsilon Shiny gatherings to help do little,\r \r\n\n[00:37:56] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Mike Thomas",
        "trans_text": "fun little, teasers for the upcoming shiny comps. So I'm really looking forward to that. And, Mike, where can they find you? I will be there too as well, Eric. I'm excited for, that gathering. Yeah. And folks can find me on LinkedIn. If you search Catchbrook Analytics, you can see what I'm up to. Ketchb\r \r r o o k. You can also find me on mastodon@[email protected].\r \r And one last, callback to Michael Friendly.\r \r His GitHub handle is just Friendly. Github.com/\r \r friendly. That's awesome.\r \r\n\n[00:38:29] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Sure is. You got it at the right time.\r \r That's easy. Yeah. I wish I'd been more, well, at least I got our podcast eventually. I just had a fight for it. So\r \r one of those things. One of those things. First of all, the problem is the social handles. But, you know, it's never a problem to listen to our weekly. We hope you enjoyed it. Again, we love hearing from you, so don't hesitate to give us your feedback.\r \r And also we hope to see you for episode\r \r 159\r \r of this very podcast\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_13_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "chap_timestamp": 55,
        "chap_text": "Revisiting test mocking"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "chap_timestamp": 26,
        "chap_text": "Grammar checks with rspell"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "chap_timestamp": 32,
        "chap_text": "Styling with flexbox"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "chap_timestamp": 24,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_13_highlights",
        "chap_timestamp": 18,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_12_highlights",
        "ep_date": "2024-03-20",
        "ep_duration": 44,
        "ep_description_short": "An honest take on common patterns and anti-patterns for re-use of data analyses that hit a bit too close to home for your hosts, a cautionary tale of garbage online references pretending to be authentic material, and a new (human-created) cheat sheet with terrific best practices taking front and center. Episode Links This week's curator: Sam Parmar…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_12_highlights",
        "description_long": "\r \r\n\nAn honest take on common patterns and anti-patterns for re-use of data analyses that hit a bit too close to home for your hosts, a cautionary tale of garbage online references pretending to be authentic material, and a new (human-created) cheat sheet with terrific best practices taking front and center.\n\nEpisode Links\n\nThis week's curator: Sam Parmar - @parmsam_ (Twitter) & @[email protected] (Mastodon)\nPatterns and anti-patterns of data analysis reuse\n$%@! R help from $%@! AI\nBest Practice for R :: Cheat Sheet\nEntire issue available at rweekly.org/2024-W12\n\nAdditional Links\n\nJon Harmon's request for additional R4DS funding: https://fosstodon.org/@R4DSCommunity/112099679313058951\nLinux Unplugged Episode 554: SCaLEing Nix https://www.jupiterbroadcasting.com/show/linux-unplugged/554/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nA Crook Man's Eyes - Mega Man 5 - Nightswim - http://ocremix.org/remix/OCR03679\nPlastik Skies - VROOM: Sega Racing - Palpable, Diodes - https://ocremix.org/remix/OCR03726"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://twitter.com/parmsam_"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://fosstodon.org/@parmsam"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://www.milesmcbain.com/posts/data-analysis-reuse/"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://www.rostrum.blog/posts/2024-03-15-ai-garbage/"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://github.com/wurli/r-best-practice"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://rweekly.org/2024-W12.html"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://fosstodon.org/@R4DSCommunity/112099679313058951"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://www.jupiterbroadcasting.com/show/linux-unplugged/554/"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "http://ocremix.org/remix/OCR03679"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "links": "https://ocremix.org/remix/OCR03726"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back of episode 157 of the R Weekly Highlights podcast.\r \r My name is Eric Nantz, and I'm so delighted you joined us from wherever you are around the world for our weekly show where we talk about the latest highlights that you can see on this week's Our Weekly Issue.\r \r And as always, I am joined at the hip here. My line mate in Our Weekly Fund is my co host, Mike Thomas. Mike, how are you doing today?\r \r\n\n[00:00:27] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'm doing well, Eric. It was starting to warm up here on the East Coast. Now we were getting a a cold week. So it's it's a little frustrating, but I think that maybe the theme of this week's highlights. We are venting this week in some of these highlights and I am here for it.\r \r\n\n[00:00:42] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Oh, as am I. And and even in the preshow, that all you can listen to, you heard about Mike here heard about my events on some recent rabbit holes that I went under. But, yeah, we're gonna we're gonna have a lot to share today because we do, feel very relatable to a lot of the concepts\r \r we're about to talk about here. And how is this issue possible?\r \r Well, our curator this week was Sam Parmer, another good friend of mine from the life sciences industry.\r \r He has put together a terrific issue we're gonna talk about here. And as always, he had tremendous help from our fellow Rwicky team members and contributors like all of you around the world with your awesome pro requests\r \r and other suggestions.\r \r\n\nSo, yeah, let's get the, quote, unquote, venting session\r \r going, and we're gonna go fast with this because Miles McBain here,\r \r Mike, has some very insightful,\r \r tidbits to share, which I can tell have been gleaned from a lot of experience in data science\r \r called the patterns\r \r and antipatterns\r \r of data analysis reuse. So what do we have here? Why don't you set this up for us? This is too relatable. It's a phenomenal blog post\r \r\n\n[00:01:52] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Mike Thomas",
        "trans_text": "talking about, you know, the data analyst curse\r \r and, you know, understanding that, you know, every\r \r data analysis and data scientist role that Miles has been in and I agree with this as well.\r \r At some point in time, you're redoing variations\r \r of the same analysis. And there there's 2 assumptions that he's making,\r \r for those\r \r who would be able to to relate to this blog post. The the first one is that your work is is written in code like R, Python, Julia, or Rust. If you're using if you're using, in his words, Power BI or God forbid Excel,\r \r you probably won't relate to this. And then second,\r \r you're using a technology like Quarto, Rmarkdown, or Shiny,\r \r such that sort of your end deliverable is generated from that that code. So if if this sounds like you, I am assuming that maybe you'll be able to relate to this blog post as I did.\r \r\n\nAnd when you're redoing, you know, that same analysis,\r \r in sort of different ways,\r \r one of the first things maybe that you may start out doing as a as a beginning developer\r \r is copying and pasting.\r \r Right? From from one, version of your report\r \r to the next version of your report that you need to create. And,\r \r you know, this can be a quick solution that you have, but it may not be very extensible\r \r or maintainable\r \r because when it comes time to update some sort of global,\r \r you know, version of this analysis,\r \r you would have to copy and paste to each different version that you have out there.\r \r And when you're trying to fix a bug or or create an enhancement, that same concept would apply that instead of just doing that update in one specific place, you would need to copy and paste that to all of the different places because you don't have something like a template.\r \r\n\nAnd this is where you can start to move on towards oh, I'm going to create a sort of a single template\r \r that is going to have,\r \r parameters in it that I can set that will,\r \r be able to allow me to run different versions\r \r of this analysis just based upon, the different parameters that I'm passing to this.\r \r And in theory,\r \r this is this is great. And I think this is exactly what we all strive for.\r \r But if you have done this long enough,\r \r if you have sort of been in this world\r \r long enough, you'll start to see that as you create this parameterized\r \r global version,\r \r with each new variation of your analysis that someone's asking you to run, or each new dataset that's coming in,\r \r there's going to be a new edge case that you're going to have to handle.\r \r\n\nAnd what that means is probably an additional parameter and if you're like me, this can get into now you're starting to write like conditional if statements,\r \r to test and see, you know, if this particular variation\r \r matches this one very, very specific edge case. And now your your global template is just getting super bloated because,\r \r it's trying to handle all of these different particular cases. And then at some point, someone says, hey. Why don't we,\r \r why don't we manage those parameters with with YAML or JSON? Because,\r \r for sure. Right? Now we're talking about configuration.\r \r\n\nAnd,\r \r you know, then you have a a YAML or or a JSON file that is supposed to to manage and handle these parameters.\r \r And maybe it starts out small because there's only a few global parameters,\r \r there. But, again, as you introduce these different versions of this analysis or somebody asks for this new thing or this new dataset comes in, you know, it wants to look at your analysis at a different angle, you're just adding additional parameters. And now all of a sudden your YAML file starts to get pretty pretty long.\r \r And then maybe at some point, you are having a second YAML file to manage the configuration of of the first YAML file, and it's it's YAML all the way down. And,\r \r it things just start to be\r \r unwieldy, and you start to think, hey, maybe I just need to go back to cut and paste.\r \r\n\nCopy and paste. And it can drive you a little insane as I would say, Miles may have gotten to in the,\r \r the\r \r the paragraph here titled Power Overwhelming, which I think is is where we start to, sort of go off off the rails and it I mean that in the nicest way because this is incredibly incredibly\r \r relatable. So\r \r then,\r \r Eric, if you wanna take it away to talk about maybe we start to move towards a a package\r \r framework.\r \r\n\n[00:06:31] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 31,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Right. And first, yes, we all can very much relate to this because the entire spectrum of that that build up up to this point,\r \r I have seen with my own eyes. I have committed some of this in my own hands, if you will.\r \r And, yes, sometimes the only way we learn is through painful experiences.\r \r I have had some extremely\r \r sophisticated\r \r templates in our markdown before\r \r that had a boatload\r \r of params\r \r in the end.\r \r And sometimes I would be shared with different teams, and then they realize, oh, yep. That particular dataset\r \r for that\r \r study has this type of efficacy variable, and I didn't cover it. So it just keeps adding on, adding on, adding on until it's a point where no one knows where the central place is for that thing. And everybody copy pasted\r \r to a different study. Some of this is ironically still happening. We are trying to put the reins on it. But yes.\r \r\n\nAnd when you get to this point,\r \r you think about what are ways that I can make it easier for us to maintain\r \r some kind of structure to this, still make it easy for the end user\r \r to implement in their analysis pipelines,\r \r but still be able to tap into some of the modern practices\r \r to help maintain this reusable code.\r \r And, yes, spoiler alert, that does mean creating an internal package,\r \r and that may be intimidating to many people. Well but the thing is, I would say,\r \r once you've been through these hardships, you're at a point to appreciate the upfront work to build a package,\r \r maybe more so than if we just told you this if you're brand new to data science in your particular industry or particular group.\r \r\n\nThen you're gonna be ready to absorb some great resources out there already, especially in the our ecosystem\r \r to get a package off the ground.\r \r Why should you do this, though? Is that that way instead of having these template variables\r \r and these massive templates,\r \r you can have functions\r \r with function parameters that cover much of this much of this, operation and functionality.\r \r And you don't have to have it perfect the first time. Maybe you just automate certain parts of it and just kinda build on it over time. But having the package is gonna let you opt into additional best practices\r \r to get ready for cases where maybe your package analysis\r \r functions are being used in cases you didn't anticipate.\r \r\n\nBut you can build in things like automated testing. You can build in documentation\r \r on these parameters\r \r so that you can use the wonderful tools like use this, test that,\r \r dev tools to help make this package more robust in the R ecosystem. And, of course, Python fans, you have similar frameworks\r \r on that side as well. But just getting to that package step is a huge first step to start in writing some of the wrongs\r \r that you may have experienced in your respective effort.\r \r Now,\r \r like anything, there's some there's some gotchas to worry about.\r \r And another issue that I've seen firsthand\r \r and I've seen very talented people do this firsthand\r \r is that you started this great analysis package for your group.\r \r\n\nMaybe you called it the name of your group. Who knows?\r \r And then over time, either you or others say, hey. You know what? What if this package did this new thing? What if this package did do this new thing?\r \r Suddenly,\r \r your your catalog of functions going into this internal package\r \r starts to balloon up.\r \r And maybe it gets to the point where you have so many functions, and some of them just don't really relate to each other. But because it felt like such hard work to get that package off the ground, everybody just wants to put it in one place. So they only have to load 1 package, and then it's all there.\r \r But you're running into the risk, as Miles points out,\r \r of complexity\r \r overload\r \r and a lot of bloat.\r \r\n\nAnd especially\r \r if you need to make a change or deprecate something in that package,\r \r suddenly, the whole package is being updated in ways that maybe you didn't anticipate.\r \r And so that's where\r \r going through this exercise,\r \r yes, getting to the package is a great first step. But there are a lot of diminishing returns if you decide to put everything but the kitchen sink, so to speak, in this\r \r one internal package.\r \r I've also seen this in a capability tool that we used to author for helping design clinical trials.\r \r We had a monolithic,\r \r and I do mean monolithic\r \r application\r \r that was meant to do everything for our clinical program,\r \r and we just could not maintain it anymore. There was just so much in frameworks that honestly half of us didn't even understand,\r \r but that it was all in one\r \r monolithic code base.\r \r\n\nIt just at some point, the technical debt became too much.\r \r What did we realize and what Miles transitioned to in this piece is that instead of having this single package,\r \r try making your own internal,\r \r like, group of packages.\r \r They call he calls it the personal Versa packages. Of course, we're familiar\r \r within the R ecosystem, the tidyverse and other\r \r groups of related packages that may make some decisions,\r \r may have common, you might say, data structures that they operate on, but they've separated their purposes. They separated their concerns\r \r into fit for purpose\r \r packages.\r \r\n\nThis way, instead of having to update this monolithic piece with maybe that one little change,\r \r now you have a set of packages. They all contribute to a greater whole as they say,\r \r but now you can write\r \r updates to these in fit for purpose fashion.\r \r So he mentions in his, examples here in his current job, he's got a fun a package called check yourself,\r \r definitely before you wreck yourself. I'm just saying, to help you look some quality checks, you know, for your dataset.\r \r Great. First step in a data analytical pipeline that makes a lot of sense.\r \r And then because Miles is a huge fan of reproducible analytical pipelines,\r \r they have a package on top of targets called t d TDC targets.\r \r\n\nAnd that's helping them build these pipelines in a unified way. It's still leveraging targets on the back end, but they're helping bootstrap that a bit easier. But, see, he separated out the data checking and the analytical pipeline building into this two sets of packages.\r \r There may be others that deal with internal APIs. I'm living that world right now. Do I wanna put all API calls in 1, like,\r \r company package? Oh, heck no. We wanna separate that out into its own fit for purpose thing because,\r \r spoiler alert for me, testing APIs is a much more wieldy effort than testing normal r functions. So why do you wanna boatload why do you wanna put a monolithic package to do all of that? You wanna separate that out as best you can. You're getting flexibility,\r \r but it is gonna take discipline to get there.\r \r\n\nSo\r \r I do think that it's not gonna be easy to do this all right away. You've gotta start somewhere. But, honestly, the first step is recognizing when you have a problem.\r \r Because sometimes you may send these great, like, end products of, like, these templates\r \r or these monolithic\r \r templates or monolithic packages.\r \r And everybody in leadership thinks, oh, you're doing great. Yeah. This is helping the company so much.\r \r But what are you standing on? Is that foundation solid?\r \r You really gotta pay attention to that because it's one thing to get the short term win by doing the copy paste, you know, method,\r \r but it's gonna fall down on you at some point.\r \r\n\nAnd, honestly,\r \r nobody like I said, nobody gets this perfect the first time, and we are all continuing learning on this. And that's where the post concludes where you're gonna have these humble beginnings. Right? But then you're really honing your craft as you go along.\r \r You all don't wanna see my first internal package I did at the company. It took a lot of shortcuts that I'm not proud of. But getting there was a huge first step for me. And then as I learned from the communities, I learned from my, my teammates,\r \r learning from you know, I'm I'm very privileged to learn from Will Landau, basically, every time I talk to him about something new. So all these things\r \r just build upon it. You're you're going to get even more comfortable with this.\r \r\n\nAnd, obviously, time is another factor.\r \r Time is not infinite. We have to prioritize this. But, honestly, I'm of the belief if you take the time up front to set this up the right way,\r \r even if you don't quite know how you're gonna get to that end goal yet, but you know that there are some best practices\r \r you wanna start with, that is gonna be a huge help to minimize\r \r the technical debt that Miles is definitely outlining here if you go with that quote, unquote easy approach\r \r to do this at first.\r \r So all in all, I think the the biggest piece of advice is when you see you're doing your copy pasting a bit too much, stop, pause,\r \r try to think about what are ways that we can make this reusable\r \r and more importantly,\r \r maintainable\r \r in your team.\r \r\n\nI really resonate with many things in this and credit to Miles for putting this in such a, you know, comprehensive\r \r yet, you know, very much an evolutionary\r \r type story of what data analysis pipelines\r \r are all about.\r \r And definitely start, like I said, start small. But once you start small and do fit for purpose, you know, I think I think you're gonna be on the right foot. So\r \r\n\n[00:16:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "definitely spoken to for experience. I can tell with his insights here. So, yeah. Really excellent post and I think, Mike, you and I have been through been through this quite a few times in our internal adventures. Right? No. It's a little too relatable and there's, you know, there's a lot of things to to try to balance here. Right? As you move from a script to to function to a package, and then and then back and forth sort of depending on your use case. If I may just read a very small excerpt that I think is is worth reading. You know, he he talks about, you know, creating a massive function that gets written with with maybe a dozen arguments,\r \r you know, that has hundreds of lines of code that's it's not really much different than just a wrapper around some sort of data analysis\r \r script that you would have. And it's great that you're using functions, but you're actually, like, attempting to to template your entire solution using the functions arguments.\r \r\n\nAnd he has a little little footnote in here that says, if a function starts taking YAML\r \r configuration files as arguments, you are on borrowed time.\r \r And and the last paragraph I wanna read, this is if Shakespeare was a data scientist,\r \r he would have written this. Such a function is it's pretty much untestable\r \r due to the combinatoric explosion of possible sets of inputs, and you can bet that the internals are not written in high level domain specific code. When I look at that function signature,\r \r I hear the screams of matrices being ground to a fine powder of bits through the conical burrs of nested for loops and labored index arithmetic. I mean, it's it's\r \r it's incredible. It's poetic.\r \r\n\n\n\n[00:17:52] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And it's it's most definitely real. Right? Yep. I have seen this.\r \r The approach I've seen is, hey. You know what? This package, we're just gonna have to use our modem, custom CSV with all the params inside. Like, oh my gosh. No. Please stop the pain. Yes. But it\r \r it it is the the the the crutch that people will fall back on is, you know what? It it's a lot of work to put all those as function parameters,\r \r and I don't wanna test that. Just prune the config. It's all about the user configs. No. It's not about the user configs. What it's about is building\r \r an actual package that has actual documentation\r \r and actual testing.\r \r\n\nYes. I am firm on that because\r \r when you don't do that, you may not pay for it right away,\r \r but somebody's gonna pay for it. And it'll most likely be your end users, and that's about the worst result of all.\r \r\n\n[00:18:49] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I agree. No. We have a client who leverages a third party API that in order to send your params to that API,\r \r you send your data and then you send this this wild like ASCII\r \r file,\r \r a text file that just you know has has no\r \r the limit, you know, elimination or or whatever you wanna call it. You just have to like\r \r add an n or or a y depending on which, which things you want to receive back from the API and then you have to zip it all up and send a zip zip file. It's it's pretty wild but let's let's vent about something else, Eric.\r \r\n\n[00:19:29] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I think we need to now think about you know what? We've we've thrown a lot of knowledge your way, and we acknowledge that it's not always\r \r easy for you to know everything at once. Right? We're all continuing learning. And, of course, if we don't have the answer to a question,\r \r we're probably gonna ask for help in certain ways, especially online. Right? I mean, how many times have I googled for how to do something esoteric with, like, an r to call this, you know, API parameter or whatnot or do this new statistical function that I'm just not as familiar with? So like anybody else, Mike, I know you and I have searched, you know, the Internet's and webs quite a bit for a certain help here and there.\r \r And, you know, with the advent of r over the years, you're starting to see a lot more results there, Taylor, with r itself, certainly post on Stack Overflow and things like that.\r \r\n\nAnd then you'll start to see in these search results, you know, some things that\r \r look\r \r interesting\r \r but don't quite look right. And what is this trend we're talking about here? Well, our next highlight is coming from Matt Dre, another previous contributor to R Weekly.\r \r He, he's noticed this trend too, and we'll just kinda take this bit for a bit because I think those of you that have used R for a bit and have been searching for your various help or tutorials on there\r \r have probably seen this because you will often see these websites\r \r that are now coming up higher in the rankings\r \r that look almost too good to be true,\r \r but they kind of are too good to be true because these are sites that are coming up that have clearly\r \r you can kind of tell whether it's said explicitly or kind of implicitly,\r \r they're being written by some kind of bot, maybe some kind of AI framework.\r \r\n\nWe don't want to send traffic there. So, like, he, Matt, or I are not going to tell you the names of these sites,\r \r but\r \r they are very easy to kinda hook you\r \r in to to acting like these are authenticated,\r \r you know, very authoritative sources, I should say.\r \r And sometimes,\r \r you'll see that the same\r \r overall site is producing,\r \r like, thousands\r \r of these guides for each package individually.\r \r But the guides are not coming from the package authors. They're not coming from people in the community that we've, you know, seen or or, like, an authentic blog post.\r \r They're these, like, AI generated,\r \r you know, narratives\r \r that somehow have some great search engine optimization\r \r built in so that they're showing near at the top\r \r of your search results.\r \r\n\nBut, clearly, they're not they're not playing the right way here, and I think it kinda stinks. So\r \r the I think that's pretty clear to me\r \r why this is a bad thing for to see happen, but it's also reality that we all need to deal with. It's not like a quite one to one example here, but, of course, most of us have cell phones and we get these\r \r robocalls\r \r left and right on our cell phones. And we know they're bogus even though they try to act like they're coming from our area code. Right? But these these are, like, some real bogus results that are trying to show, quote, unquote, a guy to use a certain package.\r \r It's not. It's not. But, yeah, Matt continues in his post about just why, in his opinion,\r \r this is a bad thing that this keeps happening. Mike, why don't you take us through why? What are some of the downsides of what we're seeing here? Yeah. You know, I think what's gonna happen here for for the most part is that,\r \r\n\n[00:23:05] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 5,
        "trans_speaker": "Mike Thomas",
        "trans_text": "some of these summarizations\r \r that that take place,\r \r when it's a bot or, you know, AI, whatever you want, whatever that means, is is sort of summarizing and and trying to scrape the web and put together,\r \r these these are, you know, help sites.\r \r You know, I think what's gonna happen here is just a lot of the\r \r specificity is is going to get washed out. And,\r \r not only is the content\r \r terrible, because it's not written by a human for humans,\r \r but the ethics are pretty bad as well. They're really just trying to,\r \r either make money off of you somehow, you know, redirect you to some affiliate site, you know. And you also have to remember that, in a way, they're sort of stealing\r \r their content, you know.\r \r\n\nA lot of the the content on the web that people are are putting out there in terms of, you know, Stack Overflow help and, you know, stuff that's actually authored by by someone. And,\r \r we went down the rabbit hole a little bit, when we started talking about Copilot,\r \r is a lot of this content does not necessarily, you know, have, like, a Creative Commons license behind it that says, hey, you know, go for it and and scrape this and use it however you want.\r \r You know, it's it's probably scraping stuff that the author may have not given them consent to\r \r to scrape. So that's that's crappy.\r \r\n\nYou know, the fact that it's moving up,\r \r in terms of SEO,\r \r because, you know, I guess that's probably something that AI is is fairly good at as well. Right? To try to make this site look like a site that gets a lot of clicks.\r \r You know, that's, I guess, the name of the game these days, unfortunately.\r \r And I'm seeing it myself, you know, I'm having a harder time\r \r getting to Stack Overflow links, which\r \r are have traditionally been really the thing that has helped me the most, has helped get me to my answer the quickest. And usually, maybe I have to sort through,\r \r 2 or 3 or 4 different Stack Overflow links to to find my exact solution. But in the past, that would come up those links would come up very very high, you know, if not the first result, you know, the second result.\r \r\n\nAnd and now,\r \r they're much sparser, unfortunately. And I'm I am having to sort, like Matt,\r \r through\r \r a lot of this this crap, unfortunately, to\r \r so it stinks, you know. It's, and that is taking sort of a pessimistic view here, which which maybe I share. I don't know. I haven't put I hadn't put too too much thought into this until Matt's blog post, but,\r \r don't you know, we don't see really an avenue where this gets better as opposed to to gets worse. I don't know, Eric.\r \r\n\n[00:25:51] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 51,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I I think it's a reality, like I said, even my robocall example. It's like, no matter how many you block, there's always others that are gonna keep coming. And I think there's gonna be these sites that crop up with now AI and automation becoming so much easier for the masses\r \r or in the case of some of these, you know, non\r \r unethical\r \r corporations or whoever's behind some of these to just launch all these automated processes on some server somewhere and do the SEO gaming up of of of search results.\r \r I think the biggest thing we can recommend is to never\r \r to to have, like, a a careful eye as you're searching these results. And I think over time, you'll see these patterns such as Matt has been talking about here in this post.\r \r\n\nBut I'm gonna say the best places to draw upon for, you know, you know, help for, say, a package itself\r \r is hopefully the package documentation itself. Most of them now have package down sites. They usually have a GitHub repository or GitHub like repository\r \r and, you know, seeing what issues have been talked about for that particular package on their issue board. Like, that's a great way to learn even just by scraping through that.\r \r And also leveraging community based built resources that you know are being built by humans. And guess what? Another spoiler. We're our weekly is built by humans. Right? We are linking to content\r \r that has been created by package authors, by data scientists, by others in the field\r \r that you that are authentic. And that's why we have a curator to always sift through. We get noise too just as much as anyone else, but we wipe the heck out of those. We make sure those don't get into our issue.\r \r\n\nUnfortunately, for search engines, we don't have that control. Right? They're just always gonna kinda pop up from time to time.\r \r I think if, if it sounds too good to be true, it probably is, so to speak. So definitely\r \r have a careful eye to that, especially those, as Matt points out, will have some random affiliate links somewhere in maybe the footer of the site or it's a sidebar or whatnot.\r \r No. I don't see that for authentic\r \r R based content or data science content in my day. So\r \r I think it's more about with experience. You're gonna be able to see this more quickly.\r \r But we I think what Matt does here is at least bringing awareness to the issue that this is real. It's probably not\r \r slowing down.\r \r\n\nAnd so just making sure that you are, you\r \r know, looking at the authentic\r \r community based\r \r or, in some cases, the developer\r \r authored resources\r \r to really get you in the right direction for your particular issue.\r \r But, Matt, I see at the end of the post, yeah, you also grew up in the times I grew up with. Good old floppy disk. Right? We didn't have fancy AI bots generating these queries. We had to make sure that 5.25\r \r floppy disk somehow worked in our IBM, you know, PCs or Apple 2 GS's. Shout out to all those that use vintage Apple computers.\r \r So it's a different time now. And that I think with that just comes some some new skills that we have to learn\r \r about finding the the best from the noise as they say.\r \r\n\n\n\n[00:29:01] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yep. No. I remember,\r \r you wanted to know something. You looked it up in an encyclopedia.\r \r So I very much yeah. At the library no less. Yeah. At the library no less. I think we had we had\r \r an encyclopedia on a CD ROM at home or something like that when I was growing up.\r \r That's right. Yep. No. Times have certainly changed, and I think, you know, unfortunately, that means navigating\r \r navigating the Internet and search results,\r \r you know,\r \r requires new skills to be able to do so. But it's unfortunate\r \r that some of these sites out there,\r \r exist because\r \r it sort of feels like cheating.\r \r\n\n\n\n[00:29:49] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Now with that said, of course, what are ways that you can kinda get your your journey of data science started off right, especially if you're new and you wanna turn to maybe a human generated\r \r resource to help you. Well, one thing that has helped me over the years, and I think many others would agree,\r \r is the concept of having that handy\r \r cheat sheet next to you. So if you're looking up stuff all the time but you just want a quick reminder\r \r of how something works, you know, cheat sheets are a great way to have at your desk or at your virtual\r \r wallpaper or whatever have you to kinda get those concepts reinforced,\r \r from time to time. And our last highlight is, actually a new cheat sheet in the R community\r \r authored by Jacob Scott who is a data scientist based in the UK.\r \r\n\nAnd Jacob has put together this best practice for our cheat sheet, and he is very much upfront in his repository that this is\r \r highly opinionated in some of his preferred workflows. But I think there are some concepts here that we can very much relate to, especially in the context of if you are following the advice of what Miles authored and our first highlight, some ways you can get\r \r started pretty quickly.\r \r One thing\r \r that whether you're running our studio proper or not,\r \r but having\r \r some kind of project structure\r \r is it's one of those things that you take for granted. But boy, oh, boy, I have seen countless times\r \r people, like, throw all their r scripts in one directory that have no real relation to each other. Just throw it all in there. Right?\r \r\n\nHave you ever done that, Mike?\r \r\n\n[00:31:27] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I've seen it.\r \r Maybe I did it when I was starting out potentially,\r \r when I didn't necessarily know best practices around, you know, what an R project\r \r even was.\r \r You know, like I said, when I was taught\r \r R in undergrad,\r \r we were only taught R markdown. I didn't even know what an R script was. I I only knew the existence of of dotrmd files.\r \r So there's there's a possibility that at some point in my journey, which I don't wanna,\r \r maybe dive back into that that I would have been guilty of that, but I am very happy to have,\r \r found it and understood our projects.\r \r\n\n\n\n[00:32:04] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. And and, yeah, certainly the examples he's talking about here, they are specific to RStudio, but you can do this in any of our typical ID as well. I mean, Versus Code has workspaces you can utilize.\r \r And, of course, you know, there are loads of extensions in the classical frameworks that people turn into IDEs like Vim or Emax that do similar things too. The idea is just logical grouping of your code. And he's got a nice little snippet here in the cheat sheet about what his project structure looks like. It's got, you know, subfolders for the scripts itself. It's got, you know, potential\r \r database query,\r \r SQL scripts. You know, all and, of course, he's using RM too. That's an even another best practice that I think goes\r \r it needs to be reinforced is that these projects can have wildly\r \r different dependency\r \r requirements. And in the r side of things, having RM\r \r is a real bulletproof way, give or take a few gotchas here and there,\r \r making sure that you can reproduce that R base execution environment\r \r within reason,\r \r from project to project and be able to have that finer tuned,\r \r that finer tuned control\r \r for your dependencies.\r \r\n\nAnd then also, there's some great sections in here about how to create a repreqs, which, again, we were talking about getting help. Right? Finding ways to effectively\r \r communicate and effectively search. Well, if you know that you're having an issue with a said package or or another, you know, utility,\r \r the best way to to get help from the community, whether it's in Stack Overflow\r \r or, say, PASA community or whatnot, is having a reprec so that it shows in a very concise manner what exact error you're getting and let others reproduce that error. Reprec is not this is not the first time we mentioned reprec on this highlights podcast\r \r over the years.\r \r\n\nSo I think having that skill set is a great way to put yourself in best position\r \r to not only ask for help, but then to receive it as well. And then there are also some great sections here about how do you connect the databases. And I've used the DBI package quite a bit. He's got a little snippet about connecting\r \r to, a a database with that as well.\r \r And then\r \r others such as styling.\r \r Again,\r \r there can be different takes on how you style your code.\r \r What, Jacob recommends here, I believe, is a variation\r \r of the tidyverse style guide with certain pieces. But, again,\r \r I think the key, as we mentioned maybe a few weeks ago,\r \r is just consistency.\r \r\n\nOnce you have consistent styling, no matter if you use the tidyverse framework\r \r or, let's say, Google's framework or any your own company's framework,\r \r having consistency is gonna help you as well as your future self and collaborators\r \r on those projects.\r \r And then it concludes with,\r \r some links to learning more about the R community and building R for, you know, our projects such as r for data science, building packages of r packages,\r \r and really getting into the nuts and bolts of r, where the Vance r. And, yes, for the shiny fans out there, a link to mastering shiny as well. Highly recommended.\r \r But\r \r and I think it's a it's a great way to get started. I think for those new to the R framework,\r \r this is one of those great examples to get you started off the right way, and it's gonna wet your appetite, so to speak, to dive into some of these concepts in more detail.\r \r\n\nSo really nice nice job here, Jacob, and I think it's a it belongs in many, collections of cheat sheets out there.\r \r\n\n[00:35:36] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. This is absolutely\r \r beautiful,\r \r design wise, the way that he he drew this up. It says that, he originally created a similar version of this this cheat sheet specifically for use in the UK\r \r Department of Education, but he's created this more generalized version, I think for for everybody else, which is fantastic. And it it sort of makes me think about perhaps, you know, you may wanna create a cheat sheet similar to this within your own organization that, you know, mentions and outlines some of the specific best practices that you wanna follow and employ within your own organization. So if you're looking for inspiration to do something like that, this would be a great place to start.\r \r\n\n[00:36:16] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And he does have link in the GitHub repo to additional,\r \r additional cheat sheets that are available on Posit's site. You know, we see many contribute to that both from Posit and outside of Posit too.\r \r That style is is very reminiscent of that. So I think it's\r \r it's interesting, yeah, interesting way to get started the right way, and I'm always all for it. Again, human generated our resources out there. No bot made that resource. I can I could pretty much tell that one? That's right.\r \r Yep. And like I said, what else do bots not create? Well, it's the RWQ issue itself. We've got a curator\r \r helping with that every single week. And, again, Sam did\r \r a tremendous\r \r job with this issue, and we'll take a couple minutes to talk about our additional fines for that we found in this issue.\r \r\n\nFor me, I'm still very much in my learning journey of, you know, APIs with R, but also\r \r developing web based resources with R and pushing, like, Shiny to new directions and pushing even the portal sites I create the new directions.\r \r And friend of the show, Albert Rapp, has another terrific\r \r blog post here in his web dev for R section.\r \r One area that I simply have to always keep looking up every time, it's not muscle memory yet, but getting a handle on selecting\r \r certain elements in your CSS\r \r style sheets.\r \r And he's got both a video and an accompanying blog post that talk about\r \r how you can select\r \r particular tags of a certain type with both the source code and solution right there\r \r in in the in the post itself,\r \r selecting elements by class, lots of things that unless you really practice a bit, especially if you're new to web dev, it's gonna seem pretty foreign to you. But he brings it home with how he used these techniques to modify\r \r some of the styling behind a GT table that he was, creating. So you can give a little extra personality, a little extra style along the way. So if you're in the world of CSS style and you're just not sure where to go to get that particular nagging element that you wanna make like a bold font or make a red color background,\r \r this is a great post to let you dive into just what kind of\r \r detective skills you might need to get to that set element and make it look the way you want it to.\r \r\n\n\n\n[00:38:41] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Mike Thomas",
        "trans_text": "And, Mike, what did you find? Oh, that's a great find, Eric. And the the shiny developer in me and the web scraper in me,\r \r is very interested in in checking that one out to to dive down and figure out very specific\r \r CSS and style elements on a on a web page. That's awesome.\r \r I found,\r \r very interestingly,\r \r a phenomenal article in Nature by Jeffrey M Pirkle called No Installation Required, How WebAssembly is Changing Scientific Computing. I think we teased this a little bit last week,\r \r but it's a fantastic\r \r walk through about WebAssembly. It starts off with some quotes from, George Stagg,\r \r at Posit, who has done so much work on the WebR\r \r package to allow us to,\r \r write our code that is compatible\r \r with the WebAssembly framework and essentially have have the the work run-in\r \r the user's browser and no server\r \r required, which obviously is is pretty game changing, something we've talked about many times here. And it's really the theme in this blog post. And, it's a really interesting article because there's little anecdotes from from many people with many different perspectives on this topic.\r \r\n\nOne of those people, being,\r \r my co host, statistician Eric Nance. Oh, hello. And, you you have an awesome quote here that you're you believe WebAssembly will minimize,\r \r from the reviewer's perspective, many of the steps that they had to take to get an application running on their own machine in the context of clinical trials.\r \r I totally agree. I I I really enjoyed reading this article, and it's it's very exciting again,\r \r for me to see this topic\r \r being picked up in something like nature.\r \r\n\n[00:40:20] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Eric Nantz",
        "trans_text": "It's it's super exciting because it it means that it's it's gaining steam out there. Yeah. I'm as excited as anybody right now in this space and the fact that we're we're being recognized in places I never even dreamed of as we're we're kinda pushing the envelope here.\r \r I think it's just another piece where\r \r this has a chance to transform so many things and not only my industry, but many other places as well. And, we're just at the tip of the iceberg. There's still a lot of growth here, but\r \r I I I sense that, you know, we're gonna be talking about this for for years to come as one of these next big evolutions\r \r in technology at the intersection of data science. We're we're on the way, Mike. We're on the way.\r \r\n\nYep. And one other thing I wanna leave off with,\r \r and a good friend of the show as well, John Harmon, he's been, you know, sending out some posts on his Mastodon account\r \r and LinkedIn about a recent unfortunate event\r \r with the r for data science community and that their particular\r \r provider that they've been using\r \r for assembly funds to keep the project going has unfortunately changed direction.\r \r And now they're kind of, looking at other ways to\r \r receive, you know, robust funding through a robust infrastructure.\r \r So I will just mention if you're in this space, maybe be able to help John out with some advice on\r \r where to go for additional funding opportunities for our for data science and platforms that they can leverage.\r \r\n\nCertainly get get in touch\r \r with John\r \r personally.\r \r I'm sure he would love to hear, you know, some other advice that people have along the way. So, again, really hoping to see the r for data science group keep going.\r \r But I know it's gonna be it's always tough when you rely on a platform to help centralize some of this, then they pull the rug from under you. So let's hope for the best, John. And, certainly,\r \r\n\n[00:42:16] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Mike Thomas",
        "trans_text": "if we find any, you know, resources, we'll pass them along your way. Yes. No. Please help out, John. If you have the the means to be able to do so because this R4DS\r \r community,\r \r is is fantastic. I think that it's it's helping a lot of people get up to speed with R and get introduced\r \r with R. It's helping\r \r people like me, with very niche questions and,\r \r just an incredible community of folks who are willing to to help one another and to listen and to try to encourage each other in our R programming journeys.\r \r\n\n[00:42:47] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Absolutely. Absolutely.\r \r So, I was reading some of his latest posts here as of 4 days ago. They did get some additional funding before that host kinda pulled the rug from under them, but that's not gonna last forever. So, again, he's I'll put a link in the show notes to where you can you can contact John and contact the project. So, again, we we really hope for the best here. And talking about finding great resources for help, I mean, we've said this many times. The Hartford Data Science community\r \r has\r \r so many helpful participants\r \r at all skill levels. It is an it is a wonderful resource out there. They have book clubs. They have groups dedicated\r \r to different packages or different frameworks. It is all there for the taking.\r \r\n\nAnd, really, some of the best support you can do is even just helping out with that community\r \r on top of financial donations. So I'm sure he would welcome that as well.\r \r And speaking of welcoming, we welcome your feedback too with this humble little,\r \r you know, endeavor we call a podcast here. And what are ways that you can help us out? Well, first, the Rwicky project itself.\r \r We'd love to get your\r \r new package idea or new package resource. If you have a blog post, a tutorial,\r \r or announcement you wanna share, we're just a poll request away. It's all marked down all the time. Where you can do that is linked right in the top right corner of rweekly.org,\r \r the link of this current issue's draft\r \r or upcoming issue draft, I should say. And then you can just send your poll request there, and our curator of the week will be glad to merge that in for you. And as well, we love to hear from you in the community.\r \r\n\nThere are many ways to do that. We have a little contact page in this episode show notes that you can send us direct feedback with. You can also have a new modern podcast app like Paverse, Fountain, Cast O Matic, CurioCaster.\r \r I could go on and on. They have a little boost functionality. You can send a fun little message\r \r along the way. And, quick congrats to my friends at Jupiter Broadcasting\r \r because they use\r \r this modern infrastructure from the Fountain app to do live\r \r podcast episodes\r \r on the ground at the recent SCALE and Knicks conferences in California. It was a good time to be had, so you might wanna search them out. That was some amazing content there. And, yeah, the Knicks stuff was, quite entertaining. So I'm thinking of Bruno right away when I when I listen to this. I may have to dust off the Knicks stuff now. And, again, I'm even more inspired than I was last week. I'm sure his ears are ringing.\r \r Yes. Yeah. I'll have to link that in the show notes. Bruno, I think you'll find it very interesting.\r \r\n\nBut, as well as what's awful interesting is is hearing from you, as I said.\r \r You can also get in touch with us on social media.\r \r I am on Mastodon mostly these days with at our podcast at podcast index on social.\r \r I am also sporadically on the weapon x thing at the r cast and as well on LinkedIn as well. You can just search for my name, and you'll see all my show announcements and other fun announcements there. And, Mike, where can the listeners find you? Yeah. Probably best on LinkedIn. If you search Catchbrook Analytics, k e t c h b r o o k, you can find out what I'm up to,\r \r\n\n[00:45:54] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 54,
        "trans_speaker": "Mike Thomas",
        "trans_text": "or on mastodon@[email protected].\r \r\n\n[00:45:59] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome stuff. And certainly, yeah, we love hearing from you, as I said. And our weekly training keeps on going. And hopefully, we\r \r keep going again for the foreseeable future. But I can guarantee you there will be no robotic voices on this podcast. You can be sure we are the authentic Eric and Mike, whether you like it or not.\r \r\n\n[00:46:18] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 18,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That's right.\r \r\n\n[00:46:19] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. So we will close-up shop here. And thanks again for joining us from wherever you are. And definitely helps if you wanna spread the word for others in your in your organizations learning data science. You know? Spread your word about the podcast is probably some of the best support we can get, so we greatly appreciate that. So we will close-up shop here and we will be back with another episode of our weekly highlights\r \r next week"
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_12_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "chap_timestamp": 22,
        "chap_text": "Analysis re-use"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "chap_timestamp": 31,
        "chap_text": "Garbage in, garbage out"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "chap_timestamp": 49,
        "chap_text": "New cheat sheet"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "chap_timestamp": 47,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_12_highlights",
        "chap_timestamp": 39,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_11_highlights",
        "ep_date": "2024-03-13",
        "ep_duration": 33,
        "ep_description_short": "A collection of tips for spreading the good word about your awesome R package, how spring cleaning a package codebase doesn't have to be a dreadful experience thanks to usethis, and the culmination of a learning journey to bootstrap node JS projects powered by webR. Episode Links This week's curator: Colin Fay -…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_11_highlights",
        "description_long": "\r \r\n\nA collection of tips for spreading the good word about your awesome R package, how spring cleaning a package codebase doesn't have to be a dreadful experience thanks to usethis, and the culmination of a learning journey to bootstrap node JS projects powered by webR.\n\nEpisode Links\n\nThis week's curator: Colin Fay - [@_ColinFay]](https://twitter.com/_ColinFay) (Twitter)\nMarketing Ideas For Your Package\nSpring clean your R packages\nwebrcli & spidyr: A starter pack for building NodeJS projects with webR inside\nEntire issue available at rweekly.org/2024-W11\n\nSupplement Resources\n\nrOpenSci software review process: Aims and scope https://devguide.ropensci.org/softwarereview_policies.html#aims-and-scope\nColin Fay's hexmake Shiny app https://github.com/ColinFay/hexmake\nNo installation required: How WebAssembly is changing scientific computing https://www.nature.com/articles/d41586-024-00725-1\ntryr - Client/Server Error Handling for HTTP APIs https://github.com/analythium/tryr\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nVivid Orbis - Marble Madness - Gaspode - https://ocremix.org/remix/OCR04555\nBlack Genesis (Floating Continent) - Final Fantasy VI Balance & Ruin - Brandon Stradery, Rexy - https://ocremix.org/remix/OCR02796"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://twitter.com/_ColinFay"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://ropensci.org/blog/2024/03/07/package-marketing/"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://www.jumpingrivers.com/blog/spring-clean-r-package-usethis/"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://colinfay.me/webrcli-and-spidyr/"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://rweekly.org/2024-W11.html"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://devguide.ropensci.org/softwarereview_policies.html#aims-and-scope"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://github.com/ColinFay/hexmake"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://www.nature.com/articles/d41586-024-00725-1"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://github.com/analythium/tryr"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://ocremix.org/remix/OCR04555"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "links": "https://ocremix.org/remix/OCR02796"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We are back at episode 156 of the R Weekly Highlights podcast.\r \r If you're new to the show, this is the weekly podcast where we talk about the latest highlights that have been featured\r \r on this week's our weekly issue. My name is Eric Nantz, and I'm delighted you joined us from wherever you are around the world. And, you know, I never do this alone. I have my awesome cohost join right here, my line mate, partner in crime here, Mike Thomas. Mike, how are you doing today?\r \r\n\n[00:00:30] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'm doing well, Eric. A little better than the the Red Wings, though. It seems like they've been skidding in the last 3. Come on, Red Wings. Let's let's pick it up here.\r \r\n\n[00:00:39] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 39,
        "trans_speaker": "Eric Nantz",
        "trans_text": "There's been a a bit of anger, and there's speculation\r \r that I think you're familiar with this and those that follow sports in general in the US are familiar with this. There's more advertising now on players' jerseys.\r \r They literally just put a patch for, of all things,\r \r a trash company\r \r on the Red Wings jersey.\r \r Oh, that's bad. They are winless since then. Now I'm not one of those people who's gonna say this is exactly a correlated event, but I'm just saying,\r \r couldn't they have waited till next year? I'm just saying. So\r \r\n\n[00:01:14] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 14,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. We'll see, Mike. Yeah. Well, it's certainly correlated, but we'll hope it's not causal.\r \r\n\n[00:01:19] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Exactly. Yes. Thank you for cleaning that up. Ironically, talking about trash coming and cleaning it up. Well, luckily, you know it's not trash here. What we're talking about here today, we don't have to worry about losing streaks here. We're on a a hot streak of awesome highlights this year for sure. And our curator this week is the esteemed Colin Faye, of course, the architect of all things GOLM and many of our shiny\r \r and web in general technology tools, which we'll be talking about later in this episode. But as always, he had tremendous help from our ROK team members and contributors like all of you around the world with your awesome pull requests, suggestions\r \r and general feedback.\r \r\n\nSo let's get right to this. Right? And one of the kind of rites of passage, you might say, as you develop your R skills and your journey into data science,\r \r do you have that great idea for maybe that new analysis technique,\r \r maybe that new data source that you want to make as easy as possible for yourself\r \r and potentially others to bring into R and do some cool analysis with?\r \r Well, that, of course, is running a package. Right? This used to sound so intimidating, but with the frameworks that we've been featuring\r \r heavily on our weekly highlights since the life of this show and the life of our weekly in general, there are lots of amazing tools in place that get you started right on that journey to create your package.\r \r\n\nAnd let's say you've used those tools. You've got an awesome package\r \r ready to go. But you might ask yourself,\r \r now what?\r \r How do we exactly get this in the hands of our users? And our first highlight\r \r is coming from, once again,\r \r the very awesome rOpenSci\r \r blog\r \r authored by Ioannini Balenis Salbin and Ma'al Salmon returning once again\r \r with their series that is inspired by their recent workshops with our open side champions\r \r about how you can promote and release your r package to the world.\r \r And so like I said, Mike, first step is just getting it out there at all. What kind of advice do you have for us here?\r \r\n\n[00:03:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Well, I I mean, I'll even\r \r set the tone before that. Creating an r package\r \r to me is just such a great idea to try at some point because it sort of forces you to use a lot of great best practices around writing\r \r good software\r \r around the the science that underlies what you're trying to do. So I would highly recommend taking a stab at creating a package if you have never tried to do so before,\r \r I think you'll find it a pretty rewarding experience and I think it'll make you a better better programmer.\r \r But once you have created that package, you're exactly right, Eric. How can we how can we market it? And and one of the first steps, which I wholeheartedly\r \r agree with that Yanina and Mael recommend\r \r is to create a great read me.\r \r\n\nI can't stress this enough, you know, your read me will help others,\r \r understand exactly what it is your package does,\r \r how to install it, and maybe a few different examples of how to get started\r \r using it.\r \r It may even, as you create that Readme, help you sort of refine your idea around what you actually wanted this package to do and may cause some changes to your actual functionality not speaking from experience or anything like that but it's it's one of those, exercises kinda like a rubber duck I think that forces you to explain exactly,\r \r you know, in in\r \r layman's terms, non code terms, what your package is trying to accomplish. And and it's a a great idea.\r \r\n\nSpend all the time creating, you know, the coolest hex logo that you possibly can as well. Not that I've wasted hours doing that at the end of a project, but that's a super fun part of it as well and I think that from a marketing perspective any sort of visual\r \r fun aids can help market your your package as well\r \r if you use GitHub you Nina and Mel recommend that you pin that package repository to your profile so that as soon as somebody visits your GitHub that'll be sort of the first thing that they see that stands out and that's a great idea as well.\r \r The next,\r \r the next recommendation that they have around publishing\r \r is one that I need to take to heart because I have not done this yet and it is create a universe on our universe,\r \r which as we've talked about on the podcast before, is this absolutely\r \r incredible resource created by your own. And,\r \r it is a phenomenal place to to host your packages\r \r that automatically, I think, displays\r \r the documentation\r \r and metadata around your package in just a beautiful really\r \r accessible way.\r \r\n\nAnd also, I think allows others to install it it very quickly because I think in in some cases it'll build binaries if I have that\r \r correct. Yes. It is building binaries. Yep. Okay. Which can make the installation experience a lot better for\r \r your users\r \r and then you know after that sort of I guess the the holy grail right would be potentially public publishing it to crayon\r \r which is sort of the final way to make installing your package probably the easiest\r \r to the largest\r \r array of users, across different experience levels\r \r out there.\r \r\n\nAnd one thing that that I also hadn't thought of it as well, and if you're familiar with the rOpenSci project, is that they have a peer review process\r \r which is a phenomenal thing that is in place to sort of ensure robustness and rigor around your R package and ensure, again, that you're using,\r \r some of the best practices around software development\r \r and creating an R package.\r \r It's not something that I've done before. I I think that it's a fantastic fantastic resource and it's something that I wanna take advantage of, to me, and I think maybe this blog is debunking that that myth a little bit. I was never sure that my packages were sciency\r \r enough, for our OpenSci to necessarily,\r \r consider, you know, peer reviewing the work that I've done. But, as I know that they have office hours and and things like that that are publicly available,\r \r I would definitely recommend that folks take advantage of these resources\r \r that they offer. And in that peer review process, I think, as they mentioned,\r \r they may catch a lot of things, that you might get flagged on when submitting to CRAN. So they may help you expedite that process of getting your package\r \r onto CRAN.\r \r\n\nSo those are their recommendations\r \r around publishing. And then maybe, Eric, you can talk a little bit about their recommendations around promoting your package.\r \r\n\n[00:07:46] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 46,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. And this is a a skill set that is admittedly sometimes not intuitive to many of us, especially as we're new to this this, situation\r \r of getting the package out there\r \r but trying to get it into the hands of the user base that we intended to have, especially as we wanna garner initial feedback\r \r and, frankly, make make a positive difference. Right? And so there are lots of interesting ways. And, again, maybe not a one size fits all for everybody, but I think the advice here in general is quite sound.\r \r One of those is\r \r taking advantage\r \r of the\r \r lowest friction to get this out there on various either social media or other publishing platforms.\r \r\n\nOne of them, of course, I'm not gonna be ashamed to say I'm biased with this, is, hey. Send it to us at our weekly. Right? We have a section every single week on new packages\r \r that have been released to the R ecosystem,\r \r whether they're on CRAN\r \r or on GitHub only or or a GitHub like repository.\r \r And we always also link to the R Universe project in every issue as well. So that is, again, we are, as I say at the end of the show all the time, a poll request away from making that announcement on our weekly. We definitely recommend\r \r you take advantage of that.\r \r\n\nAnd, also, if you wanna spread the word on kind of your intention of the package and maybe some more up to date notes from yourself\r \r to your audience,\r \r another great way\r \r is to start your own blog. Right? There have been plenty of frameworks now in the R community that will make creating a blog with markdown\r \r super easy.\r \r I, of course, speak with great success with the blog down package.\r \r Now Quarto, of course, that we can talk about routinely on the highlights\r \r has its own mechanism for creating a website with a blog component.\r \r So those would be another terrific way that you could\r \r spread the word about your package and then posting that on various social media channels such as Mastodon,\r \r LinkedIn,\r \r some of\r \r the others out there.\r \r\n\nAnd those, again, are great ways to get the word out. Again,\r \r not natural for yours truly to do all this, but\r \r over time, you really start to see some really great nuggets come out in the community as you follow these feeds, and you could definitely put your package\r \r as one of those items in those feeds.\r \r And then as you as you said, Mike, going through the rOpenSci process\r \r from the creation and peer review process of your package is a terrific way to enhance the quality.\r \r I personally have not done it, but I've lived vicariously through my esteemed friend Will Landau and his peer review process for targets,\r \r which is you know, why we recognize in the R community for\r \r innovations, to say the very least. And, yeah, rOpenSci has done a tremendous job with targets.\r \r\n\nAnd one of the other bits of advice that are in this post here is that if it is on rOpenSci,\r \r they have additional channels to market your package,\r \r such as featured tech notes that are going on their our open side blog, which is what we're reading through right here as we speak. And also, as you mentioned, they also have community calls and even can set up dedicated working sessions where maybe you, as a package author,\r \r wanna give a chance for, you know, a prospective user to hop on a video working session with you. And you can talk about the package and maybe debunk some issues,\r \r But it's another great way to get the word out because those are\r \r very, you know, relaxed atmosphere,\r \r just, you know, practical discussions,\r \r and another excellent way for your users to learn about, the way your package works if you're in the rOpenSci\r \r ecosystem here. And, of course, social media and blog posts are just one way to get the word out. Another terrific way,\r \r especially in the community of the R community,\r \r the worldwide presence of these user groups and also the R Ladies user groups.\r \r\n\nAnother terrific way to maybe have a short presentation\r \r or a short working session, maybe an online workshop of 1 of these working groups.\r \r Another terrific way to get the word out about your package. I've seen some really great great showcases of that throughout the years on these various online forums now, especially\r \r since the pandemic. Many of these are remote. They're sharing recordings on YouTube or other video channels. Another terrific way to get the word out.\r \r And I dare say another fun way, if you're really adventurous, to do a little livestream once in a while like I used to do in the past, which I hope they get through someday. But, again, there are many different avenues for you to get your get your package out there. And certainly, if it is a very scientifically focused package,\r \r there are some very well renowned\r \r manuscripts out there\r \r such as getting it into the R Journal itself\r \r or the Journal of Statistical Software,\r \r many others that are domain specific as well, which, of course, in my field, we do a lot of literature review. We're seeing a lot of new algorithms\r \r being published,\r \r and they often have an accompanying R package to go with that publication.\r \r\n\nAnother very traditional yet very powerful mechanism\r \r for getting the word out there. And one little bit, Mike, as you said, you were really sure if a package you're creating is, quote unquote, scientific\r \r enough for an rOpenSci, you know,\r \r scope. But what we'll what we'll link to in the show notes is, a section on their online peer review book where they do talk about the intended scope that they look for with respect to bringing a package on board to rOpenSci.\r \r And the great news is that doesn't have to be a very focused domain specific\r \r scientific algorithm or method. They have many packages\r \r that are involved in making data more accessible,\r \r making APIs more accessible. There are lots of interesting domains here that, you know, could be a good fit. Again, may not be for everybody, but, again, if it does fit in that scope, you might benefit greatly\r \r by going on our open side.\r \r\n\nAnd certainly,\r \r I'll also speak on the perspective of those in an industry where maybe you don't get a chance to\r \r publicize this to the worldwide, our community, until you get the, quote, unquote, blessing of getting an open source. Maybe you have to deal with this internally at your organization. If you have a large organization,\r \r how do you make sure that\r \r your user base within the company get their eyes on it? I'll go back to what I said maybe a few minutes ago.\r \r Having an internal blog is a cool thing to do too. I'm actually trying this out now as I speak,\r \r doing a little portal blog for our internal group to share package announcements that our group is creating and having those broadcasts on either some\r \r newsletter or some other, you know,\r \r distribution service within the company. So it's not just us making these cool packages out there and then, you know, others in statistics or data sciences\r \r not not getting the word of it. We're gonna find ways to get that message across. So I think a lot of these principles can apply to those of you that I'm gonna steal a phrase from my friend Michael Dominic with the Coda Radio podcast.\r \r\n\nYou dark matter developers out there, I see you. I know you're out there. There are great ways you can take some of these techniques internally\r \r at your respective organizations, too. So\r \r really, really great blog post. Gives you a lot of great ideas to follow-up on. And again, I think just getting the package out there, you've done immense work to do that. It's a journey. I know how it goes but getting the word out there so that your user base can get their hands on this, is, you know, a really critical component to making sure that you can make the package even better as your users get their hands on it. So, yeah, really great advice here, and I highly recommend what we're talking about here. Yeah. I know. And that's a great point, Eric, too, because not all of us can share\r \r\n\n[00:15:41] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Mike Thomas",
        "trans_text": "our our packages with, you know, the the general public in the outside world, but I I think you absolutely can take these principles\r \r and leverage them within the communities inside your own organization,\r \r through whatever means, you know, necessary that you have available to to do that, but but still leveraging these principles I think is a great idea.\r \r\n\n[00:16:10] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 10,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Now what if, Mike, you're in the situation of you've you built that package, but maybe it was,\r \r I don't know, 5, 6, maybe even 10 years ago.\r \r You look at the code base and you realize,\r \r oh, past me did that.\r \r If past me knew what present me knows now, I probably wouldn't have done it that way.\r \r You might be in the situation where your package may deserve\r \r a bit of what we'll call spring cleaning, as they say. And so our next highlight, comes to us from the Jumpy Rivers blog. We featured them quite heavily on highlights in the past, authored by Rhian Davies,\r \r and is appropriately entitled Spring Cleaning\r \r Your our packages. And they start off with\r \r relating to that Jumpy Rivers themselves have put many packages on, say, GitHub or CRAN and whatnot,\r \r and some of them develop it more than, say, 5 years ago.\r \r\n\nAnd then as we learn I mean, I'm a continuous learner, as they say.\r \r Lots of new, you know, best practices,\r \r maybe modifications\r \r to existing best practices.\r \r And then you realize, yeah, you know what? I should try some of that in my legacy package\r \r that needs a refresh. How\r \r do we go about that efficiently?\r \r There are some practical things you can start with,\r \r one of which is if your package is on a GitHub or GitHub like repository.\r \r There\r \r was\r \r about\r \r 3 or 4 years ago, Mike, there was a movement\r \r to change the nomenclature\r \r of default branches.\r \r\n\nWe won't get into all the details here, but the connotation of master didn't exactly sit well with many people in today's, you know, communities.\r \r So there's been a movement to change that to a more friendly term such as Maine or something like that. And so there is an easy way\r \r to rename your branch right away. And we're going to talk about this heavily on this segment.\r \r They use this package author by Posit is\r \r the superstar here, so to speak. We're getting these tips\r \r operated on efficiently with as less friction as possible. So there is a handy function called\r \r get default branch rename.\r \r\n\nIt's a long function name, but it literally says what's on the tin, what it does. So once you do that, your branch becomes main. You can push that up to GitHub, and you are all set.\r \r But, of course, it doesn't end there. We've got we might have some additional things that we wanna tidy up with respect to the package metadata.\r \r This was new to me, Mike. I'm curious if you knew about this before,\r \r but there were times I wrote my description file for a package,\r \r frankly, by hand back in the old days. Yep. You remember.\r \r And so I'm updating a package\r \r that, again, I've lost there, like, 8, 9 years ago.\r \r\n\nAnd there is this little gem that's in this blog post Now if you wanna tidy that up so that things like you have\r \r fields in more alphabetical order, maybe spacing correct, making sure that\r \r consistent names with maintainers and and author fields are correct,\r \r There is a use tidy description function\r \r that will basically put everything in the standard order,\r \r alphabetize the dependencies, and make sure everything just looks really tidy.\r \r So if you happen to do all that manually,\r \r that is awesome. I love seeing that.\r \r And then\r \r another part is\r \r we don't always want to do things ourselves all the time, right?\r \r\n\nWe're in 2024.\r \r There is a new technology in certain platforms such as GitHub to automate many of these checks in action.\r \r And, Mike, there is even more use this magic\r \r for getting that set up for you, isn't there?\r \r\n\n[00:20:00] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 0,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. There are. And as we talk about\r \r things that we used to do that we no longer do.\r \r Right?\r \r Travis CI, I think used to be that the most popular tool for continuous\r \r integration, which is, you know, running code essentially,\r \r on maybe some separate server.\r \r And a lot of times this was around running tests, ensuring that all your unit tests pass,\r \r when you create a pull request before\r \r that pull request actually gets merged into the main branch.\r \r Nowadays,\r \r we're using continuous integration quite a bit as well for, like, creating package down sites,\r \r and updating, you know, what's shown\r \r in that that, package down branch of your repository\r \r that spins up the the whole package down site that folks can go to and see the beautiful version of your your packages documentation. So, Travis c, I sort of used to be the only game in town, but it's GitHub actions now.\r \r\n\nYou know, I think I think that's probably the primary way that folks are going these days. And fortunately, again, use this package,\r \r allows you to\r \r easily\r \r create,\r \r that continuous integration GitHub action\r \r with, the function. Stop me, if you're not expecting this, but the function name is use GitHub action. And you can, supply sort of what type of check you want to create and that essentially creates a whole entire YAML file that will execute, the unit tests in your package,\r \r run those tests,\r \r when a PR takes place, I think, for the most part. And you you can alter that YAML file if you want to,\r \r you know, change\r \r when, those checks get fired,\r \r or or other certain specifications of those unit tests, getting run-in this continuous integration,\r \r situation.\r \r\n\nSo there's a lot of different options here, within, you know, being able to use GitHub actions depending on sort of how strictly\r \r you want to run the tests on your package, and then, you may also want to\r \r take a look at it and see how much test coverage quote unquote,\r \r your package has, which is sort of the ratio, I believe, of the number of lines of unit testing code versus the number of lines of of sort of our code that your functions\r \r themselves\r \r have, and and you wanna sort of ideally be as as close to a 100%, I think, as possible. I think there's a lot of a lot of opinions out there on that that we don't necessarily need to get into. But it's probably a good idea to show your users sort of in general at a high level\r \r that you are are writing a lot of tests around the functionality for your package to ensure that, you know, your logic is doing what you expect it to do, and that it continues to satisfy\r \r those expectations as you you make changes and and refactor\r \r over time.\r \r\n\nAnd the last two things that, they recommend are 1, creating a hex sticker, which is a callback to our our first blog as well, which I will highly recommend. I use a site called Canva,\r \r which I think I pay a couple bucks a month for, but, it is it's pretty incredible just the the stuff that you can do. And nowadays, it seems like everybody's\r \r leveraging,\r \r you know, these generative a ai models to,\r \r sort of\r \r write a prompt of what you want shown on your HEX\r \r logo and then, you know, that'll spit out a wild image for you that that you can crop to, a HEX background. In my case, I I do that pretty easily with Canva. And, we've been I've spent way too much time on that recently but it's it's super fun and can be a fun way for folks to,\r \r it can be the first thing that they see when they navigate to your package down site or, you know, browse the vignettes within in your package, in the RStudio IDE.\r \r\n\nAnd I think it can can sort of create some excitement and engagement around your package.\r \r And then the last thing,\r \r that they will recommend is,\r \r contributing\r \r and code of conduct, adding that\r \r to your repository\r \r in your package as well to let users know the best way,\r \r and sort of the guidelines and principles that you expect\r \r people,\r \r that want to contribute to your package,\r \r to contribute to your package in in a friendly way,\r \r in a safe environment\r \r that, works sort of for everybody that that's working on that that repository.\r \r So some excellent excellent\r \r spring cleaning,\r \r if you will,\r \r ideas and and examples from Jumping River. Spring is here, and I think it's it's time for all of us to start diving into these.\r \r\n\n\n\n[00:24:27] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I've literally been living this life for, like, 3 weeks now with this legacy package and seen so many areas that need a little attention, a little package and seen so many areas that need a little attention, a little cleanup here and there. And so all these principles either have or will take action quite a bit. And back to HEC stickers. Yes.\r \r Yours truly did revise a\r \r HEC sticker for this legacy package.\r \r I'm gonna give a quick plug. If you want,\r \r in the in the blog post here, they're referencing the hex sticker or, I believe, the sticker package or hex sticker package,\r \r easy for me to say, as in our way of doing it. And then, also, if you wanna stick with VAR about bringing all shiny in it,\r \r many years ago, Colin Faye, as part of a shiny contest submission, released the Hex Make Shiny app where you can literally create a hex sticker,\r \r superimpose an image on top all within a Shiny app and download it. So I actually use that literally to make a new hex sticker for my internal package.\r \r\n\nThat was that was a lot of fun. So I'm\r \r never shy to plug that that fun shiny app for my bookmarks as well. And, honestly, yeah, back to the contributing guidelines,\r \r when I would build these legacy packages, you know, back then, maybe I was naive. It always seemed like it would be just me, so I didn't put a lot of thought into it. But you know what?\r \r The these packages,\r \r again,\r \r I think can really thrive when you have somebody at least\r \r that wants to be active with you, if not maybe developing day to day, but at least, you know, helping you test things out. Maybe they're a liaison to other users, and then they have feedback, and then they can, you know, find the best way to, you know, help you with that feedback.\r \r But you wanna give them the easiest way to get started with that. So these contributing guides,\r \r whether your package is open source or within the confines of your industry firewall,\r \r I think those are critically important to make sure that you give\r \r these others that maybe are willing to step in this. They'll know where to start. Things like a contributing guide, also making good use of issue labeling in your whatever your system is for issue ticketing,\r \r things like good first issue or help wanted or, you know, you know, things like that. You know? And, obviously, it's project specific, of course, but making it as easy as possible for people to really drill down to see which areas they can contribute to the most. So, again, great things to think about as you're already in the midst of making your pack as a little more tidy along the way. Yeah. Really good advice here.\r \r\n\nWell, I teased this earlier, Mike, but, our curator here has been hard at work not just curating this issue, but,\r \r Colin has been knee deep in this\r \r learning journey and this saga of supercharging\r \r his workflows\r \r with WebAssembly.\r \r And in fact, we are gonna be talking about in the last segment here, it is, I believe, the 6 posts in his series of exploring WebR and WebAssembly\r \r with respect to, you know, interactive web applications.\r \r And what we're going to talk about here, what seems to be kind of a culmination of everything he's been learning here,\r \r is the idea\r \r of having new tools available\r \r that within, say, the native JavaScript\r \r world\r \r of bringing WebR,\r \r WebAssembly\r \r powered by R\r \r into\r \r these,\r \r these applications\r \r via 2 new utilities that work in tandem. So let's dive right into this where\r \r earlier in his explorations,\r \r he's been prototyping some interesting use cases of,\r \r say, converting an existing Shiny app in the WebR,\r \r preloading packages\r \r in an Express JS API, you know, bringing your own functions in WebR and then building them into the the the Node. Js app and whatnot.\r \r\n\nWell, he realizes\r \r that a lot of that was, you know, kind of, you know, piecemeal learning a bit here and there ad hoc.\r \r What if we wanna take those best those practices that he's been outlined into a very easy way to make it happen that might have some parallels to what we get in the R community\r \r when we build packages with, say, dev tools, use this. And in the Shiny situation, of course, what Collins authored with the golem package. What's a way to bring that all together\r \r in this native kind of WebAssembly and JavaScript world?\r \r So in this blog post, he announces 2 new utilities to make this happen,\r \r one of which is called WebRCLI,\r \r which again is going to be very similar\r \r to kind of a dev tools use this paradigm\r \r along with other functionality we'll get to later\r \r that's going to help you create\r \r a no JavaScript\r \r project,\r \r but with the bindings to WebR\r \r already baked inside,\r \r things that he was building manually in the earlier stages of this journey.\r \r\n\nThis package or this utility\r \r is going to bootstrap that for you, not too\r \r unlike\r \r what you would do with use this and say use this use package or create package. I forgot the exact name of it, but it's where it gives you the scaffolding of an R package right away. And then it's up to you to fill in the blanks, if you will. This is doing a very similar framework with, again, the WebAssembly piece of all this.\r \r And so that in tandem with the other utility,\r \r which is called Spider,\r \r which is looking like a way to build\r \r extensional functionality\r \r on top of WebR itself,\r \r such as\r \r what we get in typical R installations\r \r where we want a package from CRAN or or maybe even from GitHub with the remote package.\r \r\n\nWe have functions to literally install that package. Right? Install that packages\r \r or remote install GitHub or whatnot.\r \r Spyder is giving you\r \r a utility to use a native JavaScript function that will look very similar to those installation commands,\r \r and it's giving you those built on top of WebR\r \r to bring those packages down to your local project.\r \r This,\r \r this is kind of amazing to me. It's not just\r \r taking their installation.\r \r It is putting them in a project specific directory\r \r that, if you're familiar with r m, will look very similar.\r \r I went through the GitHub\r \r example that we'll have linked to in the show notes.\r \r\n\nHe ignores this, but I and his GitHub ignore. But what I did is I cloned this locally to give it a try. And sure enough, there is a directory\r \r that when you go inside it, it will it's called webrpackages.\r \r You go in there, It will look very similar to your r mv library where you download packages.\r \r This is fascinating to me. Colin has figured out how to load these packages\r \r from a file store\r \r into these WebAssembly\r \r powered applications.\r \r This is massive to me\r \r because where I'm going with this, ongoing pilot submission with WebAssembly,\r \r we want to explore ways of not just grabbing packages from\r \r the WebR binary\r \r repository on the fly, so to speak.\r \r\n\nBut should we want to distribute packages as part of a bundle?\r \r How do we bring those into the application locally?\r \r So I will be looking into this quite closely to see if I can take some nuggets from this, whether it's for this particular pilot or for future explorations\r \r the CI can mirror this with things like Shiny Live,\r \r that we're using right now in our pilot submission.\r \r So the wheels are turning after I read Collins post here. But this is again, this is all fascinating to me. So one thing you notice that we didn't mention here is that we're not talking about Shiny here. Right? He is speaking on behalf of those that maybe are familiar\r \r with JavaScript native ways of building a web application,\r \r but you have a function in R or a package in R you wanna leverage as the back end to that Node. Js or other JavaScript like app,\r \r this set of utilities\r \r is your way to make that happen.\r \r\n\nAnd I definitely invite you, if you do have, you know, Node. Js and NPM installed on your machine,\r \r give this a shot. I literally ran through the blog post this morning,\r \r and everything worked to a tee. Everything worked as advertised. So\r \r this, I think, is opening a lot of possibilities\r \r here.\r \r But as we often say in these explorations,\r \r it's early days. He has not tested this over than a few examples, and he is very eager to get community feedback on how this goes for those also that are willing to explore this kind of blazing trail,\r \r if you will, of this of this new journey here.\r \r\n\nSo there's notes at the end about how he kinda pulled this off from, like, a back end perspective.\r \r But again, he's looking for feedback on this, and I definitely am intrigued\r \r by what I'm seeing here.\r \r And I can't wait to to learn more about how this works under the hood.\r \r But this is a great time to talk about WebAssembly right now because I'm thrilled to say\r \r as of yesterday when we record this episode,\r \r there is a fascinating new article released by Nature\r \r authored by Jeffrey Pirkel.\r \r It's entitled\r \r no installation required, how web assembly is changing scientific computing.\r \r And I'm humbled to say to yours truly has a small little quote in here based on our current explorations,\r \r but I will say\r \r this is the kind of stuff I am super excited about. We are trying to push the envelope here.\r \r\n\nWe think there is a massive potential\r \r in many industries for this. Of course, I'm coming from life sciences, but there are many, many others\r \r that I think can make heavy use of WebAssembly.\r \r This article has terrific narrative\r \r around kind of the genesis of this from George Stagg himself as he started prototyping WebR\r \r along with other members of the scientific community and how they're showcasing\r \r the use of this technology. So great time for me to see this. And, again, super excited to dive into\r \r what Colin's exploring here and see how we can supercharge this in the future.\r \r\n\n[00:34:47] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. Me as well. And, Eric, I'm glad that you you shouted out that article because if you didn't, I was going to you know, when I first started doing this podcast, I was\r \r starstruck that I got to record with the, you know, the the host of the r podcast and the Shiny Dev series. Then I think I've gotten a little comfortable,\r \r with you, but but now you are featured\r \r in Nature Magazine and I'm right back where I started. So hats off hats off to you that\r \r that that is an awesome awesome accolade and it's it's super exciting as well to\r \r see that, you know, the scientific community is is talking about this stuff as well. And it's not just us\r \r software nerds,\r \r you know, that that are the only ones caring about this, that it's it's really something that other folks seem to be seeing as well as a pretty\r \r revolutionary\r \r thing that's starting to come into the ecosystem. And and fortunately,\r \r we do have folks like Colin who are at the the cutting edge of, the this WebAssembly stuff. You know, Colin curated this week, and and when I saw the blog post, I thought this\r \r\n\n[00:35:55] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 55,
        "trans_speaker": "Eric Nantz",
        "trans_text": "was a little bit of insider trading, but I'm very glad that, I'm very glad that this one made the highlights. It's a great example.\r \r\n\n[00:35:57] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 57,
        "trans_speaker": "Mike Thomas",
        "trans_text": "You know, one of the the the toy examples here is is, called this WebR SpongeBob,\r \r example that he has, which I think just sort of allows you to,\r \r you know, essentially change some text, a string that you write to what's called sponge case. A quick story, during a particularly slow period a couple years ago,\r \r for me, I highly considered creating this exact r package. I didn't end up doing it, and and glad I didn't because it looks like maybe Colin was the one who created the spongebob package. I'm not not sure if it was him or somebody else, but, somebody somebody took care of it for all of us. Obviously, that's a very important package in the art community. So it's nice nice to have that one out there.\r \r But this is a phenomenal guy. To use your own. Right? To use your own. Yeah. And like you said, you know, it's incredible. I haven't actually tried it myself, but it sounds like you maybe forked the repository as well and ran through this and found that there were no issues. Obviously, I think\r \r Colin in both the the read me's in these repositories and this blog post as well makes a lot of disclaimers that,\r \r this\r \r is very early on, very experimental.\r \r\n\nYou know, expect a lot of bugs. He,\r \r I think may already be seeing some bugs and edge cases that he's hoping to to solve, but regardless, I think the the fundamental concepts here of what's being done are are really driving sort of this this idea in this space\r \r forward about,\r \r you know, that this this web assembly topic and not needing to manage dependencies,\r \r in ways that\r \r traditionally were were a little difficult and sort of making that much easier and much more accessible to a wider variety of people, which is is incredible. So I'm excited to see, how this this continues and patiently waiting on on blog post 7.\r \r\n\n[00:37:45] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 45,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Me as well. And it's,\r \r Collins in this realm of, I'm gonna say, you know, key\r \r amazing thought leaders in this space that are being very adventurous in what's happening here,\r \r in the same category as I would consider Bob Rudis and his explorations with WebR\r \r tying into things like observable\r \r framework and whatnot.\r \r WebR is this engine that is powering so many things.\r \r Yes. I've been coming to them mostly from the shiny perspective with Shiny Live, but it is so\r \r much more than just that. We even feature, what was it, 2 or 3 weeks on this very podcast,\r \r a blog post\r \r that had,\r \r you know, our counsel\r \r basically embedded into the post itself to try out the code that was being being showcased there. Right? Education side,\r \r web application side. And now as as that nature article is showing even, you know, high throughput,\r \r high HPC like computation\r \r in the browser,\r \r It's all it's all coming together. It is. I mean, I don't know. I haven't been this geeked out in years that of ways that we can\r \r tie our entire data science with a novel technology. And I'm I know I can't stop talking about it, but at the same time,\r \r this\r \r is the start of something. I still remember sitting\r \r at the positconf\r \r presentation by Joe Chang at the end there, and all of us are looking at each other across the room is like, yep, we're going with this. We're going to try stuff out and see what happens. Challenge\r \r accepted, Joe, if you're here listening to this. So, yeah, really cool stuff to see what Colin's exploring here. And it does show that I still have a lot to learn, but at the same time, I'm gonna enjoy learning about this.\r \r\n\n\n\n[00:39:28] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 28,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Likewise. Likewise. And then on the you know, I I take it from a shiny perspective as well.\r \r And then with the sort of duct deep, you have to think about the data side of it right and maybe you have an external connection to a database which makes things easier maybe not and you know the fact that there's, now\r \r these integrations between DuckDV and and WebAssembly that I think are going to solve sort of that final\r \r last piece\r \r for us in a lot of ways in terms of connecting the data to the application or or whatever you're showing on screen in an easy way,\r \r it's it's incredible.\r \r\n\n\n\n[00:40:00] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 0,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Absolutely is. And we're gonna be hearing a lot more about this throughout the year. I'll also give a a plug once again that we'll we're thrilled to have George Stagg give a keynote at the upcoming shiny conference coming up in April. So if you're not registered for that, I highly recommend\r \r coming to that event as well. And, yeah, my cohost here is gonna have a shiny app on there as well, so we're really excited for that. Yes. That's exciting. Coming up quick. It sure is. It sure is. But, you know, it's quick. You know, it's always a a quick yet very educational read whenever you see our weekly every single week. We don't try to bog you down too much where we give you, you know, the the awesome resources,\r \r blog posts,\r \r tutorials, as we mentioned at the top, new packages, hitting the ecosystem,\r \r updated packages,\r \r and much, much more. So we're gonna take a couple of minutes to share some additional highlights here. And going back to the Shiny train for a little bit,\r \r I had a thought provoking\r \r insight here that it was led by this blog post from Jacob Soboliewski\r \r over at Absalon\r \r entitled Using Test to Develop\r \r Shiny Modules.\r \r\n\nNow this is something that usually you don't really think about until you get to the stage where your module is almost done and you're thinking about, okay, how do I make sure that it's robust enough? But,\r \r Jacob here does a great outline here about how the concepts of test driven development really come into play. Whereas if you're really iterating on a specific module,\r \r there are ways to test it efficiently\r \r without having to run the entire app every single time, making clever use\r \r of test that functionality and custom functions and whatnot.\r \r And this looks like some I'm gonna start looking at as I start revamping some of my major shiny apps or building new ones in terms\r \r of making that development cycle of developing modules just a wee bit faster to my to get to get things done quicker as they say. So, yeah, really thought provoking for a post from Jacob here. Yes. I\r \r\n\n[00:42:01] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Mike Thomas",
        "trans_text": "found a blog post, an additional highlight here from\r \r Alexandros\r \r Kuretsis,\r \r from Absalon,\r \r entitled Our Plumber How to Craft Error Responses That Speak Fluent\r \r HTTP.\r \r You know, we talk about Shiny a lot, Eric. I've\r \r said that a few times today. But, you know, one thing that we talk about a lot is creating the best user experience\r \r as possible around our Shiny apps. And a lot of times that includes error handling in a graceful way\r \r for the user to understand sort of what went wrong instead of just getting disconnected from the server. Right?\r \r That that's what we try to avoid.\r \r\n\nAnd the same principles\r \r I believe apply to APIs. You know like plumber APIs. Right? That where if something does go wrong there's going to be an error code that gets sent back,\r \r to the other application that's making the request\r \r and typically that error code is going to be either of a 400 type error or a 500\r \r type error. And and 500 type errors typically mean that something went wrong, I think, on the server side.\r \r Whereas,\r \r 400 type errors are are typically, you know, something bad happened,\r \r in terms of the the the inputs that went into that request of the API didn't satisfy sort of what the API was expecting,\r \r as opposed to, you know, the the server being down or something like that. So\r \r understanding sort of the difference between those and being able to to return something more informative,\r \r back to the applications that maybe they can create some sort of a UX based upon what type of error code comes back, so the user can understand exactly what went wrong. You know, should they should they fix this particular field that they just filled out incorrectly before clicking a button that sent that API request,\r \r you know, or or give them some information about how to potentially rectify the problem, or do they need to contact IT because the the server itself is down. Right? And understanding that difference is is really important. So this is a great blog post that I think walks through,\r \r a discussion around that, how to make things safer there. And then I will also shout out\r \r a project by, Peter Salamos and his team at Analytium,\r \r and the package is called tri r, t r y r, that tries to do the exact same thing. I think it's client server error handling for HTTP APIs,\r \r and he has a lot of examples with Plumber there and the same exact idea, you know, that you're trying to provide sort sort of a more informative error code, response\r \r back to the application\r \r that, sent that request initially. So some great resources here, to to shout out. And I have been knee deep in Plumber lately and and really enjoying it. So this is very timely for me.\r \r\n\n\n\n[00:44:43] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Really, really awesome insights there. And I'm also in the train of EVRA helping build new APIs\r \r or consuming existing APIs\r \r and having our layers on top of that. So, yeah, having any way to give that UX, you know, a much more pleasant experience for not only me as a developer,\r \r but my end user who is not gonna give 2 wits about what's actually behind the scenes. They just wanna know what happened and how to fix it. So anything like this to translate to crypto 403s or to 502s or,\r \r 69, whatever you wanna call it. They're all cryptic at the end to most statisticians and data scientists. So being able to translate that, and having a robust kind of paradigm for air handling is very welcome\r \r in this space. But I think it speaks to this new trend that we're seeing\r \r is that we're interfacing with other systems of some sort. I've traditionally been HPC systems, and now I'm really\r \r augmenting that with these web services that may or may not be high performing, but at the same time, they're doing one thing. They're doing it well, and they want to be agnostic\r \r to what front end we have of it. So, of course, I'm biased to r. Why wouldn't I be? So having to package interfaces with that and making that UX seamless,\r \r that's a win for me.\r \r\n\nYou know what else helps you win? Unlike what's happening to my poor red wings, is that reading\r \r our weekly every single week will help you win the game of leveling up your data science knowledge.\r \r I tried. I tried. I'm trying to give them good luck for tonight. But, anyway,\r \r yeah, every single week we have a new issue online and it's released basically every Monday morning. And then, you know, the train keeps going\r \r and we are powered by the community. Right. We, as I mentioned earlier, you know, every single week, we look at your awesome pull requests. And you may wonder, how do I get that on there? It's all linked at rweekly.org.\r \r We have a link to the upcoming issue draft right at the top right corner.\r \r\n\nWe're just a pull request away from that new blog post, maybe that new package that you just created\r \r following the advice we just mentioned in the first highlight. Our week is a great way to showcase that. It's all marked down all the time. You know, I've lived marked down lifestyle with my package documentation,\r \r my internal blog posts, some of this external stuff I'm doing. You know?\r \r Without markdown, if I had to do, like, LaTeX for all this, I would cry. I would just cry, Mike. Thank goodness for markdown.\r \r Yes. You are exactly right. Thank goodness for the shiny include markdown function as well. Shout out. Very, very nice. Yes. I've used that heavily and with no regrets at all. Yes. So, yep, all markdown all the time of our weekly,\r \r And also, we'd love to hear from you directly as well. There are many ways to do that. We have a contact page linked in the episode show notes right at the bottom of our show notes that you can click to.\r \r\n\nWe also if you're listening to a modern podcast app, WebPoverse, Fountain, Cast O Matic, CurioCaster, there's a whole boatload out there. You can send us a fun little boost along the way right in your podcast app itself. All details are linked in the show notes as well. And lastly, we are sporadically on various social media outlets. I'm mostly on Mastodon with atrpodcast,\r \r at podcastindex.social.\r \r Also, on the Weapon X thing from time to time with atrcast\r \r as well as LinkedIn.\r \r You can find me on there with show announcements and, you know, blog posts and the like. And, Mike, where can the listeners find you? Sure. LinkedIn is probably the best place to see what I'm up to. You can just search Catchbrook Analytics,\r \r\n\n[00:48:09] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Mike Thomas",
        "trans_text": "k e t c h b r o o k.\r \r And if you wanna find me on Mastodon, you can find me at [email protected].\r \r\n\n[00:48:20] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. I think we've, put a nice little bow on this episode. But, again, it's been a great recording session once again, Mike, and, we hope to see you all for our next edition of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_11_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "chap_timestamp": 55,
        "chap_text": "Marketing your R package"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "chap_timestamp": 10,
        "chap_text": "Spring Cleaning"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "chap_timestamp": 1,
        "chap_text": "Starter pack for webR and nodeJS"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "chap_timestamp": 27,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_11_highlights",
        "chap_timestamp": 54,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_10_highlights",
        "ep_date": "2024-03-06",
        "ep_duration": 41,
        "ep_description_short": "How an attempt to solve a clever programming exercise led to a new patch to the R language itself, a review of the enlightening results for the recent data.table community survey, and creating a Doom map in R, because why not? Episode Links This week's curator: Eric Nantz - @theRcast (https://twitter.com/theRcast) (Twitter) &…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_10_highlights",
        "description_long": "\r \r\n\nHow an attempt to solve a clever programming exercise led to a new patch to the R language itself, a review of the enlightening results for the recent data.table community survey, and creating a Doom map in R, because why not?\n\nEpisode Links\n\nThis week's curator: Eric Nantz - @theRcast (Twitter) & @[email protected] (Mastodon)\nI Patched R to Solve an Exercism Problem\n{data.table} Community Survey: Results and insights\nDoom plots\nEntire issue available at rweekly.org/2024-W10\n\nSupplement Resources\n\nhttps://exercism.org/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nBonus Bop - Donkey Kong Country 2: Serious Monkey Business - Xenon Odyssey, The UArts \"Z\" Big Band - https://dkc2.ocremix.org/\nHangarmageddon - Doom Dark Side of the Phobos - EvilHorde - https://ocremix.org/album/4/doom-the-dark-side-of-phobos"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://jcarroll.com.au/2024/02/26/i-patched-r-to-solve-an-exercism-problem/"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://rdatatable-community.github.io/The-Raft/posts/2024-02-25-survey_2023-aljaz_sluga/"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://aitap.github.io/2024/01/01/doom.html"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://rweekly.org/2024-W10.html"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://exercism.org/"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://dkc2.ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "links": "https://ocremix.org/album/4/doom-the-dark-side-of-phobos"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We are back with episode 155 of the R weekly highlights podcast.\r \r This is the weekly show where we showcase the awesome resources\r \r that are available every single week on this week's our weekly issue. My name is Eric Nantz. And as always, I'm delighted that you joined us from wherever we are around the world.\r \r And, yes, spring is in the air around here, and I'm feeling happy as always to be joined at the hip by my awesome cohost, Mike Thomas. Mike, how are you doing this morning?\r \r\n\n[00:00:30] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Doing well, Eric. Yep. Spring is in the air here in the the East Coast as well.\r \r Trying to start planning some travel and some conferences and looking forward to,\r \r getting back and and seeing some folks that I will not have seen in a year here coming up, in the next couple of months. Summer feels like it's not that far away.\r \r\n\n[00:00:48] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That's right. And this is a little bit closer to my, sports exploits. We're getting closer to hockey playoff season, and the nerves are starting to happen for my beloved bread wings to try and squeeze in a wild card slot. And it won't be easy, but we're we're getting the vibes. We're getting the positive vibes here. We'll find out.\r \r\n\n[00:01:06] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 6,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes.\r \r\n\n[00:01:07] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 7,
        "trans_speaker": "Eric Nantz",
        "trans_text": "But as always, I just want you all about to talk about hockey stuff, but we're gonna talk about our weekly here and the awesome resources that we mentioned in this week's current issue.\r \r And, let's check the notes here. Oh, oh, oh, yep. That was me curating this week.\r \r In between random\r \r visits to, like, school libraries and swim meets. I somehow curated this issue, but I think we got a good one to talk about here.\r \r And I never am able to do this alone whenever it's my turn because I have tremendous help, as always, from our fellow r Wiki team members and contributors\r \r with your, I believe, 8 or so poll requests to this issue, which is very welcome. Awesome addition, indeed.\r \r\n\nAnd I thank all of you that have been contributing to rweekly. So without further ado,\r \r we're gonna dive right into it, Mike, and I think you're gonna lead us off with\r \r a really fun exploration\r \r that has a lot of twists and turns that eventually involve patching the r language itself.\r \r\n\n[00:02:04] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. This is a blog post from Jonathan Carroll titled, I patched r to solve an exorcism\r \r problem.\r \r I didn't know where exorcism was going. I wasn't sure if we were getting into to religion or what sort of road we were going down here, but there is a website called exorcism.org\r \r that has,\r \r a lot of different challenges across many different programming languages that allow you to to try out a different programming language each\r \r languages each month\r \r and try to solve some sort of non trivial\r \r problems, you know, not just printing hello world in that language, but actually actually trying to solve a fun little toy,\r \r exercise. Sort of reminds me of Advent of Code,\r \r you know, on the on this particular\r \r website and, you know, Jonathan shows how he has been doing these exercises across a multitude of languages including\r \r Haskell, Go, Julia, Python, JavaScript,\r \r Scholar, Rust,\r \r Fortran, Lua.\r \r\n\nPretty pretty incredible\r \r work that he's done. Here he's gotten quite a few badges on exorcism\r \r based upon some of these challenges.\r \r And one of the the recent challenges\r \r was to write an algorithm\r \r that converts,\r \r integers into roman numerals.\r \r And probably in a lot of languages, this is something that's tricky.\r \r But for those who know or for those who may not know,\r \r there is a function in base r called as.roman\r \r in the standard base r library\r \r and it allows you to just provide that function with an integer and it will return\r \r what I thought was a string. I guess it's of class Roman, which is quite interesting.\r \r\n\nBut it'll provide you with the the Roman numeral equivalent.\r \r And that's pretty incredible. So I think Jonathan thought, you know, at this point, he's done. It was almost like, you know, a little cheat that he has in the R language to be able to very easily\r \r solve this problem and, it's a pretty short algorithm when it's just a single function\r \r that's already been implemented.\r \r And one of the wild things about,\r \r R's ability to work with roman numerals as well is you could assign, you know, the output of this as Roman\r \r function\r \r to a variable,\r \r and then you could\r \r do that again with a different integer that you're converting to a Roman,\r \r a Roman numeral.\r \r\n\nAnd you can do math with those 2 different objects that are both these these roman,\r \r numeral objects. You can add them together. You can multiply them. It's it's pretty it's pretty incredible.\r \r I'm not sure\r \r how useful this is on a on a day to day basis. It's something I've never, I guess, had a a use case for, but I'm sure there's folks out there, you know, that that had a particular use case where it made sense to not only, you know, provide roman numerals to whatever that end output deliverable is,\r \r or maybe to even do some math on multiple roman numeral\r \r objects. So I I guess a pretty cool the more you know type thing with with base r.\r \r\n\nSo, you know, Jonathan\r \r realized,\r \r unfortunately, as he began to run some some tests\r \r to try to convert,\r \r numbers, I believe, 1 through\r \r 3,999\r \r to Roman numerals,\r \r that one of the that one of the tests was failing. And, there was a mismatch between what he he was expecting and what the as Roman function\r \r returned\r \r because,\r \r the last a 100 integers from 3,899\r \r to 3,999\r \r returned NA values.\r \r And this was a little confusing. I guess, in a lot of other languages,\r \r they\r \r sort of state that,\r \r and this might be in R as well, I believe, that,\r \r any of their Roman numeral conversion algorithms really go up to 3,999.\r \r\n\nThat's sort of the the final integer\r \r value, that we have Roman numerals for.\r \r So Jonathan was sort of\r \r expecting,\r \r the the limit here to be 3,999,\r \r not 3,899.\r \r So we had to dive into the source code and and this is sort of where it goes from, you know, oh, I have this, problem on exorcism.org\r \r that are already has a nice little base function for As Roman. I got a one liner.\r \r I'm gonna get this this new badge\r \r and it it quickly\r \r cascades into, you know, in the spirit of yak shaving,\r \r quickly cascades into oh my goodness.\r \r Now I have to dive into this and it looks like I'm gonna need to submit a patch to r itself and becomes something much bigger, than maybe he initially set out for. So, Eric, do you wanna take it away with, the the patching to r?\r \r\n\n\n\n[00:06:52] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Absolutely. And, boy, do I feel seen with the yak shaving analogy here because I literally have been going through this on an internal package at the day job where I just wanted to beef up the test suite a little bit. And, boy, did I know now I'm solely in the internals of Unix batch processes\r \r along the way.\r \r So Network tests.\r \r Yeah. Unit tests. Exactly. So, luckily, I knew how to patch it. I knew who it was responsible for it, but this is a little different here because\r \r John has indeed discovered\r \r that within the source code of r itself that's responsible for these roman numeral conversions,\r \r he did indeed see\r \r traces\r \r of the number\r \r not being 3,000999\r \r 9, but\r \r 3,899\r \r littered throughout the code base.\r \r\n\nNow you may ask, how on earth do you actually search the source code for R itself? Well, we are very thankful as a community\r \r that there is,\r \r on GitHub, a mirror\r \r of the\r \r r source code.\r \r I believe it's actually under Winston Chang's account still. It's called r dash source.\r \r You've been here before, Mike. I sure have. This is gonna be the bookmarks for a very,\r \r very long time. And in fact, it'll often turn up on Google\r \r if you're searching for a package of source code on a GitHub repository.\r \r Oftentimes, if the package is already on CRAN, this will be in, like, the top five results, this CRAN mirror of that said package.\r \r But, regardless, we're talking about the r source here. So\r \r taking advantage of that platform, John did indeed, like I said, search for\r \r where this number is actually showing up. And, yeah, it is showing up quite a bit,\r \r albeit some of these are what you might call false positives. They're not really having to do with that function itself. But in the typical GREP call, you did indeed find a lot of files in the source\r \r r library, both in in r files, c files,\r \r and documentation\r \r files.\r \r\n\nSo he did have to do a little more intelligent filtering to figure out just where\r \r all this is really taking place, and sure enough, he does eventually find it. And within format call and the like,\r \r but then\r \r he discovers there is\r \r a utility\r \r type function\r \r with the name roman.r.\r \r So\r \r very straightforward. And there sure enough, there is a comparison\r \r of the range\r \r being from 0 or greater than 3,900.\r \r There it is. He has found it.\r \r And sure enough, now what's the next step? Right?\r \r Well,\r \r r itself, we mentioned there is a mirror of the source code on GitHub. That's not actually where the upstream code lives for development.\r \r It's actually using the subversion\r \r repository.\r \r\n\nShout out to all those who use subversion in the past. It's been a while for me, but that is where if you are wanting to learn about contributing to the art project itself, you're gonna have to pull down that SVN mirror to your local machine\r \r and then run a patch through SVN.\r \r The and there's an SVN diff, patch there, I believe.\r \r The command I'm rusty with my subversion\r \r coding here. But, when John reached out to the maintainers,\r \r on the mailing list, for r, they did recommend, hey. You know what? It looks like you're on to something. Please submit a patch and file a Bugzilla report.\r \r Just like we talk about for contrary to open source in general,\r \r finding the best way to reach a project and making sure that issue is tracked\r \r and then there's actionable feedback on that, that's the way to go. Right? So John is following\r \r the protocols that have been established by the our project team\r \r to submit this report.\r \r\n\nAnd then now comes a part well, he submitted it. Now you wait. Is it gonna get merged in?\r \r Sure enough. It does get merged in. This is exciting stuff here. Right? John has literally patched\r \r the R language itself for this issue.\r \r Now\r \r as you think about, well, will this really work?\r \r What's a great way to test if your patch is gonna work? Well, guess what? Comes containers again.\r \r John discovered, you know, what I've been using for years now and, you know, that our community has been using for years\r \r is being able to bootstrap\r \r particular R versions with Docker and particular the Rocker project\r \r to be able to check if this patch is indeed going to work\r \r on the upstream version of R that's coming\r \r from the bleeding edge of the subversion repository.\r \r\n\nHe was able to pull that down into a container\r \r and then verify that his patch actually indeed works.\r \r So what's next? Well, obviously, when the next version of point release of r is released,\r \r this patch will be included in it. When that happens, it'll probably be later this year.\r \r But this process this blog post illustrates\r \r such a unique story here in terms of the nature of open source\r \r and the fact that\r \r one little learning exercise\r \r turned into\r \r patching the language itself. But John concludes the post with some really great\r \r advice if you find yourself in a similar situation in the future, whether it's in our package or another language entirely.\r \r\n\nFirst, don't always assume that the language itself is broken. Of course, you want to check that you haven't misspecified some. So read the documentation, run some additional tests. That's always helpful.\r \r And then when you do think you've pinpointed something, guess what? Nature of open source, go into the source code itself. And, yes, we have learned that, yes, even with the R source code, the base R source code, there are ways to grep that both on the GitHub repo\r \r and also, through Linux\r \r utilities like grep and the like. So having a good knowledge of that is extremely helpful for some of these niche bug bugs like this.\r \r And then\r \r don't wait to communicate.\r \r\n\nAgain, John reached out to the mailing list, put out what he was finding in his explorations,\r \r got a response from the maintainer,\r \r able to get direction on how to proceed next\r \r without, you know, going too far without that buy in. And that can happen sometimes. Some people can submit patches\r \r without checking with a maintainer first, and then there might be a little disagreement\r \r or maybe other work that wasn't merged in earlier.\r \r Always communicate early. Nothing bad can happen. My opinion from communicating early on this.\r \r And then, yeah, if you find this issue, of course, if you have the capacity,\r \r it's excellent. If you can ease the burden of the maintainers to fix the patch yourself,\r \r sometimes you might need a little help. And, again, don't hesitate to ask. Maybe a code review,\r \r maybe another test case that you like someone to assist them with.\r \r\n\nSo I think this post is a terrific story of how to go about this process.\r \r And, yeah, don't be afraid of\r \r communicating with the R team on these issues because\r \r guess what? Like anything open source, it's not like they're gonna be able to catch everything themselves. And sure enough, this this hard coded limit\r \r went through r for years years years for roman numeral conversion without somebody really discovering it. So\r \r better late than never. Right? But with open source, you can, you know, do your part as a user and as a contributor\r \r to make that fixed and benefit everyone else in the process. So,\r \r again, if nothing else, also count John's blog post because there is some gratuitous,\r \r very fun Simpsons\r \r imagery too that always warms my, retro viewing hearts.\r \r\n\n\n\n[00:14:47] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. No. I I really appreciated sort of those last points that Jonathan made to to talk about, you know, how he was able to succeed and and maybe those those 4 different things that he recommends. You may consider if you find yourself in the same\r \r situation and it's a pretty empowering thing, right, to be able to because we live in open source world to be able to, you know, contribute and submit a patch to the the our,\r \r language itself that you know, you know, thousands, millions of people are going to to use and be affected by. That's that's pretty incredible. And I think Jonathan's put together a pretty nice road map here to help you do that if you find yourself in a similar situation. I think you you may need to to turn back time to, you know, about 2,005\r \r to use SVN in a mailing list to do so. But,\r \r we we gotta use the tools tools that we have, and,\r \r that that's just a that's just teasing.\r \r\n\n\n\n[00:15:42] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I I would say sometimes it can be intimidating to figure out, okay, just how deep does this rabbit hole go. But sometimes with a little perseverance, it does indeed pay off. This was really,\r \r really interesting\r \r interesting exercise. And and you know what? I'm gonna bookmark that exorcism site. That that is some really top notch ways to hone your programming craft. So nice find there as well. I agree.\r \r\n\n[00:16:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Eric, you know what else is interesting? The results of the 2023\r \r data dot table survey.\r \r\n\n[00:16:26] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 26,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Oh, yes. And this is a good callback to just a few weeks ago. We were mentioning how the data dot table project was indeed, you know, revamping some of its governance and making\r \r easier and more transparent for ongoing road map ideas and how users can contribute. So, of course, what's the best way to hear how users are receiving your package and wanting either suggestions for improvement or what? And that is to release a survey earlier in the year. And this blog post is coming from the data. Table blog and, in particular, the author, Alja Sluga.\r \r And he starts off with,\r \r first of all, thanking everybody that has filled out this survey, and they got almost 400 responses, which is really nice for a survey like this. And we'll walk through a couple of the key findings here and where it might relate to the data dot table\r \r project in the future.\r \r\n\nThere is the post leading off a little bit of demographic style information\r \r showing that, you know, the majority\r \r of users did have an a very much an experience set\r \r using r for 7 plus years\r \r and data dot table, you know, quite a bit in that time frame as well.\r \r And then, you know, many are using it every day that responded to the survey, so there might be a little bit of selection bias here going on. But, hey, it's always good to quantify that information.\r \r And then he gets into some of the, you know, the the tangible feedback itself.\r \r And there were very specific questions,\r \r but there was very a very obvious\r \r kind of trend that came in terms of what users appreciate\r \r the most about data dot table, and it's something that actually brought me\r \r to some use of data dot table in my early days of our programming.\r \r\n\nThat is performance.\r \r It is very memory efficient.\r \r If you've been down the road of having that massive CSV or other text file\r \r and having the base r, read dot CSV,\r \r crash your r session because of memory limits, well, data dot table has always been very efficient in this space. And when people need speed, they turn to data dot table more often than not.\r \r And then another positive feature, which ironically has another side to the coin to bear on your perspective,\r \r is the syntax of data dot table itself.\r \r I think, Mike, you and I agree that it is very unique\r \r in the syntax as compared to other frameworks in the R language.\r \r\n\nBut when you invest in that DSL, if you will, you can accomplish a lot in a pretty concise way.\r \r As for me,\r \r I'm just not a regular Data. Table user. So I do identify with some of the feedback that we're seeing in this post of those in the community having to look it up\r \r most of the time to figure out how to do certain operations.\r \r Again, there is some great documentation out there. It's just for me, not muscle memory yet of how to implement the syntax. So, again, it's good to see kind of tangible data\r \r showing these different trends across a different spectrum\r \r of user bases here.\r \r\n\nAnd, overall, it looks like people are pretty satisfied with the with the package itself. Again,\r \r not everything is perfect. Again, performance is becoming\r \r one of the most favorable areas.\r \r But then you might see some, you know, some not so great issues as well.\r \r In terms of desired functionality,\r \r there were some feature requests out there. And, Mike, why don't you take us through some of what the users are kinda hoping for in the future in data dot table?\r \r\n\n[00:20:03] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Absolutely. You know, I think one of the the most insightful\r \r charts for me in this blog post is this\r \r importance versus satisfaction,\r \r plot, which is really interesting. And I think just to to highlight and to sort of summarize,\r \r the the feedback from the community, you know, the the sort of data point here or feature of data dot table that had the highest importance\r \r rated with the highest importance and had the highest satisfaction,\r \r was performance.\r \r And then,\r \r you know, lower on the important side, but high in satisfaction was the the minimal dependencies,\r \r which is absolutely a strength of data dot table.\r \r\n\nAnd then higher on the importance, but lower in satisfaction,\r \r so I think these are things that, hope, you know, respondents are hoping that data dot table may improve would be, you know, the docs and the legibility of the syntax\r \r itself. So in terms of that desired functionality that they're talking about,\r \r one would be support for out of memory\r \r processing.\r \r So I think this is something that,\r \r you know, has has come to light, especially with,\r \r I believe\r \r the arrow package. Does that do out of memory processing?\r \r I believe so. Yes. Okay. So that sort of allows you to operate\r \r on disk, operate on the file on disk without bringing it all into memory first. You know, folks are looking for richer import and export\r \r functionality\r \r with parquet\r \r sort of being the the most\r \r commonly\r \r mentioned,\r \r item followed by good old xlsx format.\r \r\n\nAnd then, the last We can't escape the spreadsheets, can we? Oh my goodness.\r \r And then the last,\r \r piece of desired functionality that they have listed here is integration with the pipe\r \r operator.\r \r You know, which also lined up with, you know, how\r \r some of the questions around how,\r \r much folks are using\r \r the pipe, and I imagine\r \r they're talking about mostly the the native pipe here.\r \r Most respondents here or or the majority of respondents are\r \r responding that, the pipe is is very useful to them and they would find some sort of a convenience function for using Data. Table with the pipe,\r \r to be very very helpful.\r \r\n\nAnd then there is this notion of the I don't know how these things get these names, but this is the name that's been around for forever.\r \r But the the alias for the walrus operator, which is just a colon followed by an equal sign.\r \r And I guess the that sort of lines up with data dot table's mascot. Right? It's a walrus?\r \r That's right. Yeah. Let's go synergy there. Yes.\r \r So I I think folks who were looking for maybe a,\r \r you know, a more plain English,\r \r alias for that operator,\r \r with some of the options being either set,\r \r let, or set j.\r \r\n\nAnd set seem to be, you know, the function name that would provide an alias for that Walrus operator\r \r to be the most,\r \r popular\r \r response there.\r \r And then sort of the final chart in the way that, this blog post starts to wrap up is on the topic of actually contributing to Data. Table and to gauge\r \r folks' interest to actually contributing to the project or their contributions\r \r in the past.\r \r I guess not surprisingly,\r \r you know, spreading the word about data dot table and and just reporting issues were sort of the the top two\r \r responses in terms of what folks, would be interested\r \r in and then what maybe they have the capacity\r \r to do,\r \r you know, followed by actually contributing to the code base\r \r itself. So, you\r \r know, some users, I guess, in conclusion, are are are a little worried that the package may be abandoned or stagnating.\r \r\n\nOne thing that I would wanna say that, you know, I've seen on social media before is, like, you know, this is the next iteration of Language Wars. It's now, like, oh, dplyr or Data. Table and,\r \r you know, you have to be in one camp or the other. And if you're in one camp, you have to not like the people in the other and vice versa. And I think that's that's absolutely ridiculous. I hope that that doesn't really exist.\r \r And I would say that, you know, like anything else, it's amazing to have options and use the tool that that fits your use case and fits your comfort\r \r the best. You know, data dot table is fantastic if you wanna use it. If you wanna use dplyr and and Arrow or, you know, DuckDV, you know, you can use that too. So,\r \r I I think as long as the community continues to to rally around the package, and I think\r \r initiatives like this one here to try to get feedback and to understand how it can be improved will go a long way towards the longevity\r \r of data. Table\r \r as well.\r \r\n\nAnd I know that they have done a lot of work on this package around documentation\r \r and community,\r \r just in the last maybe 6 to 12 months. So excited to see these results, and,\r \r I I think the community is strong.\r \r\n\n[00:24:58] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 58,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And lots of positive momentum, like you said, this year with some of the steps they're taking. And not that it was very whacking in any way, but this is you know, as as open source projects evolve, you do often have, you know, newer contributors or newer users come on board and looking at what are the available options for, say, data processing, data manipulation.\r \r And it's always great to have choice in this space.\r \r I know sometimes in my industry, there are some people, they get a little, you know, maybe confused about having so many choices\r \r in domains. But you know what? For your specific project, if data. Table fits your needs and, boy, I remember\r \r many days of importing some huge textual,\r \r you know, biomarker data files and data. Table was as fast as could be in that space. And, yeah, we have lots of great code bases\r \r that leverage that package heavily. So\r \r I'm always of the mindset if it ain't broke, don't fix it. And then,\r \r also, with respect to data dot table maintainership,\r \r yeah, it is alive and well. They are really spreading the message out for various channels, and this survey should serve as a reassurance\r \r to everybody that they are really thinking of the users in mind, both those that have been using data dot table for years upon years and those that are coming new to the project because they are both equally important\r \r in the lifespan of this space.\r \r\n\nAnd, certainly, I'm really appreciative of the transparency,\r \r and I'd see nothing but great things happening for the project going forward.\r \r And the fact that they're sharing this more actively,\r \r I think, is a is a huge step,\r \r to\r \r bringing this, not that it wasn't a first class citizen before, but really putting this into the mind share of most of the R community. I think data dot table,\r \r the project itself is doing great things to make that happen.\r \r\n\n[00:26:47] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Mike Thomas",
        "trans_text": "No. I I agree as well. Lots of positive momentum, lots to look forward to, and in no way is this project doomed.\r \r\n\n[00:27:05] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 5,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Well, luckily, Mike, we're not doomed in terms of the rest of this episode because we do have some fun things to talk about here, especially on the visualization side of it. But, of course, you listening, maybe you're wondering why the heck are we talking about doom and gloom here? Well, we're not referencing that kind of doom. We're kind of referencing\r \r some that did,\r \r be a part of my retro gaming heart mech in many, many years ago\r \r in my college days, getting together with some friends and playing the heck out of the doom,\r \r game by id Software that was often a trendsetter for all these first person\r \r perspective games on here. Now just where does this have to do with r itself? Well, our last highlight\r \r has kind of done this very interesting geometric type exercise for just how\r \r do maps\r \r could be created in the context of R itself in the aspect of 3 d style visualizations.\r \r\n\nNow Mike and I had to do a bit of detective work on this, but we're pretty certain that this blog post has been authored by,\r \r Ivan\r \r Krylov.\r \r But we admit we could not find any trace of that on the blog post itself. We did some spoofing on their GitHub repo. So, hopefully, we're correct. One way or another, we're gonna go with that for now unless we hear otherwise.\r \r But Ivan leads off this post about talking about when would you want\r \r to visualize\r \r in a 3 d type landscape a function surface. So you may be thinking,\r \r if you had experience in this space, kinda like a contour map where you see, like, the elevation in a in a map setting. In fact, it reminded me of a lot of the packages that have been developed such as ray shader and ray render and the like have been doing a lot of those 3 d visualizations\r \r in R itself.\r \r\n\nAnd guess what? Base R itself comes with this built in.\r \r Especially if you're using the extension packages like Lattice. There is a way to do\r \r contour plots in that.\r \r The RGL package in the R community helps you do 3 d plots in R.\r \r But, you know, we could he he thought we could just do that, but let's let's make this fun. Let's make make a do map out of it. Now\r \r I've only seen the end product of a do map, but just what does that really entail?\r \r Well, Mike, we're going to geometry school for a little bit on this one, so buckle up here.\r \r But,\r \r apparently, in the first and second iterations of doom,\r \r there was no concept\r \r of a floor that could go up a hill or down a hill.\r \r\n\nSo, apparently, you would have, like, the sky for height, you know, but then you'd have your tiles\r \r at a certain level, maybe done at another level in a stepwise fashion.\r \r And, of course, R itself in terms of how you would visualize this is not gonna be coming with everything out of the box. So there are some open source utilities,\r \r called Zdoom\r \r and Zanodrome,\r \r which are apparently gonna help with the overall visualization of this before we feed into it in the r itself. But here comes the\r \r geometry,\r \r school at play here\r \r that a do map\r \r is gonna have a series of\r \r points or vertices,\r \r lines,\r \r sides, and sectors.\r \r\n\nAnd, yes, there are obviously point coordinates for the vertices of an x and y, and you got lines connecting them.\r \r And then you've got\r \r the sides that are available to the user when they look left or right.\r \r And then, also, there will be textures, but that's not really the point of this post.\r \r And then\r \r where the actual how the height information is presented, and those are called sectors.\r \r So Ivan's original idea\r \r was to start with the contour lines package or contour lines function\r \r and then tried to kind of makeshift some, you know, artificial slope involved to get to the heights of this. But, apparently, it didn't quite cut it where the editor was trying to fix\r \r some things that were missed in the translation.\r \r\n\nSo he kinda had to go back to the drawing board\r \r and start to go with something more universal with respect to doom maps, and that is literally called the universal\r \r doom map format,\r \r also known as text map,\r \r where then it can store the additional information\r \r of the heights of these points and not just\r \r the x and y coordinates on kinda like the lower plane, if you will.\r \r And then it gets to be really math heavy or geometry heavier because, apparently,\r \r you need to be able to split\r \r these\r \r maps of the height into triangular\r \r shapes.\r \r\n\nWe're literally and the blog post has this, a great illustration\r \r of splitting\r \r a rectangle into 2\r \r triangles of equal area\r \r with the vertices, you know, interpolation along the way\r \r and then become some clever use\r \r within base r of the array function,\r \r capturing data frames of these x, y, and now z coordinates that capture the height of the contours\r \r of these planes.\r \r And then a lot of more manipulation\r \r to start to figure out how do we connect\r \r all this together.\r \r Lots of custom data frames being created here.\r \r Lots of other temp files being created here for that mapping utility.\r \r And then once he's able to feed in\r \r these variables\r \r into the mapping software, yes, at the end, you have yourself\r \r a doom\r \r literal doom screenshot of he fed it into\r \r this open source utility that I mentioned earlier.\r \r\n\nI think it was\r \r more more manual processing of another utility called SLADE.\r \r And sure enough, there is a a reproducible rscrubber. If you have that same\r \r map emulation\r \r software,\r \r you do get a shot. The player looking at a contoured hill\r \r with\r \r looks like from the game itself, like, I wouldn't be able to tell the difference. Like, you're some overworld type area. So\r \r I admit I have never thought to try anything like this, but guess what? If you wanna try this out with the right software installed on your system, the our script is downloadable.\r \r You can check it out yourself and give it a shot. And, yeah, maybe it's a great way to boost your geometry and mapping skill set at the same time and having some fun along the way. So, hopefully, Ivan, we're getting your name right here, but,\r \r thanks for opening our eyes to\r \r use of r that I never thought I'd see happen in my lifetime. But guess what? There's nothing that r can't do. Right, Mike? Absolutely. And it's incredible how much of\r \r\n\n[00:33:50] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Mike Thomas",
        "trans_text": "what's generated here is from base r's\r \r plotting functions\r \r as well, and just, you know, sort of vectors and and things like that. If you download this r script,\r \r that's linked at the end of this blog post,\r \r it's it's fairly\r \r concise,\r \r I think, you know, what's necessary. He has these 3 different functions,\r \r triangulate\r \r as text map, and then the final one, image to doom, that spits out a file that I believe you can pass to this software\r \r slate or something like that that'll help generate,\r \r this exact image that we're seeing on screen.\r \r Fairly concise. It's a really cool,\r \r you know, I just\r \r I'm really enjoying reading the code here.\r \r\n\nI learn something new every day. Today, I learned that there's a function in r called is dot unsorted\r \r to test if,\r \r the vector that you pass to it is sorted in ascending order or not. I'm not sure if I have any use cases for it, but I'm\r \r certain that probably sometime in the future,\r \r I will.\r \r The code comments are are incredible. He has an a beautiful actual diagram\r \r in the code comments here,\r \r plotting this coordinate map.\r \r Just just literally\r \r using\r \r comments and characters on your keyboard. That's absolutely fantastic, and it lines up with,\r \r the diagram that's in the blog post under the triangular\r \r sectors,\r \r section.\r \r\n\nSo,\r \r you know, really interesting use case. I'd be interested to see sort of how maybe you could take this to the next level with RayShader, and then, you know, maybe make doom look like it's in the, you know, 2023\r \r sort of graphic state. You know, Eric, to be honest, I don't wanna date you, but I'm not familiar with doom. Halo was probably my my first,\r \r you know,\r \r the foray into first person shooters,\r \r if you will, on the old Xbox 1. And,\r \r even all the way back then, I think the the graphics were a little bit of a step up than, than than what we have in Doom. But, you know, I'm sure I I'm sure I would have enjoyed Doom if if I had been there.\r \r\n\n[00:35:53] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I think I dare say I would have. And, that if if if that was dating me too much, and I better not mention Wolfenstein because that even predated Doom and that,\r \r Id's first entry into the FPS space that kinda changed the world. But, yeah, if you're you talk about going step back in retro graphics. Yeah. That one's a bit hard on the eyes. But, but, yeah, we've actually seen\r \r very interesting use cases\r \r of games like this\r \r where maybe it's not so much the actual end product that you can get, but they are extendable via mods and things like that. And that's where\r \r having code like I believe the doom code's in the public domain now. So, like, you could literally browse this yourself,\r \r and, hence, you see the modding community go to town on things like this. But but, yeah, I I definitely got the same same vibes as you did, Mike, about how you could combine this with some of the awesome work of, like, Ray Shader and the like to really beef up a a fun demonstration\r \r that's built entirely with R itself.\r \r\n\nBut, yeah, I did take a look at the script. Like you said, that's available for download. Very well commented.\r \r And, yeah, easily reproducible with the right software. So I think this is,\r \r again, if you thought R wasn't\r \r able to do certain things in terms of visualization\r \r that combines with retro gaming, well, this post has definitely solved that for you.\r \r Yes. I'll have to check out Ivan's previous post because he's definitely got a a great selection of additional topics with respect\r \r to, you know, integrations with c,\r \r looks like,\r \r others on on contributing to r itself. Yeah. Lots of great nuggets here, and, I'll definitely keep this bookmark.\r \r\n\n\n\n[00:37:33] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Mike Thomas",
        "trans_text": "You know what? You know what I always say? R is the 2nd best language for doing just about anything. Conan said it better myself.\r \r\n\n[00:37:40] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And maybe And what may be the 2nd best resource for everything in r might be rweekly itself because we have a mix of everything as well from\r \r highlights of what we talked about today, our awesome interesting,\r \r use cases via blog posts, tutorials,\r \r new packages and updated packages, and the like. So we'll take a couple minutes to talk about our additional finds here.\r \r And for me, this isn't so much our specific, but we alluded to it earlier, Mike, that it is conference season. It's starting to get underway with various conferences out there.\r \r And maybe you,\r \r are like me, especially in my earlier days where I would go to these meetups for the first time,\r \r I'm a bit of a shy dude, I must say. So, you know, what's the best way to kinda feel\r \r comfortable and, you know, ways of connecting with others? Well, my additional find here is from the jumping rivers blog authored by Rhian Davies and Keith Newman\r \r called an introvert's guide to networking at a conference.\r \r\n\nSo this is very nice\r \r very nice way to kinda ease that, maybe, that little fear or apprehension you might have at the beginning of these events\r \r and how you might navigate certain situations,\r \r how to keep contact with people that you do end up networking with, you know, what are some ideas for icebreakers and whatnot,\r \r And not to feel too much pressure if you're being sent on behalf of, say, your organization\r \r that you're a part of, but really is trying to soak in that experience\r \r in an optimal way. So,\r \r yeah, I I definitely resonate with a lot of these points here. And, also, I'll mention a a a heads up that we often hear at the various posit conferences\r \r is the idea when you're in a group setting, having the Pac Man rule, having, like, an open slot so that people can join your group to to join in on the discussion.\r \r\n\nThings like this with practice really do add up and help make you feel\r \r a lot more comfortable. So really great post by the jumping rivers blog, and, yeah, it'll be\r \r hopefully a Pazitconf would be my next, in person event, and I'll be taking this to heart like always.\r \r\n\n[00:39:44] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I like that one a lot. Another one that I found was from El Saman\r \r on the key advantages of using the key ring package.\r \r And the Keyring package allows you to essentially store secrets,\r \r that are retrievable, I think, through environment variables would be the most common way to do that. And,\r \r you know, one of the differences between\r \r using Keyring and and maybe using a dot r environment\r \r file that would be, like, project specific is with Keyring, you can store that particular secret once and for all per computer\r \r that it's on, which which is nice. You know, you don't necessarily have to do that on a project\r \r to project basis.\r \r\n\nYou also do not have to worry about somebody accidentally,\r \r forgetting to git ignore that dotrEnviron\r \r file and it making its way up to,\r \r GitHub or GitLab or whatever sort of hosting service that you use for your git repository. So that's a nice feature\r \r as well,\r \r that you may be interested in in leveraging as opposed to sort of doing the, the old hard coded way with, you know, sys dot,\r \r get env and,\r \r setting environment variables that way. So it might be interesting for some folks who are are looking to,\r \r brush up on their best practices around security and environment variables and passwords and secrets and all that stuff.\r \r\n\n[00:41:04] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. This is terrific when you're using R and, like, a traditional\r \r client kind of setting where you may have a a team using RStudio IDE\r \r or whatnot on your local machine. The key ring package is gonna be instrumental to helping, like you said, keep some of those credentials secure and not nag them all the time for it and minimize the potential for leakage.\r \r Unfortunately, I don't think this would be a way this would be compatible with, like, a Shiny app that's deployed on a server somewhere, but I will have to look into this a bit more because I know the Keyring itself is used every single day. I go on to my Linux\r \r system here at home. I often have to prompt once for my administrative password to do a certain task, but that's being stored in the Keyring credential store and not anywhere else. So\r \r lots of lots of ways that I'm sure this could be used, that I'm probably not even aware of. So great find as always.\r \r\n\n\n\n[00:41:58] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 58,
        "trans_speaker": "Mike Thomas",
        "trans_text": "And then we have one more that I think we would be remiss\r \r not to mention, at least to give a quick shout out to Bruno Rodriguez. We are at part 10 of reproducible data science with Nix, and the discussion here is on contributing\r \r to Nix packages. So if you have been following along with Bruno's saga,\r \r and crusade on getting\r \r folks to check out next next for for doing reproducible\r \r data science and having that that fully sort of reproducible\r \r environment,\r \r that you can come back to, you know, years from now and run your code, and it'll still output that same thing.\r \r Check out part 10. It's the latest in the series, and it will not disappoint.\r \r\n\n\n\n[00:42:38] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. It goes so nice. So we talked about earlier with the idea of patching such an influential project as the R language itself. But guess what? Yeah. NIX, the momentum keeps coming.\r \r And, yeah, I was even doing a little poking unrelated\r \r to NIX itself when I'm then continuing my efforts with this shiny\r \r application as a web assembly bundle for my R Consortium work. And I'm poking around the WebR repo,\r \r that George Stagapos has been working on. And I see a commit\r \r saying they've made it or I should say it was Shiny Live, Shiny Live for R. I see a commit that they are making things compatible with Nick's packaging.\r \r So\r \r plot thickens. It seems like more attraction's happening\r \r with respect to the the big players in the art community itself with Nick. So, yep, Bruno, I'm really excited to to\r \r not sure if your series is ever gonna end, but I'll be bookmarking in one way or another.\r \r\n\n\n\n[00:43:34] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I hope it doesn't. That's awesome.\r \r\n\n[00:43:36] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. There's much more than just that in this week's issue. Again, tremendous fun\r \r curating this for all of you. And, thanks to John Carroll again for his\r \r awesome utility. We call it the Curinator to help boost drive some of these feeds for us in a more systematic way with GitHub Action. So thanks, John, for making that for our curator team here.\r \r But, of course, our weekly does not move, does not live without all of you in the community.\r \r For your contributions,\r \r we invite you. If you see a great blog post, a great new package,\r \r or a great new tutorial,\r \r and you want the our weekly audience to see it, well, we're a poll request away talking about contributing. Right? You won't have to dive into any internals of R itself to do this. You just have to go to rw.org.\r \r\n\nThere's a little handy link to the draft right at the upper right corner. You can just submit a poll request with your markdown link all formatted for you and all set to go. That's a great way to contribute to the project.\r \r And as always, we are looking for curators as well. If you wanna sign up for that or get to know the process around that, we\r \r also have links directly linked at the top of each issue. Probably you can get involved with our weekly.\r \r And then, also, we love hearing from you and the community. We got the handy contact page and the episode show notes\r \r of this episode\r \r as well as\r \r with a modern podcast app like Pawverse or Fountain. You can send us a little boost along the way directly in your app to give us a little fun along the way, with with all of you. And then, also, we are sporadically on these social medias.\r \r\n\nI'm more often on Mastodon these days. We're vet our podcast at podcast index.social.\r \r Sporadically on the weapon x thing, we've got the r cast. And on LinkedIn from time to time, cross posting the episodes and chiming in from time to time with some fun art projects.\r \r\n\n[00:45:30] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Mike, where can the listeners get a hold of you? Sure. You can find me on LinkedIn if you search, Catchbrook Analytics, k e t c h b r o o k. You can find out what I'm up to. Or occasionally on mastodon as well at mike_thomas\r \r atphostodon.org.\r \r And, I guess a little episode cleanup,\r \r quickly,\r \r around 2 things that I had mentioned. I I think I did shout out at some point in the podcast, don't write tests. Please write unit tests. That was, course, satire\r \r and a joke.\r \r And secondly, I think I may have said that R is the 2nd best language for for doing just about anything. Obviously, it's the first best language for doing just about anything. So little clean up there.\r \r\n\n[00:46:11] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "trans_timestamp": 11,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I think it's implied, but, you know, it never hurts. Right? And, yeah, I expect the transparency on this show. Yeah. So we fully appreciate that, Mike, as always.\r \r And, yeah, I'm about to probably go through some more react shaving, if you will, of an internal project. But just as I think I'm at the finish line, I'm probably gonna find something else to\r \r to buy my time with. But, yep. Thank you as always for all of you around the world for listening, and we will be back with another edition of ROWG highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_10_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "chap_timestamp": 3,
        "chap_text": "Roman numerals to patching R"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "chap_timestamp": 19,
        "chap_text": "data.table survey results"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "chap_timestamp": 4,
        "chap_text": "Doom plots"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "chap_timestamp": 57,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_10_highlights",
        "chap_timestamp": 37,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_09_highlights",
        "ep_date": "2024-02-28",
        "ep_duration": 8,
        "ep_description_short": "Flipping a Hello World function on its head, assorted improvements landing in ggplot2 3.5.0, and why authoring beautiful code is so worth it. Episode Links This week's curator: Jon Carroll - @carroll_jono (https://twitter.com/carroll_jono) (Twitter) & @[email protected] (https://fosstodon.org/@jonocarroll) (Mastodon) HelloWorld(“print”)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_09_highlights",
        "description_long": "\r \r\n\nFlipping a Hello World function on its head, assorted improvements landing in ggplot2 3.5.0, and why authoring beautiful code is so worth it.\n\nEpisode Links\n\nThis week's curator: Jon Carroll - @carroll_jono (Twitter) & @[email protected] (Mastodon)\nHelloWorld(“print”)\nggplot2 3.5.0\nBeautiful Code, Because We’re Worth It!\nEntire issue available at rweekly.org/2024-W09\n\nSupplement Resources\n\nlazygit - Simple terminal UI for git commands https://github.com/jesseduffield/lazygit\nAdvanced R - Expressions https://adv-r.hadley.nz/expressions.html\nJenny Bryan's talk on code smells and feels https://github.com/jennybc/code-smells-and-feels\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nEverybody Wants to Rule the Wisps - Sonic Colors - The Good Ice - https://ocremix.org/remix/OCR04368\nYou Are Not Confined - Final Fantasy IX - Sonicade - https://ocremix.org/remix/OCR01064"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://fosstodon.org/@jonocarroll"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://yjunechoe.github.io/posts/2024-02-20-helloworld-print/"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://www.tidyverse.org/blog/2024/02/ggplot2-3-5-0/"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://ropensci.org/blog/2024/02/22/beautiful-code/"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://rweekly.org/2024-W09.html"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://github.com/jesseduffield/lazygit"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://adv-r.hadley.nz/expressions.html"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://github.com/jennybc/code-smells-and-feels"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://ocremix.org/remix/OCR04368"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "links": "https://ocremix.org/remix/OCR01064"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with episode 154 of the R Weekly Highlights podcast.\r \r This is the weekly podcast where we talk about the latest and awesome resources that you can find every single week on the latest our weekly issue. My name is Eric Nantz, and I'm so delighted you joined us today from wherever you are around the world.\r \r\n\n[00:00:21] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 21,
        "trans_speaker": "Mike Thomas",
        "trans_text": "And I never do this alone. He is my line mate and tag team partner here, Mike Thomas. Mike, how are you doing today? Good. I like that hockey reference, Eric. I have been living in the terminal for the last couple days, so I'm going to crawl out of the terminal here for a few minutes and,\r \r excited to get a little higher level with the highlights today.\r \r\n\n[00:00:41] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I've been in the terminal myself.\r \r Fun little,\r \r I don't wanna call it a hack because it's a legit tool.\r \r But,\r \r I was getting jealous of some of these really fancy Git GUI interfaces I often use locally.\r \r Shout out to the GitKraken project. That's one of these.\r \r Can't really install that on my, my company's HPC infrastructure.\r \r So I may put this in the show notes just for kicks. Found a terminal based Git tool called lazy Git.\r \r It's not lazy. It's really powerful.\r \r And it's written in Go, actually. But that's my end cursor's\r \r Git interface, which has been super smooth for me. So if you if any of you out there are a need for a great kinda terminal\r \r git experience\r \r that gives you that great overview of, like, branches,\r \r your staging area, commit history,\r \r It's all right there. So, shout out to Lazy Git. Fun project.\r \r\n\n\n\n[00:01:39] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 39,
        "trans_speaker": "Mike Thomas",
        "trans_text": "No. That's a great shout out. I I love the the Git GUI clients or or sort of anything that tries to help make it a little bit more manageable\r \r than it is. Understand that there is need, right, to go straight to the the git bash shell,\r \r once in a while for doing in particular things, but I I think sort of in general for 99% of my use cases,\r \r it helps to use something that's a little more gooey to help you avoid making Git mistakes, which can be hard to undo.\r \r\n\n[00:02:08] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 8,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. No hope. Don't get me started. I had to do undo a lot of nonsense the past couple weeks in one of my repos, but I digress. Only we can undo our recordings of this podcast. We gotta get our act together, shall we? You might you might dare say it's showtime, folks. But, yes,\r \r this, issue this week was curated by John Carroll who is, another longtime\r \r contributor and curator for our weekly. And as always, he had tremendous help from our fellow Rwicky team members and contributors like all of you around the world.\r \r Now we're gonna lead off here with a post that's gonna flip a lot of your assumptions perhaps on it on their head, so to speak. Because our first post here comes from June Cho\r \r who is a PhD candidate in linguistics at the University of Pennsylvania\r \r and has often been at the cutting edge of going not just a little bit into r, but really deep\r \r into the fundamentals of r itself. And, boy, this one is if you wanna go deep in how functions are composed, this is for you.\r \r\n\nSo he leads off with a typical premise that when you're learning any language,\r \r typically, you're gonna do the infamous hello world type example just to make sure things are quote unquote working.\r \r Well, apparently, there's been some,\r \r over the years, albeit I'm not seeing this until this post,\r \r there have been some pretty,\r \r adventurous developers out there for various languages\r \r that might play a little trick on your mind\r \r by not just having a function that prints the 10 stacks hello world as in a typical print call in things like Java or or other languages.\r \r But instead\r \r of having a function literally called hello world,\r \r putting the the string of print in it, and it still somehow prints hello world.\r \r\n\nLike, what is going\r \r on there? Well, apparently,\r \r there's a lot of ways and multiple languages to kind of flip the concept of arguments and functions.\r \r So June explores in this post,\r \r what can we do with the R language in this in this case? Well, in order to get there,\r \r you gotta learn about some of the,\r \r self described quirks in the R syntax that you may not see\r \r until you really dive further into it. Case in point,\r \r anytime we define a function, he has some examples here of, like, summing or\r \r adding numbers together,\r \r It first needs to see that that is represented as a expression or not. And if it does, it needs to determine if that value is a function or not.\r \r\n\nAnd how does it know that it's a function or not? Apparently, there are very intricate orderings here\r \r with respect to evaluating\r \r the scope of this\r \r in terms of these language objects.\r \r In a language object,\r \r if it is a function, it's always gonna be first in line. And he has an example where he literally goes to this expression,\r \r finds the first item of it, and, indeed, it is the function that's being wrapped into that. And, of course, to review,\r \r even the operators you see in r, like the plus, multiplication,\r \r etcetera,\r \r those are all functions under the hood. Right? So they would be first in this stack of the language object.\r \r\n\nOnce you know that,\r \r you can now start to do some crazy stuff with actually flipping the order of this and superimposing\r \r different\r \r different ways of architecting this. And this is where you need to dive into\r \r some concepts that scared the heck out of me in my early days of R, and that is deparsing.\r \r And also a new function, not, I mean, new to me, I should say,\r \r the sys.call\r \r function\r \r which can actually find\r \r where\r \r the which returns the expression\r \r of a function of where that call was taking place. And, again,\r \r we're gonna try to explain this at a high level, but, obviously, look at the post for the detailed examples here. But then he shows\r \r how to actually get these functions from these syscalls\r \r and what is actually returned inside of them, which, again, first align\r \r is the function itself, and then the second would be the arguments\r \r being supplied to it.\r \r\n\nSo once you have that,\r \r you can now start to do a little bit of flipping of that order.\r \r And instead of having the typical print hello, world, you can have the hello, world with the syntax of print, and it's still gonna give you what that output of that function would be in ordinary language.\r \r Now that gets it gets even more bizarre here, bizarre to me anyway, because, again, I haven't dived this much into functions ever.\r \r But you can also\r \r write wrappers around this to do this with any function, not just a manually specified like hello world printing.\r \r He has an example register function that he defines\r \r where it's going to dynamically\r \r grab\r \r the name of that function in this\r \r language object calling stack,\r \r register a new function with that name,\r \r and then\r \r basically in that cut function environment,\r \r now give you that alias\r \r to, again, flip the argument and function on its head.\r \r\n\nAnd then lastly,\r \r in terms of where I see this,\r \r you can go back to the other way\r \r and make it the typical print hello world, which is called unflipping.\r \r Again, some clever use of the substitute function to make that happen. He has an example here called unflippery. He shows how to reverse\r \r this kind of bizarre sequence so you can get back to what you wanted to do with a call statement to get there.\r \r But, yeah, if you ever wanted to know just how far you can take\r \r this\r \r reversing\r \r of function arguments and function calls themselves\r \r to mimic what you often see in the other programming languages\r \r in terms of these thought experiments of just how far you can take it.\r \r\n\nJune's example, again, fully reproducible. You can run all this in your console\r \r and inspect these language objects,\r \r these calling stacks, and just how\r \r these functions built into r, like matching function calls,\r \r finding the system call itself,\r \r and then\r \r clever use of the eval and substitute\r \r functions to kind of change the ordering of things.\r \r This can this can be pretty powerful,\r \r albeit\r \r This probably could be a great fodder for maybe an April fools joke someday for somebody not knowing what to expect out of your package functions.\r \r I don't know. I'm just saying we're still out of April yet, but may y'all keep this in mind for some\r \r good time, pranks in the future with my art friends.\r \r\n\n\n\n[00:09:08] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 8,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I would have to agree, Eric. If you do prank me with that, I I can't say. I'd be be laughing too hard because some of this stuff is fairly convoluted. I think some of this can\r \r can trip up beginners as well, and there's probably some fair critiques of the R language,\r \r you know, for for newcomers who who might get tripped up in some of, you know, that this meta programming and and real quirks about the ability to sort of program on the language itself.\r \r And like you said, I think it is important though for for anyone,\r \r using R, probably experienced developers, maybe more so to to read a blog post like this and understand\r \r these different things. You know, I think it's very important to to understand that your operators are functions in and of themselves.\r \r\n\nIt was a refresher for me. I I think maybe something I knew at one time but happened to forget,\r \r that you could wrap the function name\r \r in your console\r \r in quotations\r \r and run that and it would still return sort of what you would expect. So I ran, you know, some 4 and then I I wrapped\r \r some in quotes, double quotes, and and ran that again and it returned 4 again. And, it was just a little little bit of a shock to the system to to recall that, you know, that is is possible.\r \r You know, I think we see a lot of code sometimes with with folks using, like, the the get function or assign\r \r or manipulating,\r \r the environments that you're using, you know, within sort of beginner r code. And I think\r \r that stuff can be pretty powerful, but it can can trip you up if you are trying to to build, you know, our software that is going to go into production\r \r somewhere or is going to, as you may,\r \r lament with Eric, you know, run through a GitHub action that that may treat environments, you know, a little bit differently than what you have going on on your local machine. Sorry to sorry to dig that that stuff. Bad memories. My bad memories.\r \r\n\nBut, this this also reminds me of the the advanced r book, which I think would be a nice complement to a lot of the content in here. There is a chapter in there called metaprogramming\r \r that runs through, you know, the big pictures there, the important concepts, expressions,\r \r you know, quasi quotation when we think about nonstandard evaluation\r \r and our and our sort of ability to do that, which is is unique to R in a way that I believe is not really possible in in Python.\r \r And, you know, a lot of these different quirks that you have to think about when understanding\r \r and working with, this type of functionality.\r \r\n\nSo really, really interesting blog post, you know, I I think really creative\r \r examples here by June to to just show us how some of these internals work under the hood.\r \r\n\n[00:12:01] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. You'll definitely want your r terminal side by side as you're as you're reading this and kinda try this out interactively.\r \r Boy, I wonder if this could be augmented with Quartle and having that fancy evaluator inside, but I digress. But in any event,\r \r evaluator inside, but I digress. But in any event, one way or another, you'll wanna practice this if you ever wanna see this in action. Because someone like me, I definitely like to be hands on when I'm learning these concepts. So I would I would definitely have my fancy terminal side by side as as reading June's post. But, yeah, he's got a whole boat of of awesome posts in his,\r \r in his blog, especially around other areas of the tidy verse. He's been front and center. So definitely check out his his site, with his back catalog of really awesome explorations\r \r with the language, in more ways than one.\r \r\n\nAnd in our next highlight today, we've got a a great, showcase of the recent advancements\r \r that landed\r \r in the latest version of ggplot 2. Again, one of the more fundamental\r \r pillars of visualization in the art language itself.\r \r Ggplot2 just recently had version 3.5.0\r \r land on CRAN.\r \r And in this highlight, we got a terrific blog post from the tidyverse blog\r \r by one of the, I believe, newer ggpod 2 maintainers\r \r to an brand.\r \r I haven't seen his name before this.\r \r But, yeah, great, great to see this post here, and we'll walk through some of the the key features and and key improvements here. Leading off here is a very important infrastructure improvement to help bring the mechanism behind guides in ggplot2 to a little more consistency\r \r with other systems in ggplot2.\r \r\n\nMainly speaking that up to this version,\r \r the object oriented paradigm that the guide system was following\r \r was still using\r \r s 3.\r \r Well,\r \r now with this rewrite that they've had in ggplot2, 3.5.0,\r \r now guides\r \r are now being the system behind guides is now rebranded to use gg proto,\r \r bringing it in line with the other\r \r parts of ggpod 2 that have been used in heavy customizations,\r \r such as, you know, layers, facets, scales, and whatnot.\r \r Meaning that now the door is open\r \r to treat new extensions on the guide system\r \r just like any other extension that we could do in this space. So I think this is gonna be, hopefully, a launching point for others to make even more customized versions\r \r of the guide system\r \r as they see fit in the ggplot2 landscape. So really nice to see that consistency\r \r being brought in from a back end level.\r \r\n\nAnd speaking of visuals,\r \r with ggplot2,\r \r a lot of the graphs these days are making heavy use\r \r of gradients and patterns in their visualizations.\r \r Well, now\r \r they are first class citizens\r \r in the ggpa 2 ecosystem\r \r with respect to new functions\r \r that are\r \r that can be used\r \r such as within the fill argument using the patterns argument.\r \r And you get\r \r being able to tap into the grid system where it has built in functions in the grid package called linear gradient,\r \r radial gradient, and others,\r \r within the pattern function. So you can now have those really nice looking gradient bar charts,\r \r gradient backgrounds for scatter plots. This looks really sharp and not just gradients too.\r \r\n\nIf you have a pattern you wanna use to really distinguish\r \r that particular facet or that particular bar from the others, you can also leverage patterns using within the scale fill manual directive.\r \r That is really powerful stuff. There's some great\r \r examples in there of a bar chart that has\r \r multiple patterns inside to really, you know, really catch your eye, so to speak.\r \r But looks like what they've done is some really important improvements\r \r to how the alpha\r \r aesthetic was being applied to this situation.\r \r And that was a hurdle they had to overcome to make all this happen. So\r \r lots of great improvements there for even more\r \r custom visualization\r \r for how you display colors\r \r in your ggplot graph. But, of course, there is much more to this.\r \r\n\n\n\n[00:16:46] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 46,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. There is, Eric. You\r \r know, in terms of the scales, you know, ggplot has has changed how plots interact\r \r with these variables created with the I function, which I believe is is from base r, and it creates this this class, if I'm not mistaken, or or a pen prepends\r \r the class as is\r \r to the object's\r \r class.\r \r So,\r \r what this allows you to do from from my interpretation\r \r of the blog post is to be able to prevent, you know, some of the clashes that happen, when you are introducing, you\r \r know, for example, here, like,\r \r an additional scale on your plot. So one of the,\r \r examples that they give\r \r is if you have, you know, sort of 2 calls to to Geonpoint 2 to Geonpoint\r \r layers here on your ggplot, you know, just using the empty cars package and, you know, for one of those layers,\r \r within your aesthetic, you're you're setting the color as a variable within the MT cars,\r \r dataset, the drv drive variable. And then you wanna layer on a second point on top of that that that's going to serve as as, like, a circle,\r \r around\r \r the dots from the first layer, and you want those colors to be, you know, some predefined string of colors like red, blue, green that you had set. You know, previously, this would you would actually run into an error here and it would not be able to find,\r \r those colors for your 2nd layer, but now, if you leverage that I function\r \r around the the variable that holds the string containing your colors,\r \r you'll be able to\r \r add the circles around that or or add this additional layer aesthetic,\r \r without that clashing with the guide, with the legend that was developed in the first layer at all. So\r \r we're on a podcast trying to describe DataViz again, Eric.\r \r\n\nThe best way to best way to check this out is certainly through reading the blog post.\r \r And another sort of improvement here around ignoring scales is the ability\r \r within the, ggplot annotate function\r \r to\r \r add some text in specific locations,\r \r that that will not clash against multiple annotate\r \r layers,\r \r again, leveraging this this as is function, this this capital\r \r I function,\r \r that allows you to have sort of greater control over where you wanna annotate\r \r different, text\r \r overlaid on different parts or layers of your ggplot\r \r chart.\r \r\n\nSo\r \r lots of great code examples here. I I think sort of the best way to dive into this content and these improvements, which I think are are\r \r mostly\r \r subtle,\r \r and may not affect most of your day to day work within ggplot,\r \r but the the best way to do that is definitely to take a look at this this blog post. Take a look at the code snippets and and see,\r \r how these may relate to your Dataviz work on a day to day basis right now with ggplot.\r \r\n\n[00:19:43] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I'm I'm definitely seeing, especially towards the end, these examples, I think, have taken inspiration by the community itself, large with ggplot too. Some of these features that I think have been exposed in additional packages\r \r are now coming into ggplot2\r \r proper. You'll see kinda towards the end of the post some new ways to angle the orientation\r \r of labels on on your various,\r \r point annotations. I have an example with the empty car set and flipping\r \r the annotations sometimes with, like, 45 degrees or or or less.\r \r And then others,\r \r being able\r \r to do some padding around the labels too. Again, that's really neat. I think I've seen that in additional packages.\r \r\n\nAnd, yes, certainly, those that have been creating those fancy violin plots or box plots, in general,\r \r and have been really frustrated of how to deal with outliers efficiently.\r \r Well, guess what? Now geomboxplot\r \r has an option\r \r to remove outliers entirely or just the outlier is a false directive.\r \r Very nice. Very nice.\r \r But you can still just hide them with sending that outlier shape of na. So you've got you got you got multiple ways to handle outliers. But, again, it's great to see if you just wanna wipe them out, you wipe them out. So really nice\r \r improvements to the, ggplot\r \r to, box plot directives. But, again, lots of looks like very nice improvements, and it sounds like they wanted to do this more incrementally. But it just so happened that a bunch of these improvements landed in 3.5.0.\r \r\n\nBut again, we're all to benefit from it.\r \r And I always like to see at the end of these posts on the Tidyverse blog and others from Pawsit,\r \r they always make a point to recognize all of those that have contributed to this release. So you get all the GitHub handles,\r \r of the numerous contributors\r \r to this particular release. But, again, congrats to the team, and look forward to putting this, in the production for my workflows very soon.\r \r\n\n[00:21:43] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. And you could be included in that list of acknowledgments\r \r and famous if you, find, you know, even that for the smallest use case, a grammatical\r \r issue in in a vignette or some documentation\r \r as well\r \r so always feel free that that you can contribute\r \r to open source and there there is no pull request too small in my opinion\r \r\n\n[00:22:17] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Eric Nantz",
        "trans_text": "And rounding out our highlights today, we've got a really fun post here because\r \r Mike and I have dealt with this in various ways in our respective workloads,\r \r making sure that the code that we personally are writing\r \r and the code that we have\r \r with our collaborators\r \r into a more, you know, central project.\r \r Then we're kind of on the same page as the cliche goes.\r \r But there are ways that you can make sure that that is easy to opt into.\r \r And in this case, we have a terrific set of resources and narrative from our last highlight today.\r \r A blog post from the esteemed rOpenSci\r \r blog.\r \r\n\nNot one, but 2 authors here. We got Mao Salmon who again returns back to the highlights yet again. Her her streak continues.\r \r And also coauthor with Ioannina Bellini Salbin,\r \r who is a community manager at rOpenSci\r \r now and very, frequent contributor in the open source community space and data science space. And they have this awesome blog blog post titled Beautiful Code. Because you're worth it. No. Don't don't get worried, folks. We're not we're not getting sponsor from a certain fashion company. But I digress.\r \r Let's dive into what makes beautiful code in the minds of my own. I mean, Yanina here.\r \r\n\nWell, let's start off with\r \r spacing.\r \r And, you know, this is something\r \r I have to I have to have a little confession here as I read through this the first time\r \r is that it's it's one thing when you see in the example here, you've got inconsistent use of spacing between operators,\r \r maybe between arguments or, you know, separated arguments and whatnot.\r \r And, yeah, that that can that can just be a little bad UX, so to speak, as you're reviewing that. But having the unified\r \r system for how you're treating both space between function parameter names or operators after the function call\r \r and this indentation\r \r on the new lines, that's hugely important for readability.\r \r\n\nBut I I admit they also have great advice too\r \r of not necessarily\r \r putting, like, a new line between all of your declaratives.\r \r And I've been kinda guilty of maybe putting too many new lines between\r \r my various function calls, but instead to try to group them\r \r in kind of related chunks, so to speak.\r \r Whereas maybe you have a tidyverse pipeline\r \r ish, you know, syntax,\r \r and you wanna keep, like, a lot of that data manipulation in one concise area,\r \r then you maybe break it up with another part of your function operation and you're doing a new operation.\r \r A lot of times in my shiny ass, I would kinda break things up maybe a bit too much.\r \r\n\nBut again, I think it's not so much what's right or wrong. It's be consistent.\r \r Be consistent with yourself. Be consistent with your main your collaborators.\r \r And I think then you're gonna have what they envision as well. Proportion code will be easier for reviewing,\r \r easier for debugging.\r \r And also, another\r \r trick that they recommend as well\r \r is maybe you realize you have a lot of lines in that particular pipeline.\r \r Well, there's nothing stopping you from having more fit for purpose functions inside that overall pipeline to help break out\r \r some of that potential long scrolling syndrome that you might have with these more of a reversed pipeline. So\r \r being able to leverage\r \r that mechanism\r \r is really important too.\r \r\n\nBut, it's not just about this, obviously, the spacing and the use of maybe fit for purpose functions.\r \r There are obviously other ways that you can have concise and beautiful code too without being in the code itself.\r \r And that we have to talk about comments now, Mike. What what do what do they say about comments here?\r \r\n\n[00:26:14] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 14,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. So\r \r the the section title is not too wordy,\r \r just the right amount of comments, and they even link to a blog post on our hub called why comment your code as little and as well\r \r as possible.\r \r This is one that I am probably super guilty of as well just like creating sort of too much vertical space probably\r \r between, you know, different pieces\r \r of logic,\r \r within\r \r a lot of a lot of our code. And, you know, I I guess I have sort of mixed mixed feelings on on this.\r \r And\r \r I think, you know, the idea\r \r is to use, you know, very self explanatory\r \r functions,\r \r function names, or variable names where by just by looking at the code, you know, it's very easy to understand exactly what's going on.\r \r\n\nI I think in a perfect world, you know, that\r \r that we wouldn't have to write any any comments at all because, you know, function names and and our variables would be so self explanatory. But I think we all know that that's just not necessarily the case.\r \r And\r \r I think, you know, this is something that I see a lot in\r \r a lot of the open source packages\r \r that that posit, you know, formally, RStudio has put out for years years years.\r \r And something that I probably need to adopt a little bit better, but it's, I I think the the concept of really only introducing\r \r comments when\r \r you think it's not necessarily self explanatory.\r \r\n\nWhat's going on. You know, when there's an additional anecdote,\r \r additional piece of information\r \r that you need to provide on top of, you know, what the logic is doing\r \r itself. Because if if somebody wanted to understand exactly what was going on and didn't, you know, they could always dive into the the help documentation\r \r for each of those functions,\r \r to to understand exactly what's going on in it. As long as you're writing good descriptions\r \r in your\r \r roxigen comments above those functions, you know, defining what the parameters,\r \r represent and defining sort of the overall goal of the function and and what it returns,\r \r then I think there's a lot of good arguments there.\r \r\n\nBut\r \r again, you know, I would agree with you, Eric, that it's consistency\r \r would be key here. It's probably, you know, we're starting to get even more and more into sort of gray area when to comment and when not to comment.\r \r But if you can set, you know, some, you know, basic high\r \r level rules and decisions\r \r within, you know, your team about, you know, when to comment and when not to comment,\r \r and try your best to to follow those. I think that that consistency will will help your code base be more maintainable over time.\r \r\n\n[00:28:51] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 51,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And and I do admit being in industry versus\r \r releasing a package open source. There's,\r \r it's almost I got to be 2 personas in one of for a lot of my projects.\r \r The hear me out here. This may sound bizarre, but hear me out. Is that\r \r there is the purest in me that wants to make things as concise as possible from a development standpoint.\r \r I know the project very well. Right? I mean, I I built the package. I built this shiny app for five years. I I know the intricacies,\r \r but I need to think about, do I really wanna be the only one on this project to help maintain and help develop a new feature?\r \r No. I want people from my team or maybe others in the organization to help me out from time to time.\r \r\n\nWell, sometimes\r \r the comments that I put in my package source, you know, functions and documentation\r \r alike,\r \r they're kind of serving another purpose. It's not just to highlight a particular\r \r idiosyncrasy\r \r or a particular\r \r area we need to be aware of.\r \r It's kind of doubling as a teaching mechanism too. Like, often in my comments, I'll maybe describe what it's solving, and then I'll put, like, a reference. And guess what? It's gonna probably be a Stack Overflow reference\r \r or or a blog post. You know? Just\r \r to get that get that in there right into the eyes of that collaborator is gonna help me. Yes. Ideally, that would all go in a GitHub issue or or a dev notes journal or whatnot.\r \r But sometimes\r \r you gotta\r \r get strike while the iron's hot, so to speak. When you have a collaborator looking at your code base, maybe\r \r whipping up posit workbench or whatnot and looking at this code,\r \r you wanna put that front and center of, like, not just to be aware of the issue,\r \r but how did I or anyone\r \r get an insight into how to solve that? And a lot of times, I don't solve these myself. I've leveraged a vast R community\r \r that have\r \r treaded those waters before, maybe an API call or maybe other\r \r operations like that in the Shiny space. And I am not shy about putting those links to external references in the code base itself.\r \r\n\nAgain, I'm an industry.\r \r 99% of what I do doesn't see the light of day outside the firewall. So I wanna make sure that for future me and future collaborators,\r \r they have a better understanding of why that solution's in place. So that's my mini soapbox for today.\r \r\n\n[00:31:17] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. And I think it even I couldn't agree more, Eric. And I think it even in a higher level, you know, just having that,\r \r you know sort of\r \r code style guide within your organization\r \r can go\r \r a really really long way towards getting everybody on the same page here.\r \r And you know, I think we can all agree on a couple of these last tips from Yael, Amael, and Yanini,\r \r on early return and and the switch function.\r \r So if you have a particular function and and I think Jenny Bryan refers to this as like, the happy path. If there is an if statement,\r \r it within that function, and if else, if you will,\r \r and you sort of expect most of the time for it to go down this first path,\r \r You can actually early return, have a return call,\r \r within that first chunk of your if statement,\r \r sort of assuming that it will never get to that that second portion most of the time. And that can save you a little bit of time, make your code a little bit more lightweight.\r \r\n\nAnd you know, Erica, as you and I know, these these little things, you know, might save like a a millisecond,\r \r right, to to make a change like this. And it may seem like like not much. But if you consistently\r \r do this throughout your projects,\r \r you know, those little milliseconds\r \r can add up and and turn into an improved user experience and and that's regardless of whether you're developing a shiny app or if you're developing\r \r a, just an R package in general that others are going to be using.\r \r You know, I I think, you know, these little things, especially these early returns,\r \r can can add up over time. And then the the switch function is one that\r \r I don't see used enough. It is the definition of an oldie but a goodie, Eric. If you have nested if statements, if you have like an an if else,\r \r or an if, and then an else if, and then another else if, and then another else if, to handle all of these different cases of what this, variable could potentially take on for a value.\r \r\n\nPlease leverage the switch function. It makes it so much easier to define all of those different all that different case logic,\r \r for the different values that that particular variable\r \r can take on and it it looks much cleaner it's just much easier to handle\r \r so and that's a phenomenal recommendation as well because that is something that I do see time and time again way too often\r \r are these long lengthy nested,\r \r if else statements.\r \r\n\n[00:33:48] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I I, there's a lot of legacy projects where I fell into the if else else else if trap. And, yeah, I definitely need to refactor that the switch sometime. You know?\r \r It it it you know, I I was thinking as I'm I'm reading through all these tips. You know? There are some analogies you can make, especially as you're doing maybe some of these things you're just not as comfortable with because you didn't know about them in the first place. Like I like, what you're talking about, the early returns, the switch, and and a different naming convention.\r \r Honestly, I think it's gonna it's gonna be a little hard at first, especially if you're,\r \r you know, you have old habits like I do. And I I see my old code bases from 4 or 5 years ago. I'm like, oh my goodness. What was I thinking? Well, this is similar to, frankly, keeping healthy from, like, a fitness standpoint. You may it may seem uncomfortable at first, but you build up. You build up. You build up. And then suddenly, the the next time you make that new shiny app, that new R package,\r \r even just that new set of functions you're gonna pass off to that colleague,\r \r these will be front and center. It won't be the old habits anymore.\r \r\n\nOf course, easier said than done. Right? You gotta start somewhere.\r \r This is fresh in my mind because I'm refactoring\r \r a 7 year old package as I speak.\r \r And boy, oh, boy, were there some issues there, which is a great segue into kinda how this post concludes where, you know, occasionally,\r \r if you do have the time, and I realize time is hard to come by with a lot of our jobs these days, but taking a little bit of time to do what they call spring cleaning of your code,\r \r seeing what are some gaps that you can solve with the knowledge you've gained\r \r from hopefully reading our weekly and listening to this podcast or other ways\r \r of of learning about codevelopment.\r \r\n\nAnd there's a link also in the blog post to about the how the tidyverse team is doing spring cleaning. So that might be some inspiration as well. And then, of course, take advantage of automation when you can. There is the lint r package. It's just gonna help you with things like the spacing issues\r \r and syntax issues\r \r that, again, can automatically point where these are so you don't have to manually scan it. This is fresh in my mind too because I was helping,\r \r do a little, new feature\r \r to one of the internal companies packages that my esteemed teammate, Will Landau, maintains.\r \r And he built in winter checks in the GitHub action, and I forgot to run that locally. And I was like, oh goodness. I messed up stuff up.\r \r\n\nBut it it pointed it to me. Then I ran it locally, got it fixed. Now they get that fancy green check mark in the in the PR check. So lots, lots of great great tips here for sure.\r \r\n\n[00:36:28] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 28,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yes. Absolutely. And I think if you're a manager, especially of data analysts or data scientists,\r \r try to build in. I know it's hard, but but try to build in\r \r time, at least once during the year to to take a day or or a couple days or a week even to to go through your repositories\r \r and take a look at that code and and see\r \r what you can do. I think they're calling it referring to it as spring cleaning here to to maybe improve that code styling\r \r or develop some refactoring to keep that code up to date,\r \r and keep it as maintainable\r \r as possible. As a as a a quick story,\r \r I have a former\r \r employer who,\r \r won't work with me on a on a project because of some code that I wrote 6 years ago\r \r that broke,\r \r I guess, internally\r \r recently. So they they they think that I'm a pretty terrible R programmer,\r \r because the code that I wrote 6 years ago is no no longer working there even though I've I've offered to help. So this is I'm not gonna name name any names or anything like that but, I I would just say don't don't be that person. Understand that that software needs to be maintained\r \r and managed and improved over time and, you know, don't judge somebody on the code that they wrote,\r \r you know, even a couple years ago because we're all consistently\r \r learning, improving, and and I don't even look like looking at the code that I, you know, wrote a couple years ago. So we're,\r \r but let's lift each other up here.\r \r\n\n\n\n[00:37:56] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Exactly. All positive vibes. Yeah. We don't we don't need that. We could do a whole another hour podcast on that kinda issue. Trust me on that.\r \r But, you spotted someone else in here to post in this post, Mike, because I there's there's an opportunity for a a real, nice quote to live by here. Right? Oh, there is a quote that I absolutely love. I we need to get t shirts made up of this, Eric. I might get this tattooed on myself.\r \r\n\n[00:38:19] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Mike Thomas",
        "trans_text": "But, the the the line in here is\r \r the code you don't write has no bug. Unbelievable.\r \r\n\n[00:38:26] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 26,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That oh, my goodness. Yes. We we need\r \r a shirt, whoever's listening out there. Yeah. Please please make this. We will take our money after you print it. We will buy it. That is, I love that line and it just speaks to so many aspects\r \r of my development life. Yeah. So there there's there's a boatload of additional resources that they link to at the end of this post.\r \r And, also, I have a link to the, one of the inspirations that it's supposed to begin with is that rOpenSci\r \r recently had their\r \r their second cohort of champions,\r \r onboarded\r \r and they ran some virtual workshops\r \r and some of those materials are online with respect to package development. So I'll have a link to that in the show notes too. And that particular external resource,\r \r wowed me for another reason,\r \r is that they also use the same Hugo theme that I did for an internal documentation site at the company about our HPC system. System. I was like, hey, I know this theme. That was awesome. So it's great when I feel like I'm I'm thinking similar to all these people I look up to in the community. That was just that was awesome stuff. Oh, that is awesome, Eric. You know what I think we should put on the back of that t shirt? I should, I think, you know, the front could say the code you don't write has no bug and the back could say, the code that an LLM writes for you probably does have a bug.\r \r\n\nBingo. We need we need a patent soon or or well, somebody's gonna take that run with\r \r it. Oh, goodness. Just kidding. Yeah. You know. You know. You know how it goes. But,\r \r we also know how it goes is that, yeah, the rest of the issue has a set of fantastic blog posts, new packages, updated packages,\r \r calls to action, you know, call to events, and everything else that you can find every single week at Our Weekly. So we're gonna take a couple minutes, tell us some additional finds that came our way that we we wanted to highlight here.\r \r And, of course, me being an audio video kind of, you know, junkie, so to speak, with doing this podcast and other media ventures.\r \r\n\nThis post here really hit home. There was a recent post,\r \r that I saw a Mastodon\r \r from Matt Crump about how he was\r \r exploring importing MIDI audio data into R for his cognition experiments.\r \r Well,\r \r he ended up using a mix of command line calls, the FFmpeg, which is kinda like the Swiss army knife, so to speak, of media,\r \r conversions and then another\r \r utility called fluid synth and some Python code,\r \r but, using a lot of shell commands. Well, your own ooms who, of course, is heavily involved with the infrastructure behind our OpenSci and the our universe project,\r \r decided to take matters in his own hands\r \r and decided to create a package called fluid synth\r \r to help wrap some of these system utilities\r \r for bringing in and parsing\r \r MIDI data. So if you ever find yourself having to analyze these and maybe use them\r \r in a data driven way and then also rendering that to an audio file,\r \r yeah, your Roam's package\r \r got you covered. So I have to add that to my toolbox amongst many other great utilities in the audio visual space in the art community.\r \r\n\n\n\n[00:41:41] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That's a that's a super niche little, package there. I like it.\r \r I wanted to highlight a webinar series that's actually been going on through the our consortium,\r \r our insurance series. I believe it's hosted by, 2 folks at Swiss Re, which is an insurance company.\r \r Georgios Bacalukas and Benedicte Chamberge.\r \r And they\r \r it\r \r this video series looks fantastic.\r \r Eric, I'm just gonna walk you through the titles\r \r of the first few videos here. The first one is from Excel to programming in R,\r \r great content applicable everywhere.\r \r From programming in R to putting R into production.\r \r\n\nNow, I know I'm getting you more excited. Oh, yeah.\r \r Our performance culture,\r \r and lastly, high performance programming in our so these are the 4 webinars that are now available through the our consortium's\r \r website.\r \r I'm not sure if they're going to continue to have more webinars or not. But if you are in the insurance space or if you're,\r \r into actuarial science, I would highly recommend checking out these webinars.\r \r\n\n[00:42:45] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 45,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. What a what a excellent, you know, set of resources here. And I love the fact that\r \r they're being shared with others because I know that, you know, r is making big headways in the world of insurance and the world of finance and everything else in between. And, of course, I'm in life sciences, but it's great to see these tailored to that audience but with concepts that are most definitely\r \r universal\r \r to anybody in our respective industries\r \r because you gotta start somewhere. Right? More often than not, Excel is that window to data analysis that people use routinely and then be able to take that programming based approach with our boat tailored to that kind of audience\r \r going all the way to writing highly performing code.\r \r\n\nYeah. That's something that I am doing, trying every single day, and I can't pretend that I know everything about. So I'll definitely have to check these out. Looks like even they got wind of a certain project called Parquet. So that's really speaking to our eyes on this.\r \r\n\n[00:43:44] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 44,
        "trans_speaker": "Mike Thomas",
        "trans_text": "No. That that was my journey from Excel\r \r Excel guru,\r \r\n\n[00:43:49] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Eric Nantz",
        "trans_text": "into to R and changed my life. There's a lot more in this issue. Of course, we're gonna we're gonna have to start to wrap things up here. But, if you wanna get in touch with us, if you wanna help with the Rweekly project itself, that's always something we welcome. Whether it's your poll request,\r \r contributions, or\r \r suggestions,\r \r we're all just a poll request away to the upcoming issue draft,\r \r all linked at rweekly.org.\r \r That's where you'll find everything.\r \r I I have, inkling that the next curator could definitely use a bit of help if you get my drift. So yeah. Please send those\r \r requests to the project way.\r \r\n\nAnd also, you can get in touch with us directly. A few ways to do that.\r \r We have in this episode's show notes a handy link to the contact page if you want to send us feedback\r \r there. You can also if you're on the, podcast 2.0\r \r train with your modern podcast app, there's a boatload to choose from out there at podcastapps.com.\r \r You could send us a fun little boost along the way to give us a little message directly from within your app itself.\r \r Details on setting that up are also in the show notes. But, also, we are on the various social media spheres from time to time. I'm mostly on Mastodon these days with at our podcast, at podcast index dot social.\r \r I will admit I'm a little late,\r \r replying back to Bruno's been checking in with me on my next journey. I I have some follow-up with you. It's coming soon. Trust me.\r \r\n\nBut, also, I am sporadically on the weapon x thing with at the r cast. And lastly, on LinkedIn from time to time popping in with some announcements and\r \r episode posts. But, Mike, where can the listeners get a hold of you?\r \r\n\n[00:45:27] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Sure. You can find me on mastodon@[email protected],\r \r or you can check out what I'm up to on\r \r Catchbrook Analytics, k e t c h b r o o k.\r \r\n\n[00:45:41] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome stuff, my friend. And, yeah. We we had a we had a heck of a a kind of a therapeutic preshow session. You all didn't get to hear it. But, Mike, listened to my\r \r GitHub action rant that may be becoming a rep for x in the very near future so that I can talk about it here later. But in any event, I'm gonna get back to the old day job here. So we're gonna close out this, episode of our weekly highlights, and we'll be back with another episode\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_09_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "chap_timestamp": 37,
        "chap_text": "Flipping Hello World"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "chap_timestamp": 57,
        "chap_text": "ggplot2 3.5.0"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "chap_timestamp": 17,
        "chap_text": "Beautiful code"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "chap_timestamp": 57,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_09_highlights",
        "chap_timestamp": 52,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_08_highlights",
        "ep_date": "2024-02-21",
        "ep_duration": 17,
        "ep_description_short": "Putting those bike pedals to work with a comprehensive exploratory data analysis, navigating through a near-inferno of namespace and dependency issues in package development, and how you can ensure bragging rights during your next play of Guess My Name using decision trees. Episode Links This week's curator: Tony Elhabr - @TonyElHabr…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_08_highlights",
        "description_long": "\r \r\n\nPutting those bike pedals to work with a comprehensive exploratory data analysis, navigating through a near-inferno of namespace and dependency issues in package development, and how you can ensure bragging rights during your next play of Guess My Name using decision trees.\n\nEpisode Links\n\nThis week's curator: Tony Elhabr - @TonyElHabr (Twitter) & @[email protected] (Mastodon)\nMy Year of Riding Danishly\nTame your namespace with a dash of suggests\nGuess My Name with Decision Trees\nEntire issue available at rweekly.org/2024-W08\n\nSupplement Resources\n\n{fusen} - Inflate your package from a simple flat Rmd https://thinkr-open.github.io/fusen/\nR Packages Second Edition https://r-pkgs.org/\n{usethis} - Automate package and project setup https://usethis.r-lib.org/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nSwing Indigo - The Legend of Zelda: Majora's Mask - sschafi1 - https://ocremix.org/remix/OCR04560\nWhat Lurks Behind the Door - Final Fantasy V - Lucas Guimaraes, Andrew Steffen - https://ocremix.org/remix/OCR04542"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://mastodon.skrimmage.com/@tonyelhabr"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://www.gregdubrow.io/posts/my-year-of-riding-danishly/"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://rtask.thinkr.fr/tame-your-namespace-with-a-dash-of-suggests/"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://mhoehle.github.io/blog/2024/02/12/decisiontree.html"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://rweekly.org/2024-W08.html"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://thinkr-open.github.io/fusen/"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://r-pkgs.org/"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://usethis.r-lib.org/"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://ocremix.org/remix/OCR04560"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "links": "https://ocremix.org/remix/OCR04542"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We are back with episode 153 of the R Weekly Highlights podcast.\r \r This is the weekly show where we talk about the latest happenings and the tremendous resources that you can find every single week at the rweekly.org\r \r website.\r \r My name is Eric Nantz, and I'm delighted that you joined us from wherever you are around the world.\r \r We're about in the past the halfway point in February, so spring is coming soon, I hope. But I can't do the show alone. Of course, I am joined by my awesome cohost, Mike Thomas. Mike, how are you doing this morning? I'm doing well, Eric. Yeah. I think probably the audience can can hear in our voices that spring isn't quite here yet, but, we're getting there.\r \r Yeah, combo. The cold weather, kids bringing you know what home from their respective day cares or schools. It just it it never ends. It never ends. But, nonetheless,\r \r we're gonna power on through here. We got a lot of exciting content to share with you all today,\r \r and this content for this particular issue was curated\r \r by Tony Elhaubar, who had tremendous help, as always, from our fellow rweekly team members and members like you, contributors like all of you around the world with your awesome poll requests and suggestions for more excellent resources.\r \r\n\nAs I said, Mike, we do sense spring is coming, and that's where I know my kids like to start getting their bikes out to take their bikes rides around the neighborhood and whatnot.\r \r Well, it's appropriate that as the weather's warming up, our first highlight today\r \r is taking a very data driven approach to just how far you can take your bikes\r \r and analyze that for some real fun, exploratory data analysis and\r \r and and the like. And this post comes to us from Greg Dubrow,\r \r who is a data analyst who\r \r is now based in Denmark, and he has a, you know, very passionate,\r \r hobby, so to speak, of riding his bike basically everywhere he can go. He's been doing this wherever he's been in the world. His first part of the blog post gives a nice background\r \r on the various bikes he's had growing up, even a little mishap he had,\r \r last year during that, which any bike enthusiast can probably relate to.\r \r\n\nBut, nonetheless,\r \r he talks about,\r \r you know, taking advantage\r \r of recording\r \r his bike riding data using an app called Strava.\r \r I've not heard of this before, but, apparently, it gives you a boatload of metrics\r \r having to do with your bike riding.\r \r And the first question comes, okay. Well, you got this data on the app. Right? How do you get it out of that? Well,\r \r you could download a bundle from your profile on the Strava site as one way to get a CSV\r \r text dump of that, which he does end up doing. But\r \r like anything else, there is an API for that. Right? And not only that, there is an R package\r \r to help you grab this data from R itself called RStrava,\r \r which he utilizes as well as, like I said, the aforementioned\r \r CSV data dump, if you will, and merges that together\r \r to give them a nice tidy dataset after some, you know, very\r \r usual cleaning and reshaping\r \r and and manipulation of dates and whatnot so that it's actually\r \r ready for analysis. So, again,\r \r an awesome data driven approach,\r \r to take advantage of modern tech to put this data into R itself.\r \r\n\nYou've got the data. Now what? Like a lot of the posts we cover in our weekly, we start with some fun exploratory data analysis.\r \r And to get things going quickly,\r \r he makes use of a very cool package that I've actually seen utilized\r \r with some of my colleagues at the day job as well as others in the community\r \r called data explorer.\r \r This is a really nice package that gives you a very quick way\r \r to explore, say, the missingness in your data\r \r as well\r \r as doing some very nice correlation\r \r heat maps right off the bat with your numeric variables.\r \r And he senses that, yeah, most of these variables have a positive correlation\r \r to the key metrics, such as distance\r \r and the actual\r \r moving time of the bike, where this app is apparently smart enough to detect when the bike is actually moving\r \r versus stationary.\r \r\n\nSo really novel use of tech here,\r \r but the post has both the variables and their percent of missing values as well as this aforementioned,\r \r heat map with the correlations to help begin informing\r \r just what kind of relationships he will explore later on in the post. And you start to sense some of the things you might think intuitively,\r \r such as the average speed of his bike being positively correlated\r \r with distance, albeit not as a huge relationship right off the bat,\r \r and also some correlations\r \r with\r \r the power output of the ride and measured an average wattage usage\r \r may have some negative correlations\r \r with other metrics\r \r and the like. And then augmenting\r \r these visuals from the correlation perspective\r \r is the tried and true scatterplot,\r \r which uses\r \r a very novel functional approach that he got inspiration from one of Cedric Shurer's posts that he does all things ggplot2\r \r and with a little bit of permac magic with patchwork,\r \r able to get these nice correlation plots for the key response variables of distance,\r \r moving\r \r time, and average speed, and you, again, start to see positive correlations amongst many of the key metrics,\r \r such as calories, average watts, moving time, and etcetera,\r \r to give him a better idea of what he might expect out of a more rigorous analysis.\r \r\n\nAnd just where does this regular analysis take place? Well, we all like some tables. Right? So he starts off with creating some fun GT tables\r \r of just the metrics\r \r in terms of the total time, elevation,\r \r total calories output throughout the year.\r \r And you can see out of 446\r \r rides, yeah, he's burned a lot of calories and generated a lot of energy. Lots of cool, cool summaries there. And then we got some more visuals, Mike, where he's looks at the seasonal pattern\r \r of his ride shares per month. So why don't you take us through some of the visuals you're seeing here? Yeah. It's a really nice, visual blog post. I I think Greg notes that he leveraged\r \r\n\n[00:06:31] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 31,
        "trans_speaker": "Mike Thomas",
        "trans_text": "some of the tutorials that Cedric Shearer has put together. And if you are in the DataViz\r \r space, especially in the our DataViz space, that is a name that you are certainly familiar with. One of the visuals that I thought was was pretty cool,\r \r that that he used was,\r \r most rides during, you know, it's showing, the number of rides that he has and and the type,\r \r sort of in this polar area coordinate diagram. And the reason that he did that is to correlate them to the hour of the day\r \r that it took place. So it's a this this chart is sort of representing a clock\r \r which is a really cool, I think, use case of these polar area coordinate,\r \r diagram type charts. I struggle to find a lot of use cases for those those charts in a lot of my\r \r EDA analysis and DataViz work, but I think this is a perfect use case for it.\r \r\n\nSo I really appreciated that.\r \r You know, going back to talking about some of the dependent variables\r \r that he used. One of the the dependent variables,\r \r that Greg used was called kilojoules,\r \r I believe. Hopefully, I'm pronouncing that somewhat correctly.\r \r And, he used that variable instead of calories\r \r because,\r \r according to Garmin,\r \r frequently asked questions, calories expended\r \r are the total energy,\r \r in the time that it took to do the workout that you expended, while kilojoules is the energy burned, actually burned by the workout and that formula is watts times seconds times a1000. So that was that was very interesting to me, and,\r \r you know, I know a lot of workout apps there sort of focus on calories, and and maybe they should be focusing on kilojoules\r \r instead. So I I thought that that was pretty interesting, you know, some of these GT tables,\r \r and the way that he was able to format them in the blog post to have a lot of these GT tables actually side by side,\r \r instead of one on top of the other using some HTML\r \r was a pretty cool,\r \r nifty trick to make this, this blog post sort of nice and neatly\r \r put together as well.\r \r\n\nSo a lot of really interesting,\r \r work here, and then he actually fit some models\r \r at the end of this here. There's a time model, a kilojoules model, and then a Watts model as well. And the the model fits all look look pretty good. I'm pretty impressed and it's sort of a function, I think, of just the amount of data that, this Strava app allows you to to have, control over and to take a look at. And you can do some pretty cool, as as Greg shows us here, some pretty cool analysis with your your workout and exercise data, particularly with your your cycling data in the Strava app. So a really cool use case,\r \r I think walking through a lot of different types of data visualization, some predictive modeling,\r \r sort of an an end to end data science project here using a pretty nifty data set. So, hats off to to Greg for a great start to our weekly highlights this week.\r \r\n\n\n\n[00:09:25] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 25,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Really awesome approaches here. And looking at even the source of this quartile document that this blog post is based on, you're gonna see, like you Mikey said, those nifty tricks of putting the the tables and the some of the plot side by side. Really, really nice,\r \r easily viewable post here. We got the table of contents on the right margin. Yeah. Lots of ways to hop back and forth amongst us. So, again, Quartle gives you a lot of these niceties out of the box.\r \r And really, hats off to\r \r owning your data as best you can, albeit, yeah, a third party app is collecting it, but fair play to Strava for giving an API for users to expose this because there are some others out there in the fitness tracking space that aren't quite as friendly about you getting your\r \r exercise\r \r and workout metrics out of it. So\r \r really encouraging to see\r \r For all you cyclists listening out there and I'm a part time cyclist when I can.\r \r\n\nYeah, that's really cool to see you be able to take advantage of this amount of data. And, you know, he's got to be, Greg's got to be a pretty fit person to be able to have this amount of rides in in 2023\r \r even with the injury that he underwent earlier in the year. Like, that is impressive stuff, impressive\r \r dedication, and, yeah, may maybe I need to not be so lazy this year. We'll see.\r \r\n\n[00:10:48] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Mike Thomas",
        "trans_text": "And hats off to Greg as well and Quarto\r \r for the nice, collapsed code chunks that allow you to see exactly how he did what he did in this blog post.\r \r\n\n[00:10:58] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 58,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Isn't that a great, you know, UX, so to speak, of digesting the parts you like? And then maybe you're more interested in, say, the modeling part or more interested in the visualization part or, of course, interested in everything, but you can opt in to looking\r \r at all those details and still get the full cohesive story here. So, yeah, really enjoyed the post. Looks like he spent a lot of time drafting this together. But, again, it's all all available for us to see in the open. And and, yeah, I'm gonna have to maybe get a new bike this year so I can start tracking some metrics.\r \r\n\n[00:11:28] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 28,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Me too.\r \r\n\n[00:11:38] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Now maybe, Mike, you you're on a long bike ride. It may seem, Mike, every time you think you've got to your destination, there's some little hurdle along the way. Right? And maybe it's a traffic light. Maybe it's, you know, who knows what else is happening\r \r out there. Sometimes package development\r \r can feel like you're so close. You get that glimmer of hope,\r \r and then something really crazy happens.\r \r That's where our next highlight comes in, coming us from our our fine threads at Think R.\r \r This has been authored by Swan Fuller\r \r Clay. I probably didn't pronounce that at all correct, but apologies in advance.\r \r\n\nBut they have an excellent blog post here about how you can tame the namespace of your R package\r \r and making use of the suggest\r \r call of it.\r \r So like any good story, this starts with what seems to be a smooth road. There,\r \r the example package in this post is a simple wrapper on top of ggplot2\r \r to help export the plot with a simple function they call saveplot.\r \r It looks innocent enough. Right? We are simply\r \r letting the user specify,\r \r after they specify the ggplot object, the extension,\r \r which can be 1 or more\r \r of, like, PNG, JPEG, or PDF,\r \r where to put it, what's the file name.\r \r\n\nPretty straightforward stuff is just wrapping a call to gg save with a little bit of per on top of that.\r \r And the usage looks very straightforward. The example looks very logical. You're gonna plot your dataset, use the save underscore plot, clean up after yourself.\r \r Well constructed example.\r \r So like anything in package development, you're gonna start checking this on your local system\r \r using dev tools colon colon check most of the time.\r \r It comes through flying colors.\r \r No issues\r \r at all. No errors. No warnings. No notes. You are feeling good about it.\r \r And like in good practice, this package code is on version control with GitHub.\r \r\n\nSo\r \r why not just rely on your local system to do the checking?\r \r We like to use GitHub Actions now to do a lot of this automated checking as well.\r \r And that's where things start to go a little off the rails because\r \r we are now embodying the infamous slogan in CS and development.\r \r It works fine on my machine.\r \r But on the CI check,\r \r we see a cryptic error.\r \r And where does this rely? Well, you go down the rabbit hole of checking the logs.\r \r In the details, there's an error saying that there was an error running the example\r \r code, which, again, the example looks straightforward.\r \r\n\nWorks fine locally. Right?\r \r Go down that back trace a bit further\r \r a bit further,\r \r and then you see this error about load namespace.\r \r There is no package called SVG\r \r lite.\r \r Oh, boy.\r \r What on earth happened here? Now we gotta put our detective hat on.\r \r Where in the world is SVG light being used, Mike? What gives?\r \r\n\n[00:14:52] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Well, it's going to be in, and you'd only see this in the source code potentially,\r \r or the, the the package description file, but it's it's going to be in the, it's a dependency of ggplot specific to the ggsave\r \r function. When you are saving\r \r a plot using the ggsave function from ggplot2,\r \r as an SVG,\r \r it's going to employ the SVG lite package. And one of the reasons why you don't have this,\r \r in your CICD check is because SVG\r \r Lite is not\r \r a hard dependency of ggplot2.\r \r Svglight is in the suggest\r \r portion of, the dependencies of gg plot 2. So it is not going to get installed automatically\r \r when you specify that ggplot 2 is a dependency\r \r of your package.\r \r\n\nSo, you know, this is a very familiar, probably, territory\r \r for those of us who have done a lot of our package development\r \r and ran into similar situations like this before either, you know, wrestling with, whether dependencies\r \r dependency should be, a hard import or should be in the suggests,\r \r section of your description file. How to manage dependencies that are only specific to, maybe, vignettes, or things like that.\r \r So this is very familiar territory to me. I have I have, maybe, a story that that I might tell if we have a little bit of time here, but I think it it sort of just goes to the the overall\r \r narrative here that sometimes, you know, things may work well on your machine, but when you start to employ CICD\r \r that, you know, is going to leverage a different machine to build and test that package,\r \r you may see a failure there. And and honestly, that's that's a good thing. Because what that means is that when someone else on a completely different machine than yours\r \r wants to use your package, and that's that's the whole idea, to build software that is useful for other folks as well, they might run into the same issue. Even though you saw no issues,\r \r warnings,\r \r errors, or notes\r \r in your your own DevTools check run,\r \r you know, it's a good thing, in my opinion, that when you you send it off to GitHub actions in this case, that, this error presented itself and pops up and,\r \r you know, let you know sort of exactly what the issue was. I think the error message is is pretty descriptive, and, obviously, you do have to do a little bit of detective work to to figure out, hey, where the heck is is f SVG light, even impacting us in this particular case. But,\r \r if you if you've been around the block a little bit with ggplot2 and you're you sort of understand what you're trying to do here in terms of saving that plot, hopefully, it won't take you too long to figure that out,\r \r as it it did in the case of of Swan.\r \r\n\nSo, you know, I think this blog post,\r \r also nicely calls out the use of the the Fusen package, not Fusen, it's the Fusen package,\r \r which, for those who are unfamiliar, is a package that\r \r streamlines,\r \r the development of our packages. And I believe it sort of uses an R Markdown\r \r approach, a chunks approach to sort of execute\r \r different commands,\r \r through a a nice documentation framework,\r \r and sort of build out all of the different components\r \r that you need, for that R package.\r \r So,\r \r you know, I don't know. Eric, if you wanna take over sort of, more of the the final\r \r solution here to ensure that this,\r \r\n\n[00:18:23] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 23,
        "trans_speaker": "Eric Nantz",
        "trans_text": "that this package passed all of its CICD checks when it went to GitHub actions. Oh, yeah. I'm chomping at the bit for this because, boy, do I feel seen on some of the ways this can be implemented. So\r \r now that we realize that SVG light is definitely\r \r required for this safe plot function, there are a couple options\r \r or how this could be tackled here. One\r \r is that in the r oxygen\r \r preamble for this function,\r \r we declare an import from\r \r SVG light, the SVG light function. That is certainly a valid approach. Right?\r \r Well, when you run a check again, even locally,\r \r you're gonna see something appear that may seem really scary, and frankly, it can be,\r \r where you will be warned about,\r \r hey, you know what? Now,\r \r the imports of your package may seem small, may only seem like it needs YuJaPaw 2 and SVG lite.\r \r\n\nBut that has now ballooned to 21\r \r non default packages\r \r that are now gonna be required at install time to get your package installed.\r \r Now the CRAN maintainers\r \r put this check-in our command. Check this note, I'm about to say, is that importing from so many packages make the package vulnerable\r \r to any of them becoming unavailable.\r \r Yes. We have covered in years of this podcast\r \r when one dependency suddenly got, quote, unquote, archived on CRAN. In fact, they even infected ggplot2, I believe, and amongst others. So how how we appropriate here.\r \r So\r \r but you but you still need this package, or do you need it?\r \r\n\nNow there this is where suggest comes in in terms of\r \r now taking this preamble out of the r oxygen,\r \r putting SVG in the suggest field,\r \r and then in your function having a check via the require namespace function\r \r to check if that user has installed it or not on their local system\r \r and to prompt them to install it in order to get the full support of all those file types that are being exported,\r \r but it would still import, in the case of the solution here, it will still import the file\r \r types or export, I should say, the file types that don't need SVG light. So there's a happy medium in here from the UX experience to what they politely say avoid the backlash\r \r of what can happen from both you as a developer, but also as the end user to know what to do next.\r \r\n\nSo it may seem like a little more upfront work, but the good news is is that\r \r now the dependency footprint of your package going to CRAN\r \r has become much less,\r \r such that now the user\r \r or in your CICD for running the examples can opt into installing this package\r \r without having the hard dependency on it and, hence, minimizing\r \r the potential\r \r for the dreaded archival status on CRAN if any of these dependencies\r \r end up going away.\r \r So there is another nugget here, though, is that\r \r when you install a package from, say, GitHub, like, they have a nice snippet on here using the remotes\r \r colon colon install GitHub, name of the package repository,\r \r by default, it will not\r \r install\r \r dependencies that are marked as suggests.\r \r\n\nThat's where you have to supply the dependencies flag of true\r \r in order for your local system as an end user\r \r to grab, in this case, that SVG like dependency.\r \r That's a nuance that has tripped me up so much in my day to day work when I thought I'd install a package from GitHub. I'm ready to throw it in my shiny app or throw it in my over pipeline, and then I realized, oh, what's that error? Oh, nope. Didn't get that suggest package when I installed it. So that's at the end of the post, but it's bitten me up many times. And that's contrary to the base r install dot packages function, right, which will install by default your the packages that are listed in the suggest portion of the description file.\r \r That is correct.\r \r\n\nThere's a dichotomy there that unless you really stumble into it, you don't really know exists. So that was\r \r that was some shared learning for me.\r \r So, well, I'm curious, Mike, to hear your\r \r your your tail, if you will, of this of this issue.\r \r For me, I have two minds on this.\r \r If I'm developing a package that's just for internal use at my day job,\r \r admittedly,\r \r I'm probably just gonna put it in imports anyway because at that point, I know I'm not going to CRAN.\r \r It's more about does this pipeline I'm making\r \r is the benefit of throwing this on to, say, a Shiny app hosted on Pawsit Connect or other areas.\r \r What's the easiest way for me to control what's happening there? And that's typically if I have a description file, just throw it all in imports.\r \r\n\nBut if in the situation of either a, you know, CICD\r \r or CRAN itself, yeah, I definitely would take this advice to heart because\r \r it will make your life as a maintainer easier\r \r not to worry about s v in this case, SVG lite's\r \r tangled web of dependencies when all you needed is for one\r \r additional\r \r type of file to export in this case. It is not\r \r gonna impact the baseline functionality\r \r of said package.\r \r It's just an enhancement on top of it. I admit sometimes it's hard to find that good, like, threshold of when you go to import only or when you go to suggest only. I think that comes through experience. But for me, it also depends on what context you're gonna be releasing this package in.\r \r\n\n[00:24:04] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. I would agree. You know, I think I'll default here and punt a little bit and say that the our packages\r \r book, which is authored by Hadley Wickham and and maybe Jenny Brian and and a few others,\r \r don't quote me on that. I think has some really good discussion\r \r about\r \r when to list a package as a hard dependency versus a soft dependency, and and also\r \r how to handle, you know, packages that are just being used. This is something that we run into a lot, packages that are just being used\r \r in a vignette, you know. And ggplot2\r \r is one for me that that\r \r happens quite a bit with because, you know, maybe I I don't have any functions\r \r within my package,\r \r itself that, you know, leverage ggplot2. We're just returning data. But in my vignette, I wanna show how this package can be useful to users. So I I wanna build a beautiful chart,\r \r you know, and have that be on our package down site and folks come and see that and look at that and be like, wow, this is what I can do with this package. But not necessarily, you know, auto plot anything for them because I have plenty of opinions on why I don't necessarily like like functions\r \r that do that. We just try to return the data and let you, you know, use ggplot2,\r \r use Echarts for r, do do whatever you want, GT,\r \r to make it beautiful.\r \r\n\nBut,\r \r I guess one other thing that I will add as an anecdote here that that Swan mentioned, which I think is really good advice is when you are managing the dependencies,\r \r you know, within your particular package, highly recommend using the the use this, use package function,\r \r which will handle,\r \r not only, you know, where things should be listed within that description file, making sure you don't have anything duplicated in there, but also it will handle the relationship between that description file and your namespace file, and any updates that need to be, taken on that name space file, which should not be done by hand,\r \r which is highly recommended. So I I would recommend leveraging that package. Just another\r \r example where use this can be awesome.\r \r\n\nI had\r \r had a I'll try to keep this brief, but we developed an open source package\r \r recently that actually downloads some publicly available data that's stored as a zip file on a website.\r \r And when it downloads, you know, onto my machine or or onto any of our our,\r \r company resources, local machines, any of my teammates machines,\r \r the the data comes in, and it's it's strange data set in the zip file of these text files, where, say, there's say, there's 4 datasets,\r \r for example.\r \r There would be 8 text files total. The first four would be the column headers,\r \r and then the next 4,\r \r would be the actual data itself without column headers. So you just have to stitch them together and and, you know, file 1 is the headers for the data in file 5. You know, file 2 goes with file 6. File 3 with 7 and 4 with 8. You can match them up. They're they're ordered that way when you download them online.\r \r\n\nSo we never had any issues locally with essentially, you know, returning a data frame that matches the headers to the data itself,\r \r until we try to use the the with our package,\r \r in our unit testing to do this programmatically\r \r deployed\r \r to GitHub Action CICD.\r \r And when,\r \r we, you know, ran these tests locally, everything works totally fine because we just said, you know, you match file\r \r 1 with with file 5 and and 2 with 6, and so on, and so forth.\r \r When, the with our package\r \r ran, you know, on this this Linux box, probably,\r \r on GitHub actions,\r \r the files that got unzipped from the zip folder\r \r got unzipped\r \r in\r \r strange orders. Not the order that they were stored in. So just got totally totally totally reordered. And it was very difficult to figure out, you know, what the issue was that was was going on here. And, so we just had to write in a little extra logic that uses the naming conventions of the filenames to match them together, which wasn't a big deal at all. But we couldn't rely on the order that those files came in because for whatever reason, when this this ran on GitHub actions,\r \r and unzipped these files, they unzipped in a totally different order than what took place locally for us. So,\r \r you know, just an example of how you can pass all of your checks locally, but not necessarily,\r \r when you, you know, are running it in a separate environment, which is a good thing. I was glad that we ran into that issue, so that if for some reason, you know, somebody,\r \r leveraging our package experienced the same issue where the the files unzipped in a different order,\r \r you know, our our functions would still work.\r \r\n\n\n\n[00:28:41] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 41,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Boy, is that is that just par for the course. When you see the expect the unexpected, so to speak, when you put in things in CICD, I I had a similar thing, albeit it was more of me shooting myself a bit in the foot on this. But\r \r I was doing a pipeline in GitHub Action. It's not an RPAC. It's about a set of functions that grabs a SQLite database from online, does some transposing, does some massaging,\r \r does some fuzzy duplicate finding, and then sends it back out as S3 objects.\r \r Well, in my development, I was starting to do, like, date cleaning with the luberday package.\r \r I had installed it locally. I forgot\r \r to add it to my manifest for the GitHub action to install. And I actually was leveraging\r \r a friend of the show, Peter Solomis'\r \r DEPS package to make a JSON file of the dependencies. I just forgot to rerun that darn thing and then commit it. So I'm like, wait. That worked fine on my machine. I was like, well, dependencies again. So it happens even in non package context. So you just gotta gotta keep keep the vote of keeping that stuff up to date, whether it's an rmblock file, a dep.json,\r \r or whatever else. Just, yeah, keep that stuff up to date, man.\r \r\n\n\n\n[00:29:51] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 51,
        "trans_speaker": "Mike Thomas",
        "trans_text": "It's hard. It's hard. There's a lot to it. But in my opinion, it's it's super important because we want the user experience of others, you know, using the software that we create to be\r \r as as high quality as possible.\r \r\n\n[00:30:04] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That's, it's all the name of the game, isn't it? Yep. But, really entertaining read here and very informative too. So credit to thank Arver\r \r sharing her knowledge of the developments in the trenches, so to speak.\r \r And, Mike, yeah, those are the 22 pretty heavy content highlights here. And we're going to have some fun with this next one because\r \r I like me a little game now and then.\r \r So our next highlight is going to do a little fun classification\r \r magic to hopefully help you win this game even even faster than you might expect.\r \r And this is coming to us from Michael Hoe,\r \r professor in statistics\r \r and data science at the University of Gresfel, Germany.\r \r\n\nAgain, pronunciation is not my strong suit here.\r \r But he starts introducing this blog post about a game that he likes to play\r \r called guess my name\r \r where each player will have a card with 16\r \r kinda avatars on them. They each have different, like, you know, hair color, maybe slightly shirt, you know, different genders, all that.\r \r And the object of the game\r \r is the each player will pick who they wanna represent on this game, but then the opponent\r \r has to ask\r \r questions\r \r to help narrow down who that opponent would actually be on on the board itself.\r \r And they can only ask questions about the picture of the person,\r \r and they must and they the response to that must be either yes or no. So you can kinda start crossing off who is not and then figuring out eventually who that person actually is. So, of course, naturally, the winner of the game is gonna be one that finds the answer in the least amount of questions.\r \r\n\nAnd so Michael, what he does in the first part of his post is actually compiles a spreadsheet of all the about 12 questions that we will logically ask in this game\r \r amongst then the players that this these questions would represent.\r \r So you can download that spreadsheet right off the the blog post if you want to look at that for reference. He's got a snippet of it in the post itself such as, like, do they have headgear, do they have glasses,\r \r blonde hair, etcetera, etcetera.\r \r Now\r \r that doesn't that's a great starting point. Right? But\r \r what where do you help determine\r \r what should you ask first in order to maximize your chance of winning?\r \r\n\nIt's decisions, decisions. Right? Well, literally here because we're gonna look at decision trees as a way to help take a data driven approach\r \r to find the solution.\r \r This is not something I would have expected, but it's a pretty clever use\r \r of the classical\r \r classification\r \r tree method\r \r where he feeds in the data.\r \r In this case, like I said, that spreadsheet\r \r of questions and then the membership of each person responding\r \r yes or no to those questions,\r \r throws it in in our part,\r \r call after it does some massaging of the data.\r \r And then the rest of the blog post now gives you a decision tree\r \r that you can use as a strategy going forward\r \r for how you might identify these players.\r \r\n\nSo\r \r if before seeing this post, Mike, would you have guessed that the first question that someone should ask is whether the player has blonde hair?\r \r\n\n[00:33:31] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 31,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I wouldn't have guessed that, but it has been a little bit, of time since I last played,\r \r a game like this. I think there's a game\r \r very, very similar. Maybe it's it's more US based. And I think it's called called Guess Who. Played it a lot when I was growing up and it you know, you you flip the flip the people up and down after you ask questions, and it's kinda like a 20 questions game to see who who can figure it out first. So this sounds like exactly\r \r the same thing. And if I remember correctly, I think that was one of my one of my top questions. Does the player have blonde hair? You know?\r \r And trying to narrow down,\r \r who the person is that you're you're trying to get at. But I guess it all depends on, it all depends on your on your strategy and the the data or or the people that you have on your on your card.\r \r\n\n\n\n[00:34:17] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That's right. And so when you look at this decision tree further,\r \r once you get through that initial question, then we start branching off into questions like, is the is the picture have something green in it or something red? So you're looking at color next across the entire picture.\r \r Now the type of gear they're wearing, is there some headgear?\r \r Is there a short sleeve or a long sleeve shirt visible?\r \r Alright. Can we see the eyebrows or the glasses? Like, it is a very interesting\r \r dichotomy here of where you should go next. But,\r \r yeah, it just shows you\r \r another clever use\r \r of classification\r \r methods, which, again, are typically the backbone\r \r of almost all types of machine learning, especially in the dichotomous approach\r \r where you're trying to optimize that response or\r \r predicting a response.\r \r\n\nThese are the fundamental building blocks. Obviously,\r \r if you're in a more rigorous analysis, you might look at other methods and classifications\r \r as a random forest, GBM, and the like. But if you ever want a gentle introduction to what classification\r \r trees are actually doing,\r \r with a little,\r \r perhaps,\r \r ways you can use this in your in your activity time later on on the weekends, this, you could do a lot worse than seeing what Michael's post has here. No. This is a super super cool, super fun application. I guess not something that I've I've seen too often in the highlights before. We've seen some exercise data,\r \r\n\n[00:35:42] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Mike Thomas",
        "trans_text": "you know, before, but in terms of actually, like, playing a game, I think this is is super cool, and a great use case, and I think a great learning case for leveraging decision trees and the the r part package itself. You know, sometimes I think algorithms can be explained best on, like, small data sets where you can see sort of exactly\r \r the decisions that are being made by the algorithm or or how the math really plays out.\r \r Just as a another final story\r \r for for the week, I do have somebody in my family. I'm not gonna name names. But when we play Clue,\r \r they essentially\r \r need a laptop with Excel open next to them to be able to sort of track\r \r everybody's\r \r responses\r \r in a spreadsheet,\r \r which is way over the top,\r \r analytics approach.\r \r\n\nAnd,\r \r to be honest, they they actually are the person that that usually wins, which makes me feel like I need to to do something during that game. But I'm off the clock, you know, so to speak, when I'm playing board games. So I try\r \r not try not to go\r \r try not to pull out all the stops. But if this person does keep winning, I may have to spin up r in something like this and come back to Michael's Michael's post because I think a decision tree type of approach is is not only applicable to this particular game that we're looking at here, but, Clue is another one that that comes up for me that would be a fantastic\r \r use case and application\r \r for leveraging something\r \r like a decision tree, because it's a question based game as well, where you're trying to sort of narrow things down,\r \r into the the smallest, you know,\r \r number of pieces of information that sort of give you the\r \r the the best idea of of what the true answer is at the end of the day. So,\r \r\n\n[00:37:24] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 24,
        "trans_speaker": "Eric Nantz",
        "trans_text": "that that's the end of story time for me for this week. It does make me think, albeit it probably have to use even more rigorous methods for this. But as a kid, I loved playing that game Battleship\r \r and trying to figure out which space should I target first. And then based on that, knowing that it didn't hit, how far away should I go from my next target? I could sense there'd be a lot of fun data driven approaches to that.\r \r But for those of you listening, if you're interested in more the technical math behind\r \r this idea, well, the blog post has a terrific appendix here where you can really, really get get to school, so to speak, on how classification\r \r methodology works here. Michael does a terrific job with kind of the mathematical\r \r optimization formulas that are under the hood. There's also some nice visuals along the way. So this is if you're in in a situation and trying to learn about classification\r \r in general, like I said, not only do we get the the fun intro of this post, but also the the appendix is really giving you a lot of great details for how this all really works under the hood.\r \r\n\n\n\n[00:38:29] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Absolutely. No. That break that battleship. Oh, that's that's another good one. Where to where to guess next? That kinda, like, brings me to the Monty Hall problem a little bit, like, which door should you pick based on the first door that you you selected? I once I don't know. Spent spent too much time with an actual deck of cards trying to prove out whether the Monty Hall\r \r problem and solution was actually the right way to go and and that was probably my first introduction into into Bays without really knowing it.\r \r\n\n[00:38:55] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 55,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Isn't it interesting? It's almost everywhere in your life, but you just may not realize it until it's all in Chelsea.\r \r Yeah. Well, you make me wanna play games the rest of the day, but, unfortunately, I won't be able to do that. But what we can tell you, though, is that the rest of the hour week, we issue as a terrific section\r \r of additional\r \r resources, tutorials,\r \r blog posts, new packages, updated packages,\r \r tons more to choose from. So we'll take a couple minutes here to talk about our additional highlights here. And sticking with the earlier part of the show, looking at great uses of ggplot2\r \r for EDA\r \r and whatnot,\r \r there is a terrific package\r \r called g g magnify.\r \r\n\nThis has been authored by David Hugh Jones, who I believe we have featured on the highlights before,\r \r where, in essence, you can take a ggplot object,\r \r and then within that same plot,\r \r draw a boundary\r \r of, in essence, a panel\r \r that you can then use as zooming in on those particular data points and put that in a section on the same plot.\r \r This is pretty interesting to me because\r \r now,\r \r obviously, I'm a big fan of interactive graphics and interactive HTML where if you had this in, say, PlotViewer or not, you could just do the, you know, the zooming of a particular plot in real time, get those coordinates, and then zoom back out. But if you're in the realm where maybe you're confined to static representations,\r \r then gg magnify might be a really interesting way for you to call out a particular section of that scatterplot\r \r or that distribution\r \r plot and then be able to really emphasize just kinda what's happening in that subregion\r \r of the plot while maintaining, you know, a good clever use of space and whatnot. So gg magnify, I never heard of this one before, so I'm gonna put that in my\r \r visualization bookmarks to follow-up with later on.\r \r\n\n\n\n[00:40:48] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Mike Thomas",
        "trans_text": "No. That's a great one, Eric. I'm gonna shout out, Romain Francois for his blog post\r \r on the request perform stream,\r \r function from the HTTR 2 package, and how he found a bug and submitted a pull request as well. So he actually asked it. And I don't know for folks who are connected to him on social media, you may have seen that he has authored a package recently,\r \r that will write a Valentine's or not necessarily Valentine's Day poem, but I think will write a poem for you, I believe, leveraging chat GPT\r \r about anything that you want. I think it started out around Valentine's Day,\r \r which is\r \r is where I saw it first. And he actually ran into an issue\r \r asking\r \r the,\r \r Chatter package, which is from, I believe, the the ML verse, which leverages chat GPT,\r \r which I know a lot of tangential packages have been built on top of at this point. He was asking it to write a\r \r poem about Gollum, and he asked it to use many many emojis,\r \r in in that poem.\r \r\n\nAnd, unfortunately,\r \r he received an error. And one of the reasons for the error, or I think the big reason in particular,\r \r is that,\r \r the this package, Chatter,\r \r leverages the h t t r two package, and and obviously streams back the response\r \r from the ChatGPT\r \r API.\r \r And it streams it back in in chunks of bytes.\r \r And, unfortunately,\r \r it was cutting off an emoji\r \r in the middle of the number of bytes within that emoji because it's encoded as as a few bytes. And it couldn't essentially stitch together the emoji from 2 separate chunks\r \r of bytes, if you will. So,\r \r this was, I guess, you know, an unexpected\r \r bug, and,\r \r Romaine went as far\r \r as submitting a pull request to the h t t r two package about a way to go about this.\r \r\n\nPotentially, I think using the the read lines function instead of the read bin\r \r function. And there's, actually, I mean, you can go into the pull request. It's it's linked in the blog post, and you can see, you know, the fantastic\r \r conversation, the way that he frames\r \r the problem to the Rlib,\r \r team that manages the h t t r two package. You can see his back and forth conversation\r \r with with Hadley Wickham on how they eventually went about and resolved,\r \r and closed this this pull request, and resolved this bug, and merged it back into main. So now, if you are installing the htrt2\r \r package from from GitHub, and hopefully soon from CRAN,\r \r you won't run into the same issue that Romaine ran into when trying to,\r \r ask ChatCPT\r \r for a response that includes emojis.\r \r\n\n\n\n[00:43:39] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 39,
        "trans_speaker": "Eric Nantz",
        "trans_text": "My goodness. Yeah. You saw my rabbit holes. Right? I mean, that credit to Romaine and Hadley for finding a a now we can fix this because this is this is an area where I take for granted that all these symbols are just gonna work no matter if we're passing data in or taking data out. Oh, there's a lot behind those emojis, folks.\r \r It ain't just the fun graphics. There are a lot of these raw bytes and bits that if you're not you're not taking it correctly\r \r because we're involving, like you said, the APIs of chat GPT and what this chatter package,\r \r knowing what's being handed off, that can be quite important. So, well, credit to credit to Romaine and Hadley for putting this together. And, yes, at the end of the post is a very lovely poem about one of our paper packages called Gollum that will never cease to amaze us.\r \r\n\n\n\n[00:44:26] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 26,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Absolutely. And I think, you know, it's also if you if you do sort of follow that pull request, it's just a great example\r \r of how to contribute to a package and to make it easy on the on the maintainer or as easy as possible on the maintainers to get that bug fixed.\r \r\n\n[00:44:42] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Excellent. Excellent. And you know what else makes it easier for you to learn about what's happening in the data science and the art communities? Well, that's where you just bookmark our weekly .org.\r \r Have you have checked that out every Monday morning. We have a new issue released\r \r like this one we talked about here. But, of course, the entire back catalog\r \r is also available. You can see right on the home page.\r \r And, of course,\r \r this is a project by the community, for the community.\r \r The lifeblood is you and the community. So we love your poll request. We love your suggestions.\r \r You can get in touch with sharing that resource via poll request. We just thought about poll requests. Right? Our weekly is very embedded into that workflow. The link is directly on each each issue's\r \r front page where you get a link to the upcoming issue draft for next week. You'll be able to quickly send your poll request there. It's all marked down all the time. Very easy to get up and running quickly.\r \r\n\nAnd, also, yeah, we're always happy if you wanna join the team as a curation role. We definitely have spots, and we have links so you can get information on that at r wicked.org.\r \r And, of course, we love hearing from you and the audience as well. You have a few ways to get in touch with your humble host here. One is the contact page. We have the link link directly in the episode show notes.\r \r We also have a fun little if you have a modern podcast app like Paverse, Fountaincast O Matic, and whatnot, you can send those fun little boosts along the way, which is directly from you to us in your favorite podcast app. And, of course, we have,\r \r some presence on the social medias.\r \r\n\nI am mostly on Mastodon these days with at our podcast, at podcast index.social.\r \r Sporaglia on the weapon x thing with at the r cast and then also on LinkedIn\r \r sharing some posts and other fun announcements from time to time. And, Mike, where can the listeners get ahold of you? Sure. You can find me on Mastodon as well at mike [email protected],\r \r\n\n[00:46:39] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 39,
        "trans_speaker": "Mike Thomas",
        "trans_text": "or the other place that I am present on social media a lot is on LinkedIn.\r \r If you search Ketchbrook Analytics, k e t c h b r o o k, you can probably find out what I'm up to.\r \r\n\n[00:46:50] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome stuff. Like I like we heard about before. Congrats on that recent package you open sourced. I'm sure there are lots of fun stories behind that as well that you'll see on Mike's, LinkedIn post from time to time. So Yes. Thank you.\r \r Absolutely.\r \r So we're gonna close-up shop here for episode 153,\r \r and we hope to see you back for episode 154\r \r of the Our Weekly Highlights podcast\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_08_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "chap_timestamp": 15,
        "chap_text": "Cycling EDA"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "chap_timestamp": 38,
        "chap_text": "Tame your package namespace"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "chap_timestamp": 24,
        "chap_text": "Guess my name with decision trees"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "chap_timestamp": 1,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_08_highlights",
        "chap_timestamp": 42,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_07_highlights",
        "ep_date": "2024-02-14",
        "ep_duration": 50,
        "ep_description_short": "A few great tips for ensuring your R package doesn't \"talk too much\" (within reason), shrinking down the size of your images with a new API directly available in a new package, and the first opportunity in 2024 for submitting your proposals for R Consortium projects is on the horizon. Episode Links This week's curator: Jon Calder (@jonmcalder…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_07_highlights",
        "description_long": "\r \r\n\nA few great tips for ensuring your R package doesn't \"talk too much\" (within reason), shrinking down the size of your images with a new API directly available in a new package, and the first opportunity in 2024 for submitting your proposals for R Consortium projects is on the horizon.\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder) (Twitter)\nPlease Shut Up! Verbosity Control in Packages\nR Consortium Infrastructure Steering Committee (ISC) Grant Program Accepting Proposals starting March 1st!\nOptimize your images with R and reSmush.it\nEntire issue available at rweekly.org/2024-W07\n\nSupplement Resources\n\n{lifecycle} Manage the life cycle of your exported functions and arguments https://lifecycle.r-lib.org/\n{logger} lightweight, modern and flexible, log4j and futile.logger inspired logging utility for R https://daroczig.github.io/logger/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nSunny Side Up - Yoshi's Island DS - ZackParrish - https://ocremix.org/remix/OCR04558\nSalut Voisin! - Final Fantasy IV - colorado weeks, Aeroprism - https://ocremix.org/remix/OCR04553"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://ropensci.org/blog/2024/02/06/verbosity-control-packages/"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://www.r-consortium.org/blog/2024/02/08/r-consortium-infrastructure-steering-committee-isc-grant-program-accepting-proposals-starting-march-1st"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://dieghernan.github.io/202402_optimize-images-r/"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://rweekly.org/2024-W07.html"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://lifecycle.r-lib.org/"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://daroczig.github.io/logger/"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://ocremix.org/remix/OCR04558"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "links": "https://ocremix.org/remix/OCR04553"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with episode 152\r \r of the R Weekly Highlights podcast. We're happy to join us wherever you are\r \r around the world. And this is the weekly show where we highlight, no pun intended, the awesome, highlights section of the our weekly website,\r \r particular issue atrog.org.\r \r My name is Eric Nansen. Yeah. We're almost midway through February. This has always been the time of year where I kinda wanna get to spring now, you know, just to cheer things up a bit. But, yes, we are back, and I'm not alone. I'm always joined at the virtual hip here by my awesome cohost, Mike Thomas.\r \r Mike, how are you doing today?\r \r\n\n\n\n[00:00:40] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Doing well. Waiting on spring. Also,\r \r we had about 60 degree weather here in New England this past weekend. And today, we got a foot of snow. So\r \r\n\n[00:00:50] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Them's the brakes. Them's the brakes, man. It just never ends, does it? Yep. But\r \r we'll get through February soon enough. But, one way to speed things up is listening to those banter about this week's our weekly issue.\r \r And if you're not familiar with the project, every week, we have a new curator\r \r to to take the reins. And this week, it is John Calder, another longtime member of our curation team. And as always, he had tremendous help from our ROCE team members and contributors like you all around the world.\r \r So I wouldn't be shocked that if some of you listen to this podcast, there might be a section or 2 when you might hear yours truly kind of ramble, but you'd be like, yeah. Yeah. We get it, Eric. Maybe tone it down a notch. Well, guess what? That can also happen with our packages as well,\r \r especially those that like to, you know, through no fault of their own,\r \r give you a heads up through messages or warnings or other diagnostics\r \r as, you know, operations are commencing\r \r analytics.\r \r\n\nBut there may be some cases where you want the user to kind of be able to opt in or opt out of this kind of behavior.\r \r So our first is gonna talk about, as a package author,\r \r how you can take advantage\r \r advantage of some nice utilities both within r itself and within the r ecosystem\r \r to help give you a give your package users a little more control\r \r on the verbosity,\r \r so to speak, within their package experience.\r \r And this comes from the awesome rOpenSci project once again. In particular,\r \r the blog post has been authored by Mark Padgham, who is a open source\r \r software developer at rOpenSci as well as, returning once again, Myles Salmon. The street continues with highlights that she's involved with. And this blog post starts off with,\r \r basically, if you've written any package or function, you've probably have done this once or twice or, frankly, in my case, a lot more where you have a function. You know it's going to do some complicated stuff. And especially for you as a developer, you want to see what's happening in your console as things are\r \r being processed.\r \r\n\nAnd you might have an argument\r \r that says something like verbose or quiet as a simple true or false just indicating,\r \r you know, a little switch to turn that diagnostic on and off.\r \r It's spread throughout the R ecosystem. You're going to find many, many functions and packages\r \r that have this approach.\r \r But\r \r as they say in the blog, it could introduce a bit of clutter\r \r and making the user have to customize this every time for each function.\r \r Well, maybe instead, the approach you might wanna take\r \r is having this configured at the package level.\r \r And that's where using an option statement could come in quite handy as you, the package author,\r \r where you might have an option talking about, you know, is my package message gonna be quiet or not?\r \r\n\nAnd then the user could set that option themselves,\r \r run the function\r \r without having to introduce another parameter in that set function.\r \r And then maybe they want\r \r the situation switched, they can just run that option again,\r \r rerun the function without any changes to the function code or the function call,\r \r and it will give them the behavior they want.\r \r So that is one approach, and we're starting to see more of that.\r \r But, you know, guilty as charged here on this very podcast. I have not done this much enough, but I'm definitely thinking about,\r \r this approach.\r \r\n\nNow there as usual, there are community, you know, you know, comes to the rescue again, so to speak. If you\r \r want to tap into somebody kind of doing this boilerplate for you, so to speak,\r \r guess what? There is,\r \r packages that we talk about on this show quite a bit, the CLI package and by proxy, the rlang package, which is actually, you know, building a lot of this functionality with their own equivalent\r \r of, like, the typical message,\r \r warning, and stop functions that you find in base r.\r \r And so you can opt into using rlang and CLI\r \r in your package if you want to take a dependency on that to kind of mimic this kind of behavior at a package level.\r \r\n\nThey have functions called, like, inform,\r \r COINFORM.\r \r And then there are options that you can tweak at the COI or rlang level\r \r that could\r \r your package could tap into.\r \r And so that is another great approach if you just want to take advantage of other great work in your package to control verbosity.\r \r Now there are some things that you wanna consider with that,\r \r especially\r \r if you think about, you know, how deep you wanna go with this.\r \r One of those is just simply\r \r how do you wanna control the level verbosity.\r \r\n\n[00:05:42] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 42,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. So one interesting thing that I've seen done in a lot of packages that I've used, but never really knew exactly how to implement it in some of the packages that we've authored\r \r is the idea of displaying a warning or a message only once per session. I think that's that's really interesting. I think it's really powerful because it sort of lets lets you know, okay, this is something that you should be aware of but we're not gonna continue to to throw it in your face over and over and over again. And, I think that's really useful, probably a nice feature of the the R ecosystem. I don't know if that really that concept exists in other ecosystems\r \r as well.\r \r\n\nBut, you're able to do that by setting, the frequency parameter\r \r of the rlib message verbosity options\r \r to the string once,\r \r which I hadn't seen before. So there's a great little section here that talks about exactly how to do that and I am looking forward to trying to implement that in some of the packages that we've developed because I think that could be a much better user experience,\r \r to just be able to display some of these these messages or warnings, only one time per session.\r \r Then Mel also talks about and, excuse me, not just Mel, but Mark as well,\r \r also talk about,\r \r regaining package level control\r \r from your global options. And and this is sort of the issue\r \r that takes place when you have dependencies, right, upon other packages that are using our lang or CLI or with our\r \r to display messages, and you don't necessarily\r \r have as much control\r \r to turn that verbosity\r \r on and off because it's it's not your package. It's not your code. It's a dependency,\r \r of your package. So there's a a really nice couple of code snippets in here that employ the local options function from R link, which is really interesting. And that would allow you to essentially locally,\r \r within the function that you're authoring, turn on verbosity\r \r or or off. So you could set the r rlibmessage\r \r verbosity,\r \r as as verbose\r \r or wants or or essentially whatever you want and control that sort of in this to me, it feels with R ish,\r \r but it but it's a function called local options from the rlang package that allows, you know, within that function to to handle the verbosity specifically.\r \r\n\nAnd I think that a lot of these concepts and code snippets can be\r \r especially helpful when you are developing your package or debugging your package because maybe you you know that this warning message is going to pop up, and you're you're trying to do a lot of little tweaks and you don't necessarily wanna see that over and over and over again as you develop.\r \r But, obviously, in in the production version of your package that you're going to release out to the world, you you do want those warnings to pop up to users who aren't going to be running the same exact function over and over and over again like you might be doing during development. So I thought that that was a really powerful concept too. There's some fantastic,\r \r R code snippets\r \r as well. And it's a really great overview and blog post around this topic of verbosity, which which, again, Eric, I think is pretty unique to the highlights and not one that we see too often. And it gets back to really usability,\r \r user experience,\r \r and, you know, how easy it is for other folks to be able to to use and be comfortable with your r package. And to me, the little things go a long way. I know you feel the same way. That's certainly a a shiny concept as well, but I think it it extends very much, into our package development to try to make the tools that we create as useful as possible to others.\r \r\n\n\n\n[00:09:18] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 18,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. It was really excellent,\r \r summary here. And, also, I\r \r I kind of laugh about this, but I stumbled into this by happy accident almost as I'm updating an internal package at the day job where\r \r I'm deprecating a couple of function arguments in favor of a more simple third one.\r \r And I tapped into, you know, looking at the r packages online book, talking about their deprecation section, and I saw a package called life cycle, which is what the tidyverse often uses to give these messages. And, apparently, they default to once per session, as you said, with the Arlang options\r \r of, hey. This function parameter for, like, say, tidy r, gather, or spread is deprecated. Please use this instead. And lo and behold, I was able to tap into that with my internal package as well where, you know, for it's been over\r \r 5 years of existence, if not longer. And it's only now that I'm introducing this, in essence, soft deprecation right now.\r \r\n\nAnd then a version later, it's gonna be like it's gone after that. But I'm being nice right now and saying, hey. Guess what? Use this new path argument, not these, like, 2 arguments instead. And this Boeing display once per session, so they don't get annoyed by it, but enough to get the hint. So it's nice that life cycle is just another one in these packages. We wanna see how\r \r others wrap the use of Arling or COI. That's a great demonstration of it. And, yeah, Mike, it's something where I just haven't done this a lot in practice, but\r \r seeing what options are available, whether it's just a simple Boolean to turn it on and off or the different levels of it. Another great complement to this as well, if you wanna do more systematic\r \r messages and maybe parse by other systems,\r \r a lot of these concepts also apply with the logger package,\r \r which I've been using quite a bit in my more back endy kind of package development in Shiny apps where I need to send that session kind of operation pipeline\r \r diagnostic\r \r to not just the r console, so to speak, but also to, say, a database where I'm keeping track of all the activity\r \r so I know where maybe some of the gotchas are that or where time is being spent on my app or my package. So there's lots of the principles here can apply in many different ways. So it's really, really good to see here.\r \r\n\n\n\n[00:11:34] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I couldn't agree more, Eric. And those are 2 great shout outs to the life cycle and logger package. I think that complement these concepts,\r \r similarly.\r \r\n\n[00:11:52] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Speaking of compliments,\r \r I I don't have a great segue for this, but I'll go with it. Bear with me, Mike, here. But, you remember the early days of the Internet when you would load these pages that were, you know, configured by frameworks like GeoCities,\r \r things like this? And\r \r there might be a page that you found that's kind of entertaining. But do you notice that\r \r it's taken a while to load?\r \r Has this big image, and it just scrolls slowly, slowly, slowly, slowly into focus until it's finally rendered.\r \r That's one of those cases where an image was probably uploaded in its most raw form possible, you know, straight from whatever software they use to produce it or or camera that they took a picture of. Who knows what else?\r \r Well, this can also happen if you're developing or writing a blog, maybe with R Markdown or another framework.\r \r\n\nAnd you notice that, yeah, that image you put on there,\r \r that's that's a bit hefty.\r \r Well, there are ways that you can,\r \r optimize that for web viewing or other documents that you want to minimize the footprint of. That's where our second highlight comes in. This is a blog post called optimize your images with r and the resmush\r \r API,\r \r fun name.\r \r This is authored by Diego\r \r h. I couldn't quite track down, what he does, but, apparently, he is part of the rOpen Spain project, which is quite intriguing.\r \r But he talks about a recent need that he had in in his,\r \r in his work with one of his package vignettes,\r \r such as his package called TidyTerra, which has a lot of images.\r \r\n\nAnd he likes to include precom precomputed\r \r images or precomputed results in his vignettes.\r \r And he noticed that that was producing\r \r higher size file size images that\r \r maybe the CRAN maintainers wouldn't necessarily like in big nets and such in PDF form or whatnot.\r \r So he decides, write this r package that ties into this, service called resmush\r \r where it's an API.\r \r And this is interesting. It's freely available.\r \r Don't need your API keys for this, at least yet, where it'll give you for an image of, say, 5 megabytes or less, it'll give you a way to compress that with various optimization algorithms.\r \r Throw your PNGs or JPEGs or bitmaps or whatever have you,\r \r and it will give you that compressed image.\r \r\n\nAnd with the demonstration in this blog post, it really looks\r \r like no discernible difference.\r \r Really top notch, easy to use.\r \r And it seems like this is a great use case for not just\r \r those static files you might produce as part of a standalone document,\r \r but it looks pretty online as or friendly for online files as well.\r \r So I yeah. I'm intrigued by this. I never heard of this service before, but curious, Mike, if you had to deal with image sizes and looking for a way to optimize those further like this? I have but,\r \r\n\n[00:14:56] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Mike Thomas",
        "trans_text": "you know, I haven't found a great tool for optimizing image sizes. So this blog post is is very, very timely. It's it's pretty incredible to me that he was able to get\r \r this, you know, geospatial\r \r image down from from 1.7\r \r meg to,\r \r like, what is it?\r \r 762\r \r kilobytes?\r \r I mean, he almost took an entire meg off of this image size and I can't tell\r \r the difference at all. And obviously, when we are submitting packages\r \r to Kran, I think 10 meg is the\r \r the top,\r \r the largest\r \r package size that you can submit to to Crayon, if I'm not mistaken, Eric. Does that sound right? That sounds about right. Yeah. That sounds right. So I mean if if you have vignettes, detailed vignettes, especially that are containing images and things like that, that can you can hit that fairly quickly\r \r with some of these additional assets like images and it makes it very difficult.\r \r\n\nI will say this blog post is going to be super helpful for some folks who are trying to create detailed vignettes, with images\r \r that are looking to to ensure they stay under that CRAN threshold.\r \r It looks like resmush,\r \r allows\r \r a lot of different formats that all of some of the existing packages like XFun,\r \r TinyR, OptOut,\r \r maybe handled a couple of these cases like PNG\r \r and JPEGs,\r \r but but not necessarily GIFs or bump files or or TIFFs or PDFs. And ReSmush handles all of these different formats, I guess, except\r \r PDF. It looks like it's the only format that it doesn't handle. But, obviously, I think most of the time when you're you're working on image compression, you're you're typically working with probably a PNG or a JPEG or a TIFF file or something like that, on the case of some of these geospatial\r \r images. So this is super handy. One of the other things this just reminded me of that I I will call out as well is if you are trying to create very thorough documentation\r \r around your R package,\r \r particularly with a package down site,\r \r you'll often see a section on the package down site that has articles on it. And initially, I thought that that was just sort of an, representation of the vignettes that you have in your R package.\r \r\n\nAnd it is. But you can also do something called create an article, which is not a vignette, but it lives on your package down site within,\r \r you know, within that same article's\r \r section, but doesn't\r \r go to CRAN if you were to essentially submit that package. It's it's it's ignored from from the r build, and you can create one of these\r \r articles, if you will, using the use this package, use article\r \r functions. That's really handy, I think, when you are trying to, you know, add additional documentation\r \r around your package that isn't necessarily a vignette that that folks using your R package in an interactive setting within an r an IDE\r \r necessarily need to be able to have access to. You know, as long as they have an internet connection, they can go take a look at, this this article's\r \r section on your package down site. And it's not something that's going to be built as part of your r package. So it'll help save that size if you are looking to keep your package size, smaller. So I think these are all fantastic resources. I'm excited to check out the re smash\r \r package. It looks like it takes advantage. Eric, you you may have mentioned this, of this re smush dot it,\r \r free online API,\r \r that does a lot of the horse work here, which is is pretty cool. So shout out to that service\r \r as well, and and shout out to Diego for this awesome r package.\r \r\n\n\n\n[00:18:33] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Absolutely. And, apparently, this ReSmush,\r \r service has been used heavily in\r \r content management frameworks like WordPress, Drupal. I mean, those things may sound familiar. So, apparently, it's got its battle tested as they say. So I'm curious to\r \r give it a shot. And and not to sound too meta here, but in our weekly itself, whenever you see images in each issue,\r \r we actually do have some routines that go through the images that the user\r \r has linked to.\r \r And we we used to have an automated way of doing this. Now it's a script way of doing it where we compress those images using some other utilities. So I'll have to see if Resmush can give us an even better take on that. But it is a nice segue to say that there are more than one way to do this in the our ecosystem. So,\r \r Diego's blog post below talks about some functions packages\r \r from EWAY, who, of course, we've mentioned many times on this very podcast.\r \r\n\nHis x fund package has two functions called Tinnify\r \r and OptiPNG\r \r that if you have those utilities\r \r on your system,\r \r well, one uses a service called tiny PNG, an API service.\r \r Another uses an OptiPNG\r \r system library.\r \r So, yeah, you may you may find that there are other routines in your ecosystem that can help you just as much as the resmush one. But it's a good roundup at the end of the blog post if you wanna see just what is available in this space because,\r \r as usual, there's always more than one one way to handle it.\r \r These will have their advantages and disadvantages. But, hey, an API service that's free to use,\r \r it almost sounds too good to be true, but, apparently, it's still there. So we'll we'll keep leveraging it, I guess, after seeing this blog post.\r \r\n\n\n\n[00:20:16] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Free to use and no API key. It's pretty incredible.\r \r\n\n[00:20:33] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. And wouldn't it be nice, Mike, if everything we could do just didn't really have a big cost to it or much time involved? It just magically worked. Well, sometimes you have this idea\r \r for a major project that can benefit\r \r perhaps the entire our ecosystem,\r \r whether it's a package or a suite of packages\r \r or to help with community efforts as well. Well, this is a time of year.\r \r If you wanted some backing for it, this is the time to think about it because our last highlight is more of\r \r a, my call call to action or public service announcement here where\r \r the our consortium\r \r for another year is about to\r \r open their proposal,\r \r opportunity\r \r for their infrastructure steering committee to accept, you know, proposals for grants backed by the r consortium project itself. So if you're not familiar with the r consortium, as we talked about quite a bit on the podcast, but just to state a brief background of it, it is\r \r a joint\r \r collective effort of multiple industry\r \r multiple companies within industry as well as the R Foundation\r \r to help bring\r \r support for infrastructure\r \r of the R project itself and community efforts that support the mission of R itself.\r \r\n\nAnd so starting March 1st this year, they will have\r \r the open,\r \r open call for proposals.\r \r And you may wonder what will these proposals look like. Well, guess what? On the our consortium site, they do have a section\r \r on all of the\r \r already funded projects. If you wanna get a familiar\r \r or you wanna get familiar of what's been funded before, both on a technical level\r \r and community effort.\r \r And this call for proposal is a bit on the technical side, but it can be used to help, you know, things with community efforts.\r \r Actually, a a listener of this very show, a regular listener, John Harmon, actually has been funded by the r consortium with this API to r\r \r package development, which is we've been keeping eyes on that in the suite of packages\r \r that John's been developing. That's been really fun to watch.\r \r\n\nWe've seen efforts like DBI\r \r go through the R Consortium, which is, of course, the\r \r translation\r \r of database\r \r APIs to R. That's been huge in my daily work and seeing DBI really take their infrastructure up, you know, a few notches.\r \r That was that was great to see\r \r as well. And like I said,\r \r technical efforts to bootstrap the community as well.\r \r So there's lots of opportunities here. So if you or a team\r \r are thinking of a way to help the R ecosystem,\r \r help the R community in general,\r \r and you want support from the R Consortium, this is the time to\r \r get those proposals ready to go. But I can speak from experience working in the ARC consortium and my,\r \r submissions working group. It's been a pleasure to work with them, and they've been instrumental in a lot of our life science efforts. So certainly, highly recommend to check that out.\r \r\n\n\n\n[00:23:34] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Mike Thomas",
        "trans_text": "No. And, again, this is one of those things that just makes me love the our ecosystem.\r \r You know, the fact that we have initiatives like the ARC consortium who are are trying to essentially,\r \r you know,\r \r further the science and improve the world\r \r using our software. And it's it's incredible. It warms my heart.\r \r So, you know, this is also another reason if you you have, you know,\r \r at year end,\r \r you start thinking about donations and causes that you or your company may want to support, you know, take a look at our open site, take a look at our consortium.\r \r I guess this is part of the Linux Foundation projects Correct. Which is is pretty cool. And consider, I would say, contributing,\r \r to one of these causes because because they're phenomenal,\r \r that they help everybody. And I do like the fact that this is both a technical and social\r \r sort of call.\r \r\n\nSo submit your proposals, check out the blog post. All the information that you could ever need is in here, including a link to learning more about how exactly you can submit that proposal. And, those important\r \r dates around the grant cycle are are March 1st,\r \r closes April 1st. So you have that that one month window. And then, I guess, there's a second grant cycle that'll be later in the fall of 2024.\r \r So keep your eye out. I'm sure we will,\r \r rehash this as some of these dates get closer.\r \r And looking forward to seeing what comes out of this next round of proposals.\r \r\n\n[00:25:00] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 0,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And, I I've got my eye on this in a few ways. So, that'll be the, teaser in this business to say stay tuned. But in any event, as you said, Mike, we're we're gonna continually keep an eye on this. And you may be wondering, well, how do you keep an eye on efforts like this in general? Well, guess what? It's all in our weekly itself. Right? Each issue does have a section on upcoming events. Maybe it's webinars or presentations where you might hear about these efforts, and there is a specific section on grants and funding proposals. So this is right in that very section. So that's why you if you haven't bookmarked our weekly, you definitely should. Am I biased? Heck, yes. I am, but in a good way, of course. And speaking of the issue, there's always more than just the highlights that we touch on here. So we'll take a few minutes to talk about the additional highlights that we found here. And for me, I found a, quite entertaining post\r \r from Angela who has the r critique blog\r \r about some of the discoveries she had about, quote, unquote, hidden objects.\r \r\n\nDefinitely had her, books like scratch her head a little bit.\r \r At a high level, what she discovered is that in r, much like you have in your Linux or Unix system,\r \r you might have, in the case of r, objects that have a period in front of their name.\r \r That's kind of in Linux and Unix, and I'm a clencher, to denote what we call a hidden object,\r \r which by default viewing, you're not gonna see right away,\r \r only if you do, like, a special option to show hidden files.\r \r Well, guess what? When she tried to wipe out objects in her Rstudio session\r \r using, like, the erase button in the environment pane or whatever it is,\r \r she saw a dialogue appear that says,\r \r okay,\r \r so wipe out all your objects. And then there's a checkbox that's saying include hidden objects as well.\r \r\n\nThat was kind of bewildering, and that would be for somebody new to this. But apparently, you can take advantage of this in r. Maybe you want to make an object that\r \r may be more, like, behind the scenes and you don't want it to, like, be up front and center in any environment viewer.\r \r Putting the period prefix on on that could help in that case.\r \r In any event, she does have some interesting commentary on how that might not be the best approach depending on your situation. But nonetheless,\r \r one of those things where I can sympathize seeing some as odd as that and kind of going deep into just why that is.\r \r And, apparently, it's still a feature request to be able to view those, like, more easily in in the viewer. But, yeah, to each their own, I guess. But entertaining read nonetheless.\r \r\n\n\n\n[00:27:38] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Mike Thomas",
        "trans_text": "No. That's\r \r that's a great call out. And sometimes,\r \r when I am removing some of these objects in my environment, and I think I'm always including that that checkbox, including the hidden objects as well, sometimes my memory doesn't really decrease as much as I was sort of expecting it to. So I gotta look in into that, another hidden,\r \r hidden\r \r feature of of our studio that I have to dive into, maybe for another blog post for another day. But an awesome blog post that I am super super excited about because I've been watching this project.\r \r It's been, I think, probably over a year in the making with some folks working really, really hard on it from ideation to\r \r now, production,\r \r is the censored package has arrived. I believe censored 0.3.0\r \r is now on CRAN,\r \r and this is a package that allows you to work hand in hand within the Tidymodels ecosystem,\r \r for censored regression and survival analysis. So if you are in the life sciences, wink wink,\r \r to to somebody I know, I I think you may be very excited about this package\r \r as well. You may be surprised that even for some of us who are not in the Life Sciences,\r \r for credit risk problems, which are problems that that we work on Fairly often, we may want to know the time until a loan defaults or Absolutely. Until some bad credit event\r \r takes place or some good credit event takes place. You can you can have the opposite. Right? If somebody's gonna gonna prepay their mortgage early, I I kinda wanna know,\r \r when that could potentially happen. But now I'm now I'm getting into the weeds,\r \r because survival analysis makes me makes me very happy and and gets me very excited. And I'm nerding out, but this censored package is all I've ever been looking for to be able to work\r \r doing survival,\r \r regression analysis within the Tidymodels ecosystem.\r \r\n\nThere's all different, type arguments\r \r that allow you to predict, survival probabilities,\r \r the the quantiles of the event time itself,\r \r the hazard,\r \r just based upon tweaking this one argument,\r \r called time within the particular engine,\r \r that you are setting. And if you use tidy models, you'll be familiar with the syntax of how you construct\r \r these models. It's gonna feel very natural. So I'm I'm very excited about this. Big thanks to Hannah Frick and Emil Fettfield for, I think, doing a lot of the legwork to get this package, onto CRAN and in a place where we can all use it.\r \r\n\n[00:30:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Oh, this is awesome. Yeah. I remember when Tidy Miles was kinda first person on the scene. The survival analysis was requested quite heavily\r \r in the beginning, and it's great to see, yeah, to see this factored in. Hey, man. I have a soft spot for survival techniques as well.\r \r My dissertation\r \r used this quite heavily, and, boy, we didn't have tiny miles around back then. So don't don't look at my r code from back then. My goodness.\r \r Shout out to those that dealt with the s sweep and and latex compile issues. I see you. I hear you. I've been there. Done that.\r \r But, yeah, sensor looks absolutely awesome. I in fact, we have some projects going on\r \r that are, you know, not quite the typical, like, did a patient survive or not? It's,\r \r certain events in, say, a trial, like, life cycle of, like, enrollment prediction and things like that, and and we could definitely use some time to event analysis on that. So I will definitely be keeping an eye on this.\r \r\n\n\n\n[00:31:00] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 0,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Me too. And,\r \r just to to let folks know, it looks like there are probably 11 different engines or algorithms that you can use within, this censored package all the way from tree based models to proportional hazard models\r \r to, random forests and and more of your traditional survival regression\r \r model. So lots of options here to\r \r leverage sort of that that tidy models feel and approach to survival analysis problems.\r \r\n\n[00:31:28] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 28,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. It it fits really nicely with the whole ecosystem in general, and I definitely am expecting that as the community gets our hands on this, we're gonna see more\r \r engine supported. In fact, if I had if in a time, I would go back to said dissertation\r \r research and see if I could augment what's called a competing risk engine to this because that's exactly the the type of survival\r \r technique I used. Hey. Maybe someday. Who knows? But,\r \r nonetheless, ER communities, you know, and the tidy models team does a terrific effort once again.\r \r And there's a whole boatload of terrific efforts you see in each our weekly issue. If you haven't known by now, please please do this. Bookmark arweque.org.\r \r\n\nJust do it now. You'll never be disappointed. There's so much great content on here. Awesome packages that we didn't scratch the surface of, especially as I see this issue a lot in the space of spatial visualization and other\r \r visualizations. I can definitely help an EDA, like an exploratory data analysis,\r \r and to visualize these things quite quickly.\r \r Some awesome enhancements to data. Table, which we covered about last week, getting more details on that. And, of course, upcoming events that we're seeing in the r community. So definitely bookmark rweekly.org.\r \r And, of course, this is for the community, by the community, so to speak. So we value your contributions\r \r from wherever you are. If you found a great blog post, new package,\r \r or other resource that you want the world to know about, we're just a pull request away, folks. It's all marked down all the time. If you can write a sentence in plain text, you know how to do this. And it's simply\r \r linked directly in each each issue. We have a link directly to the upcoming draft. Very easy to send us a poll request on that front. And, also, we'd love to hear from all of you,\r \r not just for your poll request, but how we're doing on this very podcast. We have a little contact page\r \r linked directly in the episode show notes. We also have\r \r a fun little opportunity if you have a new modern podcast app like Paverse, Fountain, Cast O Matic,\r \r many others.\r \r\n\nI just responded to somebody's post on Mastodon asking for a better podcast app, and I sent them to a nice resource called podcastapps.com,\r \r which has a whole boatload of these to choose from. They can send us a little boost along the way if you wanna get in touch with us directly.\r \r And then, also, we are available on the social medias,\r \r mostly on Mastodon these days for me personally, where I'm at our podcast at podcast index.social,\r \r sporadically on the weapon x thing with at the r cast, and mostly also on LinkedIn from time to time with, a little\r \r little post about these very episodes. And I love hearing from you and the community. It's always great to to hear from all of you. But,\r \r Mike, where can the listeners find you? Likewise. Probably the best place is LinkedIn. You can\r \r\n\n[00:34:14] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 14,
        "trans_speaker": "Mike Thomas",
        "trans_text": "see what I'm up to if you search for Catchbrook Analytics,\r \r k e t c h b r o o k. Or you can get in touch with me on mastodon@[email protected].\r \r\n\n[00:34:26] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "trans_timestamp": 26,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome stuff. And, yeah, you keep up with Mike. He's he's never he's never slowing down. He's had some great posts on LinkedIn recently, so you definitely wanna\r \r check those out. And, yeah. So\r \r nice and tidy episode this week. We're gonna close-up shop here. And, again, thanks for all of you for listening.\r \r And, we hope to see you back for another episode of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_07_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "chap_timestamp": 21,
        "chap_text": "Package verbosity"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "chap_timestamp": 52,
        "chap_text": "reSmush those images"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "chap_timestamp": 33,
        "chap_text": "R Consortium ISC grants"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "chap_timestamp": 50,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_07_highlights",
        "chap_timestamp": 0,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_06_highlights",
        "ep_date": "2024-02-07",
        "ep_duration": 34,
        "ep_description_short": "Key learnings from learners in recent R workshops, advice on navigating thorny package installation issues within renv, and a showdown of how the parquet and RDS formats perform with large data sets. Episode Links This week's curator: Ryo Nakagawara - @RbyRyo (https://twitter.com/R_by_Ryo)) (Twitter) & @[email protected]…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_06_highlights",
        "description_long": "\r \r\n\nKey learnings from learners in recent R workshops, advice on navigating thorny package installation issues within renv, and a showdown of how the parquet and RDS formats perform with large data sets.\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara - @R_by_Ryo) (Twitter) & @[email protected] (Mastodon)\nTeaching you - teaching me\nThings that can go wrong when using renv\nParquet vs the RDS Format\nEntire issue available at rweekly.org/2024-W06\n\nSupplement Resources\n\nQuartaki an introduction to Quarto https://drmowinckels.io/quartaki/\nR project management https://www.capro.dev/workshop_rproj/\nr2u - CRAN binaries as Ubuntu binaries https://eddelbuettel.github.io/r2u/\nShiny and Arrow https://posit.co/blog/shiny-and-arrow\ndata.table new release and governance structure https://rdatatable-community.github.io/The-Raft/posts/2024-01-30-new_governance_new_release-toby_hocking/\nrix is looking for testers https://www.brodrigues.co/blog/2024-02-02-nix_for_r_part_9/\nThe 2024 Shiny Conference call for speakers https://www.shinyconf.com/call-for-speakers\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nTails and the Music Maker - Picolescence - zircon - https://ocremix.org/remix/OCR02176\nWily theme - Mega Man 2 - TheManPF, Chocobao, DakotaCityRag, Gamer of the Winds, Zach Chapman - https://ocremix.org/remix/OCR04485"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://mstdn.social/@R_by_Ryo"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://drmowinckels.io/blog/2024/teaching-unlocks/"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://epiverse-trace.github.io/posts/renv-complications/"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://www.jumpingrivers.com/blog/arrow-rds-parquet-comparison/"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://rweekly.org/2024-W06.html"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://drmowinckels.io/quartaki/"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://www.capro.dev/workshop_rproj/"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://eddelbuettel.github.io/r2u/"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://posit.co/blog/shiny-and-arrow"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://rdatatable-community.github.io/The-Raft/posts/2024-01-30-new_governance_new_release-toby_hocking/"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://www.brodrigues.co/blog/2024-02-02-nix_for_r_part_9/"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://www.shinyconf.com/call-for-speakers"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://ocremix.org/remix/OCR02176"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "links": "https://ocremix.org/remix/OCR04485"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with episode a 151 of the R Weekly Holidays podcast. If you are new to the show, this is where we talk about the latest issue of Our Weekly that you can find at rweekly.org,\r \r and in particular, the highlights that have been selected\r \r by our curation team along with our usual banter and rambles along the way. My name is Eric Nantz, and I'm delighted that you joined us wherever you are around the world. And as always, joining me right at the virtual hip here is my cohost, Mike Thomas. Mike, how are you doing this morning?\r \r\n\n[00:00:31] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 31,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Doing well, Eric. It's pretty crazy that we've surpassed a 150,\r \r recordings now\r \r of the our weekly\r \r highlights. And,\r \r I guess, what's the next milestone? 200 to look forward to?\r \r\n\n[00:00:43] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 43,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That's right. The Vague 200. And, yeah. I know a lot of the podcasts I've listened to, they'll either do a fun little retrospectively thing, or they just might act like everything's business as usual. So we'll see what happens when we get there, but it should be fun one way or another.\r \r And this week's issue, speaking of fun, is from our longtime curator on the team, Ryo Nakagawara.\r \r So I have very fond memories of meeting him in IRL at one of the\r \r pa or r studio conferences long ago. That was a fun time. I hope I get to meet up with him again someday. But as always, he had a tremendous help from our fellow, our Wiki team members, and contributors like all of you around the world with your poll requests and other awesome recommendations.\r \r Well, Mike, you and I are both at one point, one way or another in our various projects or consultations.\r \r\n\nWe do have to do a little guidance or teaching along the way on various concepts.\r \r For me, I've definitely been doing a bit of that with, you know, helping with a little bit of inside our training in my organization,\r \r getting some analysts lined up with the latest and greatest resources that we have in your ecosystem.\r \r Well, our first highlight is doing just that. But it's a great perspective because anytime\r \r that I've done, whether it's a tutorial,\r \r a forum meetup, or a mini workshop,\r \r it's not just I'm trying to help the the learners, if you will, you know, learn a new concept.\r \r I often learn just as much as they do, especially from that perspective or persona of somebody maybe new to those frameworks or new to the the language itself.\r \r\n\nAnd our first highlight today comes from Athanasia Mowenkel, who is a cognitive neuroscientist\r \r and now a great R developer\r \r who recently gave a fantastic talk, by the way, at Posikoff this past year on using R Universe for her package development. So really recommend that talk if you haven't seen it. Well, on her latest blog post, she talks about some of the learnings she's had while she was helping others learn at a recent digital scholarship days at her University of Oslo.\r \r And in particular, she talked about\r \r her findings from 2 workshops that she gave. One was called Kortaki.\r \r\n\nCool name. And that's an introduction to Quarto.\r \r We've actually been talking about Quarto quite a bit in our off recording here, so that's timely.\r \r As well as our project management,\r \r another area that we're gonna be touching on a little bit later in the show, actually.\r \r So in particular, in these two workshops, she had a few interesting findings that\r \r probably have\r \r you have encountered before\r \r in one way or another, but one of them is definitely pretty esoteric that\r \r has happened to me, many times before. And we'll start with quarto here\r \r Because if you're familiar with creating slides in quarto or, frankly, even Rmarkdown before that,\r \r a lot of the organization\r \r of slides is governed by the use of headings, like the the markdown syntax headings.\r \r\n\nIn particular,\r \r having a single heading is going to give you one of those kind of title like slides with a big text in the middle.\r \r And then when you do a two level heading, I. E. With the 2 hashtags, that's when you typically denote a new slide with content underneath.\r \r Well, what was interesting in the workshop prep that she did for this quarter workshop is that she noticed that there was a slide\r \r that had some nice content, and then suddenly the huge text in the middle\r \r superimposed\r \r on top,\r \r which I have had mishaps of in the past with sharing in back when before I adopted Qartle.\r \r And I remember I was getting bewildered by just what exactly is going on here. Well, apparently,\r \r one of the learners picked up about this is that\r \r if you do\r \r a single heading\r \r but then do another heading that's 3 or more hashes\r \r in front.\r \r\n\nIt's not going to do a new slide after that first level heading. It's just simply going to superimpose that big text\r \r on top of the context that was under that 3 or, say, 4 level heading, like in her example.\r \r So\r \r the switch was to force a new slide that doesn't have, say, a typical two level\r \r markdown heading.\r \r There is the 3\r \r dashes syntax, and this works for both Quarto, and I believe for sharing it as well,\r \r where then you force it to create a new slide.\r \r Now that's something that you kind of learn from experience. It's typical we don't have to use that, but I have used that sparingly in the past. And it's a good mental note to me and future self that I can use that same\r \r syntax\r \r of, okay, I can force a new slide with that nomenclature\r \r or that, 3 dashes instead\r \r of having the mishap that we saw in her presentation slides. But the good news is once you make the fix, it's all in version control. Right? Just fix that, commit it, push it, and recompile your slides. So all is well that ends well, as I say.\r \r\n\nBut speaking of quartile, another interesting\r \r nuance\r \r is\r \r the idea of how things are actually named between HTML and some of the interfaces we use to build the slides. In particular,\r \r if you're familiar with web development, you've probably heard about something called a horizontal rule, which is literally the HR tag in HTML, which gives you that nice horizontal straight line\r \r that can use a separate or partition content, if you will.\r \r Well, she asked her learners to add that in her portal slides. Right. And then\r \r some are using the RStudio IDE with\r \r the insert field and the markdown editor, the visual editor.\r \r\n\nOthers are using the nice command palette, which has a shortcut to start adding in commands.\r \r And you notice there's a discrepancy between the 2\r \r is that in the visual editor, the insert calls it\r \r horizontal rule. But then the command palette version, it's called horizontal line.\r \r And, yeah, this may seem trivial, but it can trip up people sometimes. Like, well, that what did what did she ask me to put in? Why is it called different? And sure enough, you know, she put an issue on the Cornell issue tracker with this difference, and sure enough, the Pasa team has fixed this. So now it's consistently\r \r called\r \r horizontal line in the IDE now. So\r \r good catch.\r \r\n\nBut, again, one of those things that you don't really notice until you put this in front of people. So that was that was an interesting find on the portal side of things. Yeah. I think it's interesting that they called it that they I guess our studio or or posit decided to go with\r \r\n\n[00:07:27] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Mike Thomas",
        "trans_text": "horizontal line\r \r instead of horizontal rule which is sort of from a development perspective and especially web development, what it's what it's always been called.\r \r\n\n[00:07:37] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 37,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Now the next sections of her blog post definitely hit home with certain things I've dealt with, and that's\r \r dealing with the constraints that sometimes IT will bring upon you. And that is in particular one of my biggest bugaboos\r \r is\r \r spaces and file names or directory names. I have never had good luck with that. And apparently, some of the learners got tripped up with some of this too\r \r in respect to some of the materials\r \r that she had put together for the project management piece.\r \r And again, sometimes you can't control what you can't control. Right? But she has\r \r been in contact with IT about how can we make sure that these directory names at least have a little more structure around them or these file names have a little more structure about them to try and have the best of both worlds.\r \r\n\nThose that are doing more programming, dealing with the file systems that are being created, and those that are simply just trying to get their work done. So it can be a thorny issue.\r \r I do admit every time I tell people how to interact, you know, nicely with our POSIT workbench internally or over our HPC systems internally,\r \r I'm always that annoying person that says\r \r no spaces, only underscores and dashes in your file and their directory names. You'll thank me later. And usually they do actually.\r \r But that can trip people up as well. So I felt seen on that one.\r \r And this\r \r next one is really\r \r hitting home is that\r \r as installations,\r \r let's say, r itself\r \r accumulate over time, you got multiple r versions,\r \r which might mean that you've messed around with settings on some of the versions, maybe not. Maybe you've interacted with those site configuration files, which are basically the installation level,\r \r our profile, or our environment files.\r \r\n\nMaybe your IT group or whoever admins have done some tricky things with library pass. Well, guess what? That what she discovered is that there are some of their shared, you know, project areas.\r \r They had 5\r \r library paths at various levels in the stack,\r \r and some of them were just completely empty. So\r \r sure enough, a lot of crap can happen. She has a fun little ggplot\r \r of the different r versions that they have available\r \r and how many libraries are installed inside of them. So that, again, these things happen over time.\r \r I'm privileged because our Linux team, which is top notch at my org,\r \r has a system in place where we can load a specific R version as needed with what's called the module command in Linux. So we can just quickly say if we want to use r 422\r \r or go back to r 363 for, like, an esoteric reason, we have all that segregated away. But not everybody's that lucky. So I can definitely sympathize with the Wild West of where packages are installed.\r \r\n\nSo that was an interesting finding that she had with respect to her\r \r organization.\r \r So all in all, really entertaining blog posts. And again, just shows you that it's not just the learners benefiting from the workshop.\r \r Us on the other side of it, on the other side of the fence, so to speak. We learn just as much. So terrific blog post by Athanasia, and we really, again, I highly recommend her previous talks as well. Really entertaining stuff.\r \r\n\n[00:10:56] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. It it seems like all the content that Athanasia is is putting together lately is is really awesome. I really enjoy,\r \r following her work and I couldn't agree more with sort of the overall sentiment of this blog post that sometimes you learn\r \r more when you teach than,\r \r what you might expect,\r \r you know, because it's one of the best debugging exercises as she puts it, that you can possibly do is to actually go out and and teach something and and say it out loud. It's it's somewhat like talking to the little rubber ducky, right, that, since developers say that you should have,\r \r on your desk. So it's it's great feedback. It's a great exercise in order to, sort of, troubleshoot,\r \r your understanding and and really solidify, sort of, what you what you thought you knew and then figure out, where the gaps exist when you actually go to teach that to other folks. So that that's a really interesting reflection that resonated\r \r a lot with me,\r \r as well as the the Quarto stuff and project management. You know, I think we've absolutely\r \r all been there been there, with multiple versions of R on shared file systems and and trying to collaborate sort of before the world of\r \r RN, then posit package manager,\r \r and, now Docker, which is very relevant to me because we have a a new open source package, and I am trying to figure out what is the earliest version of R\r \r that our package will successfully\r \r install\r \r with.\r \r\n\nWe went back to to 3.5\r \r and realized that it breaks there because some dependencies, I think Tidyr\r \r being one of them, rely on our 3.6\r \r or greater.\r \r So, instead of having to install all of those different versions of R on my computer, I'm able to just change the change the base image and and spin up a Docker container and and run the installation and see if it succeeds or if it fails of our package which is is pretty cool I think just overall\r \r we have a lot more tooling now around our version management and dependency management than we used to have but but I certainly remember the heydays of\r \r logging on to sort of a shared network and seeing a 1000000 different versions of R, a 1000000 different library paths as she notes that they had 5 different R library paths at various levels,\r \r across many different versions of R. So that was that was, sort of nostalgic\r \r to see for me, but a great write up. Lots to learn from here, and thanks to Athanasya for this blog post.\r \r\n\n\n\n[00:13:22] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 22,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And we're gonna have direct links to each of the workshops that she gave in the show notes because of material freely available. Terrific slides. Terrific,\r \r you know, hands on work in those in those workshops. So, again, if you're in the space of kind of beginning your educational journey, if you will, with your respective organization\r \r on these concepts, yeah, this is some great\r \r material to draw upon.\r \r So as we were just talking about that, Mike, one of the,\r \r features in,\r \r in the previous highlight workshop\r \r about project management was leveraging the r env package for managing your r dependencies in a given project.\r \r\n\nAnd I have used r env quite a bit as the foundation for my reproducibly wares at the day job, even for my open source projects and, yes, some very important collaborations\r \r with a certain government agency and submission pilots.\r \r But like anything in life, nothing is perfect. Right? And there are going to be some snags you encounter\r \r along the way, some of which may not be inflicted by RM directly,\r \r but things that a new user\r \r might encounter in their various setups.\r \r And our next blog post for our second highlight today comes from Hugo Gruensohn, who is a data engineer\r \r with the data.org\r \r organization\r \r and part of the Epiverse project, which has been featured in highlights in the past. And his blog post is talking about some of the things that can go a little wrong when you use r m. So I'm gonna run through some of the issues that, that Hugo highlights, and then, Mike, I'll turn it over to you for some of the solutions that he talks about. But the first\r \r issue, and as a Linux user, oh, boy, do I know about this,\r \r is the issue of\r \r binary package installations versus compiling from source.\r \r\n\nSo, yes, if you are on those operating systems and you want to use a current version of a package, there's usually no problem installing the binary versions.\r \r What happens, though, is that you might need an older version of a package. And in that case,\r \r CRAN is not going to have binary versions of older package sources available.\r \r You are now into the compiling from source world that actually\r \r is the default role for most of the Linux usage of R itself.\r \r And that's where you want to pay attention to maybe the package's description file and see if they call out any system requirements.\r \r Because there are certain packages, there are going to be system requirements to be able to compile from source.\r \r\n\nTypically, these are like,\r \r c level libraries,\r \r other utilities that you might get in your package manager, for instance.\r \r But that's going to trip up our end, especially because it might be trying to install an older version of the package from CRAN. And then you're into\r \r some issues trying to figure out, okay, what what other system library do I need?\r \r Now, there are some tools in the ecosystem to help with finding this.\r \r I know there are some packages out, I believe, by Pazit's team on help to, you know, identify\r \r package dependency from a system level.\r \r\n\nA lot of times you'll end up Googling it anyway, and then you'll figure out the package name that you might need if you're on an Ubuntu system\r \r or a Red Hat system or a Mac OS, what kind of library you might need for that. And apparently, there are some gotchas in addition for those on Apple Silicon, I. E. The M one chips with binary, I should say, with source package installation. So there's a a good note, especially around G4tran for that. So my sympathies or anybody that's encountering that issue because that must be thorny to troubleshoot if you don't know what you're looking for. So\r \r I know this from experience because when, you know, we mentioned Michael Mike just now that with Docker environments, guess what? That's Linux. So you're gonna have to put in those system dependencies\r \r before you start installing those packages. And that if you don't know what you're looking for, that can be tricky. Must use r two u. There you go. Plug right 1. So they're trying to simplify this if\r \r if you're in the container world. But if you don't know, you don't know. And now you do.\r \r\n\nWell,\r \r there are other issues to deal with as well in this space\r \r is that maybe you've done the homework. Maybe you've got that system dependency\r \r already installed.\r \r But how long ago did you install that? And did a recent package\r \r that ended up having to be compiled from source\r \r utilize a newer version of that same library? That's the example\r \r that's in Hugo's post here\r \r is that, for example, the matrix stats package\r \r had a compilation error\r \r from those trying to install 1 from a version from 2021\r \r about a double max double X max undeclared variable.\r \r And sure enough, there was an explanation for this in the\r \r release notes of matrix stats\r \r that mentioned that they were moving to a different\r \r construct for this constant DBL max instead of a legacy one called double x max.\r \r\n\nAnd there you go. That could trip you up too because\r \r you think,\r \r hey, I've done what I needed to do. I got that system library in there. But sometimes you have to keep those up to date as well. So\r \r lots of little gotchas. And you may be wondering, oh, my goodness,\r \r I'm gonna be in this? How the heck do I navigate this? And that's where the next part of the post talks about some potential solutions in this space.\r \r\n\n[00:18:52] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 52,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. So as you noted, you know, CRAN will only provide binaries, I think, for the most recent\r \r versions of the R Packages that are available on CRAN. However,\r \r POSIT package manager,\r \r provides a larger collection of binaries,\r \r for different package versions\r \r historically\r \r across different platforms as well via, you know, the public Posit package manager, which is awesome. So for for those using our end,\r \r by default, it may try to install the packages in your random dot lock file from CRAN. My recommendation is to switch that over to to posit package manager\r \r as quickly as possible. I think you'll find the installation experience,\r \r not only less prone to running into errors with some of those system dependencies, but also faster,\r \r if you're installing binaries as opposed to from source. So that would be recommendation number 1, and that's that's the first sort of solution,\r \r that's that's positive here. No pun intended.\r \r\n\nAnd then\r \r they talk about extending the scope of reproducibility\r \r and introducing the Rig Package, which is honestly a package that I have not used\r \r enough, but absolutely should. And RIG is a package,\r \r an R package\r \r within the Rlib,\r \r ecosystem,\r \r and it allows you to sort of go back and forth between different versions of R. I believe you can run code against multiple versions of R at the same time. There's some pretty pretty wild things that you can do with RIG that I think help,\r \r solve some of these issues that you may run into, working with different versions of packages across different versions of R. So I think Rig can be a really helpful tool for for troubleshooting,\r \r or doing some of that exploratory work to make sure that your\r \r environment is set up correctly and appropriately in a way that's that's not going to fail. And then, obviously,\r \r you know, these we've talked about at length, even discussed already in the highlights, but there's there's Docker,\r \r there's Nix. Shout out, Bruno Rodriguez.\r \r\n\nHe has a series of blog posts on Nick's which are linked within this this blog. So hopefully, he's he's super stoked to to see, Nick's being represented here again with all of the fantastic resources that he's put together there. There's a link to using our end with Docker, the the RN vignette that's that's within the RN, I believe, package down site, as well as a link to a paper, that's an introduction to Rocker, which is one of the most popular images\r \r out there for working with R, and that paper\r \r is authored, by none other than the the creator of R2U himself, Dirk Edelbuttel, who I was talking about, as well as Carl,\r \r Boettiger.\r \r\n\nSo that might be a paper that you may be interested in in checking out that was published in 2017\r \r in the R Journal, but some just fantastic resources here,\r \r that allow you to explore some of the different potential solutions for for handling these issues that you might be coming\r \r coming into when you are\r \r trying to to work on a new project with potentially an older version\r \r of R or older version of R packages. And sort of the the final note here, and to summarize this blog post in its entirety and, Eric, I think you can you can share this sentiment.\r \r I don't think that package management\r \r is a solved problem quite yet at this point, our environment management.\r \r\n\nSo I think this there are a lot of similar sentiments in the Python ecosystem as well. There's there's Pynth, there's there's Vnth, there's Pynth, there's Pynth.\r \r A lot of different ways to go about trying to do it and I don't know if any of them are perfect. And in our end is obviously,\r \r you know, in my opinion, at least,\r \r you know, the\r \r the the most, recent and and sort of, you know, best attempt at package management thus far in the R ecosystem.\r \r I think it it,\r \r improves upon some of the things that Packrat,\r \r the previous package management,\r \r package,\r \r tried to handle. I know that there is the pack, p a k, package\r \r as well, which does allow you to create sort of a a lock file\r \r as well and and manage,\r \r some of these things. But, again, I I don't think it's a a perfectly solved problem yet. Maybe it never will be. You know, it's a very tricky thing to manage. But I think, in terms of some of those issues that you may run into when using RM, this blog post is a great resource on some of the ways that you can try to troubleshoot those issues.\r \r\n\n\n\n[00:23:17] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 17,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I echo a lot of those same thoughts, Mike. And it does take me to even just at a broader level,\r \r the issue of distributing\r \r software even just on Linux in general, because there are a lot of issues that are very common here with what's happening in the R ecosystem of packages and the Python ecosystem of package dependencies.\r \r There have been some new standards in place to help give developers\r \r kind of a single,\r \r quote, unquote, single target\r \r so that those on any Linux distribution, no matter what, can install these\r \r software utilities.\r \r\n\nI'm thinking of flat pack is one that's gotten the most attention with Snaps probably\r \r close behind that. And R, you're right. There's a lot of different ways to tackle this, and I don't think there is a perfect one in place.\r \r I do think what needs to happen, though, and I think this blog post is a great kind of precursor to it,\r \r is that these different paths of reproducibility that you want to take,\r \r whether it's the full system reproducibility,\r \r talking to the full stack, if you will, or if it's just the package dependencies,\r \r just that perspective. Those personas\r \r can mean different things into how far you go\r \r with these solutions.\r \r\n\nSo, certainly, what I'm keeping an eye on is, yes, I do often integrate r m with containers,\r \r but not r m valve of the box. I am gonna configure a little bit to my liking\r \r to make sure that it plays nicely, like you said, with deposit package manager, a huge win for container development and package environments.\r \r But also,\r \r again, you shouted them out. Bruno is\r \r on\r \r such a role here with spreading the message of of Nicks, in particular the Rick's package\r \r that he is codeveloping.\r \r Nix is taking a lot of, you know, I would say, mindshare in the general software development communities.\r \r Certainly, it's a huge topic of the podcast I listen to. And I think with time, we're gonna start seeing some\r \r enhancements to what Bruno is working on with Rick's, but also maybe others\r \r sharing their thoughts on it. I know quite a few people in the community are starting to dip their toes in it, myself included, still got a ways to go.\r \r\n\nBut anything that can simplify that full stack\r \r with or without containers, I think is going to come up kind of above the surface, if you will, as\r \r teams and organizations\r \r figure out the best way to tackle this. But there was a nugget in the in the conclusion here I wanna emphasize here\r \r is that when you have multiple team or multiple members involved on a team for a reproducibility\r \r kind of project,\r \r there needs to be a real team effort to keep up to date with everything.\r \r And I still recommend that if there's, like, a even a 2 person or more team,\r \r that one person\r \r is kind of in charge of kind of handling the RM side of things if you're doing RM for your package management because, trust me, there'd be dragons when you have multiple people clobbering that RM block file in a GitHub repo and not knowing which one is which. Which change should I pull into? So\r \r you're smiling. I know you know what I'm talking about, Mike. We've been there and it is rough when you don't have that delineation\r \r\n\n[00:26:32] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 32,
        "trans_speaker": "Mike Thomas",
        "trans_text": "set up front. I think there are a ton of organizations out there that struggle with this. We do a lot of work around this to try to set up,\r \r Data Science teams and Data Science collaborative workflows\r \r within some of our clients organizations that we work with and you know like you said it's an it's an evolving, you know, not perfectly solved problem but you have to you have to implement a framework and you have to\r \r framework and you have to set some sort of controls\r \r around how you're going to at least try to employ some of these best practices for collaboration,\r \r between team members across projects.\r \r\n\nOtherwise, you'll just be in a world of pain.\r \r\n\n[00:27:07] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 7,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And, you know, data science is hard enough, folks. We don't need more pain alongside our data science adventures. So, yeah, certainly, if you've had your share of ill successes or, frankly, maybe even not so great moments with package and environment reproduce. We'd love to hear about it. We'll tell you how to get in touch with us later in the show.\r \r And rounding out our highlights today, some of that's right up both of our wheelhouses lately in different ways. But,\r \r you know, we've been pretty vocal on this podcast and some of our other ventures\r \r about it's a it's a new era in terms of data storage formats. We're talking about databases traditionally or some of these newer methods.\r \r\n\nAnd in particular, a format that we are very excited about is the parquet format,\r \r part of the, you know, Apache Arrow project. There are lots of interesting ways\r \r that you can leverage this technology\r \r to streamline your data storage needs.\r \r And, yeah, my cohost here, Mike, yeah, you know a thing or 2 about this. But, this this last highlight is coming from Colin Gillespie, who is, the CTO of Jumping Rivers, who have been big proponents of advancing computing and their data science consulting projects and blogging for all of us to to learn about. And this is part of a series of posts that are diving deep into Apache Arrow in respect to the R ecosystem.\r \r And in this blog post here, Colin talks about some of the benefits that you can see in parquet versus what is the traditional format that we've been using in the our ecosystem\r \r since frankly the beginning of the language, and that's called the RDS format.\r \r\n\n\n\n[00:28:53] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Absolutely. And you know that I am a huge fan, of par the parquet format and sort of all the advances that have come within, data storage in the last I don't even know how long it's been. 12, 18 months between parquet, DuckDV,\r \r all those things. It's it's happened very very quickly.\r \r And Colin leverages,\r \r one of the most popular, I think, built in datasets, I believe within\r \r the Arrow R package, which allows you to easily work with, the parquet\r \r format files and query them using dplyr syntax, which we we know and love. And that that dataset is called the NYC,\r \r data and I believe that's that's on New York City taxi data, which is a pretty pretty large dataset, so it makes for a good example when wrangling\r \r and querying this large parquet\r \r file. And\r \r so one of the, you know, big comparisons here between parquet is RDS files as you talked about, Eric, which is a file format that us as our users have been using, I think, for as long as\r \r ours been around or as long as I can remember at least for essentially saving any type of object right it could be a data frame could be a list could be a model\r \r often\r \r so it's a very flexible\r \r file storage\r \r format\r \r and you know to date when we typically compared you know RDS storage to like a CSV\r \r especially if you are storing\r \r a data frame and most of the time that RDS file was going to be smaller and snappier\r \r to load than a c really having to read a CSV file. But now that we have this new file storage format called Parquet, which is columnar storage,\r \r we've sort of gone through that comparison\r \r again and this time comparing RDS to to parquet file format.\r \r\n\nAnd that's what Colin's blog post is doing here.\r \r And I think you'll be you'll be fairly surprised\r \r at the results\r \r in taking a look at, at least,\r \r this example, New York City taxi dataset\r \r appears to\r \r outperform, the parquet version appears to outperform the RDS version of this file across a few different metrics. So I don't know if you wanna dive into, I could do the drum roll and you can dive into the results here for us, Eric.\r \r\n\n[00:31:09] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Alright. Here we go, folks. Yes. And, the results are in. And one thing to note with the parquet format and how the arrow\r \r package writes to parquet is it's taking advantage\r \r of a compression\r \r utility called Snappy, which is a fun little name right there. But that alone is a huge gain\r \r in terms of writing this taxi dataset to disk.\r \r And in particular, in the average of the metrics that the columns put together here, it takes on average about 4 seconds to write to parquet format of this taxi dataset.\r \r Whereas\r \r for using the gzip compression library in RDS,\r \r takes 27\r \r seconds on average to write that to disk. Now that\r \r is some massive savings right there.\r \r\n\nSome nuances here about parquet versus, like, the traditional things like CSV and whatnot\r \r is that parquet is\r \r column based partitioning of how it writes the data set, which means they can take advantage\r \r of repeating, say, you know, values of, like, a numeric index,\r \r advantages\r \r of, like, common character strings, advantages of POSIX times,\r \r lots of interesting optimizations.\r \r We don't have time to get into it all on this podcast, but there are also some references\r \r in Colin's post if you wanna really dive into that. So, yes, we already see writing\r \r is significant here. How about reading itself?\r \r\n\nNow the results aren't quite as drastic,\r \r But as you might guess, because of the different way data is organized behind the scenes of these formats,\r \r it actually takes on average about\r \r 0.3\r \r seconds or 0.4 seconds to read that\r \r into memory from parquet. Whereas\r \r for RDS,\r \r it takes about 5 ish 6 seconds on average.\r \r Now that, if you're doing interactive analysis, may not be a huge deal to you if you're just kinda doing your data reporting\r \r and expirations.\r \r But what's the space that you and I play with, Mike? Is that it's Shiny apps. Yep. It can mean everything.\r \r Yeah. It can mean absolutely everything. And I'm literally dealing with this right now as I speak with an open source project where I don't want\r \r to load the entire\r \r contents of, in this case, a 4,000,000\r \r row\r \r dataset.\r \r\n\nI wanna just grab what I need at the app load and then as needed, add in more.\r \r I am using Parquet for that. It is a very optimal solution. And, yeah, Mike, you know a thing or two about loading Parquet in the Shiny app. So you wrote a darn article about it, didn't you? Yep. You could find it on the deposit blog post. It's a couple years old now. It may need some updating,\r \r\n\n[00:33:48] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Mike Thomas",
        "trans_text": "but, yes, there's a blog post called Shiny and Arrow, a match made in high performance,\r \r computing heaven or something like that. So feel free to to check that out if you are interested in leveraging Parquet files to make your Shiny app so it's snappy.\r \r\n\n[00:34:04] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Absolutely.\r \r So you can see that, you know, we don't wanna get the cliche. It depends on your use case. But how it concludes or, you know, the obvious question is, okay, you as new to this world, which one should you use, parquet or RDS for your your next project?\r \r Well, as you saw from the metrics, writing, there are just massive gains for writing\r \r volumeless data like this taxi data to disc with parquet. I think that if that's a concern to you and you're doing this on a regular basis\r \r and for efficiency, it does seem like parquet is a clear winner on that. For reading, importing into your r session, again, I think it depends on the context\r \r you're dealing with here. But I do think\r \r that, yeah, if you're in a pipeline that needs as much, you know, fast response time, whether that's a Shiny app or other situations,\r \r I think parquet is very attractive for those for those features alone.\r \r\n\nNow, one thing to keep in mind, though, is that\r \r if you are trying to keep as lean of a stack as possible, we were talking about dependencies earlier. Right? Well, guess what? RDS is built into R. It's been built into R since the very beginning. So if you don't want to\r \r depend on the arrow package for importing this into your R session, that's another, you know, win for the RDS camp, if you will. And again, for smaller data sets, RDS has had no issues in my shiny app or my other, you know, data science needs. So, again, it's there. It's always there. You can depend on it no matter where you're running or which version of our, no headaches on that front alone.\r \r But I did have an interesting use case for parkade. I'm gonna, you know, give a little insider baseball here on this very podcast on my exploration on this at the day job\r \r where our clinical sets are organized and,\r \r you've guessed it, SAS data sets\r \r organized across many, many, many different directory, subdirectory\r \r patterns based on\r \r the treatment, based on the study name and whatnot. Many subdirectories inside. Right?\r \r\n\nWell, we get questions from leadership about kind of how many sets do we actually have or, like, how many\r \r are SAS? How many programs do we have in this whole space that are SAS based? How many are R based? You know, can we get some metrics around it?\r \r So no one's going to do this manually. Right? Nate, nobody got time for that. So let's see if we can read all this metadata\r \r into\r \r some form of a data structure so we can interrogate it just to go to any database. Right?\r \r I used to use\r \r a bloated and I do mean bloated SQLite database to house all this.\r \r It worked fine ish\r \r until recently because I had a silly thing with modification times. I kind of had to re pivot.\r \r\n\nSo in this re pivoting, I thought, well, wait a minute here. Since there's a logical grouping and how these are organized where it's like the, I'll call it treatment ID of the treatment.\r \r And then within that, there's an umbrella of different studies or experiments under this.\r \r Well, this is right for grouping in a logical way by those two variables.\r \r And instead of having everything written to one massive file,\r \r why not distribute these as parquet files for the metadata?\r \r So that if I know I only need one particular treatment ID and one particular study I wanna get the data from,\r \r I can get this just as easily of arrow parquet files as I could with anything else. Plus, if I need to update only a specific\r \r treatment ID and study combination,\r \r I don't have to touch the rest of the study and data combination or study and treatment combinations. I can just update that one set and it will\r \r still magically bind all together if I need to further on. The magic of Arrow and the the dplyr, dplyr packages. It's all right there.\r \r\n\nSo that is saving me immense time. And the parquet files are fast. They're\r \r they're in efficient size.\r \r And I just feel a lot more organized on how I'm keeping track of all this. So that was my recent success with parquet. So, yes, your voice was in my head, Mike, as I was in this rearchitecting adventure. Like, I gotta get away from this monolithic set. What can I do here? And Parquet was the answer.\r \r\n\n[00:38:14] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 14,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I don't wanna sound too cliche, but I am very proud of you, Eric. Great job.\r \r\n\n[00:38:19] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 19,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Well, as you know, we just scratched the surface here. Every R weekly issue has a lot more terrific content for you to to learn about the R ecosystem,\r \r data science, integrations of R, and many other ways to inspire your daily journeys with data science. And, of course, we have the link to the issue in the show notes, but we're going to take a couple of minutes for some additional finds here. And I want to give a great shout out to a project that just keeps rolling along and had a massive update recently,\r \r and that is data dot table\r \r just had a major new release combining with\r \r a new governance structure for how they manage the project's life going forward.\r \r\n\nThis is a really fascinating post authored by Toby Dylan Hocking, and, again, we'll link to it in the in the show notes, but a really great kind of road map of what they've done to help put a little more governance around the data dot table project. There's been newer members joining the team. There's been new maintainership\r \r and lots of transparency\r \r on what they're looking at as new features going forward. So on top of that new release,\r \r it's really a great time if you're been using data. Table and you wanna get involved with the project. They're making that even more transparent on what the road map is\r \r and their contribution\r \r guidelines and kind of where things are are at going forward. So a big shout out again to the data. Table team. They're doing immense work in this space.\r \r\n\nAlways have tremendous respect for that project, and congrats\r \r\n\n[00:39:48] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Mike Thomas",
        "trans_text": "on the release of 1 dot 15 dot o. Yes. Congrats to that team. That's that's fantastic news. I'm gonna reach across the aisle to Bruno and,\r \r shout out his new blog post called reproducible data science with Nix part 9.\r \r Rix is looking for testers.\r \r So this is a call to action blog post in the r the rix package, spelled r I x,\r \r is in our package that leverages\r \r Nix. Essentially, allows you, I believe, to work with,\r \r Nix in that configuration\r \r from R. So if you are interested in Nix for environment and package management\r \r and,\r \r want to kick the tires on his Rick package and give some feedback, I think that would be really greatly\r \r appreciated. So check out this blog post, for info on how to get started.\r \r\n\n\n\n[00:40:36] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Huge congrats to to Bruno\r \r and Philip, the the comaintainer\r \r of REx. They have been doing immense work on this over 5 months and and and counting according to the blog post.\r \r So, yeah, getting real world usage of REx is hugely important as they get to this\r \r stable state, if you will. And and, yeah, count me in, Bruno. I'm gonna be testing the heck out of Ricks. I've already done initial explorations\r \r near the end of last year, but I am firmly on board with seeing just how far we can take it. And my initial experiences have been quite positive to say the least. But, yeah, I'll definitely put it in some more rigor and call again, shout out to all of you in the community that have been even just remotely curious about this. Give it a shot. Let them know what do you think? Because I do think in the reproducibility\r \r story\r \r that this is going to get a lot more traction as we get more users involved. So, again, huge congrats to Bruno and Philip on getting close to this major milestone.\r \r\n\nBut, of course, he doesn't just want to hear from all of you. We want to hear from all of you too. Right? And the best way to get in touch with us, you got a few ways to do it, actually.\r \r First of which is there's a contact page directly linked in the episode show notes if you want to give us a quick shout out on that.\r \r Also, if you're on the modern podcast app train like a few of us are using, say, Podverse, Fountain, Cast O Matic,\r \r many others, Pod Home, whatever have you, there are lots of great ways to get in touch with us on that via the boost functionality\r \r again or from the podcast index directly where this podcast has probably hosted it. You can find details on that in the show notes of the episode as well. And I'm doing some fun projects analyzing the massive amount of\r \r literally podcast metadata as we speak. And it's got a lot of geekery behind the scenes with,\r \r quartile, point blank, Docker,\r \r GitHub actions. There's going to be a lot to talk about with this.\r \r\n\nI just conquered GitHub Actions\r \r successfully on\r \r an automated run time of these pipelines, which I felt pretty stoked about because I'm still a bit of\r \r a newer user of GitHub\r \r\n\n[00:42:46] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 46,
        "trans_speaker": "Mike Thomas",
        "trans_text": "but I'm I'm getting there. I'm getting there, Mike. The the old dog here learns a new trick once in a while. No. That's awesome. I have no doubt that you'll nail that. GitHub Actions has been definitely a game changer for us at Catchbrook.\r \r\n\n[00:42:56] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. It's one of those things where you just can't imagine how you live without it all these years, but it is there, and it's a great service. So\r \r and, also, if you wanna get in touch with us on the social medias,\r \r I'm mostly on Mastodon these days. My handle is [email protected].\r \r I am sporadically on the Weapon X thingy with atdrcast\r \r and also on LinkedIn\r \r from time to time on there. And also a quick reminder, we plugged this a couple of weeks ago, but the call for talks is still open for the upcoming Epsilon Shiny conference. So if you have a talk you'd like to share with the rest of those shiny\r \r enthusiasts out there, Mike and I are obviously big fans of this conference. Yeah. We'll have a link again\r \r to the conference\r \r registration and talk submissions\r \r in the show notes. And, Mike, where can a list who's gonna get a hold of you? Sure. You can find me on LinkedIn by searching Catchbrook Analytics,\r \r\n\n[00:43:50] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Mike Thomas",
        "trans_text": "k e t c h b r o o k. Or you can find me on mastodon@[email protected].\r \r\n\n[00:43:59] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Very nice, Mike. And, yeah.\r \r You know, Mike deserves some extra praise here. You're not gonna know this from the polished version you hear of this episode, but he had to put up a lot of shenanigans during our recording today. So my thanks to you for putting up all that. As if you haven't had to put up with me on other episodes. So we're even.\r \r Yeah.\r \r We'll see who who causes the chaos next time around. But in any event, that's gonna wrap episode a 151 of our movie highlights, and, we're so happy to listen to us, and we hope you join us for another episode of RWBY highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_06_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "chap_timestamp": 24,
        "chap_text": "Teaching you - teaching me"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "chap_timestamp": 51,
        "chap_text": "Encounters with renv"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "chap_timestamp": 11,
        "chap_text": "Parquet and RDS showdown"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "chap_timestamp": 54,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_06_highlights",
        "chap_timestamp": 13,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_05_highlights",
        "ep_date": "2024-01-31",
        "ep_duration": 40,
        "ep_description_short": "The R-Weekly Highlights podcast has crossed another milestone with episode 150! In this episode we cover a terrific collection of development nuggets of wisdom revealed in a recent package review livestream, and how a feature flying under the radar from Git can facilitate investigations of multiple package versions. Episode Links This week's…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_05_highlights",
        "description_long": "\r \r\n\nThe R-Weekly Highlights podcast has crossed another milestone with episode 150! In this episode we cover a terrific collection of development nuggets of wisdom revealed in a recent package review livestream, and how a feature flying under the radar from Git can facilitate investigations of multiple package versions.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq - @batool664 (Twitter)\nNotes from live code review of {soils}\nLoad different R package versions at once with git worktree\nEntire issue available at rweekly.org/2024-W05\n\nSupplement Resources\n\nHow to embed videos with GitHub markdown: https://youtu.be/G3Cytlicv8Y\nReproducible Manuscripts with Quarto: https://youtu.be/BoiW9UWDLY0\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nGerudo Desert Party - The Legend of Zelda: Ocarina of Time - Reuben6 - https://ocremix.org/remix/OCR03720"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://jadeyryan.com/blog/2024-01-22_package-review/index.html"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://masalmon.eu/2024/01/23/git-worktree/"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://rweekly.org/2024-W05.html"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://youtu.be/G3Cytlicv8Y"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://youtu.be/BoiW9UWDLY0"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "links": "https://ocremix.org/remix/OCR03720"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_05_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We are back at episode 150 of the R weekly highlights podcast. I knew we're gonna get to an awesome number, and we finally did. We're happy to have you join us from wherever you are around the world where we talk about the latest and greatest highlights that we have seen in this current week's our weekly issue. My name is Eric Nantz, and I'm delighted that you joined us today. And as always, I have my awesome cohost who never stops the hustle, Mike Thomas. Mike, how are you doing today?\r \r\n\n[00:00:27] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I'm doing well, Eric. I am going on-site to a client for the first time in a long time. So,\r \r I'm showered, dressed,\r \r you know, all before\r \r 9 o'clock which is\r \r\n\n[00:00:38] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "trans_timestamp": 38,
        "trans_speaker": "Eric Nantz",
        "trans_text": "occasionally unusual. I'm not gonna fully admit to that but, yeah. Looking forward to that today and looking forward to a a quick, highlights here. That's right. Yep. You got yourself ready for the the old business professional look. I'm doing that tomorrow for an on-site thing. So we got our our week of on-site stuff. But guess what? The power of virtual means we can do this from our comfortable homes for this episode. And this episode is not possible, of course, our weekly itself. And this week's issue\r \r was curated by Batool Almazak who, of course, had great help from our fellow Rwicky team members and contributors like you\r \r all around the world.\r \r\n\nNow, Mike, you know that in our little post show last week when we were just getting our files sorted out, I had kind of lamented the fact that I was a little jealous of a certain individual that just did a really fun screen cast\r \r of a package review. Well, guess what? That is our first highlight here.\r \r I'm referring to a live\r \r package review that was conducted by Nick Tierney,\r \r very well established member of the R community\r \r and has cooperated our open side quite a bit in his tenure.\r \r Yes. And he did a terrific package review of JD Ryan's\r \r soils package,\r \r which is one of a very,\r \r ambitious, yet very powerful package\r \r trying to help surface up some very innovative data and innovative workflows for her team. To\r \r Nick's credit,\r \r he was very practical and very upfront with some of his process of evaluating a package,\r \r which, again, draws a lot from his rOpenSci\r \r roots.\r \r\n\nAnd at a high level, a few of the things that he illustrates here that I definitely need to take note of\r \r is using from the good practice package\r \r a function called GB to literally\r \r automate\r \r the more standard types of checks that they would do in rOpenSci\r \r whenever a package is on board, which, again,\r \r everybody can benefit from because it's not like rOpenSci has some esoteric requirements.\r \r These are all great practices\r \r for software development and especially in the space of our package development.\r \r Also,\r \r extensive use of the COI package. We've been singing the praises of COI quite a bit,\r \r and Nick had some nice, you know, targeted comments on making that even more seamless to give a more friendly looking\r \r message for various notes, bullet points, or even error messages\r \r that can occur\r \r in this workflow.\r \r\n\nAnd then, also,\r \r the use this package comes into play yet again. Right? We use this quite a bit in package development\r \r and getting kind of the basics of package documentation\r \r lined up with the usepackagedoc\r \r function\r \r is a terrific way to get that package level documentation\r \r up and running quickly.\r \r Throughout it,\r \r very much, in JD's blog post that we're linking to in the highlights here, she says she's rewatched this a couple of times, and her blog post is literally\r \r going through the recommendations\r \r that Nick had and the ways that she is now improving\r \r the soils package,\r \r even things like logic and the functions for directory and file paths checking. These are all things that we sometimes take for granted.\r \r\n\nBut\r \r what was also interesting is that Nick had in the live chat\r \r other really well established members of the community, such as Miles McBain,\r \r also giving his 2¢ on some of the operations that the package\r \r was doing and high level looks at how things are completely organized.\r \r So, yeah, some of the things I took away, Mike, is, yeah, I need to invest in this good practices package\r \r a lot more because that's gonna help me up my game\r \r with documentation\r \r as well. And,\r \r also, some of the nice pointers that they have here in the package documentation\r \r itself with the markdown files\r \r and the snapshotting\r \r of tests and\r \r various practices\r \r for committing these with descriptive messages. So, again,\r \r worth a watch for sure to see Nick in action because to me,\r \r I love seeing the journey just as much as the destination to rip off some friends in the Linux podcast and ecosystem.\r \r\n\nAnd Nick really showed the the actual process of package review, which I think is extremely helpful from no matter where you are in your organization\r \r or academic institution.\r \r There there are a bunch of nuggets for you to learn from here.\r \r\n\n[00:05:09] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. I'm super impressed with the soils package. I'm super impressed with the work that, JD and her team at Washington\r \r Department of Agriculture\r \r have done. It's really\r \r exciting for me to see, you know, government organizations,\r \r large organizations,\r \r you know, not only using R, but like creating beautiful R packages,\r \r and package down sites, and utilities for their team, and may maybe for for others to use as well and doing some of this work out in the open for us to be able to\r \r take a look at it, learn from it and potentially even contribute to it as well. You know, one of the the really interesting things,\r \r there are many really interesting things here,\r \r in my opinion. So this package is not on Quran. I don't know if they have the,\r \r the desire to to put this package on Quran, but it is on our universe.\r \r\n\nAnd\r \r we recently, at Catchbook authored an open source package that, obviously, folks can install from from GitHub. We haven't pushed it to Kran or submitted it to Kran yet either. But I would be interested in seeing, I guess, the the process. And I should know this by now because we've covered our universe enough on this podcast.\r \r But the process of getting a package onto our universe that isn't on crayon. I believe that there's some workflow that Yaron has for our universe to actually take a look at what is on crayon and sort of copy that over Right.\r \r Onto our universe. But I didn't realize, I guess, what the workflow was for submitting a package to to be on our universe, but not necessarily\r \r on crayon. And that's not not speaking ill of crayon, but I think there's just some particular packages,\r \r you know, in our case that,\r \r maybe, aren't necessarily worth going through,\r \r the entire crayon workflow for.\r \r\n\nThis is a really really really cool idea and I learned a ton from this, you know. Take a look at the YouTube video.\r \r Take a look at how Nick walks through this package, and Miles and Adam,\r \r walked through this package and the different things that they call out in terms of things that,\r \r she did well, things that she didn't do well. 1, I don't know if you have the GitHub repository open, Eric, at all.\r \r One thing that's like\r \r blowing my mind a little bit that I can't figure out is so in the read me, which, you know, extends to the package down site,\r \r it\r \r has a bunch of videos\r \r in it that are video demos on how to create a soils project, render Right. A word or an HTML report.\r \r\n\nAnd if you look in the read me on how these videos are sort of embedded,\r \r there's a link\r \r to the same GitHub repo and a folder called assets. Mhmm.\r \r And the folder called assets, I can't find\r \r on the repository\r \r anywhere.\r \r Wow. And it's also not get ignored. That's\r \r interesting. So I'm I'm curious as to how, like, maybe\r \r at build time when you're you're building the read me, she was able to embed these\r \r these files with a link to this this assets\r \r subfolder. But unless I'm going crazy, I can't find it. So that's really cool because one of the things that's that's called out in the blog post is the package size is very large,\r \r which would be an issue if you're submitting to CRAN, but not necessarily\r \r an issue otherwise. And and, you know, when I'm I'm thinking about packages that are large, I'm I'm obviously thinking, you know, what sort of types of files could be within that package to to make it large. And then, I I looked at the read me right away and I saw, oh, we have a bunch of video demos that must that could potentially be it. But I can't find them in the read me anywhere. So I'm very,\r \r perplexed\r \r to say the least.\r \r\n\nAnd then, maybe, the the last thing that I'll I'll call out here is, you know,\r \r her team went all the way\r \r down the path of being able to use the Rstudio IDE to create a new Soils Rstudio project. The same way that we would create a new Gollum,\r \r Gollum package. Right? Or create a new new R package through the RStudio IDE. And the the little hex sticker from soils\r \r is is\r \r on the RStudio IDE\r \r right there for for creating a quarto soil health report. It's incredible. Obviously, this this package,\r \r that they've created is going to make other folks in our organization's\r \r lives a ton easier to just get their projects up and running sort of immediately instead of having to start from scratch. So if you are someone working in an organization where you find yourself\r \r do doing the same types of projects over and over,\r \r and our package\r \r could be a huge benefit to you and a great place to start for a template would be this soils package. It's phenomenal.\r \r\n\n\n\n[00:09:53] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. There's a lot to unpack here on what JD's done. And as you're talking about the the videos and the Remi, in this blog post, I'll put the direct link to this in the show notes.\r \r She does say that there is a video tutorial from GitHub directly\r \r on how to pull this off. And it does have to do with GitHub flavored markdown. So he must have done some magic with GitHub itself. So we'll link to that,\r \r directly because my goodness, if my package is on GitHub, I definitely want to take advantage of this and make it easier for people to see some of the workflow in action for some of the packages I have in mind in the Shiny space in the future. So\r \r lots of great points, Mike. I think\r \r knowing that many of the analysts that she's working with and, frankly, the ones I work with are are using POSIT or Rstudio\r \r as their front end to this, using that new project feature and getting things ready right away is just so helpful for them. I mentioned I'm on a kind of a crusade at the day job to help make some of these initial clinical projects easier for people, and this project feature is going to be something we look at quite closely here. Definitely.\r \r\n\nAnd, yeah, you and I, Mike, we've been living the life of creating the internal or company packages for our various clients or stakeholders.\r \r And a lot of\r \r times, things move. Sometimes things move pretty fast. And sometimes, we might need to check just what happened, maybe a version behind or 2 versions behind.\r \r But then you're kind of wondering, how do I handle that? Do I have to do a whole separate r installation on a virtual machine that has, like, an old version installed?\r \r Well, we have some good news for you, folks. If you are leveraging Git for your version control,\r \r whether you're putting on GitHub or not, but just using Git for version control of some sort.\r \r\n\nMylesalmon is back on the highlights once again. Definitely a repeatable pattern here in a great way\r \r because she has discovered in her continued,\r \r I would say, journey of leveling up her git knowledge\r \r that there is a way to kind of have your cake and eat it too of loading different r package versions\r \r kind of at once without a lot of fuss involved\r \r using\r \r a very, I would say, niche feature in Git\r \r called Git Worktree.\r \r I admit I have not seen this at all, and I've been using Git for over, what, 10 years. I did not know about this feature at all. So let's break it down for you real quick. Yeah. Yeah. We're both learning something here, Mike. So I think what you and I are familiar is a concept of branching. Where in branching, you could say, I'm on my main branch, but I know I'm gonna work on this new feature or new bug fix. But I don't wanna\r \r commit that to main yet until I get through this fix. And I'll do a new branch\r \r to work through that, iterate, and then push that up and do a code review or whatnot to push that into main.\r \r\n\nI knew about that, but Git work tree\r \r is a little different.\r \r And in fact, it's more comparable, not so much the branching,\r \r but to the idea of Git stash where you just wanna put things aside in your working area of Git for a bit and then maybe fix something else real quick and then bring that back forward\r \r when you're ready.\r \r Well, apparently, with Git work tree, you can and as Mao's post illustrates,\r \r create a new folder somewhere on your computer\r \r and then have that folder\r \r be linked to that same Git repository of that package\r \r but to a different state of that package, maybe based on a commit, maybe based on another branch, maybe based on a previous release,\r \r which means that you could use that additional area that's separated from your main working area\r \r to look at, say, a previous package version.\r \r\n\nAnd she gives an example of, say, another package called riGraph\r \r and then putting the tag after that\r \r and then making a directory for that and then using git work tree to check that tag out\r \r into that other folder.\r \r And then you can remove that. Clean clean up after yourself, so to speak, when you're done doing that investigation or that previous version\r \r of using git work tree remove\r \r and then that folder name.\r \r And then then it's as if nothing happened.\r \r I'm still wrapping my head a little bit around this because it it\r \r it I've never used Git Worktree before.\r \r\n\nBut there are plenty of times at the day job where maybe I've already gone, like, 1 version, 2 versions ahead\r \r on what I need to finish.\r \r But then I'll get a request from, like, an analyst or a client\r \r or or a customer in my in my various departments.\r \r And they have a question that\r \r admittedly,\r \r some reason they're using an older version of the package. So now I can use get work tree to investigate that really quickly\r \r without having to, you know, do some clever library magic along the way.\r \r So I'm still wrapping my head around this, but definitely as we do always, we'll have a link to Miles' blog post here. But if you need to quickly check what you did a version or 2 behind,\r \r Git Worktree seems like the way to go.\r \r\n\n\n\n[00:15:11] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "trans_timestamp": 11,
        "trans_speaker": "Mike Thomas",
        "trans_text": "This\r \r is somewhat mind blowing to me. I think it's a great\r \r utility function that I now know about,\r \r with Git, and it's it's fantastic. I think it's it's very simply explained\r \r by Maelle to be able to create this just additional directories. This additional subdirectory essentially is that I think the way that she set it up,\r \r which would contain the specific version of the package that you want to\r \r work in temporarily.\r \r So, you know, I I think you you covered it excellently. This is a very nice short and sweet\r \r blog post,\r \r but I again appreciate,\r \r Mel, pointing out these nifty\r \r little tricks and tools that that we have. I didn't I had a similar use case but but not quite the same use case. I actually wanted to\r \r try out,\r \r a pack this package that we've developed on a different version of R,\r \r which I I guess I could have done and opened up a separate sort of IDE and had a local installation,\r \r of an older version of R, because I wanted to make sure that the package worked on an older installation of R. But then, we, we're taking a look at at of the utilities like R hub\r \r and things like that that allow you to test your package, against multiple\r \r versions of R on multiple different platforms\r \r and things like that.\r \r\n\nAnd that also sort of is where where Docker, I think, can come into play and be your friends to allow you to be able to spin up a container that contains a particular version of R without having to necessarily install it on your local machine, and then worry about uninstalling it and things like that. But that can be a little more tricky. But I can absolutely see plenty of use cases where, you know, instead\r \r of changing the version of R, I would wanna actually change a version of of a particular R package and and take a look at, you know, how that package was functioning\r \r in that version,\r \r compared to a previous version. The scales package is one that was giving me some headaches lately. There's some new there's some new arguments in your, your label,\r \r number or label percent,\r \r that deal with positive and negative\r \r values that that were newly introduced and and giving me some headaches recently. So this is a use case that I think I might have to to spin up by this Get Work Tree function today and dive back into that. But,\r \r excellent,\r \r excellent blog post again by Ma'el Asserta. Just again,\r \r pulling out a bag of tricks that that I didn't really know existed that are absolutely gonna be helpful for me in the future.\r \r\n\n\n\n[00:17:35] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "trans_timestamp": 35,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. And, I believe even though he's halfway across the world potentially, I might hear Bruno's voice in my ears saying, you could probably combine your use case, Mike, of checking different package versions with my Al's use case of different or of different package versions with your use case of different our versions with Nick's. I I bet there's way the titles do together. So, Bruno, I heard you even if you weren't saying that. I can I can hear you telepathically?\r \r So this would this would fit really nicely in this, and I'm excited to maybe try out some of these newer ideas as I'm getting more in the weeds, especially this past month, on some internal package development and trying to make it easier for both future me and future,\r \r collaborators as well. But\r \r if you ever thought you knew everything about Git\r \r no. I I I'm I'm one of those people that seems like I've learned something new every week about Git. So it is just amazing what we're learning in this space. And speaking of amazing, the rest of the art week of issue is just as amazing. You're gonna learn so much along the way if you read through the entire list of new blog posts, new packages, updated packages, and offer tremendous resources.\r \r\n\nSo it'll take a couple of minutes for our additional finds here. And,\r \r I I admit\r \r sometimes and I'll read an old I hate to say old, but maybe\r \r a somewhat\r \r newish or, you know, senior statistical research book. You wonder how would what would happen if I just updated my the code examples in that book to use a newer package framework, a newer paradigm? How does that compare and contrast?\r \r Well,\r \r Imo Vitfeld from posit has done just that\r \r with the introduction to statistical learning\r \r labs converted\r \r to using tidy models.\r \r This is massive. If you ever wanna see\r \r just relating\r \r a newer framework for machine learning and and and everything like that. But with\r \r a very critically renowned, well established literature\r \r of getting into the nuts and bolts of predictive modeling and machine learning.\r \r\n\nThis quartile book online of Tidy Models Labs has you covered. I've been watching this over a little bit. It looks like it's had a ton of updates since I last looked at this, but\r \r it is a very direct one to one relationship with the labs that are mentioned in the in the second edition of ISLR\r \r with using tidy models. So if you ever wondered how, like, classification,\r \r you know, linear model selection, support vector machines would look in the ISLR\r \r context. But with tidy models,\r \r this is the place to go. Highly recommended.\r \r\n\n[00:20:12] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "trans_timestamp": 12,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I was looking at that,\r \r that book and I cannot wait to fully check that out.\r \r The ISLR book is is absolutely phenomenal and tidy models is absolutely phenomenal as well. That's that's our\r \r package, suite of packages of of choice here at Catch Brook for when we're doing predictive modeling projects, and then, ISLR is is sitting on my desk essentially at all times. So it's it's going to make my life even even easier to be able to have this resource that sort of, is the serves as the translation\r \r between those two things immediately instead of having to to do it ourselves.\r \r And I just want to point out quarto 1.4\r \r has been\r \r released.\r \r\n\nBig improvement here, I think, is around dashboards. You know, we've talked about it a lot, but quarto dashboards are here. The new iteration of of flex dashboard. So try it out yourself. The other thing that I'm super excited about, but I I think is in the early stages, I'll have to check out sort of how stable it is, but it's this new new manuscript project type called typest,\r \r t y p s t, if I'm pronouncing that correctly, I'm not sure.\r \r Sounds like a much lighter weight version,\r \r of maybe Pandoc or or for rendering\r \r PDFs,\r \r really lightning fast,\r \r or or Latex essentially. I think it's it's replacing Pandoc and LaTeX.\r \r\n\nI haven't dug into it yet but if there is something out there that can render PDF reports for us,\r \r much faster and much more lightweight\r \r than what the current options are, I am\r \r super interested in. So we'll we'll see how that goes.\r \r\n\n[00:21:47] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I'm very interested as well, and I believe there was a talk at Positconf about the type support coming for Cortl. So if I'm able to find that, I'll put that in the show notes as well. But I do have a use case at the day job or maybe you wanna make a PDF even not just of the statistical results of, like, a model fit, but also we can might even use this for, like, an internal newsletter or a new internal update and send that out because in any corporation, sometimes email is the only way to get ahold of people, and this\r \r will be a great way to have attractive kind of, branding, if you will, on some of the things we do. But types can make that a lot easier.\r \r\n\nAnd, certainly, we hope that our weekly itself makes your journeys in r and data science much easier.\r \r And, of course, we love hearing from you.\r \r The best ways to get a hold of us are on the contact page linked in this episode show notes. You can also have a modern podcast app like Pod Versa Foundation.\r \r Us a fun boost along the way, and details about that are in the show notes as well.\r \r And, also, we are variously sporadically on social medias.\r \r I am at,\r \r our podcast at podcastindex.social\r \r on the Mastodon servers,\r \r\n\n[00:22:57] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "trans_timestamp": 57,
        "trans_speaker": "Mike Thomas",
        "trans_text": "sporadically on the Weapon X thing with at the Rcast and LinkedIn from time to time. And, Mike, where can listeners find you? Sure. On LinkedIn, you could search Catchbrook Analytics, k e t c h b r o o k, and see what I'm up to there. Or you can find me on mastodon@[email protected].\r \r\n\n[00:23:16] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome stuff as always. And, yeah, it's a nice tidy episode this week. And but as always, every single week, we're trying to be back here with awesome art content for all of you. So that'll do it for us for episode 150.\r \r Only 50 more to go than the big 200. We'll see if we get there. And in any event, we hope you enjoy listening, and we'll see you back for another edition of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_05_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "chap_timestamp": 16,
        "chap_text": "{soils} package review"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "chap_timestamp": 9,
        "chap_text": "GIt worktree"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "chap_timestamp": 26,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_05_highlights",
        "chap_timestamp": 23,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_04_highlights",
        "ep_date": "2024-01-24",
        "ep_duration": 57,
        "ep_description_short": "How the babeldown package enables low-friction updates to living documents, uncovering innovative functions all within the base R installation, and supercharging a static Quarto dashboard with interactive tables and visualizations. Episode Links This week's curator: Sam Parmar - @parmsam_ (https://twitter.com/parmsam_) (Twitter) &…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_04_highlights",
        "description_long": "\r \r\n\nHow the babeldown package enables low-friction updates to living documents, uncovering innovative functions all within the base R installation, and supercharging a static Quarto dashboard with interactive tables and visualizations.\n\nEpisode Links\n\nThis week's curator: Sam Parmar - @parmsam_ (Twitter) & @[email protected] (Mastodon)\nHow to Update a Translation with Babeldown\nSix not-so-basic base R functions\n3MW (Making dashboard interactive)\nEntire issue available at rweekly.org/2024-W04\n\nSupplement Resources\n\nbabeldown R package https://docs.ropensci.org/babeldown/\nDeepL API https://www.deepl.com/en/docs-api\nAlbert Rapp's Quarto dashboard repository https://github.com/AlbertRapp/quarto_dashboard/tree/master\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nSeven Pipes to Heaven - Super Mario Land - Nostalvania - https://ocremix.org/remix/OCR03256\nSmooth Mana - Secret of Mana - Gux - https://ocremix.org/remix/OCR00352"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://twitter.com/parmsam_"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://fosstodon.org/@parmsam"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://ropensci.org/blog/2024/01/16/deepl-update-babeldown/"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://ivelasq.rbind.io/blog/not-so-basic-base-r-functions/"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://3mw.albert-rapp.de/p/3mw-making-dashboard-interactive"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://rweekly.org/2024-W04.html"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://docs.ropensci.org/babeldown/"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://www.deepl.com/en/docs-api"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://github.com/AlbertRapp/quarto_dashboard/tree/master"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://ocremix.org/remix/OCR03256"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "links": "https://ocremix.org/remix/OCR00352"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We're back with episode 149\r \r of the R Weekly Highlights podcast.\r \r Oh, we're getting close to another fun little milestone, I guess. The episode numbers keep going up and so does each issue of Our Weekly.\r \r We're here to talk about the current issues, latest resources, tutorials, and specifically the highlights from the particular issue. My name is Eric Nantz, and I'm delighted that you joined us wherever you are around the world. And, hopefully, you're staying warm, especially if you're in the winter season and hopefully avoiding some ice apocalypses out there. But, nonetheless, we hope you enjoy this episode.\r \r\n\n[00:00:36] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Mike Thomas",
        "trans_text": "And staying warm in his humble abode is my awesome cohost, Mike Thomas. Mike, how are you doing today? Doing well, Eric. Yep. It's, it's pretty chilly out here in Connecticut. We live fairly close to a lake that's that's frozen for the first time in a few years, which is it's kind of nice, going out in the ice and and skating around. So trying to enjoy,\r \r as much as we can and excited to have\r \r some consistency now in 2024. I think we're we're back to back weeks for a couple weeks now on our weekly and hoping to keep it up. Yeah. The momentum is, in our favor, so to speak. So we'll keep that keep that rolling along here. And\r \r\n\n[00:01:11] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 11,
        "trans_speaker": "Eric Nantz",
        "trans_text": "and as always, the Rwicky project rolls along because we have an awesome\r \r team of curators that are helping every single week. And this week, our curator is Sam Parmer.\r \r And as always, he had tremendous help from our fellow Rwicky team members and contributors like all of you around the world with your awesome poll requests and other, heads up to us about the latest resources that you found.\r \r So let's dive right into this.\r \r We know, Mike, we have a lot of advances in technology right at our disposal via the magical world of APIs to help automate a lot of the stuff that would take a long time to do.\r \r Well, there is a very interesting area that this first highlight exposes in terms of where these APIs can really help\r \r in a much needed domain\r \r of translation\r \r of different languages for our documentation.\r \r\n\nSo our first highlight is a blog post from the esteemed rOpenSci blog by Mel Salmon, who, of course, is a former curator here at rweekly\r \r and now is a research software engineer supporting rOpenSci as well as other endeavors.\r \r And this blog post, in particular,\r \r talks about the use\r \r of the babble down R package to update an existing translation\r \r after its changes.\r \r And this is, apparently, part of a more broader initiative from rOpenSci\r \r for publishing in multiple languages, their various pieces of documentation.\r \r And as part of that effort, this babble down package has been developed to help translate\r \r markdown based content\r \r with leveraging what's called the DeepL\r \r API, which before this, I actually didn't know this exists. But apparently, this is a full fledged API built specifically for translation\r \r across many of the common languages in the world.\r \r\n\nSo in this blog post, my old blogs are a pretty simple example but yet very relatable.\r \r Having an existing markdown document in English language,\r \r and then as it's being kicked off, how would you go ahead and translate that to French in this example?\r \r So we have a very simple markdown syntax, which has got a typical headings, subtitles,\r \r and narrative inside.\r \r The babble down package has a function called deepltranslate,\r \r Give it the path to the markdown file, the source language,\r \r the\r \r target language for translation,\r \r and there you go. It's going to call the API under the hood, and you'll get that text right back, in this case, in the French language.\r \r\n\nLooks good to me, although I'm not a French speaker, so I'll I'll defer to my own others for the authenticity of it.\r \r But\r \r that's not all. That's great for, like, your initial document. But what happens\r \r if, like anything else, you're gonna update that document, you know, through, you know, maybe pull requests from your collaborators.\r \r Maybe you got a new feature you wanna document in that package or tool or whatever\r \r this is meant for.\r \r And so\r \r assuming that this document is in version control because, well, if you're not using version control, you should, especially for larger efforts. Mike and I can attest to that.\r \r The babble down package is doing some pretty clever things under the hood\r \r to detect\r \r the changes that are happening\r \r in this document\r \r so that when you feed in this updated document to\r \r the the BabbleDown package,\r \r you can there's a function called deeplupdate\r \r where it's going to take\r \r this newly changed file.\r \r\n\nAnd again, with very much a similar function parameters as the kind of the initial launch of the of the translation,\r \r you will get that new\r \r updated language of the document in French\r \r with your changes reflected.\r \r Now this is using, apparently, a hybrid\r \r of the get kind of diffs under the hood, but not just that.\r \r It's actually\r \r translating\r \r the representation\r \r of that markdown syntax of that file\r \r into XML\r \r representation.\r \r Because, again, in the web, even though markdown looks like we're just writing this in plain text, when you render it to HTML,\r \r you're putting it into another markup language, and XML and HTML\r \r are very much related in that space.\r \r\n\nSo, apparently, this XML representation\r \r is a bigger help to pinpoint\r \r exactly what is changed in that document so that she the the user of the BabbleDown package\r \r doesn't have to send the entire document back for retranslation.\r \r It's only gonna send the bits that change.\r \r And just like anything in the API world, there's no such thing as a free lunch sometimes. So if you were sending\r \r a volumous, you know, lengthy document over and over again, that could perhaps\r \r incur some costs if you're leveraging this API more regularly.\r \r So being able to only take what you need and translate it back, I think, is a really neat\r \r feature and pretty welcome, I'm sure, for those that are using this regularly.\r \r\n\nSo this is very much\r \r scratching the itch of a big need in the community as a whole in data science and other\r \r domains of making sure that we make our documentation\r \r for our tools, packages,\r \r or other, like, analytical pipelines as accessible as possible\r \r to those around the world. So I'm really excited to see just\r \r all the nifty things going on under the hope of this babble down package. Something I'm gonna keep in mind for my open source projects in the future. Yeah. I couldn't agree more, Eric. And I think this is the topic that we've talked about\r \r\n\n[00:07:01] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Mike Thomas",
        "trans_text": "on previous episodes, you know, trying to make R and the packages that we develop, and the documentation that we write\r \r as accessible as possible to as many folks as possible. Right? Around the world because R is an international\r \r programming language, and that means that we should try to do as much as we can to try to accommodate those folks. And the fact\r \r that the people working on on BabbleDown,\r \r including Ma'el, have provided us with this tool to just make it much easier\r \r for us to do so is is awesome. I think it's what open source is all about. And\r \r I really like sort of this walk through with the the API.\r \r\n\nThis deep l translate function is is really cool. As you mentioned, it allows you to specify your input file, where you want your output file to be written to, your source and your target language.\r \r And one interesting argument that I saw is an argument called formality.\r \r And in the blog post, Mal has specified this argument, as the string less.\r \r But I imagine that you could,\r \r need to have your translation be be more formal or less formal or or maybe somewhere\r \r in the middle, I'd be interested to learn a little bit more about that. And I imagine that that's sort of a parameter that the API,\r \r itself handles, which, you know, is really interesting. I think that there's probably a whole field of study here in terms of language and translation,\r \r and, you know, how different cultures represent formality versus informality.\r \r\n\nBut I I just thought that that was pretty nifty that that argument\r \r exists. And would be interested to see, sort of, how changing that argument would change the output. And I imagine that it it fully depends on on your input text and and how specific\r \r that is. This this DeepL update function is is really impressive too, and also really impressive that it doesn't use the git diff at all. As you said, it's this XML\r \r representation, and it looks like there's a package called Tinkar\r \r that sort of helps, with that translation\r \r between,\r \r your original document, it's XML\r \r representation,\r \r and finding the differences between those two XML structures. So that's that's really fascinating to me. Sort of reminds me of of the Waldo package, maybe, in some of its functionality,\r \r and being able to compare 2 files against each other. Recently,\r \r worked on a project using the Waldo package, where we're just reading, you know, these these dot TXT\r \r files, which have this this really sort of strange structure, but we're able to really easily show our end users sort of the differences between,\r \r 2 different dot TXT\r \r files, which is is super important to them. And it's it's just incredible sort of what the the community has created in terms of these packages that allow us to identify these differences, and then take action based upon the differences\r \r that we find. So this is a a really nice short and sweet introduction into,\r \r\n\n[00:09:56] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 56,
        "trans_speaker": "Eric Nantz",
        "trans_text": "how these DeepL functions within the BabbleDown package work and maybe able to help you out in your own work. Yeah. I'm even thinking if I do, like, open source Shiny work in the future, having, like, a toggle for, like, changing the language of, like, the interface elements. But then,\r \r yeah, it does bring up a lot of possibilities how this could be tied with something like BabbleDown. I'm\r \r the the wheels are turning or this could make my apps way more accessible. So this is really neat.\r \r Moving on with our second highlight today, we got, you know, as we talk about a lot on the show as well, yes, a community of our packages can supercharge so many of your workflows in data science, tool development,\r \r computing in general.\r \r\n\nBut you know what? Base R itself\r \r comes with a lot under the hood, and, honestly, sometimes it doesn't get enough of the spotlight.\r \r So that's where this blog post is gonna shed a little bit of much needed spotlight\r \r on some additional functions\r \r that may come from Bayesar, but they're definitely not so basic and they're quite powerful.\r \r And this is authored by Isabella Velasquez, who is a senior product marketing manager at Posit.\r \r And she does really great work of her blog as usual. And, this blog post in particular,\r \r we'll get to the meat of this shortly, but she's got some bells and whistles here that I think you're gonna really like as we we talk about this. But\r \r she opens with the list of 6 functions, actually, and an operator on top of that,\r \r that she's been using quite a bit and things that deserve a little more love. And we'll hit each of these quickly 1 by 1. But, we probably won't do each of them enough justice. But\r \r you may have seen as you've, like, perused maybe someone else's R package, you know, source code,\r \r that sometimes at the end, instead of an explicit return state or return of, like, a function parameter with a return function,\r \r you might see a function called invisible\r \r put in at the end instead.\r \r\n\nWhat this really means, and a cool name, by the way, is that you are, in essence, returning a temporarily\r \r invisible copy\r \r of the object.\r \r So it's going to still execute normally if you run this like in the R console.\r \r But then if you want to save this\r \r to a variable,\r \r it's not going to print the result when you run that function after saving it to the variable. So you can kind of run it interactively\r \r with just calling the function itself\r \r and then also when it's not.\r \r But here's the cool part about this blog post. You're going to see the snippets of code, but you notice that little run code button at the top there?\r \r Guess what, folks? You hit that button, it's going to run it in your web browser.\r \r\n\nTwo guesses what that's powered by.\r \r I smell a WebR implementation here. This looks really nifty. So\r \r this is this is just as an aside here.\r \r This is the potential we're starting to see here, folks, is that on top of sharing code to do something,\r \r WebR, WebAssembly in general, is gonna let us try it out in the browser about you installing a single thing. So\r \r if you're a new user to R,\r \r man alive. This is a great time to get into the language of these kind of resources inside. But you can quickly see the examples that,\r \r that Isabella puts in here and run them yourself\r \r and see what's happening. So it's really, really neat to see. So invisible\r \r definitely is something I'm starting to use more in my\r \r function authoring,\r \r in the future.\r \r\n\nAnother one that I did not know existed, so,\r \r you know, mission accomplished for her blog post is the no quote function\r \r which basically means if you want\r \r to show the syntax of, like, a character string\r \r but don't want the quotes around it, you can simply feed it into the no quote function, and now it's going to print as if you don't have the quotes around it.\r \r I think this can be very helpful, especially as you're dealing with HTML\r \r language, like links or other things that you want to maybe copy into another program or a browser\r \r toolbar,\r \r then having that no quote function for, like, a URL type function that she highlights here would be very helpful to let you copy and paste without too much friction there.\r \r\n\nSo I could see other uses for that as well.\r \r Here's one that brings back memories for me in my very early days of my R usage of visualization\r \r is the co plot function.\r \r This is a very handy function when you have, you know, a situation of analyzing multiple variables at once\r \r where you could look at\r \r different pairs of variables, perhaps even conditioning on another one\r \r as well,\r \r and you can quickly, kind of, get a read for how these variables are going to interact with each other visually.\r \r Great for correlation analysis or other association analysis at\r \r a very high level. So that's all built right in. Very\r \r nice straight to the point. You can even customize how the rows are\r \r constructed and everything like that. So really nice examples throughout.\r \r\n\nThis one,\r \r I have theories on why it's named this way, but we'll see what you think, Mike.\r \r Nz\r \r char or nz car, depending on how you want to pronounce\r \r it. When I look at that name alone,\r \r I honestly have no idea what that does at first glance. But what this function really does\r \r is that it is a way to simply return true or false\r \r on whether\r \r the character vector that you supply to it\r \r is empty or not.\r \r Now n z, at first, I thought, does that mean like non zero?\r \r I don't know about that. But then I thought, well, here's maybe an egg. This\r \r is speculation on my part.\r \r\n\nWe know, if you're a historian about the R language itself, that it was founded by Ross Ahaka and Robert Gentlemen\r \r while they were teaching at the University of Auckland\r \r\n\n[00:16:12] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 12,
        "trans_speaker": "Mike Thomas",
        "trans_text": "in New Zealand. For it. New Zealand.\r \r\n\n[00:16:16] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I I cannot take I I don't know. I've never seen this in writing, but I wouldn't be shocked if there was a little Easter egg in there somewhere because why is it called nzchar otherwise?\r \r I don't know. But in any event, I don't use this function enough. Have you used this function before, Mike? Nzchar?\r \r\n\n[00:16:31] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 31,
        "trans_speaker": "Mike Thomas",
        "trans_text": "No, I haven't. I haven't. I've seen it, obviously just come across\r \r like my, you know, sort of automated,\r \r whatever it is, let, you know, within our our studio that sort of pops up, different functions for you as you start start typing.\r \r But I don't think I've used it before. Let me see if I can take a look at what the documentation\r \r says about\r \r nzchar.\r \r\n\n[00:16:57] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 57,
        "trans_speaker": "Eric Nantz",
        "trans_text": "I did look at this before the show. I didn't see any references to my You know. You know. That's\r \r\n\n[00:17:02] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 2,
        "trans_speaker": "Mike Thomas",
        "trans_text": "like thinking there. Easter eggs there, but I would have thought non zero.\r \r Well, the n char obviously means number of characters.\r \r\n\n[00:17:13] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. That one I get. Yeah. Yeah. Number of\r \r\n\n[00:17:18] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 18,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I don't know.\r \r I don't know. Because it's not number of 0 length\r \r character vectors. It's the opposite.\r \r\n\n[00:17:26] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 26,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Right. Right. So if you're listening, I'm gonna let you know how to get feedback to us. We love to hear theories from all of you in the audience on this particular one because\r \r I've I've wondered about this for years, but, admittedly, I have not used the function much in daily practice. But, hey, now if I have a need to check if they're empty or not, I will\r \r\n\n[00:17:45] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 45,
        "trans_speaker": "Mike Thomas",
        "trans_text": "leverage this for sure. Well, I wonder if, you know, sometimes I feel like functions like this, especially within bass art sort of inherit their names maybe from the\r \r the c functions that underlay them. So I wonder That could be. A relationship there.\r \r\n\n[00:17:59] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 59,
        "trans_speaker": "Eric Nantz",
        "trans_text": "That could be because r is standing on the shoulders of c, Fortran, and the like, and of course, the s language before r. So there's a lot of legacy under the hood that, you know,\r \r you could go down lots of rabbit holes for the history of r on this. So\r \r alright. We'll move along here. Another function that I meant I have a checkered pass with,\r \r curious your pass on this, Mike, is the with package.\r \r The when I first used this, this was, in essence, a shortcut function for me where if I wanted to\r \r feed into\r \r another function, in this case, the example,\r \r Isabelle puts in here is the plot function,\r \r and you're feeding into it a data frame,\r \r but there are specifically variables of a data frame. If you're lazy and don't want to type like, in this case, mtcars$HP\r \r or mtcars\r \r $mpg,\r \r you can use the width function,\r \r supply the data frame, and then the plot function and just reference the HP and MPG\r \r without the dollar sign syntax,\r \r not too dissimilar to what you might see in a tidyverse pipeline as you're doing the piping operations.\r \r\n\nYes.\r \r It is helpful in this case, but I have tripped myself up more than I care to admit when I use this in the past. So, admittedly, I moved away from it.\r \r But hey. You know what? It is a way to to take that shortcut as long as you use it responsibly, I would guess. Yeah. It's another it's another option. Not one that I admittedly use very often, but it is an option.\r \r Yes. It is. And now this next one, I knew about what I call the single version of this. But I know there was a plural version of it, and that is the length\r \r function with the s at the end because I use length all the time to check, you know,\r \r the it says the length of a number\r \r or string or whatnot.\r \r\n\nBut if you want to quickly check for each element in a vector,\r \r length is basically a shortcut to, like, the more verbose, like, s apply or l apply syntax for doing this.\r \r So this is great. This may be another shortcut that you can put in your toolbox instead of having to do a per map on using length under the hood or an s supply under the hood. So that was that was a new one to me for sure.\r \r And then here comes the operator that I admittedly should have used way long ago.\r \r And that is called the no coacine\r \r operator. I'm probably not saying that right. But if you've seen\r \r in various conditional\r \r logic,\r \r the percent sign\r \r to vertical pipes and the other percent sign closing it, that is this null coalescing\r \r operator.\r \r\n\nAnd this is a shortcut. If you've ever done a check for if an object being null or not and you've got like\r \r an if statement. If is dot null something, then return something else, return something else.\r \r This is a shortcut to that.\r \r And, also,\r \r the esteemed Jenny Bryan herself\r \r highlighted this in one of her talks at the USAR itself in 2018, which is linked to in the blog post.\r \r So part of her\r \r underlying kind of theme of code smells\r \r and things that you can shore up in your day to day coding development and R. This operator, she shows some great examples of how it streamlines a whole lot\r \r on that if else syntax.\r \r\n\nSo that's that's a whirlwind tour of all this, but there's a lot to choose from. And, of course, that just scratches the surface\r \r of what Baysar has. So Isabella concludes the post with some additional blog posts from others in the community and what they've seen in Bayesar that's been useful to them. So\r \r really like to see it. And, again, love,\r \r love the idea\r \r of being able to run the code directly in this blog post to try things out. So\r \r\n\n[00:21:53] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Mike Thomas",
        "trans_text": "awesome stuff all around. I think it is thanks\r \r to Isabella's\r \r implementation or integration here with WebR that\r \r I have finally wrapped my brain around what the invisible function\r \r does because I have seen it in so much code on GitHub.\r \r I have never used it. I still don't know\r \r where I would really have much of a use case for it, maybe in some of our more object oriented\r \r programming, but, you know, really the idea again there is\r \r that, your your your function is primarily called for its side effect. So I guess, one of the examples,\r \r that I read up on, I can't remember whether it's within this blog post or outside this blog post, but it's like the the right CSV function from the reader package. So that's that's obviously going to write a CSV\r \r somewhere to to some destination path that you supplied\r \r and won't return anything\r \r within your console when that happens. Right? Most of the time you're doing that and you're not you're not assigning that right CSV function to a variable.\r \r\n\nSo you wouldn't know, right, that that would potentially ever return anything. But if you did\r \r assign that to a variable,\r \r it would actually return the data frame, I believe, to that variable.\r \r Which is,\r \r which is pretty interesting.\r \r You know, it makes me curious about how many\r \r different functions\r \r out there do have this invisible call\r \r at the bottom of them, such that if you did assign\r \r that function to an object,\r \r you know, that objects would be populated with with something.\r \r So I think it's interesting. I think it's really good to know. Maybe something nice to have in your back pocket,\r \r and I've finally wrapped my brain around that. And I'm not gonna walk through all the other functions that you walk through, Eric, but I will just note that the this null coalescing operator,\r \r I I think is going to save me a lot of code writing once it's finally integrated in BaseR here shortly,\r \r as opposed to, you know, in just about every project I'm working on, I I do have some test for if if this is null, right? Then take this action within some particular if statement.\r \r\n\nThe coalesce operator the the coalesce function\r \r within SQL\r \r SQL has been huge, for for Catchbook and a lot of the SQL work that we do for our clients on. Some particular,\r \r address standardization\r \r projects where we're we're trying to test if,\r \r you know, the the user has a valid\r \r address too. Right? As a second line in their address like a PO box or something like that or not.\r \r So that's that's a function in sequel that we use really really often.\r \r I believe that within d player, there is a similar coalesce\r \r function as well that can return sort of the first non null,\r \r value within a list of values that you you pass it. So we I find that pretty handy,\r \r and maybe some other folks will as well. But I couldn't agree more that the WebR implementation here that allows us to actually touch and feel these functions as we're reading about them is a game changer. So thanks to Isabella for taking the time to do that, and I am going to dive deep into the GitHub behind her pipe dreams blog here to see how she did that.\r \r\n\n\n\n[00:25:11] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 11,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And the best part is, in fact, I remember when I first saw these kind of posts, I would see the run code, and I would I would hit it. I mean, this reminds me of the learn r package a little bit too. But then I realized, oh, wait. I can actually\r \r click in that code box and change it myself. Like, it's not just the pre canned example, no less. You can experiment with all this, which makes it even more fun. My goodness. So you can kinda see why this is gonna become a huge in the realm of\r \r teaching, the realm of illustrating these concepts.\r \r I mean, think about this, Mike. I know we're not far off, I think, from a packages\r \r documentation\r \r site. We're gonna let you run the package code itself as a way to try it before you, quote unquote buy so to speak. I can't wait until we can integrate that into our package down sites. It's gonna be incredible, right? Within your examples or\r \r\n\n[00:26:02] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 2,
        "trans_speaker": "Mike Thomas",
        "trans_text": "or wherever, your your reference. That's gonna be huge. And, you know, from the first blog post that we ever saw\r \r with WebR chunks in it to where we're at now, in particular,\r \r this installation of the the tidy tab package and Isabella's blog that's coming from our universe.\r \r The installation is so fast, so much faster than it used to be. I think we're waiting, like, you know, 2 or 3 minutes previously. And now, you know, we might be waiting 10, 15 seconds.\r \r\n\n[00:26:30] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 30,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. George Stagg, the the engineer behind this at Pazit, he is,\r \r he's doing some divine work here, I must say, to make all this happen. And we are all super, super appreciative for it.\r \r So this is an area that I mentioned on this podcast I'm exploring very actively right now, and the possibilities\r \r are practically endless. But, yeah. And credit to Isabella for, again, putting a much needed spotlight on these gems inside the R language itself that you get every time you install\r \r the language for free, just like everything in R, it is open source all for you\r \r to leverage at your leisure.\r \r\n\nAnd speaking of interactivity, Mike, as we saw in Isabelle's awesome blog post from the last highlight, making it interactive with the WebR functionality\r \r Well, in the Quartle ecosystem,\r \r now we've got tremendous ways\r \r to make interactive\r \r dashboards\r \r as well.\r \r And dashboards,\r \r if you're familiar with the flexdashboard\r \r package that many use in the R Markdown ecosystem,\r \r The quartile syntax or dashboards is very similar.\r \r So you can get up and running pretty quickly, but just what is the easiest ways for you to make that into a more interactive display and not just a stack display?\r \r Well, friend of the show, frequent contributor, Albert Rapp, is back once again returning to the highlights\r \r with his, latest\r \r 3 minutes Wednesday style post\r \r of making a portal dashboard\r \r interactive.\r \r\n\nAnd you might say, well, just how do we go about this? Well, this is a continuation\r \r of a previous post where he put in the syntax needed to make, in essence, a placeholder dashboard.\r \r We've got, you know, a column here,\r \r a column there, and a row below it, and then a sidebar,\r \r but nothing in it yet. So how do we replace all that with things that can be both static or interactive?\r \r Well, just like anything in quartile,\r \r give yourself an R code chunk or even a Python code chunk, and you'd be able to\r \r add in things like a really nice markdown syntax for your sidebar.\r \r You can leverage\r \r in HTML tools hidden gem. I use this a lot in my Shiny apps. The include markdown function,\r \r where instead of writing the markdown literally inside the source code of your app or your UI function,\r \r you could have that as an external markdown file. Just reference that markdown file, and it's going to compile it in the\r \r web markup and put it anywhere you want in your HTML report or Shiny app. So he does that in the sidebar with a little bit of narrative around\r \r the dashboard itself.\r \r\n\nAnd then let's spruce it up with some nice tables, shall we? And that's where the first\r \r example of an element to put in this table or put in this dashboard\r \r is a table of the palmer penguin set using the very incredible GT package by Riccione\r \r over at Posit.\r \r Love this package. And it gives you a very attractive looking,\r \r static looking\r \r table, which, again, for many purposes would be very, very good for the majority of reports.\r \r Now, of course, no dashboard would be completely about some form of, you know, more traditional visualization.\r \r And that's where, of course, ggplot2\r \r will feed in very nicely into a portal dashboard or any type of report for that matter.\r \r\n\nBut on the old net, it's static. Right? How do we make that interactive?\r \r Well, Albert\r \r highlights another\r \r package that didn't get a lot of love initially, but, boy, it sure took off, especially last year,\r \r the ggiraffe\r \r package or ggiraffe package, maybe how you wanna pronounce it. I still don't know which one it is, but I'm go with either one,\r \r authored by David Goel\r \r on being able to turn\r \r a static ggplot\r \r produced visualization\r \r into interactive with tooltips and other great,\r \r little interactive features as well. So you can quickly\r \r give you that kind of hover functionality\r \r or filtering\r \r functionality by clicking on different points. There are lots of lots of cool things you can do with an interactive visualization on that.\r \r\n\nNow how about going back to that table? The GT table looks great, but it is a bit static in its presentation.\r \r Well, making a short little pivot to the reactable\r \r package, which, again, is one of my favorites from my Shiny apps and reports, you can have that sorting\r \r and filtering functionality\r \r inside. And then lo and behold, you could even bake in at the end of the post\r \r a way to filter the table with some controls that are embedded in the sidebar\r \r of the portal dashboard itself.\r \r And you don't necessarily need Shiny for that. There are ways you can build that with the observable JS code chunks or other ways\r \r with crosstalk as well\r \r to make that HTML element linked to that input that you put in, even the sidebar or maybe above the table\r \r or visual.\r \r\n\nAnd you can have that interactivity\r \r so that the user can customize how they want to display. In this case, the penguin's\r \r weight distribution\r \r in that table.\r \r Apparently, there's gonna be another video that he releases coming soon about making those reactable tables\r \r even more interactive. So we're gonna be staying tuned for that. That's a space I'm looking at quite closely in my exploits at the day job.\r \r So, again, portal dashboards are becoming very popular now,\r \r and you can make them very interactive\r \r very quickly.\r \r And we didn't get into the the bits that you could do with a Shiny back end as well, but,\r \r you could do a lot with portal dashboards. And I'm actively pursuing this as we speak of an open source project right now. So credit to Albert. Once again, terrific post, easily digestible with links to more detailed tutorials that he's done on these various topics, including his\r \r ebook that he's written as well\r \r on creating GT tables. So he's I don't know if he ever sleeps, man, but, boy, he is busy.\r \r\n\n\n\n[00:32:51] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 51,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Reminds me of somebody else I know who I feel like never sleeps.\r \r Who would give you that idea?\r \r But,\r \r this is awesome blog post. I am already deep into\r \r Albert's code which is, looks like we got a little bit of JavaScript going on\r \r to connect these these filters, these check boxes to the reactable\r \r table.\r \r I did not know that that was possible, but that is really really cool that he's done that. Obviously, I've seen\r \r that,\r \r sort of interactivity\r \r that you could deploy to a static site if you are using Observable JS,\r \r with the ability to to have filters that drive your charts and things like that, but did not know, we could do that with reactables. So that is super cool. That is some code that I'm going to\r \r be taking a hard look at, and really excited and grateful that Albert has put this out in the open. You know, one thing that is consistent with Albert is his data visualization\r \r projects and products are always really aesthetically nice.\r \r\n\nSo I think that\r \r that's that's awesome. And you can see him leveraging sort of the new quarto dashboard framework, where you have a card with a plot in it, and that card has a little icon in the bottom right hand corner to expand that full page, which is another one of my favorite features. Our clients absolutely love that with our quarto dashboards that we're creating\r \r these days and and with, leveraging bslib, essentially within our Shiny apps, we have the same functionality within that card function. And it looks like maybe the g g I raf package\r \r also allows you to download\r \r these interactive plots, maybe as a a static image or an HTML file as well with a little icon, a little save icon in the top right hand\r \r corner, which is just a nice utility on top of that. Albert, phenomenal blog post, with videos, content, visuals, GitHub links,\r \r everything,\r \r you name it. So this is actually a pretty big repository, it looks like, behind,\r \r this behind this blog post. It's a blog it's a repository,\r \r under albertwrap,\r \r slash quarto dashboard\r \r is where you're going to be able to find that on GitHub if you're interested. And it looks like there's just a ton of examples\r \r for interactive plots, tables, interactive selection, OJS,\r \r reactable plots,\r \r the whole 9 yards. So this is a wealth of knowledge baked into a fairly concise blog post, which seems to be a theme with Albert, and I hope nothing changes in the future. So thank you for not sleeping, Albert. And, thank you for putting this together.\r \r\n\n\n\n[00:35:26] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 26,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. There's a lot to look at in this repo. We'll have a link to this in the show notes, but it does go through each of these different iterations\r \r of how he's built this dashboard going from the completely static approach all the way to that fancy\r \r interactive,\r \r reactable version and interactive selection. So, yeah, there's gonna be a lot a lot to choose from here. Certainly, if you're a power user of things like CSS, there's a handy little\r \r SCSS snippet here too that style things a a bit more. So\r \r there's a lot to choose from in this space.\r \r So as we mentioned a number of times highlighting the Quartle dashboard functionality,\r \r there was\r \r many, many in the community asking for the flex dashboard set up in Quartle. And now that is here. And I'm very excited to see to see where that goes.\r \r\n\nAnd just as exciting is the rest of the issue of our weekly itself because the highlights don't do enough justice to the great content\r \r in the rest of the issue, which, of course, is linked as always in the episode show notes. But Mike and I are gonna take a couple of minutes to talk about some\r \r additional fines that we've, found in this issue.\r \r And going back to our first highlight, our our author, Mel Salmon, of that blog post,\r \r She's also been hard at work on another what can be a very thorny\r \r topic\r \r for both learning and teaching as well.\r \r Recently, I've been following this a bit on her Mastodon account.\r \r\n\nShe has authored a new r package\r \r with a very\r \r unique name, which I'm probably gonna butcher it right here, called\r \r sacralopopet.\r \r Yeah. Send your send your feedback to me, I guess, for that one. But in any event,\r \r this is a package\r \r that is meant to help create in your R session\r \r the not so pleasant experiences\r \r that can happen with Git.\r \r Looking at things like, you know, maybe messed up committed files,\r \r maybe a merge gone completely wrong.\r \r This is inspired by a very famous,\r \r site that you've probably bookmarked if you had a problem with Git\r \r called\r \r okay Git.\r \r\n\nYou can fill in the blank on that.\r \r But in any event, in your R session, you can do some very fun things to learn\r \r how to resolve some of these issues in Git itself\r \r that you often will find yourself in one way or another,\r \r whoever willingly or not willingly,\r \r in your version control escapades.\r \r So I'm gonna be looking at this because I'm gonna be\r \r likely teaching some form of get, you know, training or workshop\r \r at the day job. Maybe I even do that in the open source world. Who knows? But having a way to illustrate, you know, what just happens when things go wrong\r \r and let you practice\r \r how to fix it,\r \r I think that's extremely\r \r helpful because\r \r almost nothing in good goes exactly\r \r as planned the first time around. So knowing how to handle these thorny issues,\r \r especially on those merger requests, I think is very very helpful.\r \r\n\nNow, Micah, what did you find?\r \r\n\n[00:38:34] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Mike Thomas",
        "trans_text": "No. That's a great find, Eric. I found that the with our package,\r \r has a new release,\r \r version new major release, version 3.0.0.\r \r There's a nice blog post from Leonel Henry, who's on the Pasa team, I believe,\r \r talking about, sort of, what the\r \r improvements\r \r are here. It looks like a lot of the improvements\r \r are around the performance and compatibility\r \r with BaseR's\r \r on dot exit\r \r function, which if you are a shiny developer,\r \r especially somebody who's authoring shiny apps that maybe connect to a database that you want to disconnect from, which you should be doing\r \r at the end of the users at the end of the users\r \r session, not the global session, the users session,\r \r you should be leveraging that. So the with our package, may be able to to help you do that and help you test, that functionality\r \r as well. We recently\r \r put out an open source,\r \r our package\r \r for working with some agricultural\r \r finance\r \r data, and\r \r that download some data from the web. And within my testing suite, the unit test would test that. I leverage the with our package to download that data into a temp file,\r \r ingest that data into a data frame, and run my test against that.\r \r\n\nAnd everything sort of disappears\r \r at the end of those unit tests running and all the the checks pass with with, dev tools. And I don't have to worry about actual locations,\r \r within my own machine or with somebody else's\r \r machine or or within Crayon's machine when we finally send this off to Crayon about where, those those files are gonna be temporarily\r \r downloaded to with our just takes care of all that for me, and I can't speak highly enough about\r \r that package, as well as the blog post that Me'el Saman has authored around with our functionality that sort certainly helped me get set up there. So long story short, I am very much a new\r \r fan of of Withar. We'll be using it from here on out. And thanks to Leonel for,\r \r letting us know what's new in Withar 3 dot0.0.\r \r\n\n\n\n[00:40:40] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. It's been, it's been a a very helpful package in my exploits as developing\r \r both apps and packages. And, frankly, your idea\r \r of building this into the testing\r \r of your package, I think, is extremely\r \r novel, especially as you\r \r have to deal with maybe other systems or resources from other systems, and you may have to download something, may have to temporarily write a config file to send to something.\r \r You don't want that left around because you're only doing it in a disposable way, maybe through a CICD pipeline. So with our very valuable in that space,\r \r especially for other thorny issues, like even just having a temporary change of directory that I'm working in just for some esoteric reason because of some other pipeline. I have to be somewhere else just for that function and get back to where I was.\r \r\n\nYeah. With r is is\r \r is very much appreciative in that kinda utility\r \r toolbox that I have for my day to day package and app, development needs. So, yeah, really enjoyed\r \r reading about version 3 that just got released.\r \r And, of course, as we mentioned, we love hearing from you and the community, and we're gonna tell you about the various ways you can get in touch with us. Of course, first, everything you wanna learn about our weekly is at rweekly.org.\r \r So if you haven't bookmarked that, please do. That's where you'll find every new issue and every\r \r every new every back catalog, so to speak. Every previous issue is right there at the taking.\r \r\n\nAnd if you wanna join our curator team, we definitely have open slots. Please, get in touch with us. We have the details\r \r on the GitHub repository\r \r for our weekly. That's linked to, directly in the our weekly site itself.\r \r And, also, we love hearing from you directly for this very show. Whether it's me butchering another package name or whatnot or or our, speculation of our history, we'd love to hear it. So\r \r you can do that via the contact page that's linked in this episode show notes. It's always there.\r \r And, also, if you wanna send us a fun little boost of your feedback using a podcast app\r \r such as Podverse, Fountain, Cast O Matic, or the podcast index itself, that's all right there. We have links to how to do that in the show notes as well. And thanks to all of our previous boosters for giving us some much needed encouragement, and we always welcome your feedback on that side too.\r \r\n\nAnd, also, we are sporadically on the social media spheres.\r \r I'm on that weapon x thing from time to time with at the at the r cast, but also more frequently,\r \r I'm Mastodon with [email protected],\r \r and I will cross post from time to time on LinkedIn. Just search for my name. You'll probably find me. And, Mike, where can the listeners find you? Likewise. Probably best on mastodon@[email protected].\r \r\n\n[00:43:27] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Mike Thomas",
        "trans_text": "And if you wanna find me on LinkedIn, best way is to search Catchbrook Analytics,\r \r k e t c h b r o o k,\r \r to find out what I'm up to lately.\r \r\n\n[00:43:36] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "trans_timestamp": 36,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Awesome stuff. I enjoy seeing your post from time to time. Your your your hustle never stops either, so I hope you get some rest too when you can.\r \r But in any event, we're gonna stop hustling, so to speak, on this episode. We'll wrap things up here, and we'll be back with another edition of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_04_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "chap_timestamp": 35,
        "chap_text": "Babeldown for updating translations"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "chap_timestamp": 34,
        "chap_text": "Not-so-basic R functions"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "chap_timestamp": 14,
        "chap_text": "Interactive Quarto Dashboards"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "chap_timestamp": 12,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_04_highlights",
        "chap_timestamp": 44,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_03_highlights",
        "ep_date": "2024-01-17",
        "ep_duration": 41,
        "ep_description_short": "A tour of how the httr2 package streamlines API processing in R, five must-have ggplot2 extension packages for your next visualization, and the Appsilon Shiny Conf 2024 is shaping up to be the biggest yet for all things Shiny. Episode Links This week's curator: Colin Fay - [@ColinFay]](https://twitter.com/ColinFay) (Twitter) How to work with APIs…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_03_highlights",
        "description_long": "\r \r\n\nA tour of how the httr2 package streamlines API processing in R, five must-have ggplot2 extension packages for your next visualization, and the Appsilon Shiny Conf 2024 is shaping up to be the biggest yet for all things Shiny.\n\nEpisode Links\n\nThis week's curator: Colin Fay - [@_ColinFay]](https://twitter.com/_ColinFay) (Twitter)\nHow to work with APIs using the httr2 package\nFive Powerful ggplot Extensions\nCall for Speakers: ShinyConf 2024 by Appsilon\nEntire issue available at rweekly.org/2024-W03\n\nSupplement Resources\n\nEric's podindexr package (accessing the Podcast Index API from R) https://github.com/rpodcast/podindexr\nMelissa's web site https://www.melissavanbussel.com/\nggnot2 YouTube channel https://www.youtube.com/c/ggnot2\nJon Harman's web APIs with R book https://wapir.io/\nbeekeeper (rapidly scaffold API client packages) https://github.com/jonthegeek/beekeeper\nggtext - Claus Wilke https://wilkelab.org/ggtext/\npatchwork - Thomas Pedersen https://patchwork.data-imaginist.com/\nggpattern - Mike FC (coolbutuseless) https://coolbutuseless.github.io/package/ggpattern/\nggforce - Thomas Pedersen https://ggforce.data-imaginist.com/\nggbump - David Sjoberg https://github.com/davidsjoberg/ggbump\nShinyConf 2024 https://www.shinyconf.com/\nYihui Xie: RAP god (Matt Dray) https://www.rostrum.blog/posts/2024-01-12-yihui-rap/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://twitter.com/_ColinFay"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://www.youtube.com/watch?v=8tilyqp4bZY"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://albert-rapp.de/posts/ggplot2-tips/20_ggplot_extensions/ggplot_extensions"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://r-posts.com/call-for-speakers-shinyconf-2024-by-appsilon/"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://rweekly.org/2024-W03.html"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://github.com/rpodcast/podindexr"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://www.melissavanbussel.com/"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://www.youtube.com/c/ggnot2"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://wapir.io/"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://github.com/jonthegeek/beekeeper"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://wilkelab.org/ggtext/"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://patchwork.data-imaginist.com/"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://coolbutuseless.github.io/package/ggpattern/"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://ggforce.data-imaginist.com/"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://github.com/davidsjoberg/ggbump"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://www.shinyconf.com/"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://www.rostrum.blog/posts/2024-01-12-yihui-rap/"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. We are back at episode a 148 of the R Weekly highlights podcast.\r \r And coming to you from our respective,\r \r frigid areas here in the US, where we hope we can heat you up a little bit with some fun, our content, as always,\r \r coming straight from the latest issue on ourweekly.org.\r \r My name is Eric Nantz, and I'm delighted that you join us wherever you are around the world.\r \r And keeping warm in his abode there is my awesome cohost, Mike Thomas. Mike, how are you doing this morning?\r \r\n\n[00:00:29] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 29,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Doing great, Eric. Go Lions. How about that? Go\r \r\n\n[00:00:33] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 33,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Lions. For those that aren't aware, the the Detroit Lions have had a, bit of a struggle in really doing anything successful for many, many, and I do mean many years in the football landscape, but they won their 1st playoff game in 31\r \r years, folks.\r \r That's a long time. I was,\r \r I'm not gonna date myself too much. Well, let's just say I was quite younger back then. And it was,\r \r yeah. Who knew that it would take that long to get back there? But the the Ford field was rocking. And as a Michigander all my life, it was,\r \r I could see why fans are crying in the sands. That was a moment, folks, and they're not stopping. They got another game this weekend, so we'll see what happens.\r \r\n\n\n\n[00:01:13] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 13,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Keep it rolling.\r \r\n\n[00:01:15] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 15,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Keep it rolling, baby. And we're gonna keep this podcast rolling as well because we got another awesome issue\r \r to talk about that's curated by the esteemed Colin Fay.\r \r By this point, you know who he is if you listen to the show just a little bit. For those who aren't aware, he is at ThinkR, and he does awesome art packages in the shiny space such as golem, which we use quite a bit in our day to day. But as always, he had tremendous help from our fellow our weekly team members and contributors like all of you around the world with your awesome poll requests and suggestions.\r \r And first,\r \r on our highlights today,\r \r as we told you many times before,\r \r it is a new age, so to speak, in computing, and gone are the days where you have to rely on just getting your data from\r \r CSVs in a random place all the time\r \r or having to deal with other proprietary\r \r platforms or services. Now there is the wonder of APIs\r \r for you to access these services programmatically.\r \r\n\nAnd our first highlight is a great tutorial on a recent refresh, if you will,\r \r of a very important package in this space of using R to call these APIs very quickly and efficiently.\r \r And in particular, Melissa Van Basso, who is an associate statistician\r \r at Statistics Canada,\r \r and she makes a lot of our videos about our programming and statistics. And that's literally one of her taglines in her channel\r \r called g g not. And if you haven't bookmarked it, you should because she pumps out a lot of terrific content\r \r on a very regular basis.\r \r\n\nVery inspiring.\r \r Her latest video is an aforementioned\r \r tutorial,\r \r quick but straight to the point,\r \r practical tutorial on working with APIs\r \r using h t t r 2.\r \r And she sets the stage by putting on some nice analogies about how APIs\r \r with respect to security works because\r \r most of the time, these APIs,\r \r yeah, they may technically\r \r be free to use and some are not,\r \r but one way or another, you need to authenticate to them in some way, shape, or form.\r \r This can be very confusing to people, but she walks through 2 examples.\r \r 1, using OpenAI's\r \r API for, you guessed it, an image generation,\r \r request,\r \r but also\r \r something that I hope gets more spotlight in, in the our ecosystem these days\r \r is the API for GitLab.\r \r\n\nFor those that aren't aware, GitLab is somewhat analogous to GitHub, only it is free and open source, at least open core.\r \r And a lot of people are turning to that to self host their version control repositories.\r \r And in fact, many organizations\r \r use that as well within their firewalls that give them that robust Git, like, hosting platform\r \r but under their control. But they have an API as well. So she walks through 2 examples, again, using those respective APIs\r \r and how to authenticate to them with h t t r 2.\r \r And this is where you will have to inject\r \r some authorization\r \r magic, but there is a function in h t t r 2 to do just that.\r \r\n\nBut it is interesting that she selected 2 examples because not every company behind these APIs\r \r is gonna have the exact same syntax for authentication.\r \r And, in fact, these two services do require slightly different\r \r request language or request structure\r \r in that authorization\r \r header, if you will. And the good news is this video does have an associated GitHub repo where she walks through the, example very clearly,\r \r and you can quickly get a get a glance at it. It's only about 50 lines or so, but you can see the different headers that she has to inject\r \r in these various APIs.\r \r\n\nNow\r \r the best situation, of course, is if there is an r package that actually wraps this API that you're interested in. She's very upfront with the fact that in real world usage, you might wanna leverage that particular package instead of building something up yourself. But, again, this is a tutorial\r \r for how h t t r two works. So it's really great to see\r \r these, this example here.\r \r And, honestly, once you get the authentication down, that's kinda like more than half the battle, so to speak. And trust me, I've been there. I've had some wicked wars of authentication in the past.\r \r But at that point, the other interesting nuance between these examples\r \r is the type of request that you're about to send.\r \r\n\nWith respect to the GitLab API, she's interested in grabbing issue summaries,\r \r and that is facilitated by what we call a Git request.\r \r You're not really putting anything else in your request\r \r kind of transmit to the API service\r \r other than a various parameter or set of parameters in the URL of that actual request.\r \r Whereas, for the OpenAI\r \r example,\r \r she actually has to do what's called a post request, which is saying that you, as a submitter of that request,\r \r have to tell the API something about what you want or supply some important information.\r \r And in this case, it's the prompt of what kind of image she wants to generate.\r \r\n\nAnd, of course, we love animals here on this podcast. So she has a prompt of acute baby sea otter, insert penguins or whatever your favorite animal is. You can probably do that too. But that has to be a post request. That's not through the URL itself.\r \r So, again,\r \r most of these APIs will have documentation,\r \r some may be better than others, on how to handle these requests\r \r and whether it's a get request or a post request. But oftentimes, when you're kinda like doing a query of what's out there, most of the time, that's gonna be a post request of some sort.\r \r But in the end, once you get the results back, you're gonna get some nice,\r \r maybe not so nice, list of the results.\r \r\n\nOften, it's being compiled from JSON from the API itself.\r \r An h t r two will have a friendly wrapper to say, okay. This is a re a request\r \r coming back in JSON format, but I'm gonna translate that back to a list.\r \r And then\r \r it's up to you to wrangle that list afterwards. So that's more of an exercise for you to play with at the end here, but she does show a couple of examples of how you can subset\r \r this nested list for the various parameters like the title of that issue or milestone\r \r or other information such as the URL of that image that's being generated\r \r from OpenAI.\r \r\n\nThat's where\r \r there are other packages in the our ecosystem that can definitely help with wrangling lists. Mike and I love the per package for a lot of these situations.\r \r There are other interesting ones where it turns a nested list into a nested data frame. I've seen that mentioned in the past. There's lots of ways to post process this.\r \r But, again, half the battle is just getting authenticated to this and then leveraging h t t r two's new pipeable syntax\r \r to kind of build this step by step, the request process as a whole. So if you're new to it, definitely start with this package.\r \r HTTR\r \r itself came before it, and I used it extensively back in the day. But if you're comfortable with the tidyverse, you're comfortable with pipeline processing,\r \r this is gonna be a very nice fit for you as you get involved in this landscape.\r \r\n\nAnd I can speak as a package author, albeit a very,\r \r low key package,\r \r that h t t r 2 was very easy to work with.\r \r My package called pod index r, which is interfacing the podcast 2.0 API from r, leverages h t t r 2 under the hood. So I did authentication\r \r via the mechanisms that she talks about here. I do want to mention one thing, though.\r \r Never ever put your authentication keys in your script itself. And this is obviously a very brief example, but in real practice,\r \r environment variables are your friends here. So definitely take a look at that. That's also documented in the h t t r two's package Vignettes if you're curious about how that lingo works. But one thing that trips a lot of people up at the day job,\r \r if you're updating your environment variables, maybe you generated a fresh token for that service or whatnot.\r \r\n\nYou've gotta restart that hour session first because it will not take effect until you do, and I've had more than a few calls, a few messages on our teams at work of, I changed my GitHub\r \r API, PA 2, and it's not working. Help. And I'm like, did you restart your session?\r \r Oh,\r \r so don't just just it it happens, folks. It happens to the best of us. And, yes, it's happened to me even at this,\r \r experience level of APIs that just trips you up, especially the AWS ones. I'm gonna be starting on that. But, nonetheless, this was an awesome straight to the point tutorial. It's an easy watch, maybe 15 minutes at the most. And Melissa has a bunch of other\r \r terrific tutorials on his on her channel, so definitely have a look at that.\r \r\n\n\n\n[00:10:16] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. This was probably my first, that I can remember introduction\r \r to Melissa, and she does a phenomenal\r \r job, like you said, Eric, in this quick nice 15 minute\r \r YouTube post about how to work with the new h t t r two package and and I do really like the the beauty of the pipeable\r \r syntax as you sort of build up either this get or post request\r \r and then finally execute\r \r that. And, yeah, I just can't speak highly enough about how well, Melissa really articulates\r \r every step of the process.\r \r You know, why she's writing the code that she is, particular syntax,\r \r things that you can get hung up on such as having to to quote,\r \r her back tick essentially different pieces\r \r of the,\r \r the the request that you are sending\r \r to make sure that, you know, our isn't,\r \r unable to to find certain objects because you're not quoting those and things like that. She she does a really nice job better than I could ever,\r \r explaining\r \r exactly how to build up these get and post requests using h t t r 2. I'm really thrilled that we have the h t two h t t r 2 package,\r \r now out and available and battle tested.\r \r\n\nSo I I would highly recommend folks who have been using h t t r,\r \r to to take a look and see if it makes sense to switch over to h t t r 2. I think you'll find some gains in efficiencies,\r \r some gains in, just sort of the the syntax style\r \r and things like that that might make your life a little bit easier and I think you know a big\r \r key\r \r to these packages is they help developers\r \r as well\r \r create our packages that serve as wrappers to API's right that make everybody's life easier\r \r so if you're somebody that, you know, has an API out there that you really wanna create an R package around to make other people's life easier interacting with that that data source or whatever that API\r \r serves, maybe the h t t r two package\r \r will help you do that more easily.\r \r\n\nI believe in the past with h t t r,\r \r there have been vignettes and articles and things like that on how to develop in our package that wraps an API.\r \r So I'd be curious to see. I haven't haven't checked, but maybe we can put it in the show notes to see if there's sort of an updated\r \r version of that documentation using the h t t r two\r \r package, for wrapping\r \r your favorite API. But, again, a great walk through. Really nice examples here. 1 with a get request and one with a post request that sort of run the gamut of all the different types of of APIs that you may be working with. So can't speak highly enough about Melissa. If you're interested in taking a look at some of her other content,\r \r she has her own website atmelissavambusil.com.\r \r\n\nSo check it out.\r \r\n\n[00:13:09] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 9,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. And, yeah. Follow-up to your quick question there. Yes. H t t r two does have a vignette exactly tailored to wrapping API. So definitely wonderful\r \r reading. I've read it literally 4 or 5 times as I was writing my little pod index r package,\r \r to to handle this. So it's very thorough, very,\r \r straightforward. And again, touches on those those nitty gritties like authentication\r \r and managing managing those effectively. But it's got two examples\r \r using the New York Times API for books as well as GitHub just API. So again, it's great to have 2 different examples because it's almost like no way no 2 APIs do things similarly. There's always some little minor differences here and there. And we're definitely seeing that now with HTTR 2 recently,\r \r celebrating its 1 dot o release, another, I think, reason why Melissa\r \r made this video. This is kind of the unofficial or somewhat official signal that this, like you said, is is tested by many people. It's ready to go and to augment your API workflows.\r \r\n\nWe're seeing some other packages in this kinda ecosystem area of API,\r \r you know, linking, wrangling, and now testing\r \r that are basing their work on HTTR 2 as well. So it's definitely becoming\r \r your go to, I think, for a lot of the API,\r \r operations\r \r in r itself. And I'd imagine we're gonna see more packages in the ecosystem\r \r start to wrap this,\r \r more fully as they, you know, find more APIs that just haven't been helped by the community just yet. So, yeah, wonderful tutorial, and it was a thrill to meet Melissa in person at deposit conf, back in in the fall last year. Yeah. She very personable and very humble and, yeah, really great to to see her turn through this terrific content. And there we say, we we hope you keep it up. And,\r \r there was even I remember looking at her LinkedIn post announcing this video.\r \r\n\nSomeone had the request. Hey. Have you ever thought about doing a live stream of your live coding? She sounds like she's not saying no to it. But, Melissa, if you're listening,\r \r if you want a buddy to help you along that, wink wink, I'll just say that.\r \r\n\n[00:15:20] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Who knows? Who knows? And to double down on your best practices, Eric,\r \r put your API keys as environment variables in a dotrenvironment\r \r file and git ignore that thing immediately.\r \r\n\n[00:15:32] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 32,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Immediately, folks. Yep. Because,\r \r you heard my rant maybe a year and a half ago. Somebody did not do that, and we were, dinged pretty badly at the the tape shop security group when they discovered that. So, yeah, you gotta be careful there, folks. Gotta be careful.\r \r Well, Mike, we were just saying how things are becoming more normal for us as we're getting, you know, the the 2024 season of our weekly highlights up and running.\r \r Well, one thing we didn't really have as much last time around was a great post around visualizations,\r \r and sure enough, that that's been normalized to this week, if you will, because\r \r friend of the show, Albert Rapp, is back to the highlights\r \r and for his first\r \r contribution to 2024\r \r where he has both a blog post and an accompanying video\r \r talking about 5 of his favorite ggplot 2 extensions.\r \r\n\nAs we mentioned many times in highlights before, ggplot 2 is not just about gg ggplot 2, the package itself.\r \r Because of the extension system that it introduced a few years ago,\r \r now the community can take ggplot 2's functionality\r \r and supercharge it in many, and I do mean many different ways.\r \r And this roundup of extensions\r \r is a great tour de force to just see what it exactly is capable of.\r \r And the blog post is quite visual as you would expect, so we'll do our best to summarize it here. But right off the bat, one easy win for you as you think about annotations\r \r in your plots, as you think about\r \r formatting maybe your subtitles or your titles or access labels or whatnot,\r \r have a look at the g g text package.\r \r\n\nThis is one that has been mentioned in previous highlights before. This is authored by Klaus Wilk.\r \r We'll have a link to all these packages in the in the show notes as well. But this is a very quick way for you to augment that existing text that you want to put on your plot\r \r with HTML syntax or markdown syntax. So\r \r you're living the quartile lifestyle, the Rmarkdown lifestyle, or maybe your Shiny app styling.\r \r You can do that same kind of thing in ggplot2 as well. Ggtext just does this\r \r very well, very elegantly.\r \r And if you're if you're comfortable with markdown, which many people are these days, it is a terrific fit\r \r for you on on your ggplot2\r \r builds as well. And with a low HTML knowledge, the sky's the limit for what you can do in these annotations,\r \r in these textual representations.\r \r\n\nSo\r \r must have, I would say, as you think about getting those plots in a more publication ready state.\r \r Speaking of multiple plots,\r \r one thorn in my side many, many years early in my g g file 2 exploits was the fact that,\r \r you know, I had these two plots. Maybe they were they were talking about the same domain, the same type of data, but they were completely different.\r \r But yet I wanted to compose them in such a way to arrange them so they fit on a single page\r \r or whatnot.\r \r I've had a lot of battles with grid dot draw and other situations like this, but Patchwork,\r \r the r package by Thomas Lynn Peterson,\r \r software engineer at posit,\r \r is a terrific way to take almost\r \r any type of ggplot\r \r and compose multiple ones together\r \r using a very intuitive,\r \r you know, syntax that's native to ggplot2\r \r itself\r \r with the plus operator. Just kind of combining the 2,\r \r you can stack them up with the the the slice or the fraction operator if you want, but there's a lot more customizations\r \r to say take one facet and make it big wide,\r \r maybe 2 plots below that that are sharing the space equally between each other.\r \r\n\nThis has been asked for me at the day job to help bring recommendations\r \r to this because oftentimes we'll have,\r \r like I said, these plots that are doing\r \r kind of different things, but yet using the same data,\r \r and they tell kind of different stories.\r \r So having in patchwork\r \r is so helpful\r \r to just customize a layout without a lot of fuss around it. So\r \r very, very helpful\r \r if you're in that situation like I've been many years ago. I'm having a lot of flashbacks to parmfrow,\r \r\n\n[00:19:54] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 54,
        "trans_speaker": "Mike Thomas",
        "trans_text": "which I Dude.\r \r\n\n[00:19:55] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 55,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Oh, dude. Yes. Many, many. My dissertation was full of that. Yes. It was a nightmare to debug. Lot of college flashbacks for me.\r \r Yep. Yep. We didn't we didn't expect that. But every time we do this show, we always have flashbacks of some sort. Just didn't expect that one. But,\r \r moving on to more pleasant memories or things I wish I had known about before,\r \r Sometimes\r \r you wanna really get, you know, customizable\r \r with the types of patterns\r \r that you wanna put in the geomes that you\r \r surface in these plots. Maybe a gradient\r \r or maybe a little fun like symbol or or an image that you wanna fasten into a bar chart like setup.\r \r\n\nThe next package that Albert highlights is gg pattern.\r \r Gg pattern is authored by Mike FC. You probably know him as cool but useless on the various social spheres.\r \r And this is a very excellent package that lets you\r \r simply figure,\r \r specify\r \r either geometric or image type patterns\r \r to fill in your various geomes such as bar charts, such as, you know, line charts or things like that. And then Albert, in his example here on The Post,\r \r has a fun little representation\r \r of coffee bean,\r \r quantities,\r \r for\r \r for different countries in South America\r \r by using a little coffee icon\r \r in this waffle chart type setup.\r \r\n\nThat was really interesting, the things you can do with ggpatterns.\r \r So, again,\r \r this might be great for those of you who are trying to build infographic\r \r type setups or ggplot.\r \r This might be a great fit for you. And, again, combine that with things like ggtext,\r \r the sky's the limit once again.\r \r And then the next one we have here is kind of a potpourri or a collection\r \r of kind of utility type extensions,\r \r and this is off this is called ggforce,\r \r offered by the aforementioned Thomas Lynn Peterson. He has been in the ggplot2\r \r game for many years.\r \r\n\nAnd this package, I believe, came out not too long after the extension\r \r kind of paradigm or system\r \r was introduced in ggplot2.\r \r So ggforce\r \r lets you do a whole bunch of random type\r \r geomes\r \r that maybe are not quite the same kind of design choices as someone like Hadley has thought about for ggplot2.\r \r But if you wanna create\r \r bars like a bar chart with an arc or a circle geom, which is great for obviously things like pie charts or donut charts\r \r and the like, there's lots of interesting, geoms you can augment in your existing\r \r visualizations.\r \r\n\nAnd ggforce has a whole bunch more.\r \r But again, to Albert's credit, he's got a fun little tutorial linked in the same blog post. And, he created donut charts and pie charts with gg4s.\r \r Again,\r \r lots of opportunities to combine this and really tailored,\r \r again, maybe for that infographic type setup with the alternative geoms\r \r that it offers.\r \r And last but certainly not least, we've got bump charts, which are becoming a lot more common these days as I look at visualizations,\r \r and that is offered by the gg bump package\r \r that is authored by David Sjoberg, and we'll have a link again to all these\r \r packages in the show notes. This is another\r \r great utility type ggplot2 extension.\r \r\n\nDoes one thing, does it well.\r \r And his example that Albert puts in here is looking at flight tracking for European flights across various countries\r \r and the trends that you see\r \r over time.\r \r And it's very easy to see kind of the performance or you might say the launch demo profile\r \r of these. And, again, I don't do a lot of these in my day to day job, but I think this is still something that you might be able to augment pretty nicely\r \r with another package like gghighlight\r \r to really fasten in on one particular\r \r country's,\r \r trend in flight patterns or flight rankings as well.\r \r\n\nThat again, that's just 5 extensions\r \r in this massive ecosystem of ggplot2.\r \r There's there's just so much to choose from. Albert does a great job of giving you\r \r 5 quick hits that I think can augment your visualizations\r \r very well in your day to day work.\r \r And he's got links to other areas where he's put these in practice.\r \r So he's he's been doing a lot in this space. We we met Albert,\r \r at at PasaConf, and he has turned around the visualization\r \r content quite a bit. He's very excited about it, and I believe he even has a short course that he's authored as well. So definitely be on the lookout for that\r \r as well.\r \r\n\n\n\n[00:24:47] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 47,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. I really enjoy these, you know, sort of digestible\r \r visualization\r \r posts from Albert. And I guess 2 things that really stood out to me, you know, as as someone who has to provide clients with a lot of deliverables,\r \r you know, especially non technical folks at the end of the day, is the text customization\r \r in in gg text, you know, allowing you to write\r \r HTML essentially inside your string and to be able to to bold text, to to change the color of text, things like that on your your charts, I think, goes a long way towards\r \r communicating really the central idea\r \r around your data and the visualization you've created and what you are trying to,\r \r convey\r \r to the end audience. And then the other the other one that really stands out to me for very similar reasons is gonna be the g g highlight package as well, which,\r \r admittedly, I haven't used enough, but it it's incredibly\r \r simple in terms of the syntax that you can use\r \r to highlight a particular element of your chart. On this bump chart\r \r that Albert has created, you know, the the first argument\r \r in that is a dplyr filter kind of like syntax, where he's he's saying state,\r \r double equal sign,\r \r United Kingdom, because the line for the United Kingdom's flights is the one that he wants to highlight in green, and all of the other ones are going to be sort of in this in this soft gray\r \r in the background.\r \r\n\nAnd it's\r \r really 1 or 2 lines of code to be able to do that and highlight this particular line and set all the others to this background gray color.\r \r And it stands out so beautifully on the chart, and it it really\r \r demonstrates, you know, the the key concept that Albert's trying to display, which is is show the end user,\r \r the UK's\r \r trend from 2016 to 22 of incoming and outgoing flights. And if the end audience wants to also look at the data for the other 5 countries in this chart, they can because it's there. It's just sort of abstracted a little bit into the background,\r \r to make the point and make the readers focus,\r \r on the United Kingdom.\r \r\n\nSo really cool,\r \r blog post by Albert. He always does a great job including\r \r not only the the charts and his rationale behind them, but also the code behind everything.\r \r I recently had a use case where\r \r I wanted to\r \r essentially take the I had a, flipped\r \r axis chart, and I wanted to take the values on the x axis\r \r and put them within the bars.\r \r And the first place that I looked was a on Albert's website. And, of course, I came across a blog post where he was doing exactly that. And it made my plot a little bit bigger because I was able to sort of exclude the x axis itself and put those values right on the bars, so they really stand out to the end user, and they don't have to sort of line up,\r \r the bar width to the corresponding x axis value. They can just see it right at the end of the bar.\r \r\n\nAnd,\r \r it it was all thanks to Albert who made my life really easy\r \r in order to be able to accomplish that. So thanks to him again for continuing to churn out this great visualization\r \r content and expecting more of the same in in 2024.\r \r\n\n[00:28:01] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I think the a lot of these visuals you see here would fit really nicely if you're making any kind of business intelligence\r \r dashboard setup or other content\r \r where you gotta push the envelope a little bit, after that standard type of visualization. I can\r \r see this, this set being quite valuable in in this space. And, yeah, the syntax to to wrangle these packages are all doing a terrific job of if you're familiar with jgplot2, you're gonna feel right at home in putting these geoms in practice.\r \r So that user experience from a, you know,\r \r a content, you know, creator standpoint of graphs,\r \r you wanna make sure you're not, like, content shifting so much as you use these alternative geoms. So I think this is this is a great showcase of if you're comfortable with this language, you're gonna you're gonna feel right at home with the various extensions that you can push here. And, man, that g g text package, though, that is such an underrated gem in this space. I can't believe I didn't use this sooner, but better late than never.\r \r\n\n\n\n[00:29:01] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 1,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Same\r \r here.\r \r\n\n[00:29:04] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 4,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yep. And one thing we don't want you to be weighed about, our last highlight is is more of a friendly call to action here because\r \r you all know Mike and I are fans of the shiny ecosystem. We talk about quite a bit on this very show and our other endeavors.\r \r And, yes, the shiny conference for 2024\r \r is coming up this April, April 17th through 19th. And like years before, it is all virtual,\r \r but it is definitely expanding the footprint, so to speak,\r \r with not 1, not 2, not 3, but 4 exciting tracks of talk. And, of course, first off is that the early bird registration\r \r is open, so we'll have links to the registration page in the show notes to get you get your early bird tickets available there.\r \r\n\nBut in the aforementioned tracks,\r \r we have 4 tracks that you're gonna be learning about. One of them is the shiny innovation hub, and this is really looking at what are the latest developments,\r \r best practices, and creative uses of Shiny within the ecosystem itself\r \r using very novel approaches for problem solving.\r \r And that is being, chaired\r \r by Jacob Nowinski, who is the lead lab lead at Epsilon. He is chairing that track.\r \r The next track we have is Shiny and enterprise.\r \r I dare say, Mike, you might know a little bit about that as do I a little bit.\r \r That is how Shiny is being used to transform and shape outcomes in the business sector.\r \r\n\nSo going beyond analytics, looking at enhancing efficiency,\r \r helping decision making, and elevating these\r \r data analytic processes.\r \r Lots of great material there, I'm sure. And that is being chaired by Maria Gruschick who is senior delivery manager at Absalon.\r \r And this one hits a little close to home. This is the Shiny Life Sciences track because Shiny has been big in pharma and and health in general for quite a few years now.\r \r This track is being chaired by yours truly here, and we're looking for\r \r application\r \r or talks that highlight ways that Shiny has been driving insights, enhancing drug development, enhancing collaboration\r \r within life sciences. And I dare say there's been a lot\r \r discussed in this field for quite a few years, but there's no shortage\r \r of new innovations happening here.\r \r\n\nAnd then lastly, we got the shiny for good track\r \r looking at ways as shiny as being used to help\r \r make positive impacts to the communities around the world\r \r for society,\r \r really looking at how they are helping these initiatives out there. And this is being chaired by good friend, John Harmon.\r \r This is really important to see where Shiny can be used to help social impact,\r \r driving positive change,\r \r really helping the diverse communities all around the world\r \r supercharge their efforts.\r \r And\r \r I'm being more detailed about these tracks because we have calls for talks ongoing.\r \r We have until February 4th to send your submission for our talk, and the submission form will be linked in the show notes as well. So I know I speak probably on behalf of the other leaders of these tracks. We're looking for really exciting\r \r talks in this space, and\r \r don't ever feel like you have to be this huge pro at shiny to give an awesome talk. Really, I've seen some\r \r amazing talks from people just getting new to Shiny, but using it in an innovative way\r \r that is totally unexpected, but yet it's really helping their efforts. So\r \r really encourage you. If you've been using Shiny to help innovate\r \r your workflows.\r \r\n\nDefinitely send a proposal. We'd love to see it. And definitely get registered for early bird registration because this conference\r \r has been quite popular over the years, and I don't see that changing anytime soon.\r \r\n\n[00:32:55] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 55,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Well, I'm super excited for this\r \r conference again this year, Eric. I think I've been attending it ever since they hosted the first one, maybe 3 years ago now at this point, something like that.\r \r And it's it's one of my favorites,\r \r obviously.\r \r We don't hide it very well in this podcast that we love Shiny,\r \r and I am thrilled to see what's put together thus far across the different tracks. Thrilled to see you up there, Eric. I think the Shiny in life sciences will get a ton of buzz. We're seeing that space grow and grow and grow across our own client base, and I don't think,\r \r across the rest of the world is any exception\r \r as well. So I've purchased early bird tickets for our team, and\r \r I finally\r \r just began the submission process for a shiny for good\r \r app showcase\r \r so I'm going to finish that up today see if I can push that through see if see if maybe it makes the cut But mostly, I'm excited to see what everybody else has to offer for this conference. So no reason not to tune in. Check it out. It's free for students. It's it's only a few dollars,\r \r for everybody else, and it's absolutely\r \r worthwhile if you are somebody\r \r interested in Shiny, doing Shiny, beginner, intermediate, advanced. Doesn't make a difference. You will get something out of this conference.\r \r\n\n\n\n[00:34:14] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 14,
        "trans_speaker": "Eric Nantz",
        "trans_text": "You sure will. And that's a really exciting point, Mike, because, now on top of talks themselves, we love these app showcases. You've done that before. We have a great app before, and it's it's really great ways to demonstrate where Shiny is being used in practice. So, yeah, we highly encourage you to sign up for it. And, also, like I said, if you wanna share your knowledge, share ways that Shiny has been brought innovation\r \r in your work. Yeah. We love to hear about it. And with these four tracks, we think we have something for everybody here. So there no matter which industry you're representing,\r \r no matter which part of academia you're a part of or any other research or community effort, we'd love to hear about it. And I'm really looking forward to reviewing these talk proposals in a in a few weeks. And judging by what happened last year, both John and I had a very hard time narrowing down, you know, which ones made the cut because there was a lot of great submissions last year. And I expect this\r \r to be exactly the same and really looking forward to working with the Appsilon team on helping organize this as we get closer\r \r to the conference days. And, yeah, should be a lot of fun.\r \r\n\nSpeaking of a lot of fun, folks, the rest of the issue does have a lot of fun for you to to look at with leveling up your our knowledge and innovations,\r \r what's happening in the world of data science and respect the package development,\r \r you know, tutorials and whatnot. And we'll take a couple minutes to talk about our additional finds here.\r \r I'm going pretty niche on this, but it's a very important niche, especially for someone I work with quite closely.\r \r You've heard me, speak the praises of what Will Landau has been doing with the targets ecosystem\r \r and more lately, the crew package for batch processing,\r \r asynchronous\r \r processing\r \r in your ecosystem.\r \r\n\nAnd that is standing on the shoulders of 2 very important packages in your ecosystem,\r \r MirrorEye and NanoNext,\r \r which have just been updated on CRAN\r \r with some very important\r \r updates in this space\r \r with respect to where Will wants to take the crew package down the road.\r \r And in particular, the latest update for Mirai\r \r is now handling much more gracefully\r \r situations\r \r when someone needs to terminate a running job for whatever reason. There are some enhancements to the daemon behind the scenes to help make that a lot more elegant, a lot more graceful\r \r than in times past.\r \r\n\nAnd this is very helpful as you think about the ways that batch processing can be launched on other back ends.\r \r I'm looking at you, AWS. That's one of them. We got our eyes on quite a bit.\r \r And the associated package, nano next,\r \r is also\r \r kind of the system library that Mirai is based on. That also\r \r has some important updates as well. But, again, these were very important updates\r \r for what Will is trying to do with the crew package down the road. So he was he was telling me in my ear last week that, yeah, he's really looking forward to these updates, and he's got some big plans now that\r \r now these have hit. So\r \r really, big thanks to Charlie Gao, who's the maintainer of these packages.\r \r\n\nReally, really excited to see these updates here.\r \r Micah, what did you find?\r \r\n\n[00:37:27] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 27,
        "trans_speaker": "Mike Thomas",
        "trans_text": "I found a pretty cool, also niche blog post on something that I hadn't really seen discussed\r \r very much before, and it's called Security Headers for Shiny Applications. It's a jumping rivers post, I think, specifically authored by Colin\r \r Gillespie.\r \r And it's all about essentially profiling the security on the server or or your posit setup,\r \r wherever your Shiny apps are deployed.\r \r There are some functions from a package called server headers\r \r that allow you to sort of check the security\r \r around that server,\r \r such as SSL status,\r \r redirects, referrer policies,\r \r all sorts of things like that. So if you are someone interested in,\r \r information security\r \r around your Shiny apps, and may perhaps you're working with your IT team to host Shiny apps or deploy those Shiny apps on some,\r \r local or cloud based server, I think it might be of interest for you to to take a look at this blog post, because there's probably not a lot of other content\r \r out there that might be beneficial, you know, for your IT team to sort of understand,\r \r how Shiny apps are are hosted and deployed on a server and maybe the different security things that go along with securing\r \r that server in particular. So really cool one from Jumping Rivers,\r \r nice and short and sweet, and check it out.\r \r\n\n\n\n[00:38:48] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 48,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Excellent find. And, you know, as Shiny, it obviously takes more, you know, to has some more uptake in the industry as a whole, a lot of times, IT groups are are getting more familiar, especially on the\r \r the teams of security, on making sure that authors of Shiny apps are following best practices and whatnot. This might very well help those that are deploying\r \r Shiny space server products in their organizations\r \r to have a little have a little preview of what's being exposed under the hood. So, yeah, certainly great great to see that space. It's great to see developments from jumping rivers in that space as well.\r \r And certainly speaking of, really loving to hear back, we'd love to hear back from all of you and your feedback. And we got a couple somewhat indirect feedback pieces to share. One direct that literally just came as they were recording this.\r \r\n\nBut, you if you listened to last week's episode,\r \r Mike and I had some, I would say quite candid thoughts on the situation that Posit's found itself in and particularly Eway Cia's recent situation.\r \r We're gonna put a quick plug to and a shout out to Matt Dre in his recent blog post.\r \r He has basically a huge appreciation for what he was done for the work he does\r \r in in his day job at the UK government and public sector.\r \r But he gave a little shout out to to me and Mike here about where we\r \r about our discussion about heat waves, for it. So thanks, Matt, for for, putting that in your blog post. We'll link to that in the show notes as well. And literally, Mike, late breaking feedback. It's almost as if he's psychic. But, John Harmon, we just mentioned, just shot me a note that with respect to APIs, which you touched on the first highlight here, he is writing\r \r a book about using APIs from r.\r \r\n\nAnd we'll have a link to that in the show notes. It's,\r \r wapit.\r \r Io.\r \r We will link to that in the show notes. So thank you, John, for reminding me. I knew you're you're hard at work at that. I didn't realize how far along it was. So\r \r if you're leveling up your API now, it's, there's your chance.\r \r\n\n[00:40:53] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 53,
        "trans_speaker": "Mike Thomas",
        "trans_text": "That's awesome. I totally forgot. I think John had been working on some sort of like one size fits all\r \r package or project\r \r for, you know, one particular r package that could wrap any API\r \r essentially and and do it in a fairly agnostic\r \r way. I I don't know where that stands or or if I'm\r \r remembering that incorrectly and it's it's more about the book, but I am very excited to read that.\r \r\n\n[00:41:20] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 20,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. You're exactly right. He is definitely\r \r working in that space. That package you're referring to is called beekeeper.\r \r Really fun package in this space because,\r \r hey, if anything can give you that, you know, what we like to call the use this or dev tools like setup to wrap these API\r \r APIs in the packages,\r \r I think beekeeper is gonna be a great, great way to do that. So I'm I'll double check how far along it is. We'll link to it in the show notes regardless. But he's been hard at work on that, I believe, ever since he received a grant from the r consortium on this API development work recently. So, yeah, John, thanks for that,\r \r real time feedback. You're you're lucky I had that that page open as we were recording. I didn't realize that was coming through. So, yep,\r \r APIs. It's a great time being APIs with our, I'll just say that, with what John's doing and and great tutorials from Alyssa and whatnot.\r \r\n\nSo, of course, we love hearing from you as well. Wherever you are in the world, we have various ways of doing that. You can get in touch with us on our contact page, which is linked directly in the show notes for each and every episode.\r \r Also, we love to get your contributions to the rweekly project via a poll request of, say, a new blog post,\r \r new package, a new tutorial, and whatnot.\r \r All the details are at rweekly.org.\r \r We we love to hear that. We love to see that. All the curators really appreciate it when the community helps step up as well.\r \r And so we're looking for curators to join our team. Again, information on that is at rweekly.org\r \r and our GitHub repository.\r \r\n\nWe're trying to make things easier for us, but the best thing we could have is more people to help us with it. So if you're interested at all and you're passionate about this space, it would be a great time to reach out to us. And, also, if you wanna reach out to us on one of those fancy new podcast apps that you've downloaded, like Podverse, Fountain,\r \r CurioCast,\r \r or whatnot, they're all supporting\r \r the boost technology,\r \r and that's an easy way for you to send us a message directly in the show and have a little fun along the way.\r \r You can find complete details on that in the show notes, and we are proudly linked on the podcast index page where you can boost directly from there as well. Again, I wrote a little package around its API, and I got more stuff in store for that stuff coming up soon. So stay tuned. Maybe some more our content for this very show.\r \r\n\nTalk about meta. Right?\r \r Our content about a podcast to talk about on a podcast. That doesn't make a head spin. I don't know what those.\r \r\n\n[00:43:49] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 49,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Inception.\r \r\n\n[00:43:50] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 50,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Inception overload. Yep. And, but, yeah, we'd love to hear from you. And,\r \r definitely, you can get in touch with us on social medias as well. You'll find me mostly on Mastodon these days where I'm at our podcast, at podcast NSF social.\r \r Very sporadically on the x thingy, but also on LinkedIn from time to time. And, Mike, where can the listeners find you?\r \r\n\n[00:44:12] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 12,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. Probably on LinkedIn primarily. I think my handle there is Michael j Thomas 2,\r \r or you can search Catch Brook Analytics, k e t c h b r o o k,\r \r to find me there. Or if you wanna find me on Mastodon,\r \r I am at [email protected].\r \r\n\n[00:44:32] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "trans_timestamp": 32,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Very nice, Mike. Well, anyway, we will close-up shop here for episode 148, and we will be back with another new episode\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_03_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "chap_timestamp": 45,
        "chap_text": "Calling APIs with httr2"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "chap_timestamp": 47,
        "chap_text": "Five ggplot2 extensions"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "chap_timestamp": 4,
        "chap_text": "ShinyConf 2024"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "chap_timestamp": 21,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "chap_timestamp": 24,
        "chap_text": "Feedback"
      },
      {
        "ep_name": "issue_2024_w_03_highlights",
        "chap_timestamp": 15,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2024_w_02_highlights",
        "ep_date": "2024-01-10",
        "ep_duration": 10,
        "ep_description_short": "We kick off 2024 with a jam-packed episode! Learn four ways to streamline your R workflows, a proposal for a new pipe assignment operator in base R, and our raw responses to a surprising turn of events affecting one of the most influential members of the R community. Episode Links This week's curator: Eric Nantz - @theRcast…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2024_w_02_highlights",
        "description_long": "\r \r\n\nWe kick off 2024 with a jam-packed episode! Learn four ways to streamline your R workflows, a proposal for a new pipe assignment operator in base R, and our raw responses to a surprising turn of events affecting one of the most influential members of the R community.\n\nEpisode Links\n\nThis week's curator: Eric Nantz - @theRcast (Twitter) & @[email protected] (Mastodon)\nFour ways to streamline your R workflows\nThe case for a pipe assignment operator in R\nBye, RStudio/Posit! - After writing all these \"*down\" packages for these years, here I am to announce \"Yihui-down\"\nEntire issue available at rweekly.org/2024-W02\n\nSupplement Resources\n\nR-Weekly Curation Calendar Dashboard https://rweekly.github.io/rweekly-calendar/\nQuarto All the Things workshop from R/Pharma 2023 https://www.youtube.com/watch?v=k-dQ36sx4Rk\nRami Krispin's VS-Code R container template repository https://github.com/RamiKrispin/vscode-r-template\nAssignment pipe operator discussion on Mastodon https://mastodon.social/@eliocamp/111664623134443564\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://nrennie.rbind.io/blog/four-ways-streamline-r-workflows/"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "http://hughjonesd.github.io/case-for-pipe-assignment.html"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://yihui.org/en/2024/01/bye-rstudio/"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://rweekly.org/2024-W02.html"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://rweekly.github.io/rweekly-calendar/"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://www.youtube.com/watch?v=k-dQ36sx4Rk"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://github.com/RamiKrispin/vscode-r-template"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://mastodon.social/@eliocamp/111664623134443564"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Hello, friends. Did you miss us? Yes. The R Weekly Highlights\r \r podcast is back and it is 2024.\r \r We are kicking off the new year in style. We have a supersized\r \r issue to talk about. But if you're new to the show, this is the show where we talk about the latest our weekly issue that's curating the latest and greatest in our content,\r \r whether it's, adventures in data science, new packages, tutorials,\r \r and much more. My name is Eric Nantz, and I'm always delighted that you joined us from wherever you are around the world. And I certainly hope\r \r you and your loved ones, family, friends, all had a safe and relaxing holiday season, whichever ones you celebrate.\r \r\n\nYeah. It's hard to believe it's 2024 already.\r \r\n\n[00:00:45] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 45,
        "trans_speaker": "Mike Thomas",
        "trans_text": "But just like last year, I don't do this alone. I got my awesome co host, Mike Thomas, joining me once again for another year of our weekly highlights. Mike, how are you doing today? I'm doing well. Eric, I'll be honest with you. I missed this. I hope the audience missed it as well. I missed it just as much as you folks. So I am so so excited that our weekly is back,\r \r that we had a great curator this week, and, the 2024 is hopefully\r \r now off and running for us here on our weekly.\r \r\n\n[00:01:16] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 16,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. It is amazing how this makes me feel a little more normal again going back on the mic with you, so to speak.\r \r It was definitely a busy break for me, but, yeah, it's great to great to get things back in motion on the our side of it.\r \r And, yeah, that curator, that wacky individual,\r \r yeah, that was actually yours truly this time. And I really\r \r went above and beyond in a different sense, and this is totally unrelated to the issue itself.\r \r But I figured I've seen some cool stuff built with Quarto lately.\r \r I saw the new dashboards. We've actually talked about on this very show recently.\r \r I thought, you know what?\r \r\n\nFor our curator team, we often have to share this rather cryptically formed URL of our public\r \r kind of curation calendar.\r \r I hosted on Nextcloud, which is great, by the way. Nothing against Nextcloud. But the URL they give me for sharing,\r \r yeah, that's just not gonna be easy to remember. So I thought, well, wait a minute here. Guess what? Because of my streaming adventures years ago\r \r in making what I call the streamers\r \r calendar,\r \r I know there are some HTML widgets out there that could play nicely with Cortl to render this same calendar,\r \r but, hopefully, a more friendly dashboard\r \r and give us both a calendar view\r \r and kind of a more tabular view of who's on which week for the curation.\r \r\n\nSo, yeah, I took a few days. I now have a portal dashboard\r \r of our public curation calendar, which I'll link to in the show notes. It's hosted on GitHub Pages,\r \r but it takes heavy inspiration from Garrigate and Buoy's\r \r Norfolk data portal dashboard.\r \r And I figured, you know what? If he can do it, so can I? So that is now publicly available. I have a link to it in the supplements of the show notes here in case you wanna have a look, but it was my first adventure with portal dashboard. So after I got that squared away, yeah, it became down the business and curating\r \r this week's issue.\r \r\n\nAnd also, this is, like I mentioned, a supersized issue because we were off for a few weeks as a whole team. So there are a collection of stories here\r \r from previous weeks that would have been released if we weren't on break. So either way, buckle up. We got a lot to talk about, and there's a lot to read after the show too. But I can never do this alone. I have tremendous help from our fellow Rwicky team members and contributors like you around the world with your awesome poll requests\r \r to make all this happen.\r \r And we lead off with kind of a nice kind of retrospective\r \r like post of\r \r of areas that we've talked about\r \r last year, especially\r \r with respect to how you can streamline\r \r your R workflows.\r \r\n\nAnd our our author this week is the esteemed Nicole Rennie\r \r who has been a frequent contributor to our weekly highlights in the past.\r \r And she ends up giving us this nice end of year blog post talking about 4 ways that she's learned how she can streamline her\r \r our workflows. And each of these hit home with me, and I'll be curious,\r \r Mike, how much you've been using these in practice as well.\r \r The first area that she talks about,\r \r it may sound basic, but, boy, is it effective\r \r using template files.\r \r Because, you know, everyone does this. We have that set of scripts that we created.\r \r And then there just might be a new data type, but it's mostly the same. Maybe just a couple changes in variables\r \r or maybe a a similar service you're pulling from. And, yeah, you do the copypasta,\r \r as they say.\r \r\n\nWell, why not make a more templated structure\r \r like Nicola did with her tidy Tuesday analysis script? So now she has\r \r a set of scripts that she can create dynamically based on templates\r \r for that current week of TidyTuesday\r \r and having all of her reusable functions for visualization and other aesthetics and data processing\r \r all set to go. And, yes, this blog post has links to the individual blog posts where Nicola talks about this in more detail,\r \r that you can check out. So that is a great, great way to do it. Low hanging fruit, as they say, to get you some\r \r much needed savings and time.\r \r\n\nAnd speaking of templates,\r \r if you find yourself making multiple GitHub repos that look really similar in structure, especially beginning the first time,\r \r yes, I feel seen. I do this almost every day at the day job.\r \r You can leverage GitHub repository\r \r templates.\r \r This is huge because\r \r instead of, like, doing the blank repo,\r \r maybe getting your r env library in there, getting like your helper scripts for that data processing or whatnot,\r \r Why not start yourself on the right foot? Have a template structure in place.\r \r Nicole has been making great use of this in her workshop materials because she was quite busy in 2023 teaching some workshops.\r \r\n\nI'm still very privileged that we had her at the our pharma series of workshops talking about machine learning, and she had a tremendous job with the material\r \r on the GitHub repository that she created. But, yeah, that has now started in her workflow from a GitHub repository template.\r \r I have also made use of this with my fancy schmancy Docker container setup. So now every time I know I'm going to do an R related project, I want to leverage Versus Code with the Docker container and the custom\r \r RStudio IDE server edition in the Docker container.\r \r Instead of like repopulating\r \r all those Docker files 1 by 1, I just have a repository template that I do for my new repo. Makes a heck of a lot of time savings. I only have to change a couple environment variables, and then literally, I can just bootstrap that thing in less than 5 minutes.\r \r\n\nIt is, again, a huge time saver for me as well.\r \r Now 3rd up in this list is one I need to be much better at. So I'm coming confession time with Eric here. I do not do a great job of linting and styling my code. Well, guess what? There are r packages that help you with this. In particular, the lint r package and the styler package.\r \r These can take away all those spacing issues,\r \r syntax errors that you might not detect until you actually run this.\r \r If you author Shiny apps, you know what I'm talking about. You're missing that bracket, you're missing\r \r that variable? You're in trouble kind of for that reactive. Don't get me started on that. But, yeah, it's not just finding those errors. It's also making sure that your code has a consistent style. And so Styler can be customized to meet your needs,\r \r but it's gonna get you off on the right foot very quickly.\r \r\n\nAnd boy, is that helpful for multi team, multi person projects\r \r where you wanna make sure your whole team is having a unified approach on how you style the code. So I would definitely make use of Styler\r \r and also Linter to find all those nagging issues that you would manually have to detect yourself in the old days.\r \r And lastly, yeah, at the top of the show, I talked about quarto. Right? Well,\r \r quarto comes with a lot out of the box, and I do mean a lot,\r \r but there may be things that you wanna do to build on top of it. And so Nicole had an adventure\r \r in 2023\r \r in their early part of the year\r \r on building a quarto extension to help extend the styling that she did for PDF reports.\r \r\n\nThis is really useful, especially if you wanna kinda\r \r get that similar flavor as you might have in the past with some of these custom R Markdown templates,\r \r but wanna have a similar thing with Quartle.\r \r These, ways that you can build extensions might be a path forward.\r \r It definitely does take a little getting used to. I mean, certainly, if you're comfortable with LaTeX, you're gonna be right at home with some of the styling for PDF output.\r \r But in general, I believe it's using Lua scripting, so you might have to do a little level up on that as you go along.\r \r But the linked resources on her more detailed blog posts can get you up and running quickly.\r \r\n\nAnd also for a plug,\r \r I mentioned the R pharma workshops earlier. We had an R pharma workshop from Devin Pastore about building portal extensions. So I have a link to that in the supplements of the show notes as well if you want to really get into the weeds\r \r of building a complex extension.\r \r It's definitely something you might have to get used to. But again, if Kordle is not doing everything you want out of the box, you can definitely customize it. And I am a very big consumer of extensions, especially for the web based presentations of Reveal JS.\r \r Big shout shout out to Emil Hunchfeld who has built\r \r immense extensions such as, like, the code window,\r \r even that fun little confetti,\r \r extension. I'm not sure if he created that or is that someone else. But I'm I I make use of quite a few in the reveal JS space.\r \r\n\nSo, again, these are all great things that are attainable\r \r in your R journeys\r \r with making things a little more automated, a little more repeatable.\r \r And, yeah, Nikola,\r \r concludes the blog post of a little intriguing notes on what she's interested in. And, boy, she's also gonna be pursuing the Knicks package train as well. So Bruno is not the only one. I'm also trying to pursue this as well. So we might be seeing some blog posts from her about that. And, also, it looks like she's looking at Rust as well, another framework that's been getting a lot of attention\r \r in the R community these days. So\r \r fantastic way to inspire you at the start of this new year to maybe,\r \r supercharge your workflows a little bit.\r \r\n\nSo, Mike, what did you think of Nicola's,\r \r\n\n[00:10:45] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 45,
        "trans_speaker": "Mike Thomas",
        "trans_text": "blog post here? I couldn't agree more. I think there's a lot of tips in Nicola's blog post that would help us get off to a fresh start in the new year and start employing some of these best practices for ensuring that\r \r your workflows are consistent across projects and make you as efficient of a data scientist as you can possibly\r \r be. I think using template files is a great use case. I am so guilty of sometimes going from project to project and\r \r copying the majority of a read me file, for example, you know, especially where we talk about, you know, handing our projects off to clients and and how they can use the, you know, the RN\r \r package, that we have, you know, in our deliverable\r \r to essentially reproduce the environment that we created it with.\r \r\n\nAnd, really, I think Readmes for us could be a template file and a great use case that a simple script like the one that Nicola actually has screenshotted here could help with that. You know, I know that there are packages like use this and dev tools and column and things like that that will actually create scripts for you. And the and the code is is pretty lightweight, so don't be afraid to to do it yourself. I think it's a really awesome trick that can be really underrated\r \r as well.\r \r Using GitHub repository templates,\r \r I will say, is one that that I actually do and that we actually do internally. And that is is hugely helpful. And I know, Eric, you do this, quite heavily, at least within your own,\r \r personal development work\r \r because you have,\r \r GitHub repository\r \r templates that spin up your your whole environment that make use of dev containers.\r \r\n\nRight? So you can go essentially from project to project and have your your isolated environment and your development environment sort of consistent from project to project. And that is and that's really helpful as you go from project to project to ensure that all of the dependencies\r \r that you need to have, you know, within your projects that you're sort of consistently\r \r applying the same workflow to,\r \r can get installed quickly and consistently.\r \r I've seen a lot of articles lately as well from Rami Crispin,\r \r who is trying to, I think, accomplish a lot of the same things that you've talked about as well, Eric. And he has some great content\r \r online about how to set up your own, GitHub repository templates, I believe, for both our development\r \r and Python development using dev containers that have, you know, those those, dev container dot JSON files to sort of specify how you want your v s code\r \r environment to look, and then a Docker file to manage all of those dependencies.\r \r\n\nAnd\r \r one of the cool things about that as well\r \r is if you're interested in leveraging,\r \r GitHub code spaces,\r \r you can essentially\r \r do that, apply that immediately just by clicking a button within GitHub, and it will leverage\r \r those dev container assets to spin up that environment in Versus Code in the cloud for you. You don't even need to have Versus Code installed on your own laptop. I know there's a cost associated with that, but I know it's it's pretty cool. And when we think about collaborating across teams, you know, these things become really important. And for us, that's not only collaborating across teams, but it's also handing off our deliverable to to the client at the end of the day and ensuring that they can reproduce our work, and and whatever we've created for them in terms of that deliverable\r \r exactly in within the same way that we intended it to be and the way that we created it. So that's really helpful.\r \r\n\nAnd then the section on on linting and styling code, you know, it must be something in the water on this podcast, Eric, because I am also guilty of not utilizing the the linter or the styler r packages. I am very strict. We have an internal handbook about, you know, how to style,\r \r our our code and our our Python code, and we try to adhere to that pretty well. And obviously within our our code review process, you know, that that's a component of it to make sure that the code is styled, you know, in line with, sort of our expectations internally.\r \r But I was talking to a client recently who were trying to help, set up sort of a good team data science workflow and implement some best practices\r \r within their organization\r \r and really trying to convince them that code styling is is important for collaboration\r \r and streamlining code review, and making all of those processes\r \r more efficient.\r \r\n\nAnd one thing that I, I think I failed to mention to them that I need to mention to them is how the lint are in the styler package\r \r can expedite that process and maybe also provide,\r \r safeguards\r \r to ensure\r \r that your code is styled in line with the guidelines that you've set up for your organization.\r \r And maybe that's not necessarily the default\r \r styling that these packages have, but I know at least within 1 or or both of these packages, you can actually apply, you can apply some settings to how you want that code to be styled. And you can make some changes to to how you want code to be styled internally at your organization or or maybe just across your personal\r \r development projects. And I think that that is incredibly powerful\r \r and incredibly underrated, which I think is a theme of this blog post as well.\r \r\n\nI love the section on building quarto\r \r extensions. You know, quarto is super hot in the streets right now. We are moving everything to quarto. All new projects are starting with quarto. One thing that that I love as well that I think goes,\r \r very aligns very well with, Nicola's section here on building quarto extensions is\r \r we unfortunately\r \r deliver a lot of PDF reports. And that means that we,\r \r use LaTeX\r \r quite a bit.\r \r In the quarto YAML file,\r \r you can actually\r \r set up that YAML file and set up, your your latex assets along with that, your dottex\r \r files,\r \r such that you can have parameters within these latex,\r \r assets.\r \r\n\nFor example, like the title of your report, a background image in your report, subtitle, things like that,\r \r that may change on a project to project basis. And you can specify those parameter values\r \r within your quarto yml file. And those will get passed\r \r to those Latex files.\r \r We do that on every single project, you know, because the project title is gonna change. Maybe the image that we'll have on the cover page is going to change.\r \r Things like that. But it's it's amazing how well those things,\r \r play nicely\r \r with each other. So if you're someone out there who finds yourself, you know, delivering a lot of PDF reports\r \r through quarto, I would recommend checking out some of the links that Nicola has in this blog post. If you you really wanna spruce up the look and feel of that PDF report, then I think learning a little bit of Lua,\r \r can go a long way as well. But there are ample links here,\r \r as well as on the quarto website. I think that can help you really\r \r make that quarto PDF Latec report,\r \r look, you know, nicely branded to your organization or look and feel however you want it to look and feel and customize it nicely. And Nicola gives us a little bit of a preview into some of the the work that she's,\r \r posted for herself in in 2024,\r \r and I can't wait to see, what comes next from Nicola because it's it's always super relevant, always super helpful,\r \r and and I learn a lot.\r \r\n\n\n\n[00:18:03] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Me as well. And there are just so many threads here that I wanna implement both in my open source work and in my day job work.\r \r In fact,\r \r we're even thinking of, for the internal user group, I maintain, of having some kind of, maybe quarterly newsletter or bimonthly newsletter\r \r that can go out highlighting the current events and highlighting in the company initiatives.\r \r Maybe I could build that with Chordle, and then I saw a PDF setup like she's done in her earlier efforts. And, yeah, the linting thing, I really gotta get better with it. What's interesting is that in my dev container setup, I do have a hook to do linting automatically in Versus code with a dotlinter,\r \r kinda config file. So I'm I'm getting there on the right track. I just have to actually listen to the advice. But I will say the Versus Code is very obvious when it thinks you did a line longer than 80 characters. It will have a big old squiggly next to it, and it will annoy you enough that you probably will wanna change it. But certainly, I wanna make that more automated too and just get better habits. But, yeah, though those two areas and and, yeah, beefing up my templates in general.\r \r\n\nEven just today, I have a project where I want to\r \r enhance my shiny bookmarking state hack that I've done at the day job. Instead of having to build that up scratch in each app 1 by 1, I want to do a template structure. I can just fold that in because I can't quite make it a package yet, but I just want those functions there every time. So I don't have to just manually copy paste it from that existing repo into the new one, change the path, change whatever.\r \r No. Ain't nobody got time for that in 2024.\r \r So lots of things here I wanna make use of and really appreciate, Nikola's efforts on this. Couldn't agree more.\r \r\n\nAnd we're gonna shift gears a little bit to a very interesting proposal\r \r to maybe a future enhancement to the r language itself\r \r that is in the spirit of a recent enhancement that came a couple years ago.\r \r And that is making a case for a new\r \r pipe assignment\r \r operator in R itself.\r \r This blog post comes from David Hugh Jones.\r \r He's been a very active blogger in the R community,\r \r and he\r \r makes this case by talking about just kind of the status quo\r \r of how\r \r R does assignments.\r \r You can either have, you know, passing by the value itself,\r \r you know, very much saying object, whatever, assign it to, you know, the result of another function or give it a constant or whatever have you.\r \r\n\nSometimes it gets really wieldy when you have a variable that, of course, is being built upon a chain of functions. Right? This is one of the motivations for the pipe operator itself, which, of course, was\r \r first brought to light by the Magritter package. And now since r4.1\r \r now has the base r pipe operator built in, which functions largely the same way. So you can construct your, say, data processing steps in a pretty nice kind of streamlined workflow using packages such as dplyr and many others\r \r that are pipe friendly.\r \r Well, David wants to take this a little up a notch a bit more. What was in the Magritter package? It didn't get a lot of press at the time.\r \r\n\nWas it had its own version of a pipe assignment\r \r operator\r \r where it looks like you're going to do processing on a variable and then print it out kind of interactively.\r \r No. It would actually look like you're doing this interactively\r \r but actually change\r \r the value of the variable you had on the left side.\r \r So David is proposing why not do this in our proper.\r \r And he proposes this operator as like the less than sign pipe and then greater than sign. So it looks like it's a pipe surrounded by the two signs\r \r and then having that translate to a bunch of functions potentially to do something\r \r with that operation.\r \r\n\nAnd his rationale is that it could make the code much simpler to read and more expressive\r \r and being able to kind of be more succinct with the syntax that you're typing.\r \r Now, this is where it gets interesting here. It's one thing to kind of conjecture this, but he decided to take matters in his own hands and actually look at\r \r what is being used in the general, you know, set of code that's being shared in open source\r \r of\r \r where this pipe assignment could be useful.\r \r So he actually has authored\r \r his own new package\r \r called code samples,\r \r which apparently has scraped open source code that has been shared on GitHub\r \r and Stack Overflow,\r \r as well as just the\r \r R package examples themselves that come from packages.\r \r\n\nAnd he's done a nice little summary here in the blog post\r \r about how many times\r \r he has detected code that is\r \r pipeable\r \r but also pipeable and complex, having like more than a few lines in the pipeline\r \r operation.\r \r And so the post says there's about between 4 10%\r \r of operations could be simplified by an assignment pipe here, and that could be a potential gain.\r \r So you might want to look at this for yourself to kind of see in your code, do you have examples that match some of David's examples here,\r \r such as what he has from the Stack Overflow questions.\r \r Looks like a pretty unwieldy\r \r sub setting of a w variable and then trying to translate that\r \r into a more friendly,\r \r pipeable\r \r assignment\r \r operator,\r \r where it basically streams it down to 4 lines of code, technically,\r \r instead of what looks like about 16 or 18\r \r in the previous example.\r \r\n\nI will admit\r \r I've had a little bit of, gotchas when I've tried this in the Magrita approach before,\r \r and I admittedly moved away from it. But I can see where David's coming from here. So it is an interesting proposal.\r \r Now for those that are new to the r, you know, project itself,\r \r it does take a bit of time for things like this to land in. And, of course, of course, it has to be agreed upon by the r core team and whatnot. So there would be\r \r obviously a lot of discussion in play and that this would not happen anytime soon\r \r if it was to actually take shape.\r \r\n\nBut with that said, it is interesting to see what this could look like. So I credit Dave for taking the time to not only put this out into the public domain, but do some interesting kind of data scraping analysis\r \r of existing code to see where this might benefit.\r \r So definitely something to ponder.\r \r I'm kind of in between on this one. I don't really\r \r wanna say no to it, but I'm just not sure if I would be the best customer for it. So with that said, definitely food for thought, as I say. Eric, you know, this is one of those things where at first glance, it kinda gives me the heebie jeebies,\r \r\n\n[00:25:03] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 3,
        "trans_speaker": "Mike Thomas",
        "trans_text": "but then it might be, you know, this gets implemented,\r \r you know, a couple years from now, and then\r \r I finally adopt it, and then I feel maybe someday that, you know,\r \r like, don't know how I lived without it in the 1st place. Yeah. I think that happens\r \r occasionally.\r \r You know, I will give David a lot of credit\r \r because he he absolutely makes the case for it in this blog post. Doesn't just make the case for it. He actually writes the code to implement\r \r it in, Rsource. So he has, forked\r \r the Rsource\r \r repository,\r \r and then he has has made a commit that,\r \r you know, is\r \r 1200 lines of code, c code, I think, mostly,\r \r essentially, that that implements it and,\r \r kudos to him. Hats off. He's putting his money where his mouth is, and I think, absolutely, if this does get adopted, if it's something that the community does eventually want, then he will be the person essentially that that spearheaded this and that did a lot of the work I think to get it in to ours base code. Yeah. I think that probably that the base pipe itself for now is maybe\r \r still getting adopted. I would love to see some statistics on how widely\r \r used it is. We do still see a lot of code, you know, at our clients that contains the the Maggard or pipe,\r \r even new projects that they're working on.\r \r\n\nI think maybe people are just just slow to adopt\r \r new things so I would imagine that it probably wouldn't be any different if this new pipe,\r \r did get implemented. And I can't help thinking that it looks like a person standing there with their hands on their hips. That's the best way that I would that's the best way that I would describe it. Always have to sort of see something, you know, it's like seeing something in a potato chip, but,\r \r when something new comes out. But I think it's super interesting. I\r \r have a little bit of trouble, you know, the explicit\r \r assignment with the arrow\r \r is\r \r something that I think helps me for code review to be able to really clearly see when an object\r \r is getting created.\r \r\n\nI know that there\r \r are some\r \r folks out there, probably more in the in the Tidyverse community, that that,\r \r warn a little bit against the use of the assign\r \r function,\r \r for that that same reason because it's not sort of\r \r explicitly\r \r showing you where new objects are getting created in your environment as as you read some code. It's that's a function that I've tried to get away from,\r \r in in more recent years.\r \r So\r \r it's gonna be teach their own. I I would say if this is something that that you really feel\r \r could help you, then then get in touch with David and and support the cause. And I guess the great thing about open source is is you can use what you wanna use, and you don't have to use what you don't wanna use. Right? I'm sure the assignment arrow is not going away anytime soon. So I'm not very worried, but the, you know, the only place that\r \r I think it goes back to maybe our our discussion on Nicola's blog post is is adopting some style guides and sticking to them. Right? So if you want to adopt, this new pipe, if it ever gets merged, as sort of the way that you are going to go about assigning objects internally within your organization,\r \r then by all means, you know, merge that into your own style guides and into your own consistent practices. But I think consistency is important. I think ensuring that you are writing code that sets up the reviewers or the collaborators\r \r on that code, for success and to make their life easy and efficient,\r \r is really important. So that's that's really all I have on this blog post, my 2¢.\r \r\n\nI don't feel super strongly one way or the other. I think it's it's really, really interesting. And again, kudos to David for not only making the case, but for going through,\r \r the entire process of actually implementing it and what that might look like.\r \r\n\n[00:28:57] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 57,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Definitely credit to him for, you know, following through on what this actually could look like. And, you know, I'm always\r \r I will never turn down having choice in this space. I mean, there may be others that would have such great benefit of a complex pipe assignment.\r \r Have at it. Right? I mean,\r \r I don't have to use everything that's in our core or these packages that I use. I just use what's best for the project and what's best for me. So\r \r I I will admit it would make me probably have a little harder time doing code review of it as of now. But, heck, maybe a practice makes perfect. Who knows? But, yeah, the assignment operator, you're gonna have to pry that out of my cold dead hands. I use that every single time,\r \r and that helps me reason out kind of where the key variables in this pipeline.\r \r\n\nAnd, also, to me, it helps make debugging a little easier at the sake of being a little more verbose. For me, debugging,\r \r reviewing are probably the one criteria I'm gonna use as I think about\r \r whether I would implement this. But, again, I'll be very interested to see what the community has to say. So I'll be keeping an eye on, say, Mastodon and other, social areas to see what kind of,\r \r discussion this, spurs on, but we may be hearing more about this way earlier. Who knows?\r \r\n\n[00:30:10] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 10,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Keep your eye on it. You never know.\r \r\n\n[00:30:12] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 12,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yes. Yes. And,\r \r one as we get to our our last, highlight here, let me preface this by saying when we talk about highlights, we're really more that's a general term for the the areas that we think are most newsworthy and that will probably spur the most discussion\r \r in a particular issue because I will admit on the surface,\r \r when you when we talk about this last post,\r \r I would not call it a highlight per se because we're about to get a little heavy here. But I think there are some thoughts that Mike and I definitely wanna share about this. So\r \r first,\r \r if you have been using r and in particular frameworks like r markdown\r \r for any amount of time,\r \r I think if you're not new to the community, you probably know who is\r \r most directly responsible for this.\r \r\n\nWe have to\r \r thank for all these amazing innovations\r \r in Rmarkdown\r \r alongside knitter itself, which honestly made R Markdown possible. Knitter, for those that aren't aware, is kind of the engine behind\r \r frameworks like R Markdown in the spirit of sweave or swive\r \r that comes built into R itself.\r \r But, admittedly, knitter is, in my humble opinion,\r \r much easier to build upon, much easier to customize. And once r once the r markdown format came to be,\r \r there are just so many lives that have been transformed\r \r in professional\r \r development, personal development,\r \r sharing your data science, you know, blogging\r \r with R Markdown and hence, blog down. In essence, what we call the down verse, you might say.\r \r\n\nEWAY is directly responsible for this.\r \r EWAY had a blog post early this year,\r \r just a week ago.\r \r And I got wind of this from a,\r \r somewhat random post on Mastodon, and I almost didn't believe it.\r \r What has happened is that Eway was, unfortunately,\r \r given notice. And, unfortunately,\r \r posit has,\r \r decided to\r \r basically,\r \r take away his full time role,\r \r albeit to pay for the support on a contracting basis\r \r of the packages that the R Markdown ecosystem depends on. So, like I said, aforementioned like Knitter, R Markdown itself, and the like.\r \r This has come to a shock to many of us in the community, and frankly,\r \r it sounds like a surprise to Eway himself in this post.\r \r\n\nBut to Eway's credit, he has been very gracious in his response to this. He has been very cordial\r \r on acknowledging,\r \r posit for\r \r for all the years that he's been able to work on Knitter, R Markdown,\r \r and some of the newer team members that have really stepped up to help him.\r \r He he names a few names, but there certainly, there are many people that he has collaborated with,\r \r that have made the R Markdown,\r \r you know, this EwayDowns\r \r ecosystem\r \r so powerful in the in this space. So he also mentions that, as I mentioned earlier,\r \r the packages that he's been directly responsible for are not gonna be orphaned\r \r because if they have anything to do with our markdown in knitter, he is being paid to support that. It's just obviously not a full time job\r \r pay anymore.\r \r\n\nSo the one exception to this would be DT. He is looking.\r \r It sounds like Paz is gonna find someone new to that package,\r \r but, again, that this is just another, you know, consequence of this.\r \r The other interesting part of Eway's post is something I've been kind of observing a little bit. And as someone who has been a fan of, say, Linux and Unix for how many years, it definitely rings true to me a bit. Eway has been exploring kind of a more minimalist approach to some of the software development.\r \r I've seen some of the newer packages or newer utilities he's been spinning up. In fact, someone called TinyTek,\r \r a way to get\r \r latex installed in a very streamlined way onto your system without going through the full bloated like latex system,\r \r things like that. And he's also experimenting with other,\r \r areas in this, and it sounds like it's more of a philosophical shift.\r \r\n\nHe's not saying that either approach of, like, a minimalist approach versus an approach like quartile\r \r or even Shiny itself that tries to encompass a lot of things. I think they each have their value. Right? It just depends on your philosophy\r \r and where you want to take your development.\r \r Now, really, the part that hits home here is that it does sound like this was a bit of a surprise.\r \r And EWAY, for those that don't know,\r \r is a father. He's married. He's got his own house. He is definitely supporting his family.\r \r So this is now,\r \r to be perfectly frank, an uncertain time for him.\r \r\n\nSo he has put at the end of the blog post he doesn't do this, in fact, hardly ever. I don't remember last time he's mentioned this,\r \r but he did say that until he's able to land on his feet with, say, a new role in whatever industry he chooses to be, He has asked for a bit of help because of the little concern he has with this big change,\r \r and he does have a GitHub Sponsors page.\r \r Mike and I, full disclosure, are both sponsors of his work. I'm gladly so because we value so much of what he's done for us.\r \r But I will say\r \r after this post made the rounds,\r \r he has received\r \r just an\r \r earth shattering\r \r amount of acknowledgments\r \r in the comments of this post. I think we have over 300 or so, at least over 100. It has gone triple digits since I commented on it. And this is just\r \r really\r \r if you ever had any doubt\r \r of what transformative effect Eway has had with his efforts in the R community,\r \r you just read the comments on this. There are so many\r \r that have said,\r \r we owe Eway so much because of our markdown, what it's done for reproducible research, what it's done for their reporting, what it's done for their being able to connect with the community. Like I said, LogDown.\r \r\n\nI use LogDown. That's how my podcast site was built, for goodness sakes. Like, there are so many\r \r ways that we have been leveraging his utilities.\r \r So I will admit I am\r \r frankly disappointed\r \r at the way this came about.\r \r I am, again, giving full credit to Eway for being so gracious in this post.\r \r But, certainly, if you've gotten any value out of Eway's open source work,\r \r I think\r \r everybody makes their own decisions.\r \r But to me,\r \r the effects he's had on my development,\r \r our journey, my\r \r adventures in the community.\r \r He was my first interview on the our podcast, for goodness sakes. He actually said yes. I put him into a room at this local conference called MBSW\r \r with my half answer mic set up, and he talked with me.\r \r\n\nAnd he was so gracious. I felt like I was, you\r \r know, meeting Yoda's Luke Skywalker kind of thing and I'll never be at Yoda's level, but I'm just saying that's how I felt. And I just and then subsequent interviews, he has given me some of the most candid thoughts\r \r I have ever had on that show is from Eway. So\r \r I feel personally\r \r very,\r \r you know, I consider him a good friend. Obviously, we live far apart. We only get to interact briefly, but he has done so much for me personally.\r \r But if you've had any benefit from me, Haysworth, I would just at least consider\r \r helping him out in this current time.\r \r\n\nBut I share what everybody said in in the responses of this, both in the post\r \r and on X and Mastodon.\r \r So many people's lives have changed because of what Ehue has done. So\r \r I sincerely hope he lands on his feet soon. We're thinking of Ehue. If there's anything we can do, obviously, we are we are here to help. But,\r \r best of luck to you. But again, the post has so many thoughts that came to mind after reading it.\r \r It definitely,\r \r like I said, not a highlight in the traditional sense, but\r \r the the impact the UA has had on the community cannot be overstated.\r \r And I think this blog post clearly shows that. So\r \r that that's a lot for me. Mike, what do you got?\r \r\n\n\n\n[00:38:40] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 40,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Yeah. I guess I'll start with maybe a couple of calls to action. And the first\r \r call to action I would say is is if you\r \r have\r \r benefited\r \r at all, especially\r \r financially,\r \r you know, if your salary, what you do for a living,\r \r includes,\r \r you know,\r \r leveraging\r \r our markdown or ever included leveraging our markdown, and you essentially were paid to to use our markdown,\r \r which is obviously free,\r \r I\r \r would have a hard time, you know, not justifying\r \r sponsoring\r \r e way, you know, in some way. I know a lot of people\r \r have, you know,\r \r including you and I, Eric, but\r \r the the value\r \r that and I I don't think it's unfair to say, you know, monetary value that the community has has probably gained in terms of a lot of employed data scientists,\r \r getting a ton of value from our markdown.\r \r\n\nI'm not sure that's even quantifiable.\r \r So if you can, I don't think there's there's any better\r \r use case for making that charitable contribution,\r \r to Eway\r \r at this time\r \r and, you know, his journey?\r \r He is,\r \r so so that I guess that's my first call to action. And my second call to action would be\r \r if you have an opportunity\r \r within your organization, whether it be a contract opportunity or or an opportunity to where where you think, you need someone with his skill set as a as an incredible software engineer,\r \r reach out to him. Go to rweekly.org.\r \r Check out this blog post,\r \r that's called by rstudio/posit.\r \r\n\nAnd I'm sure his contact information\r \r is at the bottom, of this blog post. I know his GitHub is. He has an about page in that blog post with a contact me link where you can get a hold of him. So if you have opportunities for Eway, reach out to him and see if they may be interested, you know, because he is, he is not necessarily\r \r just this miss mythical Yoda. He is a person,\r \r you know, with a family as well. And I know at this point in time, especially within tech, there's a lot of,\r \r folks that are probably experiencing\r \r similar things depending on, you know, where you work.\r \r\n\nSo it's, it can be a tricky time and unfortunately, you always been been bitten by it as well.\r \r So let's, let's try to lift him up, you know, because he has\r \r given so much\r \r to us, and those of us who are data scientists that use\r \r the R Markdown ecosystem and PageDown and BookDown and all these all these different utilities.\r \r So I guess those are that's what I wanted to start out with, is a couple calls to action.\r \r If you haven't yet really considered sponsoring him or reaching out to him with opportunities if you you see them.\r \r Second one, it's it's hard, Eric, not to be emotional,\r \r about this. You know?\r \r\n\nAnd layoffs\r \r in in business are\r \r a reality.\r \r You know, one thing that I think is is disappointing to me, and I I don't think I'm I'm being too frank here, is is that it seemed like it was it was quite a quick\r \r surprise to Eway after someone who had had worked there for for 10 years and really\r \r given so much to, what our studio has been able to create. I have to imagine that, you know, while I understand that a lot of folks worked on on quarto, I have to imagine that a lot of it stands on the shoulders\r \r of what,\r \r Eway\r \r built within the R Markdown ecosystem\r \r for many years. So that's that's really disappointing that it it sort of came as a surprise to Eway. I'm very glad that they are\r \r at least employing him as a contractor to to be able to work on some things. You know, I guess guess the reality of business is that, you know, if you don't have enough work for someone, then you then you probably only want to pay them for the amount of work that you have for them. So I I don't know if the transition to quarto means that there's there's less work for e way to do on some of the software that he was maintaining\r \r and working on. That's just, I guess a guess, and we don't necessarily have that information\r \r at this time. But it's it's\r \r emotional, I think,\r \r more so because of the way that posit's\r \r structured as well as a public benefit corporation and not just,\r \r not just the regular corporation.\r \r\n\nRight. And it's\r \r that creates sort of this dynamic between posit and\r \r the, our community.\r \r That's unique.\r \r Right. So I think when, when something takes, when changes take place\r \r at posit,\r \r we feel\r \r the effects of that sort of personally in a way. And that's, that that's very unique. And I think. Open\r \r source is really rooted in\r \r transparency,\r \r right? When we're doing open source work, you know, the, one of the benefits and the really cornerstones\r \r of open source software development is that\r \r others can see exactly\r \r what we're doing and and what we're working on, and they can contribute to it and and try to help and things like that.\r \r So\r \r I I guess I would like like to some of these changes, for lack of a better word, to be a little bit more transparent\r \r within the community. It it feels like maybe there are some walls being built up,\r \r between the community\r \r and and posit at this point that may not have have previously\r \r existed. And I think\r \r things that come out like this, you know, I think the loss of a lot of our,\r \r posit academy folks,\r \r you know, as well as e way now.\r \r\n\nI think there's not a lot of,\r \r acknowledgement necessarily\r \r of it, except maybe by the folks who are directly\r \r affected by it. I think it's, it's unusually quiet,\r \r from, from their perspective. So I guess I would like to get a better understanding of, of sort of the directions that, that things are going, a better sense of transparency,\r \r just because of this, this really unique relationship that the art community has with, you know, what used to be our studio and what's now posit. It's it's something that,\r \r you know, is emotional, I think, to a lot of us. I don't think I'm just speaking for myself. So, you know, this was a tough blog post to read. I think EWAY may be taking it better than some of us reading it. He he's\r \r taking the high road to every extent here in this blog post. He's extremely grateful,\r \r to the folks that he worked with and who employed him for the past 10 years.\r \r\n\nHe he talks about in the the comments of the post that the in Chinese, the word crisis consists of the words, danger and opportunity. And he he's optimistic about the opportunity part,\r \r and he's not very concerned about the danger, and and he really believes it's going to be a blessing in disguise. So I guess if nothing else, I really hope that Eway, you know, finds a new role for him that he's excited about and loves, and and that he he really lands on his feet and and finds,\r \r you know, a next great opportunity\r \r for himself. So\r \r I think we we have a lot of thoughts on this blog post. I'm glad that we we we talked about it. It is, you know, emotional to me. That's that's sort of the best word that that I can use here to try to characterize,\r \r how I feel about this blog post. And I I think what Y Hue's\r \r work means to us and and what him as a member of the community,\r \r means to us.\r \r\n\n\n\n[00:46:05] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 5,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. I echo a lot of that. And you are not alone. And I've seen posts on Mastodon\r \r of others kind of\r \r a little concerned\r \r about, I would say, like you said, the silence on some of these maneuvers because as those aren't aware, we did talk last year. POSIT did do some layoffs that affected\r \r some of their open source division as well as other\r \r divisions.\r \r And, yes, you might be able to hear from other people affected by it directly, but there wasn't a lot said on the, you know, the public facing kind of communication on that.\r \r And as of now, I'm not seeing any new response to this either.\r \r\n\nI do think this may be a wake up call in a couple senses.\r \r Yes. There is an interesting dichotomy\r \r where unlike most of the tech industry,\r \r posit is a PBC.\r \r That puts you into a different lens, in my opinion.\r \r Whether you consider that right or wrong, they chose it. Right? They chose to be a PBC. That was JJ's vision that we heard in the keynote a couple years ago at at our studio conf.\r \r With that, I think there is and again, Eric's going on his soapbox here. I think there we are owed a little bit more transparency on this as\r \r those that are not just\r \r fans of open source, fans of data science, but this tooling\r \r is immensely\r \r important to the work we do, and especially in the open source side of it.\r \r\n\nYes, of course, the commercial projects\r \r help, too. But\r \r you know, for those that don't know where, Quarto, when it compiles, anything to do with our execution chunks,\r \r that's using Knitter under the hood. Guess who wrote Knitter? EWAY.\r \r So, like, Quarto is not possible on the r side of it without what EWAY did. So whoever paused it is now funneling more resources into that development, Fair Play, it's their company.\r \r Obviously, the interoperability\r \r is a big focus for them now.\r \r But at the same time,\r \r they are indeed standing on shoulders of absolutely giant efforts that EWAY has built here.\r \r So, again, I do think a little more transparency is warranted here.\r \r\n\nAnd, you know,\r \r it did it has spurred on some concerns about future directions.\r \r Again, that could be a whole another podcast in and of itself. I think we'll just leave it as we're interested to see what 2024\r \r holds.\r \r But,\r \r again, full marks, full credit to EWAY for taking the high road on everything here.\r \r And, again, the response from the community\r \r has been eye opening to say the least. I misspoke earlier.\r \r I mean, ever since the blog post, he has been hearing from many, many people,\r \r familiar names, new names, those that maybe are what I call dark matter developers and may not comment very much when they see somebody that has that\r \r impact on their daily work or their daily data science journey. They're coming out to say their thanks. So\r \r I do think just as open source in general, we need to do a better job of thanking contributors,\r \r not just in times like this, but regularly throughout the year because\r \r it can pick you up. If if you're an open source developer,\r \r you're having a rough time trying to maintain this, just having that pick me up really helps too. We don't just have to wait for an event like this. But with that said,\r \r Folker at the Evway for being gracious in this, and I would imagine\r \r he is going to be hearing from a lot of people about future opportunities.\r \r\n\nI hope he takes what's best for him and his family\r \r and certainly will be very curious what the future holds for him. Well said, Eric. Well, yeah. It's hard to transition from that, but that was a jam packed,\r \r summary of our, our highlight stories here. But we're gonna close out with a couple of additional fines that we found in this issue.\r \r And, yeah. Well, I heard you when you heard me mention in in Nicola's,\r \r segment that, you know, she's gonna be pursuing Knicks as a as a tie in with r. Well, of course, our good friend Bruno Rodriguez has been continuing his journey\r \r with the NYX, package system and r, and he has a part 8 of his reproducible data science with NYX blog series\r \r that gets more into the kind of the the into the weeds of just how\r \r open source plays a critical role in Nick's itself.\r \r\n\nAnd in fact,\r \r every package in Nick's is simply\r \r I'd say simply. I should not say simply.\r \r But it is a set of scripts\r \r that will take the upstream utilities,\r \r bundle it up into a way the next can understand,\r \r and then we can install that via the next package manager right then and there on the spot.\r \r And, of course, through,\r \r Bruno's work on the Rix package, he is trying to make that easier from within R itself.\r \r But acknowledging\r \r that many R users are very comfortable with the RStudio IDE, he's been trying to make that\r \r part of the Rix packaging process too, the Git,\r \r version of RStudio\r \r in that reproducible\r \r project.\r \r\n\nSo that then is tying into that custom R installation,\r \r that custom\r \r set of packages that that next package system is exposing.\r \r Well, RStudio\r \r is a bit of a finicky piece of software to compile and run and install manually,\r \r especially around that little thing called macOS.\r \r It's a bit wieldy.\r \r So in his post, he actually talked about setting up a GoFundMe\r \r to help pay for a specialized vendor\r \r to assist with that part of the process\r \r for macOS users.\r \r Unfortunately, it did not hit the funding. But to Bruno's credit,\r \r he has actually donated those funds that were,\r \r contributed back to the R Foundation itself. So fair play to Bruno for at least helping the R Project benefit from that request.\r \r\n\nBut I'm gonna conclude this additional fine summary back to Pazit for a second.\r \r Pause it? If you don't know now, you know that nicks is becoming a thing in data science. It's not just Bruno. Many others are pursuing this too.\r \r It's your ID folks.\r \r Maybe you could help out a bit on this too. Just saying.\r \r I'll leave it at that. Mike, what do you got?\r \r\n\n[00:52:31] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 31,
        "trans_speaker": "Mike Thomas",
        "trans_text": "There's a call to action.\r \r So that's a that's a great find.\r \r I still gotta get my hands dirty with nicks at some point these days, and I know Bruno has ample resources available to help me do that.\r \r One blog post I found that I think caught a lot of fire this past week and was really interesting was from Emily Riederer\r \r on Python Argo nomics.\r \r And it talks about essentially if you are an R developer\r \r needing to switch to Python for a particular project\r \r or,\r \r just trying to learn a little bit of Python,\r \r to to keep up.\r \r Some it talks about how to, map some of the concepts from R into Python to get you up and running. And just sort of as a quick highlight, some of the the tooling\r \r that Emily recommends you use to get started with Py, with Python.\r \r\n\nFor installation,\r \r she recommends pyenv\r \r package, which allows you to switch back and forth between different versions\r \r of Python really easily. So from on one project, you need to use Python 39, and the next project you need to use Python 310.\r \r Py n\r \r allows you to really easily,\r \r switch back and forth from the command line, I believe, between those 2, or multiple different versions of Python. You can set one to be sort of your your global version of Python. I believe that you want to use,\r \r as a default.\r \r For data analysis, we have heard a lot about the Pandas package, sort of being the equivalent maybe to dplyr.\r \r Emily argues that the polars package actually has a syntax that is more similar to dplyr. I agree as well. It's also more performant.\r \r\n\nPolars is is a really, really cool package,\r \r and it's it's really, really efficient for working with data, large data\r \r in particular,\r \r but small datasets as well. I think it it works great for, and I think you'll find that the syntax looks very similar\r \r to, what you would find in DeepBlider verbs such as select,\r \r filter, group by,\r \r that they're all mapped sort of between DeepBlider\r \r and polar, so it should be pretty familiar to look at the code there.\r \r For communication\r \r purposes, she references the great tables package,\r \r in Python, which is the port of the GT package,\r \r by Rich Iannone,\r \r I believe, at at posit, from r\r \r to Python. It's very new. So if you're a Python user looking to author,\r \r really nicely formatted tables within your reports, I would check that one out. And then notebooks, obviously, quarto.\r \r\n\nAnd lastly, in terms of environment management,\r \r I think she references the PDM\r \r package in Python as maybe being the one that would be equivalent to the r end package, or or the one that she prefers the most. So it's a great sort of list of the different tools that Emily uses to get up and running across all of her Python\r \r projects, as well as an explanation of of why she uses them and how they may,\r \r be similar or differ from your experience,\r \r using similar tooling in r.\r \r\n\n[00:55:34] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 34,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Yeah. Emily does a fantastic job here. This is something that I've struggled with immensely.\r \r Even just knowing where to start,\r \r I I have a couple of projects that because I'm extending a package in Python for some RSS feed stuff, I'm probably gonna stay in that ecosystem or some of my, you know, very, you know,\r \r very in-depth kind of podcasting 2 point o expirations.\r \r So having kind of this familiarity of knowing where to go to maybe summarize that podcast database effectively in my portal notebook, go with these packages that give me that kind of our flavor a bit. For somebody that's new to Python, I think that is that is extremely helpful. So this should be your go to post if you're like me and you're just\r \r dabbling your toes in the Python for some interoperability\r \r work without it being your full time focus. Just knowing where to go first is immensely helpful because there's\r \r a wealth of choices out there. And you can go down\r \r rabbit holes on environment management\r \r and, frankly, bang your head against the wall. I can't tell you how many times I've bought projects at the day job because of the Python VM setup gone horribly wrong. Don't give me a start. Anaconda.\r \r\n\nThere'd be dragons on my HPC system with that. So, yeah, I'm sure I'm gonna be playing with a lot of what, Emily is recommending here quite a bit.\r \r\n\n[00:56:55] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 55,
        "trans_speaker": "Mike Thomas",
        "trans_text": "Dev containers.\r \r\n\n[00:56:57] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 57,
        "trans_speaker": "Eric Nantz",
        "trans_text": "To have containers. Yes. Exactly. I do have hooks in that in mind, if only the rest of my projects could benefit from that. Well, as you can tell, we've had a we've had a fun banter here. You can tell it's been a few weeks with Mike and I, so we came with our we came with our opinions as they say. But, of course, there is much more to rweekly itself than us just bantering. The full issue has so many more great content,\r \r lots of new packages and updated packages, some that really caught my attention on the visualization side of things, especially. So definitely have a check at that at rwig.org.\r \r Also, we love to hear from all of you in the community.\r \r\n\nAnd going back to what we mentioned with VeeWay, I'm gonna make this call out now. And I will admit we don't get the whole boost thing very often on this show. I hope that changes from time to time. But for the month of January,\r \r if any of you are gracious enough to boost this show with your favorite podcast app or on the podcast index itself, which I have linked to in the show notes, I will funnel that directly to Eway for the month of January. So if you're interested in supporting Eway in a different way,\r \r the boost would be a way to I will personally make sure that happens.\r \r\n\nSo definitely keep that in mind, but, also, we just love hearing from you in general.\r \r We have a contact page on the episode show notes, and, also,\r \r we are, somewhat active on the social media spheres. I am more,\r \r active on Mastodon.\r \r My handle is at our podcast at podcast index dot social,\r \r sporadically on the x thing of at the r cast, and I'm also on LinkedIn from time to time. Mike, where can they find you?\r \r\n\n[00:58:32] \r Mike Thomas"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 32,
        "trans_speaker": "Mike Thomas",
        "trans_text": "LinkedIn is probably the best place to find me. I think my sort of tag there is Michael j Thomas 2.\r \r You can also find me on mastodon@[email protected].\r \r\n\n[00:58:46] \r Eric Nantz"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "trans_timestamp": 46,
        "trans_speaker": "Eric Nantz",
        "trans_text": "Very nice. Very nice. And like I said, it's great to be back in the swing of things with you. It feels more normal again as we kick off the month of January with this, supersized episode that we just gave you all here. Well, that will do it for us. Like I said, we came with our opinions. Hopefully, you enjoyed it. We'd love to hear from you, but we will be back with another episode of our weekly highlights\r \r next week."
      }
    ],
    "chapters": [
      {
        "ep_name": "issue_2024_w_02_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "chap_timestamp": 40,
        "chap_text": "Streamline R Workflows"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "chap_timestamp": 47,
        "chap_text": "Pipe Assignment Operator"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "chap_timestamp": 11,
        "chap_text": "Appreciation for Yihui"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "chap_timestamp": 50,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2024_w_02_highlights",
        "chap_timestamp": 3,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_50_highlights",
        "ep_date": "2023-12-13",
        "ep_duration": 41,
        "ep_description_short": "A data-driven investigation to the association of early birthdays and hockey players, one of the most-requested feature requests is coming to the next version of Quarto, and just why in the world does the View() function start with V? Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder)) (Twitter) Are Birth…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_50_highlights",
        "description_long": "\r \r\n\nA data-driven investigation to the association of early birthdays and hockey players, one of the most-requested feature requests is coming to the next version of Quarto, and just why in the world does the View() function start with V?\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder) (Twitter)\nAre Birth Dates Still Destiny for Canadian NHL Players?\nQuarto Dashboards\nWhy is View() capitalized, anyway?\nEntire issue available at rweekly.org/2023-W50\n\nSupplement Resources\n\nJJ Allaire's Quarto dashboards keynote at PyData 20203 https://www.youtube.com/watch?v=3HCAScFqr10\nMyNorfolk Quarto dashboard https://grrrck.quarto.pub/mynorfolk-dash\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://jlaw.netlify.app/2023/12/04/are-birth-dates-still-destiny-for-canadian-nhl-players/"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://www.youtube.com/watch?v=_VGJIPRGTy4"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://mm218.dev/posts/2023-12-07-View/index.html"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://rweekly.org/2023-W50.html"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://www.youtube.com/watch?v=3HCAScFqr10"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://grrrck.quarto.pub/mynorfolk-dash"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_50_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "chap_timestamp": 26,
        "chap_text": "Hockey Birthdays"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "chap_timestamp": 45,
        "chap_text": "Quarto Dashboards"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "chap_timestamp": 47,
        "chap_text": "View() with a V"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "chap_timestamp": 53,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "chap_timestamp": 6,
        "chap_text": "Episode Wrapup..."
      },
      {
        "ep_name": "issue_2023_w_50_highlights",
        "chap_timestamp": 14,
        "chap_text": "Another Eric Blooper"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_49_highlights",
        "ep_date": "2023-12-06",
        "ep_duration": 36,
        "ep_description_short": "A timely collection of tips and tricks in adopting the cli package for your R package interfaces, how the deposits package addresses an all-to-familiar problem of sharing research data, and an encore of creating your own RStats-wrapped of your most used R functions. Episode Links This week's curator: Batool Almarzouq - @batool664…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_49_highlights",
        "description_long": "\r \r\n\nA timely collection of tips and tricks in adopting the cli package for your R package interfaces, how the deposits package addresses an all-to-familiar problem of sharing research data, and an encore of creating your own RStats-wrapped of your most used R functions.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq - @batool664 (Twitter)\nCliff notes about the cli package\nHow to make your own #RStats Wrapped\ndeposits R Package Delivers a Common Workflow for R Users\nEntire issue available at rweekly.org/2023-W49\n\nSupplement Resources\n\nRethinking packages & functions preloading in webR 0.2.2 https://colinfay.me/rethinking-packages-and-functions-preloading-in-webr-0.2.2/\nhealthyr: Free Resources\nWebinar: Discover the future of R in regulatory submissions https://www.r-consortium.org/blog/2023/11/20/webinar-discover-the-future-of-r-in-regulatory-submissions\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://blog.r-hub.io/2023/11/30/cliff-notes-about-cli/"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://nrennie.rbind.io/blog/2022-12-03-how-to-make-your-own-rstats-wrapped/"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://www.r-consortium.org/blog/2023/11/30/deposits-r-package-delivers-a-common-workflow-for-r-users"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://rweekly.org/2023-W49.html"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://colinfay.me/rethinking-packages-and-functions-preloading-in-webr-0.2.2/"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://healthyr.surgicalinformatics.org/resources.html#resources"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://www.r-consortium.org/blog/2023/11/20/webinar-discover-the-future-of-r-in-regulatory-submissions"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_49_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "chap_timestamp": 19,
        "chap_text": "{cli} Cliff Notes"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "chap_timestamp": 3,
        "chap_text": "Spotlight on {deposits}"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "chap_timestamp": 59,
        "chap_text": "RStats wrapped encore"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "chap_timestamp": 52,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_49_highlights",
        "chap_timestamp": 45,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_48_highlights",
        "ep_date": "2023-11-30",
        "ep_duration": 34,
        "ep_description_short": "A glimpse of refactoring functional R code to object-oriented programming with R6, using benchmarking as another input to adopting package dependencies, and building a high-performance CSV reader by combining R and Rust. Episode Links This week's curator: Tony Elhabr - @TonyElHabr (https://twitter.com/TonyElHabr) (Twitter) &…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_48_highlights",
        "description_long": "\r \r\n\nA glimpse of refactoring functional R code to object-oriented programming with R6, using benchmarking as another input to adopting package dependencies, and building a high-performance CSV reader by combining R and Rust.\n\nEpisode Links\n\nThis week's curator: Tony Elhabr - @TonyElHabr (Twitter) & @[email protected] (Mastodon)\nObject-Oriented Express: Refactoring in R\nUsing benchmarking to guide the adoption of dependencies in R packages\nBuilding a DataFusion CSV reader with arrow-extendr\nEntire issue available at rweekly.org/2023-W48\n\nSupplement Resources\n\nSharing app state between Shiny modules https://docs.google.com/presentation/d/13___ZiOO1aEv0xiCj2TAm2JenEdy_Sfy6SEIWAltAYI/edit#slide=id.g216fe8fbc25_0_71\n{pkgdepends} Package Dependency Resolution, Downloads and Installation https://r-lib.github.io/pkgdepends\n{reactable.extras} 0.2.0 Release: Enhanced Interactivity and Efficiency for Shiny Apps https://appsilon.com/reactable-extras-enhancing-shiny-applications\nFolks, C'mon, Use Parquet https://appsilon.com/csv-to-parquet-transition\nShiny and Arrow - A match made in high-performance-web-application heaven https://posit.co/blog/shiny-and-arrow\nJadey Ryan's The Coding Cats on Etsy https://www.etsy.com/shop/thecodingcats\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://mastodon.skrimmage.com/@tonyelhabr"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://medium.com/number-around-us/object-oriented-express-refactoring-in-r-3b33b728042b"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://epiverse-trace.github.io/posts/benchmarking_design_decisions/"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://josiahparry.com/posts/2023-11-24-dfusionrdr"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://rweekly.org/2023-W48.html"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://docs.google.com/presentation/d/13___ZiOO1aEv0xiCj2TAm2JenEdy_Sfy6SEIWAltAYI/edit#slide=id.g216fe8fbc25_0_71"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://r-lib.github.io/pkgdepends"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://appsilon.com/reactable-extras-enhancing-shiny-applications"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://appsilon.com/csv-to-parquet-transition"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://posit.co/blog/shiny-and-arrow"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://www.etsy.com/shop/thecodingcats"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_48_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "chap_timestamp": 40,
        "chap_text": "Refactoring to R6"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "chap_timestamp": 24,
        "chap_text": "Benchmarking dependencies"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "chap_timestamp": 6,
        "chap_text": "DataFusion CSV reader with R & Rust"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "chap_timestamp": 7,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "chap_timestamp": 46,
        "chap_text": "A Listener Boost!"
      },
      {
        "ep_name": "issue_2023_w_48_highlights",
        "chap_timestamp": 40,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_45_highlights",
        "ep_date": "2023-11-11",
        "ep_duration": 6,
        "ep_description_short": "From the \"is there anything R cannot do\" department comes QR code scanning, a tidy time series analysis on a major problem in the roads of Pittsburgh, and rolling up your sleeves with custom ggplot2 tricks to enhance a spatial visualization. Episode Links This week's curator: Colin Fay - [@ColinFay]](https://twitter.com/ColinFay) (Twitter) Scanning…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_45_highlights",
        "description_long": "\r \r\n\nFrom the \"is there anything R cannot do\" department comes QR code scanning, a tidy time series analysis on a major problem in the roads of Pittsburgh, and rolling up your sleeves with custom ggplot2 tricks to enhance a spatial visualization.\n\nEpisode Links\n\nThis week's curator: Colin Fay - [@_ColinFay]](https://twitter.com/_ColinFay) (Twitter)\nScanning QR codes in R\nForecasting Pittsburgh Potholes with {fable}\nAdding context to maps made with ggplot2\nEntire issue available at rweekly.org/2023-W45\n\nSupplement Resources\n\nTidy tools for for time series https://tidyverts.org\nForecasting: Principles and Practices 3rd Edition https://otexts.com/fpp3/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nPlastik Skies - Daytona USA - Palpable & Diodes - https://ocremix.org/remix/OCR03726\nWaka Waka - Okami - jnWake, AarekMG, Brandon Harnish, DeLuxDolemite, Ivan Hakštok, JohnStacy - https://ocremix.org/remix/OCR04486"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://twitter.com/_ColinFay"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://ropensci.org/blog/2023/10/30/opencv-qr/"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://ctompkins.netlify.app/post/forecasting-pittsburgh-potholes-with-fable/"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://mm218.dev/posts/2023-10-31-map-context/index.html"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://rweekly.org/2023-W45.html"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://tidyverts.org"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://otexts.com/fpp3/"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://ocremix.org/remix/OCR03726"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "links": "https://ocremix.org/remix/OCR04486"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_45_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "chap_timestamp": 6,
        "chap_text": "Scan QR codes with opencv"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "chap_timestamp": 43,
        "chap_text": "Pittsburgh Potholes"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "chap_timestamp": 14,
        "chap_text": "Customizing Spatial Coordinates"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "chap_timestamp": 14,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_45_highlights",
        "chap_timestamp": 21,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_44_highlights",
        "ep_date": "2023-11-01",
        "ep_duration": 7,
        "ep_description_short": "A collection of post-workshop answers for the R/Pharma introduction to tidymodels workshop, the Shiny UI Editor takes a huge step out of the alpha stage, and a unique approach to Shiny modules with the new component package. Episode Links This week's curator: Eric Nantz - @theRcast (https://twitter.com/theRcast) (Twitter) &…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_44_highlights",
        "description_long": "\r \r\n\nA collection of post-workshop answers for the R/Pharma introduction to tidymodels workshop, the Shiny UI Editor takes a huge step out of the alpha stage, and a unique approach to Shiny modules with the new component package.\n\nEpisode Links\n\nThis week's curator: Eric Nantz - @theRcast (Twitter) & @[email protected] (Mastodon)\nAnswering some {tidymodels} questions\nShinyUIEditor: Out of alpha\n{component} - Creating components for Shiny inspired by Vue\nEntire issue available at rweekly.org/2023-W44\n\nSupplement Resources\n\nIntroduction to machine learning with tidymodels https://nrennie.github.io/r-pharma-2023-tidymodels\nSupport nav_panel within apps using the page_navbar template https://github.com/rstudio/shinyuieditor/issues/190\nShiny Developer Series Episode 26 - Peeling Back the Curtain of the Movie Vue-R Part 1 https://shinydevseries.com/interview/ep026/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nHoliday with Mia Fey - Phoenix Wright: Ace Attorney - OceansAndrew - https://ocremix.org/remix/OCR01870\nNeighburgers - Zombies Ate My Neighbors - Protricity - https://ocremix.org/remix/OCR01202"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://nrennie.rbind.io/blog/answering-some-tidymodels-questions/"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://posit.co/blog/shinyuieditor-out-of-alpha/"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://github.com/devOpifex/component"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://rweekly.org/2023-W44.html"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://nrennie.github.io/r-pharma-2023-tidymodels"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://github.com/rstudio/shinyuieditor/issues/190"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://shinydevseries.com/interview/ep026/"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://ocremix.org/remix/OCR01870"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "links": "https://ocremix.org/remix/OCR01202"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_44_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "chap_timestamp": 6,
        "chap_text": "Tidymodels workshop"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "chap_timestamp": 36,
        "chap_text": "Shiny UI Editor"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "chap_timestamp": 22,
        "chap_text": "Components for Shiny"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "chap_timestamp": 21,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_44_highlights",
        "chap_timestamp": 57,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_42_highlights",
        "ep_date": "2023-10-18",
        "ep_duration": 14,
        "ep_description_short": "Another collection of package testing workflow nuggets you can make great use of today, the definitive guide to effective use of logging in Shiny applications from the recent Shiny in Production conference, and a cautionary tale of the potential impact of default function arguments in your downstream analytical pipelines. Episode Links This week's…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_42_highlights",
        "description_long": "\r \r\n\nAnother collection of package testing workflow nuggets you can make great use of today, the definitive guide to effective use of logging in Shiny applications from the recent Shiny in Production conference, and a cautionary tale of the potential impact of default function arguments in your downstream analytical pipelines.\n\nEpisode Links\n\nThis week's curator: Tony Elhabr - @TonyElHabr (Twitter) & @[email protected] (Mastodon)\nTwo recent enhancements to my testing workflow\nShiny In Production 2023: Effective Logging in Shiny\nNote to self: be aware of functions with default arguments\nEntire issue available at rweekly.org/2023-W42\n\nSupplement Resources\n\ntestthat 3.2.0 https://www.tidyverse.org/blog/2023/10/testthat-3-2-0/\nlazytest - Runs only failed tests https://github.com/cynkra/lazytest\nEffective logging in Shiny GH repository https://github.com/tanho63/talk_shinyprod2023_logging\nshinymetrics https://shinymetrics.com\nShiny In Production 2023: Anatomy of a Shiny app\nShiny in Production 2023: Dynamic annotations: 10 tips for better text\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nOf Whips and Strings - Castlevania - Super Guitar Bros. - https://ocremix.org/remix/OCR02480\nThe Flood Plain - F-Zero - JigginJonT - https://ocremix.org/remix/OCR01494"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://mastodon.skrimmage.com/@tonyelhabr"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://masalmon.eu/2023/10/09/test-workflow-enhancement/"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://github.com/tanho63/talk_shinyprod2023_logging"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://r-critique.com/be-aware-of-default-function-arguments"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://rweekly.org/2023-W42.html"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://www.tidyverse.org/blog/2023/10/testthat-3-2-0/"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://github.com/cynkra/lazytest"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://github.com/tanho63/talk_shinyprod2023_logging"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://shinymetrics.com"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://chrisbrownlie.github.io/anatomy_of_shiny_sip23/#/title-slide"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://www.cararthompson.com/talks/shiny-dynamic-annotations/"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://ocremix.org/remix/OCR02480"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "links": "https://ocremix.org/remix/OCR01494"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_42_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "chap_timestamp": 24,
        "chap_text": "Testing workflow enhancements"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "chap_timestamp": 38,
        "chap_text": "Effective logging in Shiny"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "chap_timestamp": 16,
        "chap_text": "Default function arguments"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "chap_timestamp": 49,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_42_highlights",
        "chap_timestamp": 37,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_41_highlights",
        "ep_date": "2023-10-11",
        "ep_duration": 53,
        "ep_description_short": "How the {potools} package jump-starts your R package translations, the most-upvoted feature request lands in the RStudio IDE with GitHub Copilot integration, and a reflective post on the multiple paths to reproducible data science workflows in R. Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder))…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_41_highlights",
        "description_long": "\r \r\n\nHow the {potools} package jump-starts your R package translations, the most-upvoted feature request lands in the RStudio IDE with GitHub Copilot integration, and a reflective post on the multiple paths to reproducible data science workflows in R.\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder) (Twitter)\nHow to translate your package's messages with {potools}\nGitHub Copilot in Rstudio, it's finally here!\nAn overview of what's out there for reproducibility with R\nEntire issue available at rweekly.org/2023-W41\n\nSupplement Resources\n\npotools - Tools for Portability and Internationalization of R packages https://michaelchirico.github.io/potools/\nGitHub Copilot in RStudio, it’s finally here! https://colorado.posit.co/rsc/rstudio-copilot/\nGitHub Copilot RStudio User Guide: https://docs.posit.co/ide/user/ide/guide/tools/copilot.html\nRami Krispin's GitHub repo on devcontainers w/ R in VSCode: https://github.com/RamiKrispin/vscode-r\nR/Pharma virtual conference registration: https://hopin.com/events/r-pharma-2023/registration\nR/Pharma 2023 workshops (please register for conference before your register for a workshop): https://rinpharma.com/workshop/2023conference/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nPerson, Place, or Groove? - Pictionary - The Orichalcon - https://ocremix.org/remix/OCR01548\nForest Through the Trees - Final Fantasy Mystic Quest - Shea's Violin - https://ocremix.org/remix/OCR04484"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://masalmon.eu/2023/10/06/potools-mwe/"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://www.youtube.com/watch?v=yVq-b5xHmac"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://www.brodrigues.co/blog/2023-10-05-repro_overview/"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://rweekly.org/2023-W41.html"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://michaelchirico.github.io/potools/"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://colorado.posit.co/rsc/rstudio-copilot/"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://docs.posit.co/ide/user/ide/guide/tools/copilot.html"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://github.com/RamiKrispin/vscode-r"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://hopin.com/events/r-pharma-2023/registration"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://rinpharma.com/workshop/2023conference/"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://ocremix.org/remix/OCR01548"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "links": "https://ocremix.org/remix/OCR04484"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_41_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "chap_timestamp": 10,
        "chap_text": "R package translations with potools"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "chap_timestamp": 29,
        "chap_text": "GitHub Copilot in RStudio"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "chap_timestamp": 41,
        "chap_text": "Reproducibility in R"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "chap_timestamp": 1,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_41_highlights",
        "chap_timestamp": 9,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_40_highlights",
        "ep_date": "2023-10-05",
        "ep_duration": 53,
        "ep_description_short": "A new contender for speedy fuzzy joins of data frames enough to make Sonic jealous, a novel use of ggplot2 for creating a map that could have come from a vintage typewriter, and the immense progress of detecting R package system dependencies. Episode Links This week's curator: Ryo Nakagawara - @RbyRyo (https://twitter.com/R_by_Ryo)) (Twitter) &…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_40_highlights",
        "description_long": "\r \r\n\nA new contender for speedy fuzzy joins of data frames enough to make Sonic jealous, a novel use of ggplot2 for creating a map that could have come from a vintage typewriter, and the immense progress of detecting R package system dependencies.\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara - @R_by_Ryo) (Twitter) & @[email protected] (Mastodon)\n{zoomerjoin} 0.1.0: Superlatively-fast fuzzy-joins in R.\nCreating typewriter-styled maps in ggplot2\nSystem Dependencies in R Packages & Automatic Testing\nEntire issue available at rweekly.org/2023-W40\n\nSupplement Resources\n\nLocality-sensitive hashing https://en.wikipedia.org/wiki/Locality-sensitive_hashing\nValue 4 Value podcast by Kyrin Down https://blubrry.com/1475054/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nJazzer Soul - Soul Blade - MkVaff - https://ocremix.org/remix/OCR00194\nSuper Buck II - Super Mario Brothers 2 - Estradasphere - https://ocremix.org/remix/OCR00577"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://mstdn.social/@R_by_Ryo"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://github.com/beniaminogreen/zoomerjoin"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://nrennie.rbind.io/blog/creating-typewriter-maps-r/"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://blog.r-hub.io/2023/09/26/system-dependency/"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://rweekly.org/2023-W40.html"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://en.wikipedia.org/wiki/Locality-sensitive_hashing"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://blubrry.com/1475054/"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://ocremix.org/remix/OCR00194"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "links": "https://ocremix.org/remix/OCR00577"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_40_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "chap_timestamp": 48,
        "chap_text": "zoomerjoin"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "chap_timestamp": 25,
        "chap_text": "Typewriter-style maps"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "chap_timestamp": 50,
        "chap_text": "System dependencies in R packages"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "chap_timestamp": 29,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_40_highlights",
        "chap_timestamp": 0,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_39_highlights",
        "ep_date": "2023-09-27",
        "ep_duration": 21,
        "ep_description_short": "Reflections on the amazing posit::conf(2023), a new framework that'll have you snap into HTML slides, the Nix reproducible data science train powers forward into CI/CD territory, and leveraging parallel processing in spatial data prediction. Episode Links This week's curator: Batool Almarzouq - @batool664 (https://twitter.com/batool664)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_39_highlights",
        "description_long": "\r \r\n\nReflections on the amazing posit::conf(2023), a new framework that'll have you snap into HTML slides, the Nix reproducible data science train powers forward into CI/CD territory, and leveraging parallel processing in spatial data prediction.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq - @batool664 (Twitter)\nReflections on posit conf(2023)\nSnap Slides: a Lightweight HTML Presentation Framework\nParallel raster processing in stars\nReproducible data science with Nix, part 6 -- CI/CD has never been easier\nEntire issue available at rweekly.org/2023-W39\n\nSupplement Resources\n\nShiny in Production Tools & Techniques https://posit-conf-2023.github.io/shiny-r-prod/\nJill McKay's posit conf presentation https://jillymackay.github.io/positconf2023_vetdata/positconf2023.html#/title-slide\nScroll snap technique https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Scroll_Snap/Basic_concepts\nData science at the command line https://datascienceatthecommandline.com/\nSpatial data science with applications in R https://r-spatial.org/book/\ngeoparquet https://geoparquet.org/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nAzure Your Cause (The Color of the Summer Sky) - Secret of Mana Resonance of the Pure Land - Rexy - https://ocremix.org/remix/OCR03650\nSecrets Abound (Matoya's Cave) - FInal Fantast Random Encounter - Midgarian Sky - https://ocremix.org/remix/OCR02452\nThunder Beam (Elec Man Stage) - Mega Man Series The Robot Museum - Joshua Morse - https://museum.ocremix.org/"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://jillymackay.com/post/positconf2023/"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://yihui.org/en/2023/09/snap-slides/"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://www.r-spatial.org//r/2023/09/21/stars-parallel.html"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://www.brodrigues.co/blog/2023-09-20-nix_for_r_part6/"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://rweekly.org/2023-W39.html"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://posit-conf-2023.github.io/shiny-r-prod/"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://jillymackay.github.io/positconf2023_vetdata/positconf2023.html#/title-slide"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://developer.mozilla.org/en-US/docs/Web/CSS/CSS_Scroll_Snap/Basic_concepts"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://datascienceatthecommandline.com/"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://r-spatial.org/book/"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://geoparquet.org/"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://ocremix.org/remix/OCR03650"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://ocremix.org/remix/OCR02452"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "links": "https://museum.ocremix.org/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_39_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "chap_timestamp": 16,
        "chap_text": "Reflections on posit::conf(2023)"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "chap_timestamp": 28,
        "chap_text": "Snap scrolling slides"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "chap_timestamp": 1,
        "chap_text": "Nix and CI/CD"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "chap_timestamp": 14,
        "chap_text": "Parallel Raster Processing"
      },
      {
        "ep_name": "issue_2023_w_39_highlights",
        "chap_timestamp": 0,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_37_highlights",
        "ep_date": "2023-09-13",
        "ep_duration": 43,
        "ep_description_short": "Another adventure with incorporating R packages into a WebR application, annotating your fancy equations in a Quarto PDF document, and unleasing a Bayesian model on UFO sightings data. Episode Links This week's curator: Jon Carroll - @carroll_jono (https://twitter.com/carroll_jono) (Twitter) & @[email protected]…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_37_highlights",
        "description_long": "\r \r\n\nAnother adventure with incorporating R packages into a WebR application, annotating your fancy equations in a Quarto PDF document, and unleasing a Bayesian model on UFO sightings data.\n\nEpisode Links\n\nThis week's curator: Jon Carroll - @carroll_jono (Twitter) & @[email protected] (Mastodon)\nPreloading your R packages in webR in an Express JS API\nA guide to annotating equations in quarto documents\nUsing Stan to analyse global UFO sighting reports\nEntire issue available at rweekly.org/2023-W37\n\nSupplement Resources\n\nWebR binary R package repository - https://repo.r-wasm.org/\nHow do I preload the R packages in a node app - https://github.com/r-wasm/webr/issues/260\nMinutes from 2023-08-18 Pilot 4 R-Consortium R-Submissions working group meeting (sending a Shiny application built with containers and webR to FDA) - https://rconsortium.github.io/submissions-pilot4/minutes/2023-08-18/\nggannotate - Interactively annotate your ggplots https://github.com/MattCowgill/ggannotate\nUFO sightings around the world - https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-06-25\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nKraid’s Campfire Ballad - Harmony of a Hunter - Sebastian Mårtensson feat. Kristin Björkebäck - https://harmony.shinesparkers.net/album/harmony-of-a-hunter\nCool Burn - Mega Man 9 Back in Blue - DarkeSword - https://backinblue.ocremix.org/music.php"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://fosstodon.org/@jonocarroll"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://colinfay.me/preloading-your-r-packages-in-webr-in-an-express-js-api/"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://lpembleton.rbind.io/posts/annotate-equations/"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://www.jumpingrivers.com/blog/ufo-counts-in-stan-bayesian-r/"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://rweekly.org/2023-W37.html"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://repo.r-wasm.org/"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://github.com/r-wasm/webr/issues/260"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://rconsortium.github.io/submissions-pilot4/minutes/2023-08-18/"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://github.com/MattCowgill/ggannotate"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://github.com/rfordatascience/tidytuesday/tree/master/data/2019/2019-06-25"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://harmony.shinesparkers.net/album/harmony-of-a-hunter"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "links": "https://backinblue.ocremix.org/music.php"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_37_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "chap_timestamp": 53,
        "chap_text": "R packages in webR"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "chap_timestamp": 28,
        "chap_text": "Annotating equations with Quarto"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "chap_timestamp": 8,
        "chap_text": "Bayesian models for UFO sightings"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "chap_timestamp": 48,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "chap_timestamp": 27,
        "chap_text": "Episode Wrapup..."
      },
      {
        "ep_name": "issue_2023_w_37_highlights",
        "chap_timestamp": 9,
        "chap_text": "Bloopers!"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_36_highlights",
        "ep_date": "2023-09-07",
        "ep_duration": 35,
        "ep_description_short": "A batch of R functions to level-up your development tasks, revisting a classic R inferno on object allocation, and a call for proposals to take R's infrastructure to new heights. Episode Links This week's curator: Colin Fay - @_ColinFay (https://twitter.com/_ColinFay) (Twitter) Three (four?) R functions I enjoyed this week…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_36_highlights",
        "description_long": "\r \r\n\nA batch of R functions to level-up your development tasks, revisting a classic R inferno on object allocation, and a call for proposals to take R's infrastructure to new heights.\n\nEpisode Links\n\nThis week's curator: Colin Fay - @_ColinFay (Twitter)\nThree (four?) R functions I enjoyed this week\nPre-allocating vectors is for nerds\nGrants For R Language Infrastructure Projects Available Now!\nEntire issue available at rweekly.org/2023-W36\n\nSupplement Resources\n\nJune Choe's comment on Mike Mahoney's post https://fosstodon.org/@yjunechoe/110975018204561319\n10 years of rio\nShiny for R updates: tooltips, popovers, a new theme, and more\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic credits powered by OCRemix\n\nEscape Route - Cave Story - Corran - https://ocremix.org/remix/OCR01513\nA Flea and His Giant - Maverick Rising - Chuck Dietz - https://maverick.ocremix.org"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://twitter.com/_ColinFay"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://masalmon.eu/2023/08/30/three-r-functions/"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://www.mm218.dev/posts/2023-08-29-allocations/"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://www.r-consortium.org/blog/2023/08/31/grants-for-r-language-infrastructure-projects-available-now"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://rweekly.org/2023-W36.html"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://fosstodon.org/@yjunechoe/110975018204561319"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://chainsawriot.com/postmannheim/2023/08/28/rio10.html"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://shiny.posit.co/blog/posts/bslib-tooltips/"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://ocremix.org/remix/OCR01513"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "links": "https://maverick.ocremix.org"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_36_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "chap_timestamp": 56,
        "chap_text": "Maelle's Recent Finds"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "chap_timestamp": 55,
        "chap_text": "The vector inferno revisted"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "chap_timestamp": 4,
        "chap_text": "Call for R infrastructure proposals"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "chap_timestamp": 40,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "chap_timestamp": 12,
        "chap_text": "Episode Wrapup..."
      },
      {
        "ep_name": "issue_2023_w_36_highlights",
        "chap_timestamp": 27,
        "chap_text": "Bloopers!"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_35_highlights",
        "ep_date": "2023-09-01",
        "ep_duration": 0,
        "ep_description_short": "The next generation of object-oriented programming in R arrives on CRAN, a novel use of R to automate R scripts and documents for Tidy Tuesday analyses, and a terrific presentation de-mystifying the world of web APIs in R. Episode Links This week's curator: Eric Nantz - @theRcast (https://twitter.com/theRcast) (Twitter) &…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_35_highlights",
        "description_long": "\r \r\n\nThe next generation of object-oriented programming in R arrives on CRAN, a novel use of R to automate R scripts and documents for Tidy Tuesday analyses, and a terrific presentation de-mystifying the world of web APIs in R.\n\nEpisode Links\n\nThis week's curator: Eric Nantz - @theRcast (Twitter) & @[email protected] (Mastodon)\n{S7} 0.1.0: An Object Oriented System Meant to Become a Successor to S3 and S4\nCreating template files with R\nA Gradual Introduction to Web APIs and JSON\nEntire issue available at rweekly.org/2023-W35\n\nSupplement Resources\n\nS7 - A new object-oriented system in R https://rconsortium.github.io/S7/\nName of the game (issue 262): https://github.com/RConsortium/OOP-WG/issues/262\nTidyX Episode 109 - R Classes and Objects - Making an S3 Object Part 1 https://www.youtube.com/watch?v=k9PGOx9Oqjo\nMike's boston R user group talk\nStandard Notes (End-to-End Encrypted Notes App) https://standardnotes.com/\nHedgeDoc https://hedgedoc.org/\nfs - Provide cross platform file operations based on libuv https://fs.r-lib.org/\nRoom by Room Temperature Tracking (Jared Lander) https://www.jaredlander.com/2021/02/room-by-room-temperature-tracking/\nTed Laderas - A gRadual introduction to Web APIs and JSON https://www.youtube.com/watch?v=HA7KfdEsdpo\nOpen Call for rOpenSci Champions Program 2023 Applications (deadline September 4th, 2023) https://ropensci.org/champions/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)\n\nMusic Credits powered by OverClocked Remix\n\nFiesta Amongst the Trees - Ristar - Southwestern College Afro-Cuban Jazz Ensemble - https://ocremix.org/remix/OCR02125\nSuco de Melancia - Final Fantasy 7 Voices of the Lifestream - Red Tailed Fox - https://ocremix.org/remix/OCR01671"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://cran.r-project.org/package=S7"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://nrennie.rbind.io/blog/script-templates-r/"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://laderast.github.io/intro_apis_json_cascadia/#/title-slide"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://rweekly.org/2023-W35.html"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://rconsortium.github.io/S7/"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://github.com/RConsortium/OOP-WG/issues/262"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://www.youtube.com/watch?v=k9PGOx9Oqjo"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://github.com/mthomas-ketchbrook/boston_useR_talk"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://standardnotes.com/"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://hedgedoc.org/"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://fs.r-lib.org/"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://www.jaredlander.com/2021/02/room-by-room-temperature-tracking/"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://www.youtube.com/watch?v=HA7KfdEsdpo"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://ropensci.org/champions/"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://ocremix.org/"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://ocremix.org/remix/OCR02125"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "links": "https://ocremix.org/remix/OCR01671"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_35_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "chap_timestamp": 54,
        "chap_text": "S7 arrives on CRAN"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "chap_timestamp": 1,
        "chap_text": "Creating templates with R"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "chap_timestamp": 36,
        "chap_text": "Gradual intro to web APIs and JSON"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "chap_timestamp": 15,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "chap_timestamp": 41,
        "chap_text": "Episode Wrapup..."
      },
      {
        "ep_name": "issue_2023_w_35_highlights",
        "chap_timestamp": 53,
        "chap_text": "Bloopers!"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_34_highlights",
        "ep_date": "2023-08-23",
        "ep_duration": 29,
        "ep_description_short": "A few key practices for data preprocessing leveraging the tidyverse, more amazing wins with open source to process high-dimensional USDA geospatial data sets, and an infinitely fascinating look at how recursion and infinite data structures can be used in your R adventures. Episode Links This week's curator: Jon Carroll - @carroll_jono…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_34_highlights",
        "description_long": "\r \r\n\nA few key practices for data preprocessing leveraging the tidyverse, more amazing wins with open source to process high-dimensional USDA geospatial data sets, and an infinitely fascinating look at how recursion and infinite data structures can be used in your R adventures.\n\nEpisode Links\n\nThis week's curator: Jon Carroll - @carroll_jono (Twitter) & @[email protected] (Mastodon)\nBest Practices for Data Cleaning and Preprocessing\nAnalyzing new USDA data using open source tools\nTaking from Infinite Sequences+ Entire issue available at rweekly.org/2023-WXX\n\nSupplement Resources\n\njanitor package by Sam Firke https://sfirke.github.io/janitor\nCRAN task view on missing data https://cran.r-project.org/web/views/MissingData.html\nTidy modeling with R https://www.tmwr.org/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://fosstodon.org/@jonocarroll"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://www.jumpingrivers.com/blog/best-practices-data-cleaning-r/"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://blog.ketchbrookanalytics.com/posts/2023-08-09-geoparquet-for-usda-crop-maps/geoparquet-for-usda-crop-maps"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://jcarroll.com.au/2023/08/18/taking-from-infinite-sequences/"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://rweekly.org/2023-WXX.html"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://sfirke.github.io/janitor"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://cran.r-project.org/web/views/MissingData.html"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://www.tmwr.org/"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_34_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "chap_timestamp": 43,
        "chap_text": "Tidy data preprocessing"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "chap_timestamp": 5,
        "chap_text": "Geoparquet for large spatial data"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "chap_timestamp": 25,
        "chap_text": "Infinite data structures"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "chap_timestamp": 14,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "chap_timestamp": 40,
        "chap_text": "Episode Wrapup..."
      },
      {
        "ep_name": "issue_2023_w_34_highlights",
        "chap_timestamp": 58,
        "chap_text": "Bloopers!"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_33_highlights",
        "ep_date": "2023-08-16",
        "ep_duration": 20,
        "ep_description_short": "Another excellent use case of Nix for solving R package installation woes, a practical dev journey of wrapping C code in an R package, and a guide for using the new refugees R package from UNHCR. Episode Links This week's curator: Ryo Nakagawara - @RbyRyo (https://twitter.com/R_by_Ryo)) (Twitter) & @[email protected]…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_33_highlights",
        "description_long": "\r \r\n\nAnother excellent use case of Nix for solving R package installation woes, a practical dev journey of wrapping C code in an R package, and a guide for using the new refugees R package from UNHCR.\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara - @R_by_Ryo) (Twitter) & @[email protected] (Mastodon)\nShe issued install.packages() -- you won't believe what happened next!\nWrapping C Code in an R Package\nHow to use UNHCR’s {refugees} R package\nEntire issue available at rweekly.org/2023-W33\n\nSupplement Resources\n\nR Packages Chapter on Data: https://r-pkgs.org/data.html\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://mstdn.social/@R_by_Ryo"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://kupac.gitlab.io/biofunctor/2023/08/01/nix-for-r-intro/"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://jcarroll.com.au/2023/08/11/wrapping-c-code-in-an-r-package/"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://www.unhcr.org/refugee-statistics/insights/explainers/refugees-r-package.html"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://rweekly.org/2023-W33.html"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://r-pkgs.org/data.html"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_33_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "chap_timestamp": 37,
        "chap_text": "Installing R packages with Nix"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "chap_timestamp": 9,
        "chap_text": "Wrapping C code in an R package"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "chap_timestamp": 1,
        "chap_text": "UNHCR's refugee package"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "chap_timestamp": 15,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "chap_timestamp": 51,
        "chap_text": "Episode Wrapup..."
      },
      {
        "ep_name": "issue_2023_w_33_highlights",
        "chap_timestamp": 15,
        "chap_text": "Bloopers!"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_32_highlights",
        "ep_date": "2023-08-09",
        "ep_duration": 29,
        "ep_description_short": "How a novel blend of automation and the YouTube API formed a new R-Ladies meetup recording dashboard built entirely with R, the momentum of webR continues with a fantastic guide to create a serverless Shiny app, and a new challenger in the world of high-performance data manipulation libraries arrives. Episode Links This week's curator: Jon Calder…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_32_highlights",
        "description_long": "\r \r\n\nHow a novel blend of automation and the YouTube API formed a new R-Ladies meetup recording dashboard built entirely with R, the momentum of webR continues with a fantastic guide to create a serverless Shiny app, and a new challenger in the world of high-performance data manipulation libraries arrives.\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder) (Twitter)\nUsing flexdashboard to create a GitHub Actions-powered YouTube feed\nBuilding Serverless Shiny Apps with webR: A Step-by-Step Guide\nCookbook Polars for R Cookbook to provide solutions to common tasks and problems in using Polars with R. A side-by-side comparison of polars, R base, dplyr, tidyr and data.table packages.\nEntire issue available at rweekly.org/2023-W32\n\nSupplement Resources\n\nTube Archivist - Your self-hosted YouTube media server https://www.tubearchivist.com\nwebR code extension for HTML Quarto documents https://github.com/coatless/quarto-webr\nInto the webR-verse (Bob Rudis presentation at the 2023 New York R Conference) https://www.youtube.com/watch?v=inpwcTUmBDY\ntidypolars - Provide the functionalities of Polars with the syntax of the Tidyverse https://www.tidypolars.etiennebacher.com\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://ivelasq.rbind.io/blog/automated-youtube-dashboard/"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://hypebright.nl/index.php/en/2023/07/25/building-serverless-shiny-apps-with-webr-a-step-by-step-guide/"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://github.com/ddotta/cookbook-rpolars"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://rweekly.org/2023-W32.html"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://www.tubearchivist.com"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://github.com/coatless/quarto-webr"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://www.youtube.com/watch?v=inpwcTUmBDY"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://www.tidypolars.etiennebacher.com"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_32_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "chap_timestamp": 39,
        "chap_text": "Automated YouTube Flexdashboard"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "chap_timestamp": 17,
        "chap_text": "Serverless Shiny App with webR"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "chap_timestamp": 6,
        "chap_text": "Polars Cookbook"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "chap_timestamp": 14,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "chap_timestamp": 55,
        "chap_text": "Episode Wrapup..."
      },
      {
        "ep_name": "issue_2023_w_32_highlights",
        "chap_timestamp": 51,
        "chap_text": "Outtakes!"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_31_highlights",
        "ep_date": "2023-08-03",
        "ep_duration": 36,
        "ep_description_short": "Reducing usage of for loops with the reduce function from purrr, filling spatial maps with density gradients to account for overplotting, and a fun way to add attribution to your fancy ggplots. Episode Links This week's curator: Tony Elhabr - @TonyElHabr (https://twitter.com/TonyElHabr) (Twitter) & @[email protected]…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_31_highlights",
        "description_long": "\r \r\n\nReducing usage of for loops with the reduce function from purrr, filling spatial maps with density gradients to account for overplotting, and a fun way to add attribution to your fancy ggplots.\n\nEpisode Links\n\nThis week's curator: Tony Elhabr - @TonyElHabr (Twitter) & @[email protected] (Mastodon)\nReducing my for loop usage with purrr::reduce()\nHow to fill maps with density gradients with R, {ggplot2}, and {sf}\nAdding social media icons to charts with {ggplot2}\nEntire issue available at rweekly.org/2023-W31\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter / X / whatever it is called) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://mastodon.skrimmage.com/@tonyelhabr"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://masalmon.eu/2023/07/26/reduce/"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://www.andrewheiss.com/blog/2023/07/28/gradient-map-fills-r-sf/"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://nrennie.rbind.io/blog/adding-social-media-icons-ggplot2/"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://rweekly.org/2031-W31.html"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_31_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "chap_timestamp": 23,
        "chap_text": "Reducing for loop usage"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "chap_timestamp": 59,
        "chap_text": "Density gradients on maps"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "chap_timestamp": 59,
        "chap_text": "Social icons in ggplots"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "chap_timestamp": 13,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_31_highlights",
        "chap_timestamp": 13,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_30_highlights",
        "ep_date": "2023-07-26",
        "ep_duration": 31,
        "ep_description_short": "How consistent formatting and styling is valuable technique for debugging, a visual tour-de-force of jazzing up your ggplots with the amazing ecosystem of extension packages, and why a little investment in learning HTML and CSS is worth your time as an R programmer. Episode Links This week's curator: Batool Almarzouq - @batool664…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_30_highlights",
        "description_long": "\r \r\n\nHow consistent formatting and styling is valuable technique for debugging, a visual tour-de-force of jazzing up your ggplots with the amazing ecosystem of extension packages, and why a little investment in learning HTML and CSS is worth your time as an R programmer.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq - @batool664 (Twitter)\nTips for debugging and cleaning broken code\nJazz up your ggplots!\nFour reasons to learn HTML + CSS as an R programmer\nEntire issue available at rweekly.org/2023-WXX\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://datavizs23.classes.andrewheiss.com/news/2023-07-05_messy-broken-code-tips.html"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://waterdata.usgs.gov/blog/ggplot-jazz/"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://albert-rapp.de/posts/16_html_css_for_r/16_html_css_for_r.html"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://rweekly.org/2023-WXX.html"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_30_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "chap_timestamp": 4,
        "chap_text": "Debugging & Cleaning Broken Code"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "chap_timestamp": 25,
        "chap_text": "Jazz up your ggplots"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "chap_timestamp": 42,
        "chap_text": "HTML & CSS for R Programmers"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "chap_timestamp": 38,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_30_highlights",
        "chap_timestamp": 16,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_29_highlights",
        "ep_date": "2023-07-19",
        "ep_duration": 37,
        "ep_description_short": "The second edition of the highly-regarded R for Data Science arrives with substantial updates, an adventure with \"A Programming Language\" that brings new perspectives to functional programming approaches, and a new take on reproducibility in data science combining R with the Nix packaging system. Episode Links This week's curator: Eric Nantz -…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_29_highlights",
        "description_long": "\r \r\n\nThe second edition of the highly-regarded R for Data Science arrives with substantial updates, an adventure with \"A Programming Language\" that brings new perspectives to functional programming approaches, and a new take on reproducibility in data science combining R with the Nix packaging system.\n\nEpisode Links\n\nThis week's curator: Eric Nantz - @theRcast (Twitter) & @[email protected] (Mastodon)\nR for Data Science, 2nd edition\nArray Languages: R vs APL\nReproducible data science with Nix\nEntire issue available at rweekly.org/2023-W29\n\nSupplement Resources\n\nR for Data Science 2nd Edition: https://r4ds.hadley.nz/\nAPL: https://en.wikipedia.org/wiki/APL_(programming_language)\nTry APL in a browser: https://tryapl.org/\nJonathan Carroll could be available for your next project! https://fosstodon.org/@jonocarroll/110726981972909319\nLinux Unplugged Episode 451 The NixOS Challenge https://www.jupiterbroadcasting.com/show/linux-unplugged/451/\nZero to Nix - An unofficial, opinionated, gentle introduction to Nix https://zero-to-nix.com/\nIt's not too late to register for Eric and Mike's Shiny in Production workshop at posit::conf(2023)! https://reg.conf.posit.co/flow/posit/positconf23/attendee-portal/page/sessioncatalog?search=shiny&search.sessiontype=1675316728702001wr6r&search.day=20230918\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://www.tidyverse.org/blog/2023/07/r4ds-2e/"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://jcarroll.com.au/2023/07/07/array-languages-r-vs-apl/"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://www.brodrigues.co/blog/2023-07-13-nix_for_r_part1/"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://rweekly.org/2023-W29.html"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://r4ds.hadley.nz/"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://en.wikipedia.org/wiki/APL_(programming_language)"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://tryapl.org/"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://fosstodon.org/@jonocarroll/110726981972909319"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://www.jupiterbroadcasting.com/show/linux-unplugged/451/"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://zero-to-nix.com/"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://reg.conf.posit.co/flow/posit/positconf23/attendee-portal/page/sessioncatalog?search=shiny&search.sessiontype=1675316728702001wr6r&search.day=20230918"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_29_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "chap_timestamp": 8,
        "chap_text": "R4DS Second Edition"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "chap_timestamp": 36,
        "chap_text": "A Programming Language ... really"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "chap_timestamp": 34,
        "chap_text": "Reproducible Data Science with Nix"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "chap_timestamp": 43,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_29_highlights",
        "chap_timestamp": 7,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_26_highlights",
        "ep_date": "2023-06-28",
        "ep_duration": 57,
        "ep_description_short": "Releasing an Word document table into the land of markdown, a practical overview of sharing your machine learning model with others, and taking local control of checking the builds of your package across computing architectures. Episode Links This week's curator: Colin Fay - [@ColinFay]](https://twitter.com/ColinFay) (Twitter) Convert a Word table…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_26_highlights",
        "description_long": "\r \r\n\nReleasing an Word document table into the land of markdown, a practical overview of sharing your machine learning model with others, and taking local control of checking the builds of your package across computing architectures.\n\nEpisode Links\n\nThis week's curator: Colin Fay - [@_ColinFay]](https://twitter.com/_ColinFay) (Twitter)\nConvert a Word table to Markdown\nHow Can Someone Else Use My Model?\nHow to debug your package in a {rhub} fedora container before sending to CRAN?\nEntire issue available at rweekly.org/2023-W26\n\nSupplement Resources\n\n{datapasta} RStudio addins and R functions that make copy-pasting vectors and tables to text painless https://milesmcbain.github.io/datapasta\nMatt Kaye's series \"The missing semester of your DS education\" https://matthewrkaye.com/series.html#the-missing-semester-of-your-ds-education\nPut R in production: Tools and guides to put R models in production https://putrinprod.com\n{checkhelper} A package to help you deal with devtools::check outputs https://thinkr-open.github.io/checkhelper\nRemote Explorer Visual Studio Code extension https://marketplace.visualstudio.com/items?itemName=ms-vscode.remote-explorer\n{crew}: A distributed worker launcher framework for asynchronous and distributed computing https://wlandau.github.io/crew\nData4Good Explores Visualizing Freshwater Resources on a Global Scale https://appsilon.com/visualizing-fresh-water-resources-data\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://twitter.com/_ColinFay"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://www.rostrum.blog/2023/06/21/wordup-tables/"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://matthewrkaye.com/posts/series/doing-data-science/2023-06-20-how-can-others-use-my-model/how-can-others-use-my-model.html"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://statnmap.com/2023-06-20-how-to-debug-your-package-in-a-rhub-fedora-container-before-sending-to-cran/"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://rweekly.org/2023-W26.html"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://milesmcbain.github.io/datapasta"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://matthewrkaye.com/series.html#the-missing-semester-of-your-ds-education"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://putrinprod.com"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://thinkr-open.github.io/checkhelper"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://marketplace.visualstudio.com/items?itemName=ms-vscode.remote-explorer"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://wlandau.github.io/crew"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://appsilon.com/visualizing-fresh-water-resources-data"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_26_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "chap_timestamp": 46,
        "chap_text": "wordup, yo"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "chap_timestamp": 58,
        "chap_text": "Sharing your model with others"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "chap_timestamp": 16,
        "chap_text": "R-Hub container builders"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "chap_timestamp": 6,
        "chap_text": "Will Landau's crew package"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "chap_timestamp": 9,
        "chap_text": "Appsilon's Data4Good dashboard"
      },
      {
        "ep_name": "issue_2023_w_26_highlights",
        "chap_timestamp": 31,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_25_highlights",
        "ep_date": "2023-06-21",
        "ep_duration": 10,
        "ep_description_short": "Uncovering powerful use cases of the slice() function in the tidyverse, a batch of new features and fixes for column labeling in gt 0.9.0, and a fun journey with tidymodels and visualizations on just how much the Reverend Thomas Bayes may have earned from his own home (probably). Episode Links This week's curator: Jon Carroll - @carroll_jono…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_25_highlights",
        "description_long": "\r \r\n\nUncovering powerful use cases of the slice() function in the tidyverse, a batch of new features and fixes for column labeling in gt 0.9.0, and a fun journey with tidymodels and visualizations on just how much the Reverend Thomas Bayes may have earned from his own home (probably).\n\nEpisode Links\n\nThis week's curator: Jon Carroll - @carroll_jono (Twitter) & @[email protected] (Mastodon)\nRow relational operations with slice()\nMerging columns together and fixing up column labels in {gt} 0.9.0\nBayes Lived Here (Probably)\nEntire issue available at rweekly.org/2023-W25\n\nSupplement Resources\n\nArgument-type data masking: https://rlang.r-lib.org/reference/args_data_masking.html\n{usedthese} Summarize package and function usage https://www.quantumjitter.com/blog/usedthese/\nEasy and secure database access with a custom R6 package https://reds-code-collection.netlify.app/posts/r_db_connector/\nBuilding Reproducible Analytical Pipelines with R now available in print! https://www.amazon.com/dp/B0C87H6MGF/\nMy computer can read! https://blog.devgenius.io/my-computer-can-read-98bc339e1f66\nNew maintainer of {echarts4r}\n{carlesswhisper} Automatic speech recognition in R with whisper.cpp https://github.com/coolbutuseless/carelesswhisper\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://fosstodon.org/@jonocarroll"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://yjunechoe.github.io/posts/2023-06-11-row-relational-operations/"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://posit.co/blog/columns-in-gt-0-9-0/"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://www.quantumjitter.com/project/bayes/"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://rweekly.org/2023-W25.html"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://rlang.r-lib.org/reference/args_data_masking.html"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://www.quantumjitter.com/blog/usedthese/"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://reds-code-collection.netlify.app/posts/r_db_connector/"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://www.amazon.com/dp/B0C87H6MGF/"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://blog.devgenius.io/my-computer-can-read-98bc339e1f66"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://echarts4r.john-coene.com/"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://github.com/coolbutuseless/carelesswhisper"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_25_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "chap_timestamp": 3,
        "chap_text": "slice() use cases"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "chap_timestamp": 1,
        "chap_text": "gt 0.9.0"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "chap_timestamp": 58,
        "chap_text": "Bayes lived here"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "chap_timestamp": 20,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_25_highlights",
        "chap_timestamp": 45,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_24_highlights",
        "ep_date": "2023-06-14",
        "ep_duration": 22,
        "ep_description_short": "A batch of useful patterns for your next R project, the highly-anticipated dashboard components of {bslib} have arrived, and creating circle-based charts with customization using {ggtricks}. Episode Links This week's curator: Tony Elhabr - @TonyElHabr (https://twitter.com/TonyElHabr) (Twitter) & @[email protected]…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_24_highlights",
        "description_long": "\r \r\n\nA batch of useful patterns for your next R project, the highly-anticipated dashboard components of {bslib} have arrived, and creating circle-based charts with customization using {ggtricks}.\n\nEpisode Links\n\nThis week's curator: Tony Elhabr - @TonyElHabr (Twitter) & @[email protected] (Mastodon)\nThree useful (to me) R patterns\nTowards easy, delightful, and customizable dashboards in Shiny for R with {bslib}\nEasily create sector (pie, donut) and series of circle charts using Cartesian coordinates and ggplot2 with the new #RStats icon {ggtricks}\nEntire issue available at rweekly.org/2023-W24\n\nSupplement Resources\n\nBuilding custom bootstrap cards Shinyconf tutorial: https://www.youtube.com/watch?v=KFbDd87bIso\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://mastodon.skrimmage.com/@tonyelhabr"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://masalmon.eu/2023/06/06/basic-patterns/"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://shiny.posit.co/blog/posts/bslib-dashboards/"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://www.abdoulblog.com/posts/2023-05-31_ggtricks-intro/"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://rweekly.org/2023-W24.html"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://www.youtube.com/watch?v=KFbDd87bIso"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_24_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "chap_timestamp": 9,
        "chap_text": "Useful R Patterns"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "chap_timestamp": 46,
        "chap_text": "bslib's new dashboard components"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "chap_timestamp": 34,
        "chap_text": "Circular viz with ggtricks"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "chap_timestamp": 0,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_24_highlights",
        "chap_timestamp": 19,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_23_highlights",
        "ep_date": "2023-06-06",
        "ep_duration": 53,
        "ep_description_short": "Another terrific illustration of open-source collaboration in the latest updates to gptstudio, and a comprehensive journey of web scraping in R to bring much-needed automation to a practical research problem. Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder)) (Twitter) On updating a chat assistant app for…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_23_highlights",
        "description_long": "\r \r\n\nAnother terrific illustration of open-source collaboration in the latest updates to gptstudio, and a comprehensive journey of web scraping in R to bring much-needed automation to a practical research problem.\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder) (Twitter)\nOn updating a chat assistant app for the RStudio IDE\nStatic and Dynamic Web Scraping with R\nEntire issue available at rweekly.org/2023-W23\n\nSupplement Resources\n\nGPT RStudio addins that enable GPT assisted coding, writing & analysis https://github.com/MichelNivard/gptstudio\nA Twitter and Mastodon bot posting random R packages on CRAN https://github.com/TimTeaFan/rstatspkgbot\nCRAN Task Views: The next generation\nHow to make fancy road trip maps with R and OpenStreetMap: Use R to get geocoded location and routing data from OpenStreetMap and explore a 5,000 mile road trip around the USA\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nSupport creators with boostagrams using Podverse and Alby: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://samuelenrique.com/posts/2023-06-02-updating-gptstudio/"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://tim-tiefenbach.de/post/2023-web-scraping/"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://rweekly.org/2023-W23.html"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://github.com/MichelNivard/gptstudio"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://github.com/TimTeaFan/rstatspkgbot"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://www.zeileis.org/news/ctv/"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://www.andrewheiss.com/blog/2023/06/01/geocoding-routing-openstreetmap-r/"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_23_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "chap_timestamp": 6,
        "chap_text": "gptstudio Shiny upgrades!"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "chap_timestamp": 45,
        "chap_text": "Static and dynamic web scraping"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "chap_timestamp": 5,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_23_highlights",
        "chap_timestamp": 45,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_22_highlights",
        "ep_date": "2023-06-01",
        "ep_duration": 38,
        "ep_description_short": "Another gem in the functional programming toolkit with partial functions, simplifying R package creation using fusen, and a creative visualization of worldwide parliament representation. Episode Links This week's curator: Ryo Nakagawara - @RbyRyo (https://twitter.com/R_by_Ryo)) (Twitter) & @[email protected] (https://mstdn.social/@R_by_Ryo)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_22_highlights",
        "description_long": "\r \r\n\nAnother gem in the functional programming toolkit with partial functions, simplifying R package creation using fusen, and a creative visualization of worldwide parliament representation.\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara - @R_by_Ryo) (Twitter) & @[email protected] (Mastodon)\nCurried functions in R - Examples with purrr and ggplot2\n{fusen}: Simplifying Writing Packages for R Users\nShowing women proportion of Parliamentarians on a map\nEntire issue available at rweekly.org/2023-W22\n\nSupplement Resources\n\nYEGRUG 2023-05 Recording (Futureverse) https://www.youtube.com/watch?v=6Dp6zMelrmg\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://mstdn.social/@R_by_Ryo"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://mikedecr.netlify.app/blog/partial_fns_ggplot/"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://www.r-consortium.org/blog/2023/05/23/fusen-simplifying-writing-packages-for-r-users"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "http://freerangestats.info/blog/2023/05/26/women-parl-map"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://rweekly.org/2023-W22.html"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://www.youtube.com/watch?v=6Dp6zMelrmg"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_22_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "chap_timestamp": 24,
        "chap_text": "Partials from purrr"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "chap_timestamp": 22,
        "chap_text": "spotlight on fusen"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "chap_timestamp": 14,
        "chap_text": "Parliament Proportions"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "chap_timestamp": 42,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_22_highlights",
        "chap_timestamp": 19,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_21_highlights",
        "ep_date": "2023-05-25",
        "ep_duration": 6,
        "ep_description_short": "A must-have resource to get you primed for testing R packages interfacing with the web, how ggblend taps into new compositing functionality for clearer plots, and how R stacks up with Excel in handling dates. Episode Links This week's curator: Batool Almarzouq - @batool664 (https://twitter.com/batool664) (Twitter) Better Understanding Your Tools…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_21_highlights",
        "description_long": "\r \r\n\nA must-have resource to get you primed for testing R packages interfacing with the web, how ggblend taps into new compositing functionality for clearer plots, and how R stacks up with Excel in handling dates.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq - @batool664 (Twitter)\nBetter Understanding Your Tools Choices with Online Book HTTP Testing in R\nggblend: Blending and compositing algebra for ggplot2\nWhy should I use R: Handling Dates in R and Excel: Part 3\nEntire issue available at rweekly.org/2023-W21\n\nSupplement Resources\n\nHTTP Testing with R: https://books.ropensci.org/http-testing/index.html\nUpdating Graphics Devices for R 4.2.0: https://blog.r-project.org/2021/12/14/updating-graphics-devices-for-r-4.2.0/\nggdist Visualizations of distribution and uncertainty: https://mjskay.github.io/ggdist/\nLearning Bayesian Statistics Episode 66 - Uncertainty Visualization & Usable Stats, with Matthew Kay https://learnbayesstats.com/episode/66-uncertainty-visualization-usable-stats-matthew-kay\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nR-Weekly Highlights on the Podcastindex.org - You can send a boost into the show directly in the Podcast Index. First, top-up with Alby, and then head over to the R-Weekly Highlights podcast entry on the index.\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://www.r-consortium.org/blog/2023/05/15/better-understanding-your-tools-choices-online-book-http-testing-r"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://github.com/mjskay/ggblend/"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://www.jumpingrivers.com/blog/date-r-excel-datetimes-transition/"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://rweekly.org/2023-W21.html"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://books.ropensci.org/http-testing/index.html"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://blog.r-project.org/2021/12/14/updating-graphics-devices-for-r-4.2.0/"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://mjskay.github.io/ggdist/"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://learnbayesstats.com/episode/66-uncertainty-visualization-usable-stats-matthew-kay"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://getalby.com/"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_21_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "chap_timestamp": 16,
        "chap_text": "http testing with R"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "chap_timestamp": 25,
        "chap_text": "ggblend"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "chap_timestamp": 48,
        "chap_text": "Dates in R and Excel"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "chap_timestamp": 6,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_21_highlights",
        "chap_timestamp": 14,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_20_highlights",
        "ep_date": "2023-05-17",
        "ep_duration": 4,
        "ep_description_short": "Introducing the new ggflowchart package, how a dockerized development environment is another win for reproducibility, and our take on Colin Fay's keynote from the Appsilon Shiny Conference. Episode Links This week's curator: Sam Parmar - @parmsam_ (https://twitter.com/parmsam_) (Twitter) & @[email protected] (https://fosstodon.org/@parmsam)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_20_highlights",
        "description_long": "\r \r\n\nIntroducing the new ggflowchart package, how a dockerized development environment is another win for reproducibility, and our take on Colin Fay's keynote from the Appsilon Shiny Conference.\n\nEpisode Links\n\nThis week's curator: Sam Parmar - @parmsam_ (Twitter) & @[email protected] (Mastodon)\nIntroducing {ggflowchart}\nWhy you should consider working on a dockerized development environment\nColin Fay, Keynote: Production is like ultra running: brutal, ungrateful, but worth every step\nEntire issue available at rweekly.org/2023-W20\n\nSupplement Resources\n\nEpisode 82 (the origins of ggflowchart) https://rweekly.fireside.fm/82\nBuilding reproducible analytical pipelines with R https://raps-with-r.dev\nThe Rocker Project https://rocker-project.org\nShiny Dev Series Livestream: Fully containerized R dev environment with Docker, RStudio, and VS-Code https://www.youtube.com/watch?v=4wRiPG9LM3o\nDevelopment Container Features https://code.visualstudio.com/blogs/2022/09/15/dev-container-features\nr2u: CRAN as Ubuntu binaries https://eddelbuettel.github.io/r2u/\nA preview of Eric and Mike's Production Shiny Workshop https://www.youtube.com/watch?v=MlRwhDYI5Ec\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nSupport creators with boostagrams using Podverse and Alby: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://twitter.com/parmsam_"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://fosstodon.org/@parmsam"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://nrennie.rbind.io/blog/introducing-ggflowchart/"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://www.brodrigues.co/blog/2023-05-08-dock_dev_env/"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://www.youtube.com/watch?v=wMbhxTJNrmw"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://rweekly.org/2023-W20.html"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://rweekly.fireside.fm/82"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://raps-with-r.dev"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://rocker-project.org"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://www.youtube.com/watch?v=4wRiPG9LM3o"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://code.visualstudio.com/blogs/2022/09/15/dev-container-features"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://eddelbuettel.github.io/r2u/"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://www.youtube.com/watch?v=MlRwhDYI5Ec"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_20_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "chap_timestamp": 11,
        "chap_text": "Introducing ggflowchart"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "chap_timestamp": 53,
        "chap_text": "Dockerized Development"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "chap_timestamp": 24,
        "chap_text": "Running with Shiny in Production"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "chap_timestamp": 48,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_20_highlights",
        "chap_timestamp": 11,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_18_highlights",
        "ep_date": "2023-05-03",
        "ep_duration": 40,
        "ep_description_short": "Why effective code reviews can bring many benefits to data science teams, the origin story of the sketch package to transpile R code to JavaScript, and a primer on error handling in both R and Python. Episode Links This week's curator: Colin Fay - @_ColinFay (https://twitter.com/_ColinFay) (Twitter) Pull Requests, Code Review, and The Art of…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_18_highlights",
        "description_long": "\r \r\n\nWhy effective code reviews can bring many benefits to data science teams, the origin story of the sketch package to transpile R code to JavaScript, and a primer on error handling in both R and Python.\n\nEpisode Links\n\nThis week's curator: Colin Fay - @_ColinFay (Twitter)\nPull Requests, Code Review, and The Art of Requesting Changes\nSketch Package looks to add JavaScript to R packages\nError Handling in R and Python\nEntire issue available at rweekly.org/2023-W18\n\nSupplement Resources\n\nWhat they forgot to teach you about R https://rstats.wtf\nSketch - Interactive sketches in R https://github.com/kcf-jackson/sketch\n{purrr} safely https://purrr.tidyverse.org/reference/safely.html\nquickemu - Quickly create and run optimised Windows, macOS and Linux desktop virtual machines https://github.com/quickemu-project/quickemu\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nSupport creators with boostagrams using Podverse and Alby: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://twitter.com/_ColinFay"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://matthewrkaye.com/posts/series/doing-data-science/2023-04-14-code-review/code-review.html"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://www.r-consortium.org/blog/2023/04/26/sketch-package-looks-to-add-javascript-to-r-packages"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://towardsdatascience.com/error-handling-in-r-and-python-5a4d60f3fba6"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://rweekly.org/2023-W18.html"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://rstats.wtf"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://github.com/kcf-jackson/sketch"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://purrr.tidyverse.org/reference/safely.html"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://github.com/quickemu-project/quickemu"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_18_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "chap_timestamp": 9,
        "chap_text": "Code Reviews"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "chap_timestamp": 12,
        "chap_text": "The origins of Sketch"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "chap_timestamp": 7,
        "chap_text": "Error Handling"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "chap_timestamp": 17,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_18_highlights",
        "chap_timestamp": 51,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_17_highlights",
        "ep_date": "2023-04-26",
        "ep_duration": 34,
        "ep_description_short": "A few strict checks offered in R 4.3.0, measuring and writing performant code in the Tidyverse, and a please for indenting your code with (more) spaces. Episode Links This week's curator: Eric Nantz - @theRcast (https://twitter.com/theRcast) (Twitter) & @[email protected] (https://podcastindex.social/@rpodcast) (Mastodon) What's new in R…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_17_highlights",
        "description_long": "\r \r\n\nA few strict checks offered in R 4.3.0, measuring and writing performant code in the Tidyverse, and a please for indenting your code with (more) spaces.\n\nEpisode Links\n\nThis week's curator: Eric Nantz - @theRcast (Twitter) & @[email protected] (Mastodon)\nWhat's new in R 4.3.0?\nWriting performant code with tidy tools\nOn Indentation in R\nEntire issue available at rweekly.org/2023-W17\n\nSupplement Resources\n\nChanges in R 4.3.0: https://stat.ethz.ch/R-manual/R-devel/doc/html/NEWS.html\nA Question A Day Twitter account https://twitter.com/data_question\nAdvanced R- Measure Performance https://adv-r.hadley.nz/perf-measure.html\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nFind R-Weekly Highlights on the Podcast Index https://podcastindex.org/podcast/1062040\nGet a New Podcast App and send us a boost directly! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nSupport creators with boostagrams using Podverse and Alby: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://www.jumpingrivers.com/blog/whats-new-r43/"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://www.tidyverse.org/blog/2023/04/performant-packages/"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://www.hiddenelephants.co.uk/Blog/on-indentation-in-R.html"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://rweekly.org/2023-W17.html"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://stat.ethz.ch/R-manual/R-devel/doc/html/NEWS.html"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://twitter.com/data_question"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://adv-r.hadley.nz/perf-measure.html"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://podcastindex.org/podcast/1062040"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_17_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "chap_timestamp": 43,
        "chap_text": "Strictly R 4.3.0"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "chap_timestamp": 34,
        "chap_text": "Performant Tidy Code"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "chap_timestamp": 12,
        "chap_text": "Indenting Code"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "chap_timestamp": 21,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_17_highlights",
        "chap_timestamp": 35,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_16_highlights",
        "ep_date": "2023-04-19",
        "ep_duration": 25,
        "ep_description_short": "Using development containers to bootstrap a reproducible R and Quarto environment, a comprehensive approach to extending the data frame class, and plotting your own universe of labels with ggsolar. Episode Links This week's curator: Jon Carroll - @carroll_jono (https://twitter.com/carroll_jono) (Twitter) & @[email protected]…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_16_highlights",
        "description_long": "\r \r\n\nUsing development containers to bootstrap a reproducible R and Quarto environment, a comprehensive approach to extending the data frame class, and plotting your own universe of labels with ggsolar.\n\nEpisode Links\n\nThis week's curator: Jon Carroll - @carroll_jono (Twitter) & @[email protected] (Mastodon)\nDev containers with R and Quarto\nExtending Data Frames\nMake “Solar System” Plots With {ggsolar}\nEntire issue available at rweekly.org/2023-W16\n\nSupplement Resources\n\nR in Visual Studio Code: https://code.visualstudio.com/docs/languages/r\nRemote Development Extension Pack https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack\nPodman - Configure VS Code for Containers https://blog.while-true-do.io/podman-configure-vscode-for-containers/\nFrom disconnected elements to a harmonious ecosystem: The Epiverse-TRACE project https://epiverse-trace.github.io/slides/harmonious-ecosystem/\nExtendDataFrames https://github.com/joshwlambert/ExtendDataFrames\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nSupport creators with boostagrams using Podverse and Alby: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://fosstodon.org/@jonocarroll"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://jamesgoldie.dev/writing/dev-containers-in-r/"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://epiverse-trace.github.io/posts/extend-dataframes/index.html"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://rud.is/b/2023/04/12/make-solar-system-plots-with-ggsolar/"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://rweekly.org/2023-W16.html"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://code.visualstudio.com/docs/languages/r"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://blog.while-true-do.io/podman-configure-vscode-for-containers/"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://epiverse-trace.github.io/slides/harmonious-ecosystem/"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://github.com/joshwlambert/ExtendDataFrames"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_16_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "chap_timestamp": 3,
        "chap_text": "Introduction"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "chap_timestamp": 30,
        "chap_text": "R Development Containers"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "chap_timestamp": 38,
        "chap_text": "Extending data frames"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "chap_timestamp": 29,
        "chap_text": "ggsolar"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "chap_timestamp": 22,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_16_highlights",
        "chap_timestamp": 39,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_15_highlights",
        "ep_date": "2023-04-12",
        "ep_duration": 2,
        "ep_description_short": "A data-driven look at package loading annotations in R scripts, a fit-for-purpose package that makes a large contribution to the global R ecosystem, and a collection of amazing showcases of webR in action that is paving the way for continued innovation. Episode Links This week's curator: Tony Elhabr - @TonyElHabr (https://twitter.com/TonyElHabr)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_15_highlights",
        "description_long": "\r \r\n\nA data-driven look at package loading annotations in R scripts, a fit-for-purpose package that makes a large contribution to the global R ecosystem, and a collection of amazing showcases of webR in action that is paving the way for continued innovation.\n\nEpisode Links\n\nThis week's curator: Tony Elhabr - @TonyElHabr (Twitter) & @[email protected] (Mastodon)\nWhat are people commenting about their loaded packages?\nIntroducing rtlr - an R Package for RTL Languages\nhrbrmstr's WebR Experiments Index\nEntire issue available at rweekly.org/2023-W15\n\nSupplement Resources\n\nannotater: Annotate Package Load Calls https://github.com/luisDVA/annotater\ncld3: R wrapper to Google's Compact Language Detector 3 https://docs.ropensci.org/cld3/\nshiny.i18n: Shiny applications internationalization made easy https://appsilon.github.io/shiny.i18n/\nJavaScript for R https://book.javascript-for-r.com/\nOutstanding User Interfaces with Shiny https://unleash-shiny.rinterface.com/\nJavaScript for Data Science https://www.amazon.com/JavaScript-Data-Science-Chapman-Hall-ebook/dp/B084H2JXSY\nA Way Better Structured WebR Demo App https://rud.is/b/2023/03/12/almost-bare-bones-webr-starter-app/\nAn example of using WebR with Lit components https://rud.is/w/lit-webr/\nWebR & Pyodide: Another WebR Experiment https://rud.is/w/webr-pyodide/\nAn R template/tag function for WebR https://rud.is/w/r-template-tag-function/\nMonaco-powered WebR \"REPL\" https://rud.is/w/repl\nhttps://observablehq.com/@hrbrmstr/fiddling-with-r-universe-webr\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nSupport creators with boostagrams using Podverse and Alby: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://mastodon.skrimmage.com/@tonyelhabr"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://luisdva.github.io/rstats/package-comments/"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://matanhakim.org/posts/2023-04-05-rtlr-0-1-0/"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://rud.is/webr-experiments/"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://rweekly.org/2023-W15.html"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://github.com/luisDVA/annotater"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://docs.ropensci.org/cld3/"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://appsilon.github.io/shiny.i18n/"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://book.javascript-for-r.com/"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://unleash-shiny.rinterface.com/"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://www.amazon.com/JavaScript-Data-Science-Chapman-Hall-ebook/dp/B084H2JXSY"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://rud.is/b/2023/03/12/almost-bare-bones-webr-starter-app/"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://rud.is/w/lit-webr/"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://rud.is/w/webr-pyodide/"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://rud.is/w/r-template-tag-function/"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://rud.is/w/repl"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://observablehq.com/@hrbrmstr/fiddling-with-r-universe-webr"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_15_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "chap_timestamp": 11,
        "chap_text": "Commentary on Loading Packages"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "chap_timestamp": 30,
        "chap_text": "rtl Package"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "chap_timestamp": 6,
        "chap_text": "WebR Experiments"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "chap_timestamp": 59,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_15_highlights",
        "chap_timestamp": 56,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_14_highlights",
        "ep_date": "2023-04-07",
        "ep_duration": 37,
        "ep_description_short": "Ten unique ways to create your own Web APIs in R, and how you can import local and remote data files in CSV and (yes) Excel formats with a selection of innovative R packages. Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder)) (Twitter) Hello world examples with 10 different R web API frameworks…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_14_highlights",
        "description_long": "\r \r\n\nTen unique ways to create your own Web APIs in R, and how you can import local and remote data files in CSV and (yes) Excel formats with a selection of innovative R packages.\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder) (Twitter)\nHello world examples with 10 different R web API frameworks\nReading Remote Data Files\nEntire issue available at rweekly.org/2023-W14\n\nSupplement Resources\n\nSeeking community endorsement for an upgrade to 'Big Book of R'\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nSupport creators with boostagrams using Podverse and Alby: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://gist.github.com/psolymos/284b43b8dd0583b33ca7fc7dcf71082b"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://kieranhealy.org/blog/archives/2023/03/25/reading-remote-data-files/"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://rweekly.org/2023-W14.html"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://oscarbaruffa.com/bigbookofrupgrade/"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_14_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "chap_timestamp": 30,
        "chap_text": "Ten Flavors of web APIs in R"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "chap_timestamp": 34,
        "chap_text": "Reading Remote Data Files"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "chap_timestamp": 28,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_14_highlights",
        "chap_timestamp": 50,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_13_highlights",
        "ep_date": "2023-03-29",
        "ep_duration": 31,
        "ep_description_short": "A new perspective on the value of base R functions, enhancing the capabilities of gpttools with vector databases, and three ways you can add alt text to your R-based visualizations. Episode Links This week's curator: Ryo Nakagawara - @RbyRyo (https://twitter.com/R_by_Ryo) (Twitter) & @[email protected] (https://mstdn.social/@R_by_Ryo)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_13_highlights",
        "description_long": "\r \r\n\nA new perspective on the value of base R functions, enhancing the capabilities of gpttools with vector databases, and three ways you can add alt text to your R-based visualizations.\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara - @R_by_Ryo (Twitter) & @[email protected] (Mastodon)\nSome love for Base R. Part 1\nTeaching ChatGPT What It Doesn’t Know\nAlt Text in R: Plots, Reports, and Shiny\nEntire issue available at rweekly.org/2023-W13\n\nSupplement Resources\n\nA Gentle Introduction to Vector Databases https://frankzliu.com/blog/a-gentle-introduction-to-vector-databases\nText Mining with R - A Tidy Approach https://www.tidytextmining.com\nWriting Meaningful Alt Texts for Data Visualizations in R (Liz Hare) R Ladies NYC https://lizharedogs.github.io/RLadiesNYAltText\n{ggdatasaver} Automatically save data associated with a ggplot2 plot https://eliocamp.github.io/ggdatasaver\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nSupport creators with boostagrams using Podverse and Alby: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://mstdn.social/@R_by_Ryo"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://luis.apiolaza.net/2023/03/18/some-love-for-base-r-part-1/"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://jameshwade.com/posts/2023-03-10_vectorstores.html"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://www.jumpingrivers.com/blog/accessibility-alt-text-in-r/"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://rweekly.org/2023-W13.html"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://frankzliu.com/blog/a-gentle-introduction-to-vector-databases"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://www.tidytextmining.com"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://lizharedogs.github.io/RLadiesNYAltText"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://eliocamp.github.io/ggdatasaver"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_13_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "chap_timestamp": 20,
        "chap_text": "New Perspective on Base R"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "chap_timestamp": 1,
        "chap_text": "Adding context to gpttools"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "chap_timestamp": 41,
        "chap_text": "Alt text for visualization"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "chap_timestamp": 3,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_13_highlights",
        "chap_timestamp": 30,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_11_highlights",
        "ep_date": "2023-03-15",
        "ep_duration": 45,
        "ep_description_short": "The future of running R in your web browser is here with webR 0.1, a demonstration of integrating Quarto and webR with immense potential in the space of reproducible analysis, and two fundamental techniques from the world of software development tailored to non-programmers. Episode Links This week's curator: Sam Parmar - @parmsam_…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_11_highlights",
        "description_long": "\r \r\n\nThe future of running R in your web browser is here with webR 0.1, a demonstration of integrating Quarto and webR with immense potential in the space of reproducible analysis, and two fundamental techniques from the world of software development tailored to non-programmers.\n\nEpisode Links\n\nThis week's curator: Sam Parmar - @parmsam_ (Twitter) & @[email protected] (Mastodon)\nwebR 0.1.0 has been released\nwebR with Quarto HTML Standalone Document Proof of Concept\nSoftware engineering techniques that non-programmers who write a lot of code can benefit from — the DRY WIT approach\nEntire issue available at rweekly.org/2023-W11\n\nSupplement Resources\n\nAlmost Bare Bones WebR Starter App: https://rud.is/b/2023/03/12/almost-bare-bones-webr-starter-app/\nwebR Dashboard: https://rud.is/webr-dash/no-dplyr.html\nwebR Quarto demos: https://github.com/coatless-r-n-d/webR-quarto-demos\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nSupport creators with boostagrams using Podverse and Alby: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://twitter.com/parmsam_"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://fosstodon.org/@parmsam"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://www.tidyverse.org/blog/2023/03/webr-0-1-0/"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://rd.thecoatlessprofessor.com/webR-quarto-demos/webr-quarto-html-demo.html"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://www.brodrigues.co/blog/2023-03-07-dry_wit/"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://rweekly.org/2023-W11.html"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://rud.is/b/2023/03/12/almost-bare-bones-webr-starter-app/"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://rud.is/webr-dash/no-dplyr.html"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://github.com/coatless-r-n-d/webR-quarto-demos"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_11_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "chap_timestamp": 13,
        "chap_text": "webR arrives!"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "chap_timestamp": 47,
        "chap_text": "Quarto powered by webR"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "chap_timestamp": 59,
        "chap_text": "The DRY & WIT approach"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "chap_timestamp": 41,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_11_highlights",
        "chap_timestamp": 33,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_10_highlights",
        "ep_date": "2023-03-11",
        "ep_duration": 43,
        "ep_description_short": "A episode full of discovery in this week's edition of R-Weekly Highlights! How you can parse your own R code with parse and getParseData, a closer look at the search capabilities in R-Universe, and a look back at the key milestones in the history of the R language. Episode Links This week's curators: Kellly Bodwin - @KellyBodwin…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_10_highlights",
        "description_long": "\r \r\n\nA episode full of discovery in this week's edition of R-Weekly Highlights! How you can parse your own R code with parse and getParseData, a closer look at the search capabilities in R-Universe, and a look back at the key milestones in the history of the R language.\n\nEpisode Links\n\nThis week's curators: Kellly Bodwin - @KellyBodwin (Twitter) and Emily Robinson - @robinson_es (Twitter)\n\"I can't be parsed, mate!\" Parsing in R\nSearch for packages in r-universe\nHappy 23rd birthday, R!\nEntire issue available at rweekly.org/2023-W10\n\nSupplement Resources\n\nAdvanced R chapter 17 (Metaprogramming the big picture): https://adv-r.hadley.nz/meta-big-picture.html\nAlgorithm behind package rank calculation in R-Universe: https://github.com/r-universe-org/help#how-is-the-package-rank-score-calculated\nJeroen's RStudio Global 2021 presentation (Monitoring Health and Impact of Open-source Projects) https://www.youtube.com/watch?v=kaoe7xuIJ1U\nBuilding reproducible analytical pipelines with R https://raps-with-r.dev\n3 Years In: Reflections on Starting, Surviving, and Scaling a Data Science Consultancy https://www.linkedin.com/pulse/3-years-reflections-starting-surviving-scaling-data-science-thomas\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nSupport creators with boostagrams using Podverse and Alby: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://twitter.com/KellyBodwin"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://twitter.com/robinson_es"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://www.rostrum.blog/2023/03/03/getparsedata/"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://ropensci.org/blog/2023/02/27/runiverse-discovering/"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://www.r-consortium.org/blog/2023/02/28/happy-23rd-birthday-r"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://rweekly.org/2023-W10.html"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://adv-r.hadley.nz/meta-big-picture.html"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://github.com/r-universe-org/help#how-is-the-package-rank-score-calculated"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://www.youtube.com/watch?v=kaoe7xuIJ1U"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://raps-with-r.dev"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://www.linkedin.com/pulse/3-years-reflections-starting-surviving-scaling-data-science-thomas"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_10_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "chap_timestamp": 35,
        "chap_text": "Go Parse Your (R Code)"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "chap_timestamp": 36,
        "chap_text": "Searching with R-Universe"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "chap_timestamp": 39,
        "chap_text": "Happy Birthday, R!"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "chap_timestamp": 51,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_10_highlights",
        "chap_timestamp": 9,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_09_highlights",
        "ep_date": "2023-03-01",
        "ep_duration": 11,
        "ep_description_short": "How to easily create interactive versions of your favorite ggplots with ggiraph, bringing AutoML to R with forester, and a head-to-head comparison of R and Excel for common data wrangling and summaries. Episode Links This week's curator: Colin Fay - [@ColinFay]](https://twitter.com/ColinFay) (Twitter) Creating interactive visualizations with…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_09_highlights",
        "description_long": "\r \r\n\nHow to easily create interactive versions of your favorite ggplots with ggiraph, bringing AutoML to R with forester, and a head-to-head comparison of R and Excel for common data wrangling and summaries.\n\nEpisode Links\n\nThis week's curator: Colin Fay - [@_ColinFay]](https://twitter.com/_ColinFay) (Twitter)\nCreating interactive visualizations with {ggiraph} (with or without Shiny)\nforester: what makes the package special?\nWhy should I use R: The Excel R Data Wrangling comparison: Part 1\nEntire issue available at rweekly.org/2023-W09\n\nSupplement Resources\n\nggiraph online book https://www.ardata.fr/ggiraph-book\n{openxlsx2} read, write, and modify xlsx files https://janmarvin.github.io/openxlsx2\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://twitter.com/_ColinFay"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://albert-rapp.de/posts/ggplot2-tips/17_ggiraph/17_ggiraph.html"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://medium.com/responsibleml/forester-what-makes-the-package-special-9ece9b8a64d"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://www.jumpingrivers.com/blog/why-r-part-1/"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://rweekly.org/2023-W09.html"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://www.ardata.fr/ggiraph-book"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://janmarvin.github.io/openxlsx2"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://podcastindex.org/apps"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_09_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "chap_timestamp": 13,
        "chap_text": "Interactive viz with ggiraph"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "chap_timestamp": 31,
        "chap_text": "forester for autoML"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "chap_timestamp": 3,
        "chap_text": "R and Excel Comparisons"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "chap_timestamp": 0,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_09_highlights",
        "chap_timestamp": 38,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_08_highlights",
        "ep_date": "2023-02-22",
        "ep_duration": 50,
        "ep_description_short": "The current state and future of {rtweet}, bringing the best of testing and CI/CD in a statistical package, and navigating through a Shiny maze (literally). Episode Links This week's curator: Eric Nantz - @theRcast (https://twitter.com/theRcast) (Twitter) & @[email protected] (https://podcastindex.social/@rpodcast) (Mastodon) rtweet…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_08_highlights",
        "description_long": "\r \r\n\nThe current state and future of {rtweet}, bringing the best of testing and CI/CD in a statistical package, and navigating through a Shiny maze (literally).\n\nEpisode Links\n\nThis week's curator: Eric Nantz - @theRcast (Twitter) & @[email protected] (Mastodon)\nrtweet future\nEnsuring & Showcasing the Statistical Correctness of your R Package\nShiny Monster Maze\nEntire issue available at rweekly.org/2023-W08\n\nSupplement Resources\n\nLluis Revilla's call for a co-maintainer of {rtweet} https://github.com/ropensci/rtweet/issues/763\nDenis Pushkarev's post on the current state of core-js: https://github.com/zloirock/core-js/blob/master/docs/2023-02-14-so-whats-next.md\n{mmrm} Mixed models for repeated measures in R: https://openpharma.github.io/mmrm/latest-tag/\nShiny Monster Maze blog post: https://www.bitfoam.com/post/2023-01-24-shiny-monster-maze/\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nSupport creators with boostagrams using Podverse and Alby: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://llrs.dev/post/2023/02/16/rtweet-future/"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://epiverse-trace.github.io/posts/statistical-correctness/index.html"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://www.bitfoam.com/post/2023-01-24-shiny-monster-maze/"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://rweekly.org/2023-W08.html"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://github.com/ropensci/rtweet/issues/763"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://github.com/zloirock/core-js/blob/master/docs/2023-02-14-so-whats-next.md"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://openpharma.github.io/mmrm/latest-tag/"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://www.bitfoam.com/post/2023-01-24-shiny-monster-maze/"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_08_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "chap_timestamp": 31,
        "chap_text": "State of {rtweet}"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "chap_timestamp": 58,
        "chap_text": "Statistical Correctness"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "chap_timestamp": 27,
        "chap_text": "Shiny Monster Maze"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "chap_timestamp": 2,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_08_highlights",
        "chap_timestamp": 56,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_07_highlights",
        "ep_date": "2023-02-15",
        "ep_duration": 29,
        "ep_description_short": "A glimpse into the day-to-day of maintaining an R package, exploring gender effects in art history data with the power of resampling, and a huge win for accessible SVG plots with R-Markdown. Episode Links This week's curator: Jon Carroll - @carroll_jono (https://twitter.com/carroll_jono) (Twitter) & @[email protected]…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_07_highlights",
        "description_long": "\r \r\n\nA glimpse into the day-to-day of maintaining an R package, exploring gender effects in art history data with the power of resampling, and a huge win for accessible SVG plots with R-Markdown.\n\nEpisode Links\n\nThis week's curator: Jon Carroll - @carroll_jono (Twitter) & @[email protected] (Mastodon)\nWhat Does It Mean to Maintain a Package?\nResampling to understand gender in #TidyTuesday art history data\nManipulate SVG Plots with JavaScript in R Markdown\nEntire issue available at rweekly.org/2023-W07\n\nSupplement Resources\n\nBootstrap resampling and tidy regression models https://www.tidymodels.org/learn/statistics/bootstrap/\nAccessible Data Science Beyond Visual Models: Non-Visual Interactions with R and RStudio Packages (JooYoung Seo from rstudio::global(2021)) https://www.rstudio.com/resources/rstudioglobal-2021/accessible-data-science-beyond-visual-models-non-visual-interactions-with-r-and-rstudio-packages\nEric's adventures with Shiny modules and SVG interactions https://community.rstudio.com/t/passing-module-namespace-to-embedded-javascript-function/26988\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nSupport creators with boostagrams using Podverse and Alby: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://fosstodon.org/@jonocarroll"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://ropensci.org/blog/2023/02/07/what-does-it-mean-to-maintain-a-package/"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://juliasilge.com/blog/art-history/"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://yihui.org/en/2023/02/manipulate-svg/"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://rweekly.org/2023-W07.html"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://www.tidymodels.org/learn/statistics/bootstrap/"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://www.rstudio.com/resources/rstudioglobal-2021/accessible-data-science-beyond-visual-models-non-visual-interactions-with-r-and-rstudio-packages"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://community.rstudio.com/t/passing-module-namespace-to-embedded-javascript-function/26988"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_07_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "chap_timestamp": 38,
        "chap_text": "Maintaining an R Package"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "chap_timestamp": 33,
        "chap_text": "Resampling with Art History Data"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "chap_timestamp": 13,
        "chap_text": "Manipulating SVG Plots in R Markdown"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "chap_timestamp": 16,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_07_highlights",
        "chap_timestamp": 37,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_06_highlights",
        "ep_date": "2023-02-08",
        "ep_duration": 57,
        "ep_description_short": "Just how far back can we turn back time with an R installation, many enhancements to joining data sets in dplyr 1.1.0, and a retrospective on the 2022 thirty-day map challenge. Episode Links This week's curator: Tony Elhabr - @TonyElHabr (https://twitter.com/TonyElHabr) (Twitter) & @[email protected]…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_06_highlights",
        "description_long": "\r \r\n\nJust how far back can we turn back time with an R installation, many enhancements to joining data sets in dplyr 1.1.0, and a retrospective on the 2022 thirty-day map challenge.\n\nEpisode Links\n\nThis week's curator: Tony Elhabr - @TonyElHabr (Twitter) & @[email protected] (Mastodon)\nPostmortem of my #30DayMapChallenge 2022\nThe oldest R version one can still run today\ndplyr 1.1.0: Joins\nEntire issue available at rweekly.org/2023-W06\n\nSupplement Resources\n\nReplicating \"Zoom to selected features\" function in ArcGIS / QGIS with R shiny https://khwongk12.medium.com/replicating-zoom-to-selected-features-function-in-arcgis-qgis-with-r-shiny-652b6c714e6f\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nGuide to sending boostagrams in Podverse: https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://mastodon.skrimmage.com/@tonyelhabr"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://urbandatapalette.com/post/2023-01-map-challenge-2022/"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://chainsawriot.com/postmannheim/2023/01/30/oldestr.html"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://www.tidyverse.org/blog/2023/01/dplyr-1-1-0-joins/"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://rweekly.org/2023-W06.html"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://khwongk12.medium.com/replicating-zoom-to-selected-features-function-in-arcgis-qgis-with-r-shiny-652b6c714e6f"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://blog.podverse.fm/support-creators-with-boostagrams-and-streaming-sats-using-podverse-and-alby/"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_06_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "chap_timestamp": 10,
        "chap_text": "Historic R versions in containers"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "chap_timestamp": 43,
        "chap_text": "dplyr 1.1.0 Joins"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "chap_timestamp": 11,
        "chap_text": "Map Challenge Retrospective"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "chap_timestamp": 52,
        "chap_text": "Additional finds"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "chap_timestamp": 16,
        "chap_text": "Eric's calendar journey"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "chap_timestamp": 34,
        "chap_text": "Thank you, Maelle!"
      },
      {
        "ep_name": "issue_2023_w_06_highlights",
        "chap_timestamp": 0,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_05_highlights",
        "ep_date": "2023-02-01",
        "ep_duration": 27,
        "ep_description_short": "How you can make R package testing a little easier with switches, how the combination of group processing and compute resources can level up geospatial data processing, and a few quick wins to improve the responsiveness of your Shiny apps that got your podcast hosts to think hard about previous design choices! Episode Links This week's curator: Jon…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_05_highlights",
        "description_long": "\r \r\n\nHow you can make R package testing a little easier with switches, how the combination of group processing and compute resources can level up geospatial data processing, and a few quick wins to improve the responsiveness of your Shiny apps that got your podcast hosts to think hard about previous design choices!\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder) (Twitter)\nA testing pattern: adding switches to your code\nGeospatial distributed processing with furrr\nImproving the responsiveness of Shiny applications\nEntire issue available at rweekly.org/2023-W05\n\nSupplement Resources\n\nPreventative Care for R Packages\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://blog.r-hub.io/2023/01/23/code-switch-escape-hatch-test/"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://posit.co/blog/geospatial-distributed-processing-with-furrr/"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://www.jumpingrivers.com/blog/improving-responsiveness-shiny-applications/"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://rweekly.org/2023-W05.html"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://indrajeetpatil.github.io/preventive-r-package-care/#/preventive-care-for-r-packages"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_05_highlights",
        "chap_timestamp": 0,
        "chap_text": "Episode Introduction"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "chap_timestamp": 25,
        "chap_text": "A Testing Pattern with Switches"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "chap_timestamp": 34,
        "chap_text": "Geospatial Distributed Processing"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "chap_timestamp": 30,
        "chap_text": "Responsiveness of Shiny Apps"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "chap_timestamp": 5,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_05_highlights",
        "chap_timestamp": 14,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_03_highlights",
        "ep_date": "2023-01-25",
        "ep_duration": 12,
        "ep_description_short": "A large helping of football data for your analytics with the englishfootball package, building a Shiny application with both R and python, and a first look at upcoming conferences this year. Episode Links This week's curator: Ryo Nakagawara - @RbyRyo (https://twitter.com/R_by_Ryo)) (Twitter) & @[email protected] (https://mstdn.social/@R_by_Ryo)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_03_highlights",
        "description_long": "\r \r\n\nA large helping of football data for your analytics with the englishfootball package, building a Shiny application with both R and python, and a first look at upcoming conferences this year.\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara - @R_by_Ryo) (Twitter) & @[email protected] (Mastodon)\nenglishfootball: A Comprehensive Database on the Premier League and the English Football League (1888-2022)\nSeeing double? Building the same app in Shiny for R and Shiny for Python\nSome R Conferences for 2023\nEntire issue available at rweekly.org/2023-W03\n\nSupplement Resources\n\n{worldcup} A Comprehensive Database on the FIFA World Cup https://github.com/jfjelstul/worldcup\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://mstdn.social/@R_by_Ryo"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://github.com/jfjelstul/englishfootball"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://nrennie.rbind.io/blog/seeing-double-shiny-python-r/"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://rviews.rstudio.com/2023/01/18/some-r-conferences-for-2023/"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://rweekly.org/2023-W04.html"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://github.com/jfjelstul/worldcup"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_03_highlights",
        "chap_timestamp": 0,
        "chap_text": "Episode Introduction"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "chap_timestamp": 19,
        "chap_text": "englishfootball package"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "chap_timestamp": 10,
        "chap_text": "Shiny with R and Python"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "chap_timestamp": 31,
        "chap_text": "Upcoming Conferences"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "chap_timestamp": 57,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_03_highlights",
        "chap_timestamp": 38,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_02_highlights",
        "ep_date": "2023-01-19",
        "ep_duration": 5,
        "ep_description_short": "A glimpse into the world of end-to-end Shiny app testing with shinytest2, and an important look at the spectrum of reproducibility within R using container technology and services. Episode Links This week's curator: Batool Almarzouq - @batool664 (https://twitter.com/batool664) (Twitter) End-to-end testing with shinytest2 Part 2…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_02_highlights",
        "description_long": "\r \r\n\nA glimpse into the world of end-to-end Shiny app testing with shinytest2, and an important look at the spectrum of reproducibility within R using container technology and services.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq - @batool664 (Twitter)\nEnd-to-end testing with shinytest2 Part 2\nMRAN is getting shutdown - what else is there for reproducibility with R, or why reproducibility is on a continuum?\nEntire issue available at rweekly.org/2023-W02\n\nSupplement Resources\n\n{leprechaun}: Code generator for lean and robust Shiny applications https://leprechaun.opifex.org\nBruno's excitement for our episode on Twitter and Mastodon\nLooking to the future for R in Azure SQL and SQL Server https://cloudblogs.microsoft.com/sqlserver/2021/06/30/looking-to-the-future-for-r-in-azure-sql-and-sql-server/\n{groundhog} Reproducible R Scripts Via Date Controlled Installing & Loading of CRAN & Git Packages https://groundhogr.com\nToward practical transparent verifiable and long-term reproducible research using Guix: https://www.nature.com/articles/s41597-022-01720-9#Abs1\n{scenes} demo app\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://www.jumpingrivers.com/blog/end-to-end-testing-shinytest2-part-2/"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://www.brodrigues.co/blog/2023-01-12-repro_r/"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://rweekly.org/2023-W02.html"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://leprechaun.opifex.org"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://twitter.com/brodriguesco/status/1615688889485897728"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://fosstodon.org/@brodriguesco/109710235621904734"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://cloudblogs.microsoft.com/sqlserver/2021/06/30/looking-to-the-future-for-r-in-azure-sql-and-sql-server/"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://groundhogr.com"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://www.nature.com/articles/s41597-022-01720-9#Abs1"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://r4dscommunity.shinyapps.io/scenes"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_02_highlights",
        "chap_timestamp": 0,
        "chap_text": "Introduction"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "chap_timestamp": 10,
        "chap_text": "App testing with shinytest2"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "chap_timestamp": 14,
        "chap_text": "The Reproducibility Continuum"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "chap_timestamp": 46,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "chap_timestamp": 21,
        "chap_text": "Listener feedback"
      },
      {
        "ep_name": "issue_2023_w_02_highlights",
        "chap_timestamp": 22,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2023_w_01_highlights",
        "ep_date": "2023-01-11",
        "ep_duration": 3,
        "ep_description_short": "A big progress updates in the latest {knitr} development release (literally), how the {litr} package enables literate programming development for R packages, and how you can translate Morse code directly in R with the {remorse} package! Episode Links This week's curator: Sam Parmar - @parmsam_ (https://twitter.com/parmsam_) (Twitter) &…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2023_w_01_highlights",
        "description_long": "\r \r\n\nA big progress updates in the latest {knitr} development release (literally), how the {litr} package enables literate programming development for R packages, and how you can translate Morse code directly in R with the {remorse} package!\n\nEpisode Links\n\nThis week's curator: Sam Parmar - @parmsam_ (Twitter) & @[email protected] (Mastodon)\nAn Upcoming Clean Progress Bar in knitr\nlitr: Write an R Package Entirely with an R Markdown Document\n.-././--/---/.-./.../.\nEntire issue available at rweekly.org/2023-W01\n\nSupplement Resources\n\nRethink the progress bar issue https://github.com/yihui/knitr/issues/1880\n{fusen}R packagehttps://thinkr-open.github.io/fusen\nTutorial\n{packagefinder} https://github.com/jsugarelli/packagefinder\nWhat is Morse code? https://web.northeastern.edu/stemout/morse-code\nOur very important message to the audience:\n\n-/./.-../.-.. -.--/---/..-/.-. ..-./.-./.././-./-../... .-/-.../---/..-/- -/..../. .-. .--/././-.-/.-../-.-- ..../../--./..../.-../../--./..../-/... .--./---/-../-.-./.-/.../-\n\nAudio version of message: https://archive.org/details/output_20230110\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?elements=Boostagrams%2CValue\nA new way to think about value: https://value4value.info\nGet in touch with us on social media\nEric Nantz: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike Thomas: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://twitter.com/parmsam_"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://fosstodon.org/@parmsam"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://yihui.org/en/2023/01/knitr-progress-bar/"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://yihui.org/en/2023/01/litr-package/"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://www.rostrum.blog/2023/01/06/remorse/"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://rweekly.org/2023-W01.html"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://github.com/yihui/knitr/issues/1880"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://thinkr-open.github.io/fusen"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://statnmap.github.io/teach-package-dev-rmdfirst//stagiaire_complet.html"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://github.com/jsugarelli/packagefinder"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://web.northeastern.edu/stemout/morse-code"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://archive.org/details/output_20230110"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://podcastindex.org/apps?elements=Boostagrams%2CValue"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2023_w_01_highlights",
        "chap_timestamp": 0,
        "chap_text": "Episode Introduction"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "chap_timestamp": 27,
        "chap_text": "{knitr} progress"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "chap_timestamp": 28,
        "chap_text": "{litr}"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "chap_timestamp": 49,
        "chap_text": "Morse code with {remorse}"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "chap_timestamp": 2,
        "chap_text": "Additional finds"
      },
      {
        "ep_name": "issue_2023_w_01_highlights",
        "chap_timestamp": 38,
        "chap_text": "Episode wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_52_highlights",
        "ep_date": "2023-01-06",
        "ep_duration": 32,
        "ep_description_short": "Our first episode of 2023 covers the brand-new gpttools package to called chatGPT directly in R, a wholistic look at MLOps with the latest tidymodels tooling, and a spotlight on the lesser-known quantile regression. Plus listener feedback and much more! Episode Links This week's curator: Kelly Bodwin (@KellyBodwin…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_52_highlights",
        "description_long": "\r \r\n\nOur first episode of 2023 covers the brand-new gpttools package to called chatGPT directly in R, a wholistic look at MLOps with the latest tidymodels tooling, and a spotlight on the lesser-known quantile regression. Plus listener feedback and much more!\n\nEpisode Links\n\nThis week's curator: Kelly Bodwin (@KellyBodwin)\n{gpttools} for Chat GPT in RStudio\nMLOps: The Whole Game\nQuantile Regression\nEntire issue available at rweekly.org/2022-W52\n\nSupplement Resources\n\nWhy Everyone's Obsessed With ChatGPT, a Mind-Blowing AI Chatbot https://www.cnet.com/tech/computing/why-everyones-obsessed-with-chatgpt-a-mind-blowing-ai-chatbot\nYury's quantile regression video: https://www.youtube.com/watch?v=Gtz8ca_4hVg\nWhat is R7? A New OOP System for R https://www.jumpingrivers.com/blog/r7-oop-object-oriented-programming-r\nR Weekly Highlights Episode 98 https://podverse.fm/episode/VvyuAA4kj\nShiny Dev Series episodes with Mike discussing the Connective COVID-19 Test Spotter App:\nPart 1: https://shinydevseries.com/interview/ep030\nPart 2: https://shinydevseries.com/interview/ep031\n\nSupporting the show\n\nUse the contact page at https://rweekly.fireside.fm/contact to send us your feedback\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?appTypes=app&elements=Value\nA new way to think about value: https://value4value.info\nGet in touch with us on social media:\nEric: @theRcast (Twitter) and @[email protected] (Mastodon)\nMike: @mike_ketchbrook (Twitter) and @[email protected] (Mastodon)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://twitter.com/KellyBodwin"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://jameshwade.github.io/gpttools/"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://jameshwade.com/posts/2022-12-27_mlops-the-whole-game.html"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://yuzar-blog.netlify.app/posts/2022-12-01-quantileregression/"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://rweekly.org/2022-W52.html"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://www.cnet.com/tech/computing/why-everyones-obsessed-with-chatgpt-a-mind-blowing-ai-chatbot"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://www.youtube.com/watch?v=Gtz8ca_4hVg"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://www.jumpingrivers.com/blog/r7-oop-object-oriented-programming-r"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://podverse.fm/episode/VvyuAA4kj"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://shinydevseries.com/interview/ep030"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://shinydevseries.com/interview/ep031"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://rweekly.fireside.fm/contact"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://podcastindex.org/apps?appTypes=app&elements=Value"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://value4value.info"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "links": "https://fosstodon.org/@mike_thomas"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_52_highlights",
        "chap_timestamp": 0,
        "chap_text": "Introduction"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "chap_timestamp": 34,
        "chap_text": "gpttools"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "chap_timestamp": 23,
        "chap_text": "MLOps: The Whole Game"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "chap_timestamp": 12,
        "chap_text": "Spotlight on quantile regression"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "chap_timestamp": 5,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "chap_timestamp": 22,
        "chap_text": "Listener feedback"
      },
      {
        "ep_name": "issue_2022_w_52_highlights",
        "chap_timestamp": 20,
        "chap_text": "Closing Remarks"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_50_highlights",
        "ep_date": "2022-12-14",
        "ep_duration": 11,
        "ep_description_short": "Data munging and visualization of your Twitter archive with R, a successful Shiny app submission to the FDA, and scoring Rock Paper Scissors. Episode Links This week's curator: Eric Nantz - @theRcast (https://twitter.com/theRcast) (Twitter) & @[email protected] (https://podcastindex.social/@rpodcast) (Mastodon) Read and Visualize your…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_50_highlights",
        "description_long": "\r \r\n\nData munging and visualization of your Twitter archive with R, a successful Shiny app submission to the FDA, and scoring Rock Paper Scissors.\n\nEpisode Links\n\nThis week's curator: Eric Nantz - @theRcast (Twitter) & @[email protected] (Mastodon)\nRead and Visualize your Twitter Archive\nUPDATE: Successful R-Based Package Submission with Shiny Component to FDA\nHow to score Rock Paper Scissors\nEntire issue available at rweekly.org/2022-W50\n\nSupplement Resources\n\n{ggiraph}: Make {ggplot2} plots interactive https://davidgohel.github.io/ggiraph\nRConsortium/submissions-pilot2 GitHub repository: https://github.com/RConsortium/submissions-pilot2\nR/Pharma 2022 Conference Playlists on YouTube:\nDay 1 talks\nDay 2 talks\nDay 3 talks\nWorkshops\n\nSupporting the Show\n\nNew Podcast Apps: https://podcastindex.org/apps?appTypes=app&elements=Value\nA new way to think about value: https://value4value.info/"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://podcastindex.social/@rpodcast"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://www.garrickadenbuie.com/blog/tweet-archive-in-r/"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://www.r-consortium.org/blog/2022/12/07/update-successful-r-based-package-submission-with-shiny-component-to-fda"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://tjmahr.github.io/rock-paper-scissors-lists-are-trees/"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://rweekly.org/2022-W50.html"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://davidgohel.github.io/ggiraph"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://github.com/RConsortium/submissions-pilot2"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://www.youtube.com/watch?v=521weL2fK1A&list=PLMtxz1fUYA5A-dFv_xp1lPtjw_0c3_RKz"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://www.youtube.com/watch?v=37-HBiXGyVc&list=PLMtxz1fUYA5D7_dke-o71AA_DqyV-WpXA"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://www.youtube.com/watch?v=tTigGijpgiE&list=PLMtxz1fUYA5BPxg3zHYBkV26uJ-BMFOuX"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://www.youtube.com/watch?v=OcNzurpCCpY&list=PLMtxz1fUYA5AWYQHB5mZAs-yamNJ5Tm_8"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://podcastindex.org/apps?appTypes=app&elements=Value"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "links": "https://value4value.info/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_50_highlights",
        "chap_timestamp": 0,
        "chap_text": "Intro"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "chap_timestamp": 52,
        "chap_text": "Analyzing Twitter Archive"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "chap_timestamp": 18,
        "chap_text": "Shiny Submission to FDA"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "chap_timestamp": 14,
        "chap_text": "Scoring Rock Paper Scissors"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "chap_timestamp": 6,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2022_w_50_highlights",
        "chap_timestamp": 59,
        "chap_text": "Closing Remarks"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_49_highlights",
        "ep_date": "2022-12-08",
        "ep_duration": 37,
        "ep_description_short": "Big new features coming in {dplyr} 1.1.0, how you can make your own #rstats wrapped, and enhancing your Shiny apps with JavaScript (without knowing much JS). Plus your feedback and more! Episode Links This week's curator: Jon Carroll - @carroll_jono (https://twitter.com/carroll_jono) (Twitter) & @[email protected]…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_49_highlights",
        "description_long": "\r \r\n\nBig new features coming in {dplyr} 1.1.0, how you can make your own #rstats wrapped, and enhancing your Shiny apps with JavaScript (without knowing much JS). Plus your feedback and more!\n\nEpisode Links\n\nThis week's curator: Jon Carroll - @carroll_jono (Twitter) & @[email protected] (Mastodon)\nHow to make your own #RStats Wrapped!\ndplyr 1.1.0 is coming soon\nHow to enhance your Shiny apps with JavaScript (JS) without knowing much JS\nEntire issue available at rweekly.org/2022-W49\n\nSupplement Resources\n\nDifferences between .by and group_by() in {dplyr}: https://dplyr.tidyverse.org/dev/reference/dplyr_by.html#differences-between-by-and-group-by-\nhttps://fosstodon.org/@posit_glimpse/109424114108257429\nTravis Gerke's take on Spotify Wrapped https://www.linkedin.com/posts/travisgerke_spotify-wrapped-is-proof-that-sometimes-count-activity-7003778803088990209-E9yE\nNCmisc: miscellaneous functions for creating adaptive functions and scripts https://cran.r-project.org/web/packages/NCmisc/index.html\nOutstanding User Interfaces with Shiny https://unleash-shiny.rinterface.com/index.html\nJavascript for R https://book.javascript-for-r.com/\nPharmaverse https://pharmaverse.org\nAdmiral hackathon https://www.cdisc.org/events/webinar/pre-admiral-hackathon-workshop-introduction-r-sas-programmers\n\nSupporting the Show\n\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?appTypes=app&elements=Value\nA new way to think about value: https://value4value.info"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://fosstodon.org/@jonocarroll"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://nrennie.rbind.io/blog/2022-12-03-how-to-make-your-own-rstats-wrapped/"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://www.tidyverse.org/blog/2022/11/dplyr-1-1-0-is-coming-soon/"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://albert-rapp.de/posts/15_use_js_with_shiny/15_use_js_with_shiny.html"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://rweekly.org/2022-W49.html"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://dplyr.tidyverse.org/dev/reference/dplyr_by.html#differences-between-by-and-group-by-"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://fosstodon.org/@posit_glimpse/109424114108257429"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://www.linkedin.com/posts/travisgerke_spotify-wrapped-is-proof-that-sometimes-count-activity-7003778803088990209-E9yE"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://cran.r-project.org/web/packages/NCmisc/index.html"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://unleash-shiny.rinterface.com/index.html"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://book.javascript-for-r.com/"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://pharmaverse.org"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://www.cdisc.org/events/webinar/pre-admiral-hackathon-workshop-introduction-r-sas-programmers"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://podcastindex.org/apps?appTypes=app&elements=Value"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "links": "https://value4value.info"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_49_highlights",
        "chap_timestamp": 0,
        "chap_text": "Introduction"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "chap_timestamp": 40,
        "chap_text": "{dplyr} 1.1.0 coming soon"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "chap_timestamp": 26,
        "chap_text": "rstats wrapped"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "chap_timestamp": 34,
        "chap_text": "Shiny and JavaScript"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "chap_timestamp": 35,
        "chap_text": "Additional finds"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "chap_timestamp": 48,
        "chap_text": "Listener feedback"
      },
      {
        "ep_name": "issue_2022_w_49_highlights",
        "chap_timestamp": 8,
        "chap_text": "Episode wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_48_highlights",
        "ep_date": "2022-12-01",
        "ep_duration": 25,
        "ep_description_short": "A new approach to adding package tests with {doctest}, scraping data from dynamic web pages with {RSelenium}, and a simple checklist to power up your next bar chart. This week's curator: Tony Elhabr - @TonyElHabr (https://twitter.com/TonyElHabr) (Twitter) & @[email protected] (https://mastodon.skrimmage.com/@tonyelhabr) (Mastodon) {doctest}…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_48_highlights",
        "description_long": "\r \r\n\nA new approach to adding package tests with {doctest}, scraping data from dynamic web pages with {RSelenium}, and a simple checklist to power up your next bar chart.\n\nThis week's curator: Tony Elhabr - @TonyElHabr (Twitter) & @[email protected] (Mastodon)\n{doctest} 0.1.0: Generate Tests from Examples Using 'roxygen' and 'testthat'\nWebscraping with RSelenium: automate your browser actions\nA simple checklist for bar plots\nEntire issue available at rweekly.org/2022-W48\n\nSupplement Resources\n\nWebscraping with RSelenium and rvest: https://ivanmillanes.netlify.app/post/2020-06-30-webscraping-with-rselenium-and-rvest/\nRSelenium with Docker: https://callumgwtaylor.github.io/post/using-rselenium-and-docker-to-webscrape-in-r-using-the-who-snake-database\nShiny in Production recordings from Jumping Rivers: YouTube playlist"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_48_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "links": "https://mastodon.skrimmage.com/@tonyelhabr"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "links": "https://github.com/hughjonesd/doctest"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "links": "https://www.rselenium-teaching.etiennebacher.com"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "links": "https://albert-rapp.de/posts/ggplot2-tips/16_bars_checklist/16_bars_checklist.html"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "links": "https://rweekly.org/2022-W48.html"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "links": "https://ivanmillanes.netlify.app/post/2020-06-30-webscraping-with-rselenium-and-rvest/"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "links": "https://callumgwtaylor.github.io/post/using-rselenium-and-docker-to-webscrape-in-r-using-the-who-snake-database"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "links": "https://www.youtube.com/playlist?list=PLbARZQfpqIKJ6Un06aThcKJC7eQMSgKRD"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_48_highlights",
        "chap_timestamp": 0,
        "chap_text": "Introduction"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "chap_timestamp": 24,
        "chap_text": "Writing package tests with {doctest}"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "chap_timestamp": 16,
        "chap_text": "Scraping web data with {RSelenium}"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "chap_timestamp": 58,
        "chap_text": "Checklist for bar charts"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "chap_timestamp": 30,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2022_w_48_highlights",
        "chap_timestamp": 40,
        "chap_text": "Episode Wrapup"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_47_highlights",
        "ep_date": "2022-11-23",
        "ep_duration": 14,
        "ep_description_short": "Reshaping your R function syntax with {codegrip}, ways you can apply DRY principles to R package development, and a new online book teaching you how to create beautiful tables in R with {gt} Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder)) {codegrip} 0.0.0.9000 (https://github.com/lionel-/codegrip):…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_47_highlights",
        "description_long": "\r \r\n\nReshaping your R function syntax with {codegrip}, ways you can apply DRY principles to R package development, and a new online book teaching you how to create beautiful tables in R with {gt}\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder)\n{codegrip} 0.0.0.9000: Reshaping and navigation commands for R code\nDRY Package Development in R (slides)\nCreating beautiful tables in R with {gt}\nEntire issue available at rweekly.org/2022-W47\n\nSupplement Resources\n\nThe tidyverse style guide: https://style.tidyverse.org\nGoogle R style guide: https://google.github.io/styleguide/Rguide.html\n{dm} - Working with relational data models in R: https://dm.cynkra.com\nPosit Table Contest (deadline extended to December 2, 2022): https://www.rstudio.com/blog/rstudio-table-contest-2022/\n\nSupporting the Show\n\nGet a New Podcast App and send us a boost! https://podcastindex.org/apps?appTypes=app&elements=Value\nA new way to think about value: https://value4value.info"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_47_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "links": "https://github.com/lionel-/codegrip"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "links": "https://indrajeetpatil.github.io/dry-r-package-development/#/dry-package-development-in-r"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "links": "https://gt.albert-rapp.de/"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "links": "https://rweekly.org/2022-W47.html"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "links": "https://style.tidyverse.org"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "links": "https://google.github.io/styleguide/Rguide.html"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "links": "https://dm.cynkra.com"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "links": "https://www.rstudio.com/blog/rstudio-table-contest-2022/"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "links": "https://podcastindex.org/apps?appTypes=app&elements=Value"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "links": "https://value4value.info"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_47_highlights",
        "chap_timestamp": 0,
        "chap_text": "Introduction"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "chap_timestamp": 30,
        "chap_text": "{codegrip}"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "chap_timestamp": 20,
        "chap_text": "GIF?"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "chap_timestamp": 15,
        "chap_text": "DRY for Package Dev"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "chap_timestamp": 46,
        "chap_text": "Beautiful {gt} Tables"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "chap_timestamp": 3,
        "chap_text": "Additional Finds"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "chap_timestamp": 40,
        "chap_text": "Our First Boost!"
      },
      {
        "ep_name": "issue_2022_w_47_highlights",
        "chap_timestamp": 40,
        "chap_text": "Outro"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_46_highlights",
        "ep_date": "2022-11-16",
        "ep_duration": 10,
        "ep_description_short": "A major achievement unlocked! In episode 100 of RWeekly Highlights: The new {rtoot} package for collecting and analyzing Mastodon data, using the {unheadr} package to fix broken and irregular column headers, a tour of the apply functions in base R, and creating posters of NBA rosters with R and ImageMagick. Plus a big announcement on a new way to…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_46_highlights",
        "description_long": "\r \r\n\nA major achievement unlocked! In episode 100 of RWeekly Highlights: The new {rtoot} package for collecting and analyzing Mastodon data, using the {unheadr} package to fix broken and irregular column headers, a tour of the apply functions in base R, and creating posters of NBA rosters with R and ImageMagick.\n\nPlus a big announcement on a new way to directly support the show!\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara - @R_by_Ryo (Twitter) & @[email protected] (Mastodon)\n{rtoot}: Collecting and analyzing mastodon data!\nFixing broken and irregular column headers\nLet's Get Apply'ing\nNBA Posters\nEntire issue available at rweekly.org/2022-W46\n\nSupplement Resources\n\nEverything I know about Mastodon: https://blog.djnavarro.net/posts/2022-11-03_what-i-know-about-mastodon/\nFedi.tips (an unofficial guide to Mastodon and the Fediverse): https://fedi.tips\nRWeekly is now on Mastodon! @[email protected]\nFavorite/most important base R functions new users should know: https://twitter.com/newmeyermn/status/1591464874827460608\n\nSupporting the Show\n\nNew Podcast Apps: https://podcastindex.org/apps?appTypes=app&elements=Value\nA new way to think about value: https://value4value.info/"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "https://mstdn.social/@R_by_Ryo"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "http://blog.schochastics.net/post/rtoot-collecting-and-analyzing-mastodon-data/"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "https://luisdva.github.io/rstats/mash-colnames/"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "https://drmowinckels.io/blog/2022-11-07-lets-get-applying/"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "https://www.abdoulblog.com/posts/2022-09-26_nba-players-squad/nba-players-squad"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "https://rweekly.org/2022-W46.html"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "https://blog.djnavarro.net/posts/2022-11-03_what-i-know-about-mastodon/"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "https://fedi.tips"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "https://fosstodon.org/@rweekly"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "https://twitter.com/newmeyermn/status/1591464874827460608"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "https://podcastindex.org/apps?appTypes=app&elements=Value"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "links": "https://value4value.info/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_46_highlights",
        "chap_timestamp": 0,
        "chap_text": "Episode Introduction"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "chap_timestamp": 55,
        "chap_text": "Mastodon API with {rtoot}"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "chap_timestamp": 23,
        "chap_text": "Fixing messy column headers"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "chap_timestamp": 22,
        "chap_text": "Let's get Apply'ing"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "chap_timestamp": 28,
        "chap_text": "NBA Posters with R & ImageMagick"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "chap_timestamp": 10,
        "chap_text": "Additional Finds from RWeekly"
      },
      {
        "ep_name": "issue_2022_w_46_highlights",
        "chap_timestamp": 9,
        "chap_text": "Announcement on Supporting the Show"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_44_highlights",
        "ep_date": "2022-11-04",
        "ep_duration": 40,
        "ep_description_short": "Embracing the dual role of data scientist and software developer with state-of-the-art tooling, illustrating the fundamentals of Shiny (literally), and the TidyX crew put their data wrangling skills to the test. Episode Links This week's curator: Sam Parmar (@parmsam_ (https://twitter.com/parmsam_)) Are you Data Scientists or Software Developers?!…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_44_highlights",
        "description_long": "\r \r\n\nEmbracing the dual role of data scientist and software developer with state-of-the-art tooling, illustrating the fundamentals of Shiny (literally), and the TidyX crew put their data wrangling skills to the test.\n\nEpisode Links\n\nThis week's curator: Sam Parmar (@parmsam_)\nAre you Data Scientists or Software Developers?!\nUnderstanding ShinyApps\nTidyX Episode 121: Tell me what you want - user submitted data\nEntire issue available at rweekly.org/2022-W44\n\nSupplement Resources\n\nManage Dependencies with the deps R Package for Docker Containers\nAlternatives to paired bar charts"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_44_highlights",
        "links": "https://twitter.com/parmsam_"
      },
      {
        "ep_name": "issue_2022_w_44_highlights",
        "links": "https://milesmcbain.micro.blog/2022/10/18/are-you-data.html"
      },
      {
        "ep_name": "issue_2022_w_44_highlights",
        "links": "https://cosimameyer.com/post/understanding-shinyapps/"
      },
      {
        "ep_name": "issue_2022_w_44_highlights",
        "links": "https://www.youtube.com/watch?v=RvV6aL5RD4U"
      },
      {
        "ep_name": "issue_2022_w_44_highlights",
        "links": "https://rweekly.org/2022-W44.html"
      },
      {
        "ep_name": "issue_2022_w_44_highlights",
        "links": "https://hosting.analythium.io/manage-dependencies-with-the-deps-r-package-for-docker-containers/"
      },
      {
        "ep_name": "issue_2022_w_44_highlights",
        "links": "https://albert-rapp.de/posts/ggplot2-tips/15_alternative_paired_bars/15_alternative_paired_bars.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_44_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_42_highlights",
        "ep_date": "2022-10-19",
        "ep_duration": 28,
        "ep_description_short": "The power of Quarto's interoperability shines again with integrating R and JavaScript maps, as well as the grammar of table generation in both R and Python. Plus boost the launching of your R session with the startup package. Episode Links This week's curator: Kelly Bodwin Let’s make maps with bertin.js in Quarto…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_42_highlights",
        "description_long": "\r \r\n\nThe power of Quarto's interoperability shines again with integrating R and JavaScript maps, as well as the grammar of table generation in both R and Python. Plus boost the launching of your R session with the startup package.\n\nEpisode Links\n\nThis week's curator: Kelly Bodwin\nLet’s make maps with bertin.js in Quarto\nstartup 0.19.0 - Friendly R Startup Configuration\nThe grammar of tables in python (pandas) and R (gt)\nEntire issue available at rweekly.org/2022-W42\n\nSupplement Resources\n\nhttps://github.com/mcanouil/awesome-quarto\nhttps://github.com/neocarto/bertin\nhttps://quarto.org/docs/interactive/ojs/libraries.html"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_42_highlights",
        "links": "https://neocarto.github.io/bertin/examples/quarto.html"
      },
      {
        "ep_name": "issue_2022_w_42_highlights",
        "links": "https://henrikbengtsson.github.io/startup/"
      },
      {
        "ep_name": "issue_2022_w_42_highlights",
        "links": "https://karbartolome.quarto.pub/the-grammar-of-tables/"
      },
      {
        "ep_name": "issue_2022_w_42_highlights",
        "links": "https://rweekly.org/2022-W41.html"
      },
      {
        "ep_name": "issue_2022_w_42_highlights",
        "links": "https://github.com/mcanouil/awesome-quarto"
      },
      {
        "ep_name": "issue_2022_w_42_highlights",
        "links": "https://github.com/neocarto/bertin"
      },
      {
        "ep_name": "issue_2022_w_42_highlights",
        "links": "https://quarto.org/docs/interactive/ojs/libraries.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_42_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_41_highlights",
        "ep_date": "2022-10-12",
        "ep_duration": 7,
        "ep_description_short": "The magic of automated Shiny app deployment and data aggregation using GitHub actions, 6 productivity hacks for Quarto, and valuable tips for managing large codebases in R. Episode Links This week's curator: Colin Faye (@_colinFay (https://twitter.com/_colinfay)) Automatically deploying a Shiny app for browsing #RStats tweets with GitHub Actions…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_41_highlights",
        "description_long": "\r \r\n\nThe magic of automated Shiny app deployment and data aggregation using GitHub actions, 6 productivity hacks for Quarto, and valuable tips for managing large codebases in R.\n\nEpisode Links\n\nThis week's curator: Colin Faye (@_colinFay)\nAutomatically deploying a Shiny app for browsing #RStats tweets with GitHub Actions\n6 Productivity Hacks for Quarto\n\"Managing Large Codebases in R\" webinar\nEntire issue available at rweekly.org/2022-W41\n\nSupplement Resources\n\nlittler - scripting and command-line front-end for R https://dirk.eddelbuettel.com/code/littler.html"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_41_highlights",
        "links": "https://twitter.com/_colinfay"
      },
      {
        "ep_name": "issue_2022_w_41_highlights",
        "links": "https://nrennie.rbind.io/blog/2022-10-05-automatically-deploying-a-shiny-app-for-browsing-rstats-tweets-with-github-actions/"
      },
      {
        "ep_name": "issue_2022_w_41_highlights",
        "links": "https://www.rstudio.com/blog/6-productivity-hacks-for-quarto/"
      },
      {
        "ep_name": "issue_2022_w_41_highlights",
        "links": "https://www.activityinfo.org/support/webinars/2022-10-06-managing-large-codebases-in-R.html"
      },
      {
        "ep_name": "issue_2022_w_41_highlights",
        "links": "https://rweekly.org/2022-W41.html"
      },
      {
        "ep_name": "issue_2022_w_41_highlights",
        "links": "https://dirk.eddelbuettel.com/code/littler.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_41_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_40_highlights",
        "ep_date": "2022-10-05",
        "ep_duration": 49,
        "ep_description_short": "Design principles for data analysis, unraveling pipeline analyses with {Unravel}, and visualizing simulated environmental changes in western Canada with Shiny. Episode Links This week's curator: Eric Nantz Design Principles for Data Analysis (https://www.tandfonline.com/doi/full/10.1080/10618600.2022.2104290?journalCode=ucgs20) {Unravel} - A…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_40_highlights",
        "description_long": "\r \r\n\nDesign principles for data analysis, unraveling pipeline analyses with {Unravel}, and visualizing simulated environmental changes in western Canada with Shiny.\n\nEpisode Links\n\nThis week's curator: Eric Nantz\nDesign Principles for Data Analysis\n{Unravel} - A fluent code explorer for R\nCase Study: Simulating Environment Change Agents on Species in Canada's Western Boreal Forests\nEntire issue available at rweekly.org/2022-W40\n\nSupplement Resources\n\nCasual Inference Podcast: https://casualinfer.libsyn.com\nNot So Standard Deviations Podcast: https://nssdeviations.com/\nDesigning for Analytics Podcast: https://designingforanalytics.com/experiencing-data-podcast/\nElements and Principles for Characterizing Variation between Data Analyses (preprint) https://arxiv.org/abs/1903.07639\nStephanie Hicks' thread on the preprint: https://twitter.com/stephaniehicks/status/1108462768099856384\nLucy D'Agostino McGowan's presentation at JSM 2022: https://www.lucymcgowan.com/talk/asa_joint_statistical_meeting_2022\nMany Analysts, One Data Set: Making Transparent How Variations in Analytic Choices Affect Results https://journals.sagepub.com/doi/10.1177/2515245917747646\nUnravel presentation at UIST 2021 https://www.youtube.com/watch?v=wJ77e39XVEs\nShinyWBI https://wbi-nwt.analythium.app/apps/nwt/"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://www.tandfonline.com/doi/full/10.1080/10618600.2022.2104290?journalCode=ucgs20"
      },
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://github.com/nischalshrestha/Unravel"
      },
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://www.ketchbrookanalytics.com/post/case-study-simulating-environmental-change-agents-on-species-populations-in-canada-s-western-boreal"
      },
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://rweekly.org/2022-W40.html"
      },
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://casualinfer.libsyn.com"
      },
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://nssdeviations.com/"
      },
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://designingforanalytics.com/experiencing-data-podcast/"
      },
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://arxiv.org/abs/1903.07639"
      },
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://twitter.com/stephaniehicks/status/1108462768099856384"
      },
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://www.lucymcgowan.com/talk/asa_joint_statistical_meeting_2022"
      },
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://journals.sagepub.com/doi/10.1177/2515245917747646"
      },
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://www.youtube.com/watch?v=wJ77e39XVEs"
      },
      {
        "ep_name": "issue_2022_w_40_highlights",
        "links": "https://wbi-nwt.analythium.app/apps/nwt/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_40_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_39_highlights",
        "ep_date": "2022-09-28",
        "ep_duration": 29,
        "ep_description_short": "A collection of highlights to give your future developer self a helping hand: Deploying a Flexdashboard using GitHub Pages and Docker, an illustrated guide showcasing the perks of Git and GitHub for version control, and how the logger package integrates smoothly with plumber for an API package. Additional note: The recording of this episode was met…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_39_highlights",
        "description_long": "\r \r\n\nA collection of highlights to give your future developer self a helping hand: Deploying a Flexdashboard using GitHub Pages and Docker, an illustrated guide showcasing the perks of Git and GitHub for version control, and how the logger package integrates smoothly with plumber for an API package.\n\nAdditional note: The recording of this episode was met with unfortunate technical glitches. We apologize and promise the quality will be back to normal next time!\n\nEpisode Links\n\nThis week's curator: Jonathan Carroll (@carroll_jono)\nDeploy Flexdashboard on Github Pages with Github Actions and Docker\nGitHub - The Perks of Collaboration and Version Control\nAPI as a package: Logging\nEntire issue available at rweekly.org/2022-W39\n\nSupplement Resources\n\nSubmitting Your Work to the Table Contest | 2022 Table Contest https://www.youtube.com/watch?v=fgYgaYKpLO0\nLet's Create a Quarto Doc & Share it on Quarto.Pub | Table Contest 2022 https://www.youtube.com/watch?v=l-AQ4yAQXy0"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_39_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2022_w_39_highlights",
        "links": "https://github.com/RamiKrispin/deploy-flex-actions"
      },
      {
        "ep_name": "issue_2022_w_39_highlights",
        "links": "https://cosimameyer.com/post/git-the-perks-of-collaboration-and-version-control/"
      },
      {
        "ep_name": "issue_2022_w_39_highlights",
        "links": "https://www.jumpingrivers.com/blog/api-as-a-package-logging/"
      },
      {
        "ep_name": "issue_2022_w_39_highlights",
        "links": "https://rweekly.org/2022-W39.html"
      },
      {
        "ep_name": "issue_2022_w_39_highlights",
        "links": "https://www.youtube.com/watch?v=fgYgaYKpLO0"
      },
      {
        "ep_name": "issue_2022_w_39_highlights",
        "links": "https://www.youtube.com/watch?v=l-AQ4yAQXy0"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_39_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_38_highlights",
        "ep_date": "2022-09-21",
        "ep_duration": 45,
        "ep_description_short": "A few major benefits of adopting variable labels for R data frames, wrapping a plumber API into a package with mariobox, and getting started with obtaining new data in R via APIs and web scraping. Episode Links This week's curator: Tony ElHabr (@TonyElHabr (https://twitter.com/TonyElHabr)) The case for variable labels in R…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_38_highlights",
        "description_long": "\r \r\n\nA few major benefits of adopting variable labels for R data frames, wrapping a plumber API into a package with mariobox, and getting started with obtaining new data in R via APIs and web scraping.\n\nEpisode Links\n\nThis week's curator: Tony ElHabr (@TonyElHabr)\nThe case for variable labels in R\n{mariobox} 0.0.0.9000: A framework for packaging {plumber} APIs\nAPIs and web scraping\nEntire issue available at rweekly.org/2022-W38\n\nSupplement Resources\n\nMLOps with vetiver in Python & R: https://www.youtube.com/watch?v=oFQANK13-k4"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_38_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2022_w_38_highlights",
        "links": "https://www.pipinghotdata.com/posts/2022-09-13-the-case-for-variable-labels-in-r"
      },
      {
        "ep_name": "issue_2022_w_38_highlights",
        "links": "https://github.com/ThinkR-open/mariobox"
      },
      {
        "ep_name": "issue_2022_w_38_highlights",
        "links": "https://talks.andrewheiss.com/2022-seacen/presentation/#/title-slide"
      },
      {
        "ep_name": "issue_2022_w_38_highlights",
        "links": "https://rweekly.org/2022-W38.html"
      },
      {
        "ep_name": "issue_2022_w_38_highlights",
        "links": "https://www.youtube.com/watch?v=oFQANK13-k4"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_38_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_37_highlights",
        "ep_date": "2022-09-14",
        "ep_duration": 41,
        "ep_description_short": "A collection of highlights powered by mathematics, statistics, and a little bit of R magic: Mapping wind data with R, calculating the expected statistic in football, and how the vetiver package fits in an ML-Ops production flow using Docker and Plumber. Episode Links This week's curator: Jon Calder (@jonmcalder…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_37_highlights",
        "description_long": "\r \r\n\nA collection of highlights powered by mathematics, statistics, and a little bit of R magic: Mapping wind data with R, calculating the expected statistic in football, and how the vetiver package fits in an ML-Ops production flow using Docker and Plumber.\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder)\nMapping wind data with R\nCalculating and comparing expected points from different expected goals sources (soccer)\nUse Docker to deploy a model for #TidyTuesday LEGO sets\nEntire issue available at rweekly.org/2022-W37\n\nSupplement Resources\n\nJulia Silge's YouTube Channel: https://www.youtube.com/c/JuliaSilge"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_37_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2022_w_37_highlights",
        "links": "https://milospopovic.net/mapping-wind-data-in-r/"
      },
      {
        "ep_name": "issue_2022_w_37_highlights",
        "links": "https://tonyelhabr.rbind.io/post/epl-xpts-simulation-1/"
      },
      {
        "ep_name": "issue_2022_w_37_highlights",
        "links": "https://juliasilge.com/blog/lego-sets/"
      },
      {
        "ep_name": "issue_2022_w_37_highlights",
        "links": "https://rweekly.org/2022-W37.html"
      },
      {
        "ep_name": "issue_2022_w_37_highlights",
        "links": "https://www.youtube.com/c/JuliaSilge"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_37_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_36_highlights",
        "ep_date": "2022-09-08",
        "ep_duration": 55,
        "ep_description_short": "Using base R to decrypt an Australian coin's hidden messages, the Palmer Penguins data set achieves another milestone, and visualizing multiple statistcal properties with faded raincloud plots. Episode Links This week's curator: Miles McBain (@MilesMcBain (https://twitter.com/MilesMcBain)) Australian Signals Directorate 50c Coin Decryption…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_36_highlights",
        "description_long": "\r \r\n\nUsing base R to decrypt an Australian coin's hidden messages, the Palmer Penguins data set achieves another milestone, and visualizing multiple statistcal properties with faded raincloud plots.\n\nEpisode Links\n\nThis week's curator: Miles McBain (@MilesMcBain)\nAustralian Signals Directorate 50c Coin Decryption\nPalmer Archipelago Penguins Data in the palmerpenguins R Package - An Alternative to Anderson’s Irises\nEfficient data visualization with faded raincloud plots\nEntire issue available at rweekly.org/2022-W36\n\nSupplement Resources\n\nUsing distill template with knitr::read_chunk https://twitter.com/apreshill/status/1565752119751237638\nManuscript on raincloud plots: https://wellcomeopenresearch.org/articles/4-63/v2\n{gghalves}: https://erocoar.github.io/gghalves/\n{ggp0}: https://docs.r4photobiology.info/ggpp/"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_36_highlights",
        "links": "https://twitter.com/MilesMcBain"
      },
      {
        "ep_name": "issue_2022_w_36_highlights",
        "links": "https://jcarroll.com.au/2022/09/01/asd_coin/"
      },
      {
        "ep_name": "issue_2022_w_36_highlights",
        "links": "https://journal.r-project.org/articles/RJ-2022-020/"
      },
      {
        "ep_name": "issue_2022_w_36_highlights",
        "links": "https://dallasnova.rbind.io/post/efficient-data-visualization-with-faded-raincloud-plots-delete-boxplot/"
      },
      {
        "ep_name": "issue_2022_w_36_highlights",
        "links": "https://rweekly.org/2022-W36.html"
      },
      {
        "ep_name": "issue_2022_w_36_highlights",
        "links": "https://twitter.com/apreshill/status/1565752119751237638"
      },
      {
        "ep_name": "issue_2022_w_36_highlights",
        "links": "https://wellcomeopenresearch.org/articles/4-63/v2"
      },
      {
        "ep_name": "issue_2022_w_36_highlights",
        "links": "https://erocoar.github.io/gghalves/"
      },
      {
        "ep_name": "issue_2022_w_36_highlights",
        "links": "https://docs.r4photobiology.info/ggpp/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_36_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_35_highlights",
        "ep_date": "2022-08-31",
        "ep_duration": 17,
        "ep_description_short": "Using hierarchical forecasting to explore subway fare recovery, and how you can learn more about {gtsummary} to create your next publication-quality table within R. Episode Links This week's curator: Batool Almarzouq (@batool664) (https://twitter.com/batool664) Exploring Types of Subway Fares with Hierarchical Forecasting…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_35_highlights",
        "description_long": "\r \r\n\nUsing hierarchical forecasting to explore subway fare recovery, and how you can learn more about {gtsummary} to create your next publication-quality table within R.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq (@batool664)\nExploring Types of Subway Fares with Hierarchical Forecasting\nClinical Reporting with {gtsummary} by Daniel D. Sjoberg\nEntire issue available at rweekly.org/2022-W35\n\nSupplement Resources\n\nR-Podcast Episode 27: Get the {gt} Tables! https://r-podcast.org/027-rstudioconf-tables"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_35_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2022_w_35_highlights",
        "links": "https://jlaw.netlify.app/2022/08/24/exploring-types-of-subway-fares-with-hierarchical-forecasting/"
      },
      {
        "ep_name": "issue_2022_w_35_highlights",
        "links": "https://www.danieldsjoberg.com/clinical-reporting-gtsummary-rmed/material.html"
      },
      {
        "ep_name": "issue_2022_w_35_highlights",
        "links": "https://rweekly.org/2022-W35.html"
      },
      {
        "ep_name": "issue_2022_w_35_highlights",
        "links": "https://r-podcast.org/027-rstudioconf-tables"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_35_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_34_highlights",
        "ep_date": "2022-08-24",
        "ep_duration": 26,
        "ep_description_short": "The rstudio::conf(2022) presentation recordings are now available for viewing, and we learn about the unique development journey of the new CRAN release of the countdown package. Episode Links This week's curator: Sam Parmar (@parsam_ (https://twitter.com/parmsam_)) Talk recordings and workshop materials from rstudio::conf(2022)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_34_highlights",
        "description_long": "\r \r\n\nThe rstudio::conf(2022) presentation recordings are now available for viewing, and we learn about the unique development journey of the new CRAN release of the countdown package.\n\nEpisode Links\n\nThis week's curator: Sam Parmar (@parsam_)\nTalk recordings and workshop materials from rstudio::conf(2022)\nThe Past and Future of Shiny - Joe Cheng - rstudio::conf(2022)\ncountdown v0.4.0 - Now on CRAN!\nEntire issue available at rweekly.org/2022-W34"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_34_highlights",
        "links": "https://twitter.com/parmsam_"
      },
      {
        "ep_name": "issue_2022_w_34_highlights",
        "links": "https://www.rstudio.com/blog/talks-and-workshops-from-rstudio-conf-2022/"
      },
      {
        "ep_name": "issue_2022_w_34_highlights",
        "links": "https://www.rstudio.com/conference/2022/keynotes/past-future-shiny/"
      },
      {
        "ep_name": "issue_2022_w_34_highlights",
        "links": "https://www.garrickadenbuie.com/blog/countdown-v0.4.0/"
      },
      {
        "ep_name": "issue_2022_w_34_highlights",
        "links": "https://rweekly.org/2022-W34.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_34_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_33_highlights",
        "ep_date": "2022-08-17",
        "ep_duration": 6,
        "ep_description_short": "Avoid repeating yourself by using dplyr's across function, going inside the process of creating a custom theme in ggplot2, and a few keyboard-centric tricks to manage your RStudio pane viewing. Episode Links This week's curator: Ryo Nakagawara (@RbyRyo (https://twitter.com/R_by_Ryo)) Using across() to create multiple columns…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_33_highlights",
        "description_long": "\r \r\n\nAvoid repeating yourself by using dplyr's across function, going inside the process of creating a custom theme in ggplot2, and a few keyboard-centric tricks to manage your RStudio pane viewing.\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara (@R_by_Ryo)\nUsing across() to create multiple columns\nPretty ggplots with custom themes, ggtext, and ggh4x\nWindow and Pane Management Tricks for RStudio and your OS\nEntire issue available at rweekly.org/2022-W33\n\nSupplement Resources\n\n{ggh4x}: https://teunbrand.github.io/ggh4x/index.html"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_33_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2022_w_33_highlights",
        "links": "https://www.njtierney.com/post/2022/08/08/fun-across/"
      },
      {
        "ep_name": "issue_2022_w_33_highlights",
        "links": "https://www.michaelc-m.com/ggplot-extensions-and-custom-themes/"
      },
      {
        "ep_name": "issue_2022_w_33_highlights",
        "links": "https://datachimp.app/blog/window-managment-for-rstudio/"
      },
      {
        "ep_name": "issue_2022_w_33_highlights",
        "links": "https://rweekly.org/2022-W33.html"
      },
      {
        "ep_name": "issue_2022_w_33_highlights",
        "links": "https://teunbrand.github.io/ggh4x/index.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_33_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_32_highlights",
        "ep_date": "2022-08-10",
        "ep_duration": 51,
        "ep_description_short": "A wealth of R content from the UseR! 2022 conference is now available, focusing on accessibility in the diffify tool, and a great recap of rstudio::conf(2022) from TidyX. Episode Links This week's curator: Batool Almarzouq (@batool664) (https://twitter.com/batool664) useR2022 recordings are now on the conference YouTube channel…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_32_highlights",
        "description_long": "\r \r\n\nA wealth of R content from the UseR! 2022 conference is now available, focusing on accessibility in the diffify tool, and a great recap of rstudio::conf(2022) from TidyX.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq (@batool664)\nuseR2022 recordings are now on the conference YouTube channel\nTheming diffify for accessibility: Part 2\nRStudio::Conf 2022 Recap\nEntire issue available at rweekly.org/2022-W32\n\nSupplement Resources\n\nUseR! 2022 Program: https://user2022.r-project.org/program/overview/\nFundamentals of Data Visualization: https://clauswilke.com/dataviz"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_32_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2022_w_32_highlights",
        "links": "https://www.youtube.com/channel/UCv_a9ZGZOH588wUZHZl6T_g/playlists"
      },
      {
        "ep_name": "issue_2022_w_32_highlights",
        "links": "https://www.jumpingrivers.com/blog/theming-diffify-accessibility-2/"
      },
      {
        "ep_name": "issue_2022_w_32_highlights",
        "links": "https://www.youtube.com/watch?v=_sQGiu4fWqc"
      },
      {
        "ep_name": "issue_2022_w_32_highlights",
        "links": "https://rweekly.org/2022-W32.html"
      },
      {
        "ep_name": "issue_2022_w_32_highlights",
        "links": "https://user2022.r-project.org/program/overview/"
      },
      {
        "ep_name": "issue_2022_w_32_highlights",
        "links": "https://clauswilke.com/dataviz"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_32_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_31_highlights",
        "ep_date": "2022-08-04",
        "ep_duration": 23,
        "ep_description_short": "RStudio re-brands as Posit, the shinytest2 package continues to make waves in the Shiny community, and more Quarto tips to boost your workflow. Episode Links This week's curator: Kelly Bodwin (@KellyBodwin (https://twitter.com/KellyBodwin)) RStudio rebrands as Posit (https://www.rstudio.com/blog/rstudio-is-becoming-posit/) {shinytest2}: For…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_31_highlights",
        "description_long": "\r \r\n\nRStudio re-brands as Posit, the shinytest2 package continues to make waves in the Shiny community, and more Quarto tips to boost your workflow.\n\nEpisode Links\n\nThis week's curator: Kelly Bodwin (@KellyBodwin)\nRStudio rebrands as Posit\n{shinytest2}: For testing Shiny apps. (slides)\nOne Quarto tip a day\nEntire issue available at rweekly.org/2022-W31\n\nSupplement Resources\n\nJJ Allaire and Jeremy Howard 2-way AMA: https://www.youtube.com/watch?v=xxVVSxcjNQs\nTom Mock's Welcome to Quarto online event (August 9, 2023): https://www.addevent.com/event/Eh13574863"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_31_highlights",
        "links": "https://twitter.com/KellyBodwin"
      },
      {
        "ep_name": "issue_2022_w_31_highlights",
        "links": "https://www.rstudio.com/blog/rstudio-is-becoming-posit/"
      },
      {
        "ep_name": "issue_2022_w_31_highlights",
        "links": "https://rstudio.github.io/shinytest2/"
      },
      {
        "ep_name": "issue_2022_w_31_highlights",
        "links": "http://schloerke.com/presentation-2022-07-28-rstudioconf22-shinytest2/"
      },
      {
        "ep_name": "issue_2022_w_31_highlights",
        "links": "https://mine-cetinkaya-rundel.github.io/quarto-tip-a-day/"
      },
      {
        "ep_name": "issue_2022_w_31_highlights",
        "links": "https://rweekly.org/2022-W31.html"
      },
      {
        "ep_name": "issue_2022_w_31_highlights",
        "links": "https://www.youtube.com/watch?v=xxVVSxcjNQs"
      },
      {
        "ep_name": "issue_2022_w_31_highlights",
        "links": "https://www.addevent.com/event/Eh13574863"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_31_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_28_highlights",
        "ep_date": "2022-07-15",
        "ep_duration": 19,
        "ep_description_short": "Another great use case for Docker containers with interactive R-Markdown reports, a recap of RStudio's presence at the Appsilon Shiny conference, and building an interactive point-and-click game with Shiny. Episode Links This week's curator: Jonathan Carroll (@carroll_jono (https://twitter.com/carroll_jono)) Containerizing Interactive R Markdown…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_28_highlights",
        "description_long": "\r \r\n\nAnother great use case for Docker containers with interactive R-Markdown reports, a recap of RStudio's presence at the Appsilon Shiny conference, and building an interactive point-and-click game with Shiny.\n\nEpisode Links\n\nThis week's curator: Jonathan Carroll (@carroll_jono)\nContainerizing Interactive R Markdown Documents\nRStudio Recap From the Appsilon Shiny Conference\nHow to build an interactive point-and-click game with {Shiny}\nEntire issue available at rweekly.org/2022-W28\n\nSupplement Resources\n\nAppsilon Shiny Conference playlist: https://www.youtube.com/playlist?list=PLexAKolMzPcrYjGA1PULfm7-P12qjKmPb\nR Workflow by Frank Harrell: http://hbiostat.org/rflow/\nAlbert's video on styling a Quarto blog with CSS: https://www.youtube.com/watch?v=ErRX8plZpQE"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_28_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2022_w_28_highlights",
        "links": "https://hosting.analythium.io/containerizing-interactive-r-markdown-documents/"
      },
      {
        "ep_name": "issue_2022_w_28_highlights",
        "links": "https://www.rstudio.com/blog/rstudio-recap-from-the-appsilon-shiny-conference/"
      },
      {
        "ep_name": "issue_2022_w_28_highlights",
        "links": "https://www.youtube.com/watch?v=4-6jDDCADvU"
      },
      {
        "ep_name": "issue_2022_w_28_highlights",
        "links": "https://rweekly.org/2022-W28.html"
      },
      {
        "ep_name": "issue_2022_w_28_highlights",
        "links": "https://www.youtube.com/playlist?list=PLexAKolMzPcrYjGA1PULfm7-P12qjKmPb"
      },
      {
        "ep_name": "issue_2022_w_28_highlights",
        "links": "http://hbiostat.org/rflow/"
      },
      {
        "ep_name": "issue_2022_w_28_highlights",
        "links": "https://www.youtube.com/watch?v=ErRX8plZpQE"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_28_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_27_highlights",
        "ep_date": "2022-07-13",
        "ep_duration": 2,
        "ep_description_short": "Advice on building Docker containers for Shiny applications, an R-centric tutorial on fundamentals with shell, and tips on evaluating GitHub activity for contributors. Episode Links This issue's curator: Tony ElHabr (@TonyElHabr (https://twitter.com/TonyElHabr)) UseR!2022: Best Practices for Shiny Apps with Docker and More…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_27_highlights",
        "description_long": "\r \r\n\nAdvice on building Docker containers for Shiny applications, an R-centric tutorial on fundamentals with shell, and tips on evaluating GitHub activity for contributors.\n\nEpisode Links\n\nThis issue's curator: Tony ElHabr (@TonyElHabr)\nUseR!2022: Best Practices for Shiny Apps with Docker and More\nShell vs R Fundamentals – From Syntax to Control Structures with Zsh & BASH\nEvaluating GitHub Activity for Contributors\nEntire issue available at rweekly.org/2022-W27\n\nSupplement Resources\n\nHosting Data Apps: https://hosting.analythium.io\nslim.ai: https://www.slim.ai/\n{dockerfiler} - Easy Dockerfile creation from R: https://github.com/ThinkR-open/dockerfiler\nData Science at the Command Line: https://datascienceatthecommandline.com"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_27_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2022_w_27_highlights",
        "links": "https://hosting.analythium.io/user-2022-best-practicesfor-shiny-apps-with-docker-and-more/"
      },
      {
        "ep_name": "issue_2022_w_27_highlights",
        "links": "https://morphoscape.wordpress.com/2022/06/24/shell-vs-r-fundamentals-from-syntax-to-control-structures-with-zsh-amp-bash/"
      },
      {
        "ep_name": "issue_2022_w_27_highlights",
        "links": "https://ropensci.org/blog/2022/07/01/evaluating-github-activity-for-contributors/"
      },
      {
        "ep_name": "issue_2022_w_27_highlights",
        "links": "https://rweekly.org/2022-W27.html"
      },
      {
        "ep_name": "issue_2022_w_27_highlights",
        "links": "https://hosting.analythium.io"
      },
      {
        "ep_name": "issue_2022_w_27_highlights",
        "links": "https://www.slim.ai/"
      },
      {
        "ep_name": "issue_2022_w_27_highlights",
        "links": "https://github.com/ThinkR-open/dockerfiler"
      },
      {
        "ep_name": "issue_2022_w_27_highlights",
        "links": "https://datascienceatthecommandline.com"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_27_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_26_highlights",
        "ep_date": "2022-06-29",
        "ep_duration": 27,
        "ep_description_short": "Flexing new table-creation capabilities in the latest flextable update, how less is more with Shiny application processing, and the RainbowR community shines once again. Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder)) {flextable} 0.7.2 (https://www.ardata.fr/en/post/2022/06/23/flextable-0-7-2-is-out/) -…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_26_highlights",
        "description_long": "\r \r\n\nFlexing new table-creation capabilities in the latest flextable update, how less is more with Shiny application processing, and the RainbowR community shines once again.\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder)\n{flextable} 0.7.2 - Framework for easily creating tables for reporting and publications\nOffload Shiny's Workload: COVID-19 processing for the WHO/Europe\n(Re)launching RainbowR: a community of LGBTQ+ R users\nEntire issue available at rweekly.org/2022-W26\n\nSupplement Resources\n\nflextable gallery https://ardata.fr/en/flextable-gallery\nThe officeverse https://ardata-fr.github.io/officeverse\nSHiny and Arrow: Mike's guest post on the RStudio Blog https://www.rstudio.com/blog/shiny-and-arrow\nRainbowR https://rainbowr.netlify.app"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_26_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2022_w_26_highlights",
        "links": "https://www.ardata.fr/en/post/2022/06/23/flextable-0-7-2-is-out/"
      },
      {
        "ep_name": "issue_2022_w_26_highlights",
        "links": "https://www.jumpingrivers.com/blog/who-shiny-covid-maintenance-continuous-integration/"
      },
      {
        "ep_name": "issue_2022_w_26_highlights",
        "links": "https://rainbowr.netlify.app/posts/relaunching-rainbowr/relaunching-rainbowr.html"
      },
      {
        "ep_name": "issue_2022_w_26_highlights",
        "links": "https://rweekly.org/2022-W26.html"
      },
      {
        "ep_name": "issue_2022_w_26_highlights",
        "links": "https://ardata.fr/en/flextable-gallery"
      },
      {
        "ep_name": "issue_2022_w_26_highlights",
        "links": "https://ardata-fr.github.io/officeverse"
      },
      {
        "ep_name": "issue_2022_w_26_highlights",
        "links": "https://www.rstudio.com/blog/shiny-and-arrow"
      },
      {
        "ep_name": "issue_2022_w_26_highlights",
        "links": "https://rainbowr.netlify.app"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_26_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_25_highlights",
        "ep_date": "2022-06-22",
        "ep_duration": 46,
        "ep_description_short": "Previewing the upcoming rstudio::conf, why you should (or shouldn't) build an API client package, and monitoring Shiny application usage with Hotjar. Episode Links This week's curator: Colin Fay (@_colinFay (https://twitter.com/_colinfay)) rstudio::conf(2022) Conference Schedule (https://www.rstudio.com/blog/rstudio-2022-conf-schedule/) Why You…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_25_highlights",
        "description_long": "\r \r\n\nPreviewing the upcoming rstudio::conf, why you should (or shouldn't) build an API client package, and monitoring Shiny application usage with Hotjar.\n\nEpisode Links\n\nThis week's curator: Colin Fay (@_colinFay)\nrstudio::conf(2022) Conference Schedule\nWhy You Should (or Shouldn't) Build an API Client\nR Shiny Hotjar – How To Monitor User Behavior in R Shiny Apps\nEntire issue available at rweekly.org/2022-W25"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_25_highlights",
        "links": "https://twitter.com/_colinfay"
      },
      {
        "ep_name": "issue_2022_w_25_highlights",
        "links": "https://www.rstudio.com/blog/rstudio-2022-conf-schedule/"
      },
      {
        "ep_name": "issue_2022_w_25_highlights",
        "links": "https://ropensci.org/blog/2022/06/16/publicize-api-client-yes-no/"
      },
      {
        "ep_name": "issue_2022_w_25_highlights",
        "links": "https://appsilon.com/r-shiny-hotjar/"
      },
      {
        "ep_name": "issue_2022_w_25_highlights",
        "links": "https://rweekly.org/2022-W25.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_25_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_24_highlights",
        "ep_date": "2022-06-15",
        "ep_duration": 37,
        "ep_description_short": "Many improvements to {gt} version 0.6, and creating flow charts effeciently with {ggplot2}. Episode Links This week's curator: Batool Almarzouq (@batool664) (https://twitter.com/batool664) Changes (for the better) in {gt} 0.6.0 (https://www.rstudio.com/blog/changes-for-the-better-in-gt-0-6-0/) Creating flowcharts with {ggplot2}…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_24_highlights",
        "description_long": "\r \r\n\nMany improvements to {gt} version 0.6, and creating flow charts effeciently with {ggplot2}.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq (@batool664)\nChanges (for the better) in {gt} 0.6.0\nCreating flowcharts with {ggplot2}\nEntire issue available at rweekly.org/2022-W24\n\nSupplement Resources\n\nThe {gtExtras} is now on CRAN: https://themockup.blog/posts/2022-06-13-gtextras-cran\nNew features in {gt} 0.6: https://www.youtube.com/watch?v=F5TV9uWCJps\n{gt} table battles - Eurovision: https://www.youtube.com/watch?v=tIB_N0nUfNs\n{gt} table battles - Digital publications: https://www.youtube.com/watch?v=-c_PUee8Cu0\n{gt} table battles: Crosswords: https://www.youtube.com/watch?v=sRxdutTgyDE\nNicola's tweet of day 29 chart challenge https://twitter.com/nrennie35/status/1519960428167811074\nR-Ladies Nairobi: #30DayChartChallenge https://nrennie.rbind.io/talks/2022-may-rladies-nairobi/\nR-Ladies Nairobi Meetup YouTube Recording: https://www.youtube.com/watch?v=dY-fW7HqPP0"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_24_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2022_w_24_highlights",
        "links": "https://www.rstudio.com/blog/changes-for-the-better-in-gt-0-6-0/"
      },
      {
        "ep_name": "issue_2022_w_24_highlights",
        "links": "https://nrennie.rbind.io/blog/2022-06-06-creating-flowcharts-with-ggplot2/"
      },
      {
        "ep_name": "issue_2022_w_24_highlights",
        "links": "https://rweekly.org/2022-W24.html"
      },
      {
        "ep_name": "issue_2022_w_24_highlights",
        "links": "https://themockup.blog/posts/2022-06-13-gtextras-cran"
      },
      {
        "ep_name": "issue_2022_w_24_highlights",
        "links": "https://www.youtube.com/watch?v=F5TV9uWCJps"
      },
      {
        "ep_name": "issue_2022_w_24_highlights",
        "links": "https://www.youtube.com/watch?v=tIB_N0nUfNs"
      },
      {
        "ep_name": "issue_2022_w_24_highlights",
        "links": "https://www.youtube.com/watch?v=-c_PUee8Cu0"
      },
      {
        "ep_name": "issue_2022_w_24_highlights",
        "links": "https://www.youtube.com/watch?v=sRxdutTgyDE"
      },
      {
        "ep_name": "issue_2022_w_24_highlights",
        "links": "https://twitter.com/nrennie35/status/1519960428167811074"
      },
      {
        "ep_name": "issue_2022_w_24_highlights",
        "links": "https://nrennie.rbind.io/talks/2022-may-rladies-nairobi/"
      },
      {
        "ep_name": "issue_2022_w_24_highlights",
        "links": "https://www.youtube.com/watch?v=dY-fW7HqPP0"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_24_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_23_highlights",
        "ep_date": "2022-06-08",
        "ep_duration": 10,
        "ep_description_short": "Creating user interfaces in R with a vintage toolkit, and a candid take on learning R with the right perspectives in mind. Episode Links This week's curator: Sam Parmar (@parmsam_ (https://twitter.com/parmsam_)) {tickle} (https://github.com/coolbutuseless/tickle): a package for creating UIs in base R R will always be arcane to those who do not make…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_23_highlights",
        "description_long": "\r \r\n\nCreating user interfaces in R with a vintage toolkit, and a candid take on learning R with the right perspectives in mind.\n\nEpisode Links\n\nThis week's curator: Sam Parmar (@parmsam_)\n{tickle}: a package for creating UIs in base R\nR will always be arcane to those who do not make a serious effort to learn it...\nEntire issue available at rweekly.org/2022-W23\n\nSupplement Resources\n\nMore people use Tcl than know about it (2004) https://www.computerweekly.com/feature/More-people-use-Tcl-than-know-about-it\nThe R Tcl/Tk Interface paper by Peter Dalgaard: https://www.r-project.org/conferences/DSC-2001/Proceedings/Dalgaard.pdf\nMike FC's tickle annoucement tweet https://twitter.com/coolbutuseless/status/1532593976422805505\nMike FC's take on why tickle? https://twitter.com/coolbutuseless/status/1533685352451301376\nR for data science learning community https://www.rfordatasci.com"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_23_highlights",
        "links": "https://twitter.com/parmsam_"
      },
      {
        "ep_name": "issue_2022_w_23_highlights",
        "links": "https://github.com/coolbutuseless/tickle"
      },
      {
        "ep_name": "issue_2022_w_23_highlights",
        "links": "https://www.brodrigues.co/blog/2022-06-02-arcane/"
      },
      {
        "ep_name": "issue_2022_w_23_highlights",
        "links": "https://rweekly.org/2022-W23.html"
      },
      {
        "ep_name": "issue_2022_w_23_highlights",
        "links": "https://www.computerweekly.com/feature/More-people-use-Tcl-than-know-about-it"
      },
      {
        "ep_name": "issue_2022_w_23_highlights",
        "links": "https://www.r-project.org/conferences/DSC-2001/Proceedings/Dalgaard.pdf"
      },
      {
        "ep_name": "issue_2022_w_23_highlights",
        "links": "https://twitter.com/coolbutuseless/status/1532593976422805505"
      },
      {
        "ep_name": "issue_2022_w_23_highlights",
        "links": "https://twitter.com/coolbutuseless/status/1533685352451301376"
      },
      {
        "ep_name": "issue_2022_w_23_highlights",
        "links": "https://www.rfordatasci.com"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_23_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_22_highlights",
        "ep_date": "2022-06-01",
        "ep_duration": 42,
        "ep_description_short": "Annotated screencasts of David Robinson's Tidy Tuesday analyses, and the second edition of Deep Learning with R is on the way. Episode Links This week's curator: Batool Almarzouq (@batool664) (https://twitter.com/batool664) RScreencasts.com (https://www.rscreencasts.com/?ref=rweekly): A collection of 80+ hours of time-stamped, annotated…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_22_highlights",
        "description_long": "\r \r\n\nAnnotated screencasts of David Robinson's Tidy Tuesday analyses, and the second edition of Deep Learning with R is on the way.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq (@batool664)\nRScreencasts.com: A collection of 80+ hours of time-stamped, annotated TidyTuesday screencasts highlighting the R packages and functions used in each section and what the activity is. Screencasts by David Robinson. Annotation by Alex Cookson and Eric Fletcher. Website by Oscar Baruffa. For more detail, read the launch post.\nDeep Learning with R, 2nd Edition\nEntire issue available at rweekly.org/2022-W22\n\nSupplement Resources\n\nR DiscoRd community: https://discord.gg/FQp6ZNd\nDavid Granjon's preview of Outstanding User Interfaces with Shiny: https://twitter.com/divadnojnarg/status/1530710989574111232\nShiny Developer Series Episode 20: Outstanding User Interfaces with David Granjon https://shinydevseries.com/interview/ep020/"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_22_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2022_w_22_highlights",
        "links": "https://www.rscreencasts.com/?ref=rweekly"
      },
      {
        "ep_name": "issue_2022_w_22_highlights",
        "links": "https://oscarbaruffa.com/rscreencasts/?ref=rweekly"
      },
      {
        "ep_name": "issue_2022_w_22_highlights",
        "links": "https://blogs.rstudio.com/ai/posts/2022-05-31-deep-learning-with-r-2e/"
      },
      {
        "ep_name": "issue_2022_w_22_highlights",
        "links": "https://rweekly.org/2022-W22.html"
      },
      {
        "ep_name": "issue_2022_w_22_highlights",
        "links": "https://discord.gg/FQp6ZNd"
      },
      {
        "ep_name": "issue_2022_w_22_highlights",
        "links": "https://twitter.com/divadnojnarg/status/1530710989574111232"
      },
      {
        "ep_name": "issue_2022_w_22_highlights",
        "links": "https://shinydevseries.com/interview/ep020/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_22_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_21_highlights",
        "ep_date": "2022-05-25",
        "ep_duration": 11,
        "ep_description_short": "Amazing software development resources for data scientists, community-contributed R markdown tips & tricks to save you time, and combining GitHub gists and Carbon screenshots with gistillery. Episode Links This week's curator: Eric Nantz (@theRcast (https://twitter.com/thercast) Software Development Resources for Data Scientists…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_21_highlights",
        "description_long": "\r \r\n\nAmazing software development resources for data scientists, community-contributed R markdown tips & tricks to save you time, and combining GitHub gists and Carbon screenshots with gistillery.\n\nEpisode Links\n\nThis week's curator: Eric Nantz (@theRcast\nSoftware Development Resources for Data Scientists\nR Markdown Tips and Tricks #3: Time-savers & Trouble-shooters\ngistillery: Take local code, send it to a Github gist, get a beautiful image from Carbon.now.sh, and make it ready to share!\nEntire issue available at rweekly.org/2022-W21"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_21_highlights",
        "links": "https://twitter.com/thercast"
      },
      {
        "ep_name": "issue_2022_w_21_highlights",
        "links": "https://www.rstudio.com/blog/software-development-resources-for-data-scientists/"
      },
      {
        "ep_name": "issue_2022_w_21_highlights",
        "links": "https://www.rstudio.com/blog/r-markdown-tips-and-tricks-3-time-savers/"
      },
      {
        "ep_name": "issue_2022_w_21_highlights",
        "links": "https://jthomasmock.github.io/gistillery/"
      },
      {
        "ep_name": "issue_2022_w_21_highlights",
        "links": "https://rweekly.org/2022-W21.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_21_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_20_highlights",
        "ep_date": "2022-05-19",
        "ep_duration": 45,
        "ep_description_short": "A preview of R for Data Science (2nd edition) with missing data, creating topography maps, and (yes) playing the drums directly in R. Episode Links This week's curator: Kelly Bodwin (@KellyBodwin (https://twitter.com/KellyBodwin)) New r4ds chapter: missing values (https://r4ds.hadley.nz/missing-values.html) Making a crisp topography map with R…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_20_highlights",
        "description_long": "\r \r\n\nA preview of R for Data Science (2nd edition) with missing data, creating topography maps, and (yes) playing the drums directly in R.\n\nEpisode Links\n\nThis week's curator: Kelly Bodwin (@KellyBodwin)\nNew r4ds chapter: missing values\nMaking a crisp topography map with R\n{tr808r}: Play the drums with an R package\nEntire issue available at rweekly.org/2022-W20\n\nSupplement Resources\n\nhttps://en.wikipedia.org/wiki/Roland_TR-808"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_20_highlights",
        "links": "https://twitter.com/KellyBodwin"
      },
      {
        "ep_name": "issue_2022_w_20_highlights",
        "links": "https://r4ds.hadley.nz/missing-values.html"
      },
      {
        "ep_name": "issue_2022_w_20_highlights",
        "links": "https://milospopovic.net/crisp-topography-map-with-r/"
      },
      {
        "ep_name": "issue_2022_w_20_highlights",
        "links": "https://github.com/coolbutuseless/tr808r"
      },
      {
        "ep_name": "issue_2022_w_20_highlights",
        "links": "https://rweekly.org/2022-W20.html"
      },
      {
        "ep_name": "issue_2022_w_20_highlights",
        "links": "https://en.wikipedia.org/wiki/Roland_TR-808"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_20_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_19_highlights",
        "ep_date": "2022-05-11",
        "ep_duration": 17,
        "ep_description_short": "A dungeon-crawler for your R console, storytelling in ggplot2 with rounded rectangles, and updates to the tidymodels recipes suite of packages. Episode Links This week's curator: Colin Fay (@_colinFay (https://twitter.com/_colinfay)) Simple procedural dungeons in R (https://www.rostrum.blog/2022/05/01/dungeon/) Storytelling in ggplot using rounded…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_19_highlights",
        "description_long": "\r \r\n\nA dungeon-crawler for your R console, storytelling in ggplot2 with rounded rectangles, and updates to the tidymodels recipes suite of packages.\n\nEpisode Links\n\nThis week's curator: Colin Fay (@_colinFay)\nSimple procedural dungeons in R\nStorytelling in ggplot using rounded rectangles\nUpdates for recipes extension packages\nEntire issue available at rweekly.org/2022-W19\n\nSupplement Resources\n\nBinder - Turn a Git repo into a collection of interactive notebooks https://mybinder.org\nR-Podcast Episode 28 - Tidymodels with Max Kuhn https://r-podcast.org/028-max-kuhn"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_19_highlights",
        "links": "https://twitter.com/_colinfay"
      },
      {
        "ep_name": "issue_2022_w_19_highlights",
        "links": "https://www.rostrum.blog/2022/05/01/dungeon/"
      },
      {
        "ep_name": "issue_2022_w_19_highlights",
        "links": "https://albert-rapp.de/post/2022-05-01-use-grobs-to-get-rounded-corners/"
      },
      {
        "ep_name": "issue_2022_w_19_highlights",
        "links": "https://www.tidyverse.org/blog/2022/05/recipes-update-05-20222/"
      },
      {
        "ep_name": "issue_2022_w_19_highlights",
        "links": "https://rweekly.org/2022-W19.html"
      },
      {
        "ep_name": "issue_2022_w_19_highlights",
        "links": "https://mybinder.org"
      },
      {
        "ep_name": "issue_2022_w_19_highlights",
        "links": "https://r-podcast.org/028-max-kuhn"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_19_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_18_highlights",
        "ep_date": "2022-05-05",
        "ep_duration": 43,
        "ep_description_short": "A brand-new tables gallery powered by the R community, noteworthy items from the Appsilon Shiny conference, and R-Markdown is not going anywhere. Episode Links This week's curator: Eric Nantz (@theRcast (https://twitter.com/thercast)) RStudio Community Table Gallery (https://www.rstudio.com/blog/rstudio-community-table-gallery/) shinytest2, Rhino…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_18_highlights",
        "description_long": "\r \r\n\nA brand-new tables gallery powered by the R community, noteworthy items from the Appsilon Shiny conference, and R-Markdown is not going anywhere.\n\nEpisode Links\n\nThis week's curator: Eric Nantz (@theRcast)\nRStudio Community Table Gallery\nshinytest2, Rhino R Shiny framework top news at Appsilon conference\nWith Quarto coming, is R Markdown going away? No.\nEntire issue available at rweekly.org/2022-W18\n\nSupplement Resources\n\nhttps://community.rstudio.com/t/expected-goals-xg-shot-timeline-for-soccer-football-with-gt/86449\nhttps://community.rstudio.com/t/conditionally-formatted-state-transition-matrices/120336\nhttps://www.rstudio.com/champion\nR-Podcast episode 24 (Yihui Xie returns) https://r-podcast.org/024-rstudioconf-yihui-xie"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_18_highlights",
        "links": "https://twitter.com/thercast"
      },
      {
        "ep_name": "issue_2022_w_18_highlights",
        "links": "https://www.rstudio.com/blog/rstudio-community-table-gallery/"
      },
      {
        "ep_name": "issue_2022_w_18_highlights",
        "links": "https://www.infoworld.com/article/3658981/shinytest2-rhino-r-shiny-framework-top-news-at-appsilon-conference.html"
      },
      {
        "ep_name": "issue_2022_w_18_highlights",
        "links": "https://yihui.org/en/2022/04/quarto-r-markdown/"
      },
      {
        "ep_name": "issue_2022_w_18_highlights",
        "links": "https://rweekly.org/2022-W18.html"
      },
      {
        "ep_name": "issue_2022_w_18_highlights",
        "links": "https://community.rstudio.com/t/expected-goals-xg-shot-timeline-for-soccer-football-with-gt/86449"
      },
      {
        "ep_name": "issue_2022_w_18_highlights",
        "links": "https://community.rstudio.com/t/conditionally-formatted-state-transition-matrices/120336"
      },
      {
        "ep_name": "issue_2022_w_18_highlights",
        "links": "https://www.rstudio.com/champion"
      },
      {
        "ep_name": "issue_2022_w_18_highlights",
        "links": "https://r-podcast.org/024-rstudioconf-yihui-xie"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_18_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_17_highlights",
        "ep_date": "2022-04-27",
        "ep_duration": 55,
        "ep_description_short": "Lessons from teaching R to non-programmers, loading a large and messy CSV file with data.table and command-line tools, Bayesian analyses with the brms package, and getting a better understanding of the tidyeval framework. Episode Links This week's curator: Jonathan Carroll (@carroll_jono (https://twitter.com/carroll_jono)) 6 Lessons I learned from…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_17_highlights",
        "description_long": "\r \r\n\nLessons from teaching R to non-programmers, loading a large and messy CSV file with data.table and command-line tools, Bayesian analyses with the brms package, and getting a better understanding of the tidyeval framework.\n\nEpisode Links\n\nThis week's curator: Jonathan Carroll (@carroll_jono)\n6 Lessons I learned from teaching R to non-programmers\nLoading a large, messy csv using data.table fread with cli tools\nBayesian analyses made easy: GLMMs in R package brms\nNot so standard evaluations - Getting a better understanding of the tidyeval framework\nEntire issue available at rweekly.org/2022-W17\n\nSupplement Resources\n\nData science at the command line\nLearning Bayesian statistics podcast\nBayes Rules! An Introduction to Applied Bayesian Modeling"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_17_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2022_w_17_highlights",
        "links": "https://albert-rapp.de/post/2022-04-15-lessons-learned-from-teaching-nonprogrammers/"
      },
      {
        "ep_name": "issue_2022_w_17_highlights",
        "links": "https://redwallanalytics.com/2022/04/21/loading-a-large-messy-csv-using-data-table-fread-with-cli-tools/"
      },
      {
        "ep_name": "issue_2022_w_17_highlights",
        "links": "https://oliviergimenez.github.io/blog/glmm-brms/"
      },
      {
        "ep_name": "issue_2022_w_17_highlights",
        "links": "https://lukas-r.blog/posts/2022-04-20-not-so-standard-evaluations/"
      },
      {
        "ep_name": "issue_2022_w_17_highlights",
        "links": "https://rweekly.org/2022-W17.html"
      },
      {
        "ep_name": "issue_2022_w_17_highlights",
        "links": "https://datascienceatthecommandline.com"
      },
      {
        "ep_name": "issue_2022_w_17_highlights",
        "links": "https://www.learnbayesstats.com"
      },
      {
        "ep_name": "issue_2022_w_17_highlights",
        "links": "https://www.bayesrulesbook.com"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_17_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_16_highlights",
        "ep_date": "2022-04-20",
        "ep_duration": 53,
        "ep_description_short": "An important change coming to the R-spatial ecosystem, enhancing function error reporting with chaining, and traveling down the monad rabbit hole. Episode Links This week's curator: Tony ElHabr (@TonyElHabr (https://twitter.com/TonyElHabr)) R-spatial evolution: retirement of rgdal, rgeos and maptools…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_16_highlights",
        "description_long": "\r \r\n\nAn important change coming to the R-spatial ecosystem, enhancing function error reporting with chaining, and traveling down the monad rabbit hole.\n\nEpisode Links\n\nThis week's curator: Tony ElHabr (@TonyElHabr)\nR-spatial evolution: retirement of rgdal, rgeos and maptools\nError chaining\nWhy you should(n't) care about Monads if you're an R programmer\nEntire issue available at rweekly.org/2022-W16\n\nSupplement Resources\n\nRoger Bivand's announcement of the rgdal, rgeos, and maptools packages retirement\nGeocomputation with R\nProgress in the R ecosystem for representing and handling spatial data\nRweekly Highlights episode 72\nBruno Rodregues' monads YouTube video\n\"Function Factories\" Chapter in Advanced R"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_16_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2022_w_16_highlights",
        "links": "https://r-spatial.org//r/2022/04/12/evolution.html"
      },
      {
        "ep_name": "issue_2022_w_16_highlights",
        "links": "https://thisisnic.github.io/2022/04/09/error-chaining/"
      },
      {
        "ep_name": "issue_2022_w_16_highlights",
        "links": "https://www.brodrigues.co/blog/2022-04-11-monads/"
      },
      {
        "ep_name": "issue_2022_w_16_highlights",
        "links": "https://rweekly.org/2022-W16.html"
      },
      {
        "ep_name": "issue_2022_w_16_highlights",
        "links": "https://stat.ethz.ch/pipermail/r-sig-geo/2021-September/028760.html"
      },
      {
        "ep_name": "issue_2022_w_16_highlights",
        "links": "https://geocompr.robinlovelace.net"
      },
      {
        "ep_name": "issue_2022_w_16_highlights",
        "links": "https://link.springer.com/article/10.1007/s10109-020-00336-0"
      },
      {
        "ep_name": "issue_2022_w_16_highlights",
        "links": "https://rweekly.fireside.fm/72"
      },
      {
        "ep_name": "issue_2022_w_16_highlights",
        "links": "https://www.youtube.com/watch?v=Hlypj6-n51c"
      },
      {
        "ep_name": "issue_2022_w_16_highlights",
        "links": "https://adv-r.hadley.nz/function-factories.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_16_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_15_highlights",
        "ep_date": "2022-04-13",
        "ep_duration": 28,
        "ep_description_short": "The cone of silence is lifted for the Quarto publishing engine, re-creating a storytelling look with ggplot2, and programming a fun Dragon Realm game in Shiny. Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder)) We don't talk about Quarto…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_15_highlights",
        "description_long": "\r \r\n\nThe cone of silence is lifted for the Quarto publishing engine, re-creating a storytelling look with ggplot2, and programming a fun Dragon Realm game in Shiny.\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder)\nWe don't talk about Quarto\nRecreating the Storytelling with Data look with ggplot\nProgramming Games with Shiny - Dragon Realm\nEntire issue available at rweekly.org/2022-W15\n\nSupplement Resources\n\nRecordings of Nic Wan's Viz Buzz online graph competition on YouTube\nFlowchart Diagrams in GitHub\nQuarto GitHub discussion board\nImprove this graph! Storytelling with data YouTube video\nCRAN task views ctv package GitHub repository"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_15_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2022_w_15_highlights",
        "links": "https://www.apreshill.com/blog/2022-04-we-dont-talk-about-quarto/"
      },
      {
        "ep_name": "issue_2022_w_15_highlights",
        "links": "https://albert-rapp.de/post/2022-03-29-recreating-the-swd-look/"
      },
      {
        "ep_name": "issue_2022_w_15_highlights",
        "links": "https://www.youtube.com/watch?v=sD39WAZo99A"
      },
      {
        "ep_name": "issue_2022_w_15_highlights",
        "links": "https://rweekly.org/2022-W15.html"
      },
      {
        "ep_name": "issue_2022_w_15_highlights",
        "links": "https://www.youtube.com/playlist?list=PL6PX3YIZuHhwZ-C-jZ427D-XkLGNWFPVB"
      },
      {
        "ep_name": "issue_2022_w_15_highlights",
        "links": "https://github.blog/2022-02-14-include-diagrams-markdown-files-mermaid/"
      },
      {
        "ep_name": "issue_2022_w_15_highlights",
        "links": "https://github.com/quarto-dev/quarto-cli/discussions"
      },
      {
        "ep_name": "issue_2022_w_15_highlights",
        "links": "https://www.youtube.com/watch?v=st7_vPjq0SU"
      },
      {
        "ep_name": "issue_2022_w_15_highlights",
        "links": "https://github.com/cran-task-views/ctv"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_15_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_14_highlights",
        "ep_date": "2022-04-06",
        "ep_duration": 56,
        "ep_description_short": "A trifecta of new R packages for data validation, function logging, and a new ggplot2 extension. Episode Links This week's curator: Ryo Nakagawara (@RbyRyo (https://twitter.com/R_by_Ryo)) Exemplar: a prototype R package for data validation (https://mdneuzerling.com/post/exemplar-a-prototype-r-package-for-data-validation/) {chronicler} 0.1…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_14_highlights",
        "description_long": "\r \r\n\nA trifecta of new R packages for data validation, function logging, and a new ggplot2 extension.\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara (@R_by_Ryo)\nExemplar: a prototype R package for data validation\n{chronicler} 0.1: Implementation of the logger monad in R.\n{ggbraid} 0.1.0: Braid two lines and a ribbon in ggplot2.\n\nSupplement Resources\n\nMonads: https://ericlippert.com/category/monads/page/2/\nEpisode 62: https://rweekly.fireside.fm/62\nggbraid vignette: https://nsgrantham.github.io/ggbraid/articles/hoops.html"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_14_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2022_w_14_highlights",
        "links": "https://mdneuzerling.com/post/exemplar-a-prototype-r-package-for-data-validation/"
      },
      {
        "ep_name": "issue_2022_w_14_highlights",
        "links": "https://www.brodrigues.co/blog/2022-04-04-chron_post/"
      },
      {
        "ep_name": "issue_2022_w_14_highlights",
        "links": "https://github.com/nsgrantham/ggbraid"
      },
      {
        "ep_name": "issue_2022_w_14_highlights",
        "links": "https://ericlippert.com/category/monads/page/2/"
      },
      {
        "ep_name": "issue_2022_w_14_highlights",
        "links": "https://rweekly.fireside.fm/62"
      },
      {
        "ep_name": "issue_2022_w_14_highlights",
        "links": "https://nsgrantham.github.io/ggbraid/articles/hoops.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_14_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2022_w_13_highlights",
        "ep_date": "2022-03-30",
        "ep_duration": 15,
        "ep_description_short": "After a brief hiatus, the R-Weekly Highlights podcast is back! In this episode we discuss: Understanding the native R pipe, and using RopenSci's pkgcheck within GitHub Actions. Episode Links This week's curators: Ryo Nakagawara (@RbyRyo (https://twitter.com/R_by_Ryo)) and Batool Almarzouq (@batool664) (https://twitter.com/batool664) Understanding…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2022_w_13_highlights",
        "description_long": "\r \r\n\nAfter a brief hiatus, the R-Weekly Highlights podcast is back! In this episode we discuss: Understanding the native R pipe, and using RopenSci's pkgcheck within GitHub Actions.\n\nEpisode Links\n\nThis week's curators: Ryo Nakagawara (@R_by_Ryo) and Batool Almarzouq (@batool664)\nUnderstanding the native R pipe |>\npkgcheck now available as a GitHub action!\nEntire issue available at rweekly.org/2022-W13\n\nSupplement Resources\n\nEpisode 60: https://rweekly.fireside.fm/60\nGitHub Actions for the R Community: https://github.com/r-lib/actions/\nAppsilon Shiny Conference: https://appsilon.com/2022-appsilon-shiny-conference\nShiny Developer Series episode 30 - The Connecticut COVID-19 Test Spotter App (Part 1): https://shinydevseries.com/ep30"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2022_w_13_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2022_w_13_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2022_w_13_highlights",
        "links": "https://ivelasq.rbind.io/blog/understanding-the-r-pipe/"
      },
      {
        "ep_name": "issue_2022_w_13_highlights",
        "links": "https://ropensci.org/blog/2022/02/01/pkgcheck-action/"
      },
      {
        "ep_name": "issue_2022_w_13_highlights",
        "links": "https://rweekly.org/2022-W13.html"
      },
      {
        "ep_name": "issue_2022_w_13_highlights",
        "links": "https://rweekly.fireside.fm/60"
      },
      {
        "ep_name": "issue_2022_w_13_highlights",
        "links": "https://github.com/r-lib/actions/"
      },
      {
        "ep_name": "issue_2022_w_13_highlights",
        "links": "https://appsilon.com/2022-appsilon-shiny-conference"
      },
      {
        "ep_name": "issue_2022_w_13_highlights",
        "links": "https://shinydevseries.com/ep30"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2022_w_13_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "update_on_rweekly_and_2021_reflections",
        "ep_date": "2022-01-14",
        "ep_duration": 30,
        "ep_description_short": "An update on the current state of RWeekly, plus Eric and Mike reflect on their journeys with data science from the industry and consulting perspectives in an eventful 2021! Episode Links The very first issue of RWeekly: https://rweekly.org/issue-0.html R for Data Science Learning Community: https://www.rfordatasci.com discoRd:…"
      }
    ],
    "description_long": [
      {
        "ep_name": "update_on_rweekly_and_2021_reflections",
        "description_long": "\r \r\n\nAn update on the current state of RWeekly, plus Eric and Mike reflect on their journeys with data science from the industry and consulting perspectives in an eventful 2021!\n\nEpisode Links\n\nThe very first issue of RWeekly: https://rweekly.org/issue-0.html\nR for Data Science Learning Community: https://www.rfordatasci.com\ndiscoRd: https://www.r-discord.com/home\nAnalytics Power Hour Episode 184 - Psychological Safety and Analytics with J.D. Long: https://analyticshour.io/2022/01/11/184-psychological-safety-and-analytics-with-j-d-long/\nGitHub Project Boards: https://docs.github.com/en/issues/trying-out-the-new-projects-experience/about-projects"
      }
    ],
    "links": [
      {
        "ep_name": "update_on_rweekly_and_2021_reflections",
        "links": "https://rweekly.org/issue-0.html"
      },
      {
        "ep_name": "update_on_rweekly_and_2021_reflections",
        "links": "https://www.rfordatasci.com"
      },
      {
        "ep_name": "update_on_rweekly_and_2021_reflections",
        "links": "https://www.r-discord.com/home"
      },
      {
        "ep_name": "update_on_rweekly_and_2021_reflections",
        "links": "https://analyticshour.io/2022/01/11/184-psychological-safety-and-analytics-with-j-d-long/"
      },
      {
        "ep_name": "update_on_rweekly_and_2021_reflections",
        "links": "https://docs.github.com/en/issues/trying-out-the-new-projects-experience/about-projects"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "update_on_rweekly_and_2021_reflections"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_50_highlights",
        "ep_date": "2021-12-15",
        "ep_duration": 34,
        "ep_description_short": "A batch of Shiny tips from creating an application tailored to teaching statistics, and the Big Book of R gains nine new entries to the collection. Episode Links This week's curator: Batool Almarzouq (@batool664) (https://twitter.com/batool664) 6 simple Shiny things I have learned from creating a somewhat small app…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_50_highlights",
        "description_long": "\r \r\n\nA batch of Shiny tips from creating an application tailored to teaching statistics, and the Big Book of R gains nine new entries to the collection.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq (@batool664)\n6 simple Shiny things I have learned from creating a somewhat small app\n9 new books added to Big Book of R - In this release there’s 9 new books which covers the widest range of topics of any release to date.\nEntire issue available at rweekly.org/2021-W50\n\nSupplement Resources\n\nAlbert Rapp's YouTube channel\nR Development Guide\nDevOps for Data Science\nHandbook of Graphs and Networks in People Analytics\nHiring Data Scientists and Machine Learning Engineers\n\"Introducing {admiral}\" presentation at R/Pharma 2021"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_50_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2021_w_50_highlights",
        "links": "https://albert-rapp.de/post/2021-11-21-a-few-learnings-from-a-simple-shiny-app/"
      },
      {
        "ep_name": "issue_2021_w_50_highlights",
        "links": "https://oscarbaruffa.com/bbofr_2021-06-12/"
      },
      {
        "ep_name": "issue_2021_w_50_highlights",
        "links": "https://rweekly.org/2021-W50.html"
      },
      {
        "ep_name": "issue_2021_w_50_highlights",
        "links": "https://www.youtube.com/channel/UCdFC653IaBVC5kwj7CGo2sQ"
      },
      {
        "ep_name": "issue_2021_w_50_highlights",
        "links": "https://forwards.github.io/rdevguide/"
      },
      {
        "ep_name": "issue_2021_w_50_highlights",
        "links": "https://akgold.github.io/do4ds/index.html"
      },
      {
        "ep_name": "issue_2021_w_50_highlights",
        "links": "https://ona-book.org/index.html"
      },
      {
        "ep_name": "issue_2021_w_50_highlights",
        "links": "https://dshiring.com/"
      },
      {
        "ep_name": "issue_2021_w_50_highlights",
        "links": "https://www.youtube.com/watch?v=N7Bw8c3D5fU"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_50_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_49_highlights",
        "ep_date": "2021-12-09",
        "ep_duration": 13,
        "ep_description_short": "A fascinating journey to understand serialization of RDS files in R, and giving an old domain new life with R markdown while giving back to charity. Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder)) Data serialisation in R (https://blog.djnavarro.net/posts/2021-11-15_serialisation-with-rds/) Day 02:…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_49_highlights",
        "description_long": "\r \r\n\nA fascinating journey to understand serialization of RDS files in R, and giving an old domain new life with R markdown while giving back to charity.\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder)\nData serialisation in R\nDay 02: Postcards with distill || rmarkdown + postcards + distill + Netlify || #12daysofdusting\nEntire issue available at rweekly.org/2021-W49\n\nSupplement Resources\n\nhttps://www.netlify.com/blog/2021/12/01/dusty-domains-your-forgotten-domains-raise-money-for-charity\nhttps://dusty.domains/"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_49_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2021_w_49_highlights",
        "links": "https://blog.djnavarro.net/posts/2021-11-15_serialisation-with-rds/"
      },
      {
        "ep_name": "issue_2021_w_49_highlights",
        "links": "https://www.youtube.com/watch?v=fPSWqdJr_EY"
      },
      {
        "ep_name": "issue_2021_w_49_highlights",
        "links": "https://rweekly.org/2021-W49.html"
      },
      {
        "ep_name": "issue_2021_w_49_highlights",
        "links": "https://www.netlify.com/blog/2021/12/01/dusty-domains-your-forgotten-domains-raise-money-for-charity"
      },
      {
        "ep_name": "issue_2021_w_49_highlights",
        "links": "https://dusty.domains/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_49_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_48_highlights",
        "ep_date": "2021-12-01",
        "ep_duration": 2,
        "ep_description_short": "How GitHub Actions empowers the {cffr} package to perform automated testing with 2,000 packages, recap of the recent R-Ladies Philly workshop on automated testing in R, and introducing the new {filebin} package for easy file sharing. Episode Links This week's curator: Colin Fay (@_colinFay (https://twitter.com/_colinfay)) How I Test cffr on (about)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_48_highlights",
        "description_long": "\r \r\n\nHow GitHub Actions empowers the {cffr} package to perform automated testing with 2,000 packages, recap of the recent R-Ladies Philly workshop on automated testing in R, and introducing the new {filebin} package for easy file sharing.\n\nEpisode Links\n\nThis week's curator: Colin Fay (@_colinFay)\nHow I Test cffr on (about) 2,000 Packages using GitHub Actions and R-universe\nGetting started with unit testing in R\n{filebin} Quick & Easy File Sharing\nEntire issue available at rweekly.org/2021-W48\n\nSupplement Resources\n\nIssue 2021-W47 https://rweekly.org/2021-W47.html\nGitHub Actions for the R language"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_48_highlights",
        "links": "https://twitter.com/_colinfay"
      },
      {
        "ep_name": "issue_2021_w_48_highlights",
        "links": "https://ropensci.org/blog/2021/11/23/how-i-test-cffr/"
      },
      {
        "ep_name": "issue_2021_w_48_highlights",
        "links": "https://www.pipinghotdata.com/posts/2021-11-23-getting-started-with-unit-testing-in-r/"
      },
      {
        "ep_name": "issue_2021_w_48_highlights",
        "links": "https://datawookie.dev/blog/2021/11/filebin-quick-easy-file-sharing/"
      },
      {
        "ep_name": "issue_2021_w_48_highlights",
        "links": "https://rweekly.org/2021-W48.html"
      },
      {
        "ep_name": "issue_2021_w_48_highlights",
        "links": "https://rweekly.org/2021-W47.html"
      },
      {
        "ep_name": "issue_2021_w_48_highlights",
        "links": "https://github.com/r-lib/actions"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_48_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_46_highlights",
        "ep_date": "2021-11-17",
        "ep_duration": 9,
        "ep_description_short": "A cautionary tale about ML interpretations with food, practical solutions for dealing with big data in R, and the adventures of installing R on the new Apple Silicon hardware. Episode Links This week's curator: Tony Elhabr (@TonyElHabr (https://twitter.com/TonyElHabr) Why machine learning hates vegetables (a dialogue about Zillow)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_46_highlights",
        "description_long": "\r \r\n\nA cautionary tale about ML interpretations with food, practical solutions for dealing with big data in R, and the adventures of installing R on the new Apple Silicon hardware.\n\nEpisode Links\n\nThis week's curator: Tony Elhabr (@TonyElHabr\nWhy machine learning hates vegetables (a dialogue about Zillow)\nShould I Move to a Database?\nTransitioning from x86 to arm64 on macOS - experiences of an R user\nEntire issue available at rweekly.org/2021-W46\n\nSupplement Resources\n\nBuilding code movies with flipbookr\nA guide to modeling proportions with Bayesian beta and zero-inflated beta regression models by Andrew Heiss"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_46_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2021_w_46_highlights",
        "links": "https://emilyriederer.netlify.app/post/ml-vegetables/"
      },
      {
        "ep_name": "issue_2021_w_46_highlights",
        "links": "https://blog.rmhogervorst.nl/blog/2021/11/08/should-i-move-to-a-database/"
      },
      {
        "ep_name": "issue_2021_w_46_highlights",
        "links": "https://pat-s.me/transitioning-from-x86-to-arm64-on-macos-experiences-of-an-r-user/"
      },
      {
        "ep_name": "issue_2021_w_46_highlights",
        "links": "https://rweekly.org/2021-W46.html"
      },
      {
        "ep_name": "issue_2021_w_46_highlights",
        "links": "https://www.rstudio.com/blog/building-code-movies-with-flipbookr"
      },
      {
        "ep_name": "issue_2021_w_46_highlights",
        "links": "https://www.andrewheiss.com/blog/2021/11/08/beta-regression-guide/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_46_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_45_highlights",
        "ep_date": "2021-11-10",
        "ep_duration": 59,
        "ep_description_short": "A lesser-known R function drives finding coordinates on fictitious Pokemon maps, creating customized point shapes with ggplot2 and gggrid, and how the branchMover Shiny app can save you a load of time and effort with GitHub branch renaming. Episode Links This week's curator: Miles McBain (@MilesMcBain (https://twitter.com/MilesMcBain)) Get…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_45_highlights",
        "description_long": "\r \r\n\nA lesser-known R function drives finding coordinates on fictitious Pokemon maps, creating customized point shapes with ggplot2 and gggrid, and how the branchMover Shiny app can save you a load of time and effort with GitHub branch renaming.\n\nEpisode Links\n\nThis week's curator: Miles McBain (@MilesMcBain)\nGet coordinates from fictitious maps\nCustom {ggplot2} point shapes with {gggrid}\nbranchMover: A Shiny app for moving the default branch of your GitHub repos\nEntire issue available at rweekly.org/2021-W45\n\nSupplement Resources\n\nUsing {arrow} + {shiny}"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_45_highlights",
        "links": "https://twitter.com/MilesMcBain"
      },
      {
        "ep_name": "issue_2021_w_45_highlights",
        "links": "https://www.rostrum.blog/2021/11/04/kanto-locator/"
      },
      {
        "ep_name": "issue_2021_w_45_highlights",
        "links": "https://coolbutuseless.github.io/2021/11/04/custom-ggplot2-point-shapes-with-gggrid/"
      },
      {
        "ep_name": "issue_2021_w_45_highlights",
        "links": "https://www.garrickadenbuie.com/blog/branchmover/"
      },
      {
        "ep_name": "issue_2021_w_45_highlights",
        "links": "https://rweekly.org/2021-W45.html"
      },
      {
        "ep_name": "issue_2021_w_45_highlights",
        "links": "https://github.com/mthomas-ketchbrook/shiny_arrow"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_45_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_44_highlights",
        "ep_date": "2021-11-03",
        "ep_duration": 42,
        "ep_description_short": "An analysis of dialogue from \"The Office\", and a package promoting accessibility for visually impaired R-Users. Episode Links This week's curator: Wolfram Qin Analyzing The Office's dialogues (https://daniloderosa.com/blog/theoffice/) {BrailleR} 0.32.1 (https://cran.r-project.org/package=BrailleR): Improved Access for Blind Users Entire issue…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_44_highlights",
        "description_long": "\r \r\n\nAn analysis of dialogue from \"The Office\", and a package promoting accessibility for visually impaired R-Users.\n\nEpisode Links\n\nThis week's curator: Wolfram Qin\nAnalyzing The Office's dialogues\n{BrailleR} 0.32.1: Improved Access for Blind Users\nEntire issue available at rweekly.org/2021-W44\n\nSupplement Resources\n\n{schrute} package by Brad Lindlad\nDanilo's data viz portfolio\nThe Pudding data viz publication\nSilicon Valley Hot Dog Scene\nJooYoung Seo's Talk at RStudio::Global"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_44_highlights",
        "links": "https://daniloderosa.com/blog/theoffice/"
      },
      {
        "ep_name": "issue_2021_w_44_highlights",
        "links": "https://cran.r-project.org/package=BrailleR"
      },
      {
        "ep_name": "issue_2021_w_44_highlights",
        "links": "https://rweekly.org/2021-W44.html"
      },
      {
        "ep_name": "issue_2021_w_44_highlights",
        "links": "https://bradlindblad.github.io/schrute/"
      },
      {
        "ep_name": "issue_2021_w_44_highlights",
        "links": "https://daniloderosa.com/portfolio/"
      },
      {
        "ep_name": "issue_2021_w_44_highlights",
        "links": "https://pudding.cool/"
      },
      {
        "ep_name": "issue_2021_w_44_highlights",
        "links": "https://www.youtube.com/watch?v=vIci3C4JkL0"
      },
      {
        "ep_name": "issue_2021_w_44_highlights",
        "links": "https://youtu.be/0HvyNtltu-A?t=151"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_44_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_43_highlights",
        "ep_date": "2021-10-27",
        "ep_duration": 23,
        "ep_description_short": "A tutorial on getting started with aRtistry, simulating the Squid Game bridge scene, and a video demonstration of installing Shiny server on AWS. Episode Links This week's curator: Kelly Bodwin (@KellyBodwin (https://twitter.com/KellyBodwin)) Simulating the Squid Game Bridge Scene…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_43_highlights",
        "description_long": "\r \r\n\nA tutorial on getting started with aRtistry, simulating the Squid Game bridge scene, and a video demonstration of installing Shiny server on AWS.\n\nEpisode Links\n\nThis week's curator: Kelly Bodwin (@KellyBodwin)\nSimulating the Squid Game Bridge Scene\nThinking outside the grid - A \"bare bones\" introduction to Rtistry concepts in R using ggplot\nTBD, but likely a Shiny server video tutorial https://www.youtube.com/watch?v=JL4T0qfqY7k\nEntire issue available at rweekly.org/2021-W43\n\nSupplement Resources\n\n\"Hosting Data Apps\" Blog by Analythium\nMeghan Harris' website, The Tidy Trekker"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_43_highlights",
        "links": "https://twitter.com/KellyBodwin"
      },
      {
        "ep_name": "issue_2021_w_43_highlights",
        "links": "https://www.jhelvy.com/posts/2021-10-19-monte-carlo-bridge-game/"
      },
      {
        "ep_name": "issue_2021_w_43_highlights",
        "links": "https://www.thetidytrekker.com/post/thinking-outside-the-grid"
      },
      {
        "ep_name": "issue_2021_w_43_highlights",
        "links": "https://www.youtube.com/watch?v=JL4T0qfqY7k"
      },
      {
        "ep_name": "issue_2021_w_43_highlights",
        "links": "https://rweekly.org/2021-W43.html"
      },
      {
        "ep_name": "issue_2021_w_43_highlights",
        "links": "https://hosting.analythium.io/"
      },
      {
        "ep_name": "issue_2021_w_43_highlights",
        "links": "https://www.thetidytrekker.com/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_43_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_42_highlights",
        "ep_date": "2021-10-20",
        "ep_duration": 1,
        "ep_description_short": "A major announcement for R developers interested in type safety, thoughts on using Visual Studio Code from the perspective of a long-time RStudio user, and the adventures of filling regions between lines with ggplot2. Episode Links This week's curator: Ryo Nakagawara (@RbyRyo (https://twitter.com/R_by_Ryo)) Introducing rpp: The long-term goal of…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_42_highlights",
        "description_long": "\r \r\n\nA major announcement for R developers interested in type safety, thoughts on using Visual Studio Code from the perspective of a long-time RStudio user, and the adventures of filling regions between lines with ggplot2.\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara (@R_by_Ryo)\nIntroducing rpp: The long-term goal of the organisation is to add static type checking and other features to R, with zero cost at run time\nHow not to be lost with VSCode when coming from RStudio?\nFill the region between two lines in ggplot2\nEntire issue available at rweekly.org/2021-W42\n\nSupplement Resources\n\nType safety: https://en.wikipedia.org/wiki/Type_safety\nEric's R development repository: https://github.com/rpodcast/r_dev_projects\nVisual Studio Code R extension: https://github.com/REditorSupport/vscode-R\n\nLooking to provide feedback on this episode and the podcast in general? Feel free to get in touch with Mike (@mike_ketchbrook) or Eric (@theRcast) on Twitter!\n\n\r \r"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_42_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2021_w_42_highlights",
        "links": "https://blog.q-lang.org/posts/2021-10-13-release/"
      },
      {
        "ep_name": "issue_2021_w_42_highlights",
        "links": "https://statnmap.com/2021-10-09-how-not-to-be-lost-with-vscode-when-coming-from-rstudio/"
      },
      {
        "ep_name": "issue_2021_w_42_highlights",
        "links": "https://www.nsgrantham.com/fill-between-two-lines-ggplot2"
      },
      {
        "ep_name": "issue_2021_w_42_highlights",
        "links": "https://rweekly.org/2021-W42.html"
      },
      {
        "ep_name": "issue_2021_w_42_highlights",
        "links": "https://en.wikipedia.org/wiki/Type_safety"
      },
      {
        "ep_name": "issue_2021_w_42_highlights",
        "links": "https://github.com/rpodcast/r_dev_projects"
      },
      {
        "ep_name": "issue_2021_w_42_highlights",
        "links": "https://github.com/REditorSupport/vscode-R"
      },
      {
        "ep_name": "issue_2021_w_42_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2021_w_42_highlights",
        "links": "https://twitter.com/rpodcast"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_42_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_41_highlights",
        "ep_date": "2021-10-13",
        "ep_duration": 38,
        "ep_description_short": "Using the helpers from usethis for pull request workflows, 2021 New York R conference videos now available, and the origins of the newly released ggalignment package for D&D inspired alignments. Plus, a new era of the podcast begins with our new co-host Mike Thomas! Episode Links This week's curator: Eric Nantz (@theRcast…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_41_highlights",
        "description_long": "\r \r\n\nUsing the helpers from usethis for pull request workflows, 2021 New York R conference videos now available, and the origins of the newly released ggalignment package for D&D inspired alignments. Plus, a new era of the podcast begins with our new co-host Mike Thomas!\n\nEpisode Links\n\nThis week's curator: Eric Nantz (@theRcast)\nWelcome our brand new co-host Mike Thomas! (@mike_ketchbrook)\nPull Request Flow with usethis\n2021 New York R Conference Videos\n{ggalignment} 1.0.0: Plots 'D&D'-Style Alignment Charts\nEntire issue available at rweekly.org/2021-W41\n\nSupplement Resources\n\n{gert}: Simple Git client for R\nJared Lander's talk: GPU Computing in R\nMegan Robertson's talk: Creating Production-Level Data Science Code\nDungeons & Dragons alignment history on [Wikipedia](https://en.wikipedia.org/wiki/Alignment_(Dungeons_%26_Dragons)\nAfton Coombs' previous Twitch stream submitting {ggalignment} to CRAN!"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_41_highlights",
        "links": "https://twitter.com/thercast"
      },
      {
        "ep_name": "issue_2021_w_41_highlights",
        "links": "https://twitter.com/mike_ketchbrook"
      },
      {
        "ep_name": "issue_2021_w_41_highlights",
        "links": "https://www.garrickadenbuie.com/blog/pull-request-flow-usethis/"
      },
      {
        "ep_name": "issue_2021_w_41_highlights",
        "links": "https://www.youtube.com/playlist?list=PLlzRFZmxVl9RVwRP6WKOUXTiRMFkF2cPF"
      },
      {
        "ep_name": "issue_2021_w_41_highlights",
        "links": "https://cran.r-project.org/package=ggalignment"
      },
      {
        "ep_name": "issue_2021_w_41_highlights",
        "links": "https://rweekly.org/2021-W41.html"
      },
      {
        "ep_name": "issue_2021_w_41_highlights",
        "links": "https://docs.ropensci.org/gert"
      },
      {
        "ep_name": "issue_2021_w_41_highlights",
        "links": "https://youtu.be/fKWaErupNKE"
      },
      {
        "ep_name": "issue_2021_w_41_highlights",
        "links": "https://youtu.be/F3lC4qf84FI"
      },
      {
        "ep_name": "issue_2021_w_41_highlights",
        "links": "https://en.wikipedia.org/wiki/Alignment_(Dungeons_%26_Dragons)"
      },
      {
        "ep_name": "issue_2021_w_41_highlights",
        "links": "https://www.twitch.tv/videos/1159958423"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_41_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_40_highlights",
        "ep_date": "2021-10-06",
        "ep_duration": 50,
        "ep_description_short": "Parameterized reports in RMarkdown with Plumber, an updated history of the pipe operator in R, and creating data from an image with reticulate Episode Links This week's curator: Jonathan Carroll (@carroll_jono (https://twitter.com/carroll_jono)) The Power of Parameterized Reports With Plumber…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_40_highlights",
        "description_long": "\r \r\n\nParameterized reports in RMarkdown with Plumber, an updated history of the pipe operator in R, and creating data from an image with reticulate\n\nEpisode Links\n\nThis week's curator: Jonathan Carroll (@carroll_jono)\nThe Power of Parameterized Reports With Plumber\nPlumbers, chains, and famous painters: The (updated) history of the pipe operator in R\nCreating a Dataset from an Image in R Markdown using reticulate\nEntire issue available at rweekly.org/2021-W40"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_40_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2021_w_40_highlights",
        "links": "https://www.datalorax.com/post/power-parameterized-reports-plumber/"
      },
      {
        "ep_name": "issue_2021_w_40_highlights",
        "links": "http://adolfoalvarez.cl/blog/2021-09-16-plumbers-chains-and-famous-painters-the-history-of-the-pipe-operator-in-r/"
      },
      {
        "ep_name": "issue_2021_w_40_highlights",
        "links": "https://ivelasq.rbind.io/blog/reticulate-data-recreation/"
      },
      {
        "ep_name": "issue_2021_w_40_highlights",
        "links": "https://rweekly.org/2021-W40.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_40_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_39_highlights",
        "ep_date": "2021-09-30",
        "ep_duration": 43,
        "ep_description_short": "Data visualization accessibility, curating for R-Ladies, and a soccer data pipeline. Plus an annoucement on my goals for the future of the podcast. Episode Links This week's curator: Batool Almarzouq (@batool664) (https://twitter.com/batool664) Resources for Data Viz Accessibility…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_39_highlights",
        "description_long": "\r \r\n\nData visualization accessibility, curating for R-Ladies, and a soccer data pipeline. Plus an annoucement on my goals for the future of the podcast.\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq (@batool664)\nResources for Data Viz Accessibility\nCurating for @WeAreRLadies on Twitter\nCreating a data pipeline with Github Actions & the {googledrive} package for the Canadian Premier League soccer data initiative!\nEntire issue available at rweekly.org/2021-W39\n\nSupplement Resources\n\nRevealing Room for Improvement in Accessibility within a Social Media Data Visualization Learning Community\nWhy Accessibility is at the Heart of Data Visualization\nGrowing into the R community\n\nBecome a part of the R-Weekly Highlights podcast!\n\nI am looking for members of the community to join me in sharing their perspectives on the highlighted resources in future podcast episodes! If you are interested in learning more and possibly joining my efforts, please get in touch via my Twitter account (@theRcast) or via email: theRcast (at) gmail.com\n\n\r \r"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_39_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2021_w_39_highlights",
        "links": "https://silvia.rbind.io/blog/2021-curated-compilations/01-data-viz-a11y/"
      },
      {
        "ep_name": "issue_2021_w_39_highlights",
        "links": "https://www.pipinghotdata.com/posts/2021-09-23-curating-for-wearerladies-on-twitter/"
      },
      {
        "ep_name": "issue_2021_w_39_highlights",
        "links": "https://ryo-n7.github.io/2021-09-23-CanPL-GoogleDrive-GithubActions-Tutorial/"
      },
      {
        "ep_name": "issue_2021_w_39_highlights",
        "links": "https://rweekly.org/2021-W39.html"
      },
      {
        "ep_name": "issue_2021_w_39_highlights",
        "links": "https://silvia.rbind.io/talk/2021-05-04-data-viz-accessibility/"
      },
      {
        "ep_name": "issue_2021_w_39_highlights",
        "links": "https://medium.com/nightingale/accessibility-is-at-the-heart-of-data-visualization-64a38d6c505b"
      },
      {
        "ep_name": "issue_2021_w_39_highlights",
        "links": "https://www.youtube.com/watch?v=ozkJkiYxHGU"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_39_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_38_highlights",
        "ep_date": "2021-09-22",
        "ep_duration": 35,
        "ep_description_short": "Eras of MTV and system commands Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder)) Finding the Eras of MTV's The Challenge Through Clustering (https://jlaw.netlify.app/2021/09/15/finding-the-eras-of-mtv-s-the-challenge-through-clustering/) How to Use System Commands in your R Script or Package…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_38_highlights",
        "description_long": "\r \r\n\nEras of MTV and system commands\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder)\nFinding the Eras of MTV's The Challenge Through Clustering\nHow to Use System Commands in your R Script or Package\nEntire issue available at rweekly.org/2021-W38"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_38_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2021_w_38_highlights",
        "links": "https://jlaw.netlify.app/2021/09/15/finding-the-eras-of-mtv-s-the-challenge-through-clustering/"
      },
      {
        "ep_name": "issue_2021_w_38_highlights",
        "links": "https://ropensci.org/blog/2021/09/13/system-calls-r-package/"
      },
      {
        "ep_name": "issue_2021_w_38_highlights",
        "links": "https://rweekly.org/2021-W38.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_38_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_37_highlights",
        "ep_date": "2021-09-15",
        "ep_duration": 54,
        "ep_description_short": "Techniques for creating generative art in R, time tracking with clockify, and the four pipes of magrittr Episode Links This week's curator: Colin Faye (@_colinFay (https://twitter.com/_colinfay)) Art, jasmines, and the water colours (https://blog.djnavarro.net/posts/2021-09-07_water-colours/) {clockify} Time Tracking from R…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_37_highlights",
        "description_long": "\r \r\n\nTechniques for creating generative art in R, time tracking with clockify, and the four pipes of magrittr\n\nEpisode Links\n\nThis week's curator: Colin Faye (@_colinFay)\nArt, jasmines, and the water colours\n{clockify} Time Tracking from R\nThe Four Pipes of magrittr\nEntire issue available at rweekly.org/2021-W37\nView the entire process of recording this episode from the livestream recording on YouTube: https://www.youtube.com/watch?v=0MA_WT7IXL0\n\nSupplement resources\n\nhttps://www.cararthompson.com/posts/2021-09-10-setting-up-the-artfulbot/\n{rprojroot}: Finding files in project subdirectories"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_37_highlights",
        "links": "https://twitter.com/_colinfay"
      },
      {
        "ep_name": "issue_2021_w_37_highlights",
        "links": "https://blog.djnavarro.net/posts/2021-09-07_water-colours/"
      },
      {
        "ep_name": "issue_2021_w_37_highlights",
        "links": "https://datawookie.dev/blog/2021/09/clockify-time-tracking-from-r/"
      },
      {
        "ep_name": "issue_2021_w_37_highlights",
        "links": "https://data-and-the-world.onrender.com/posts/magrittr-pipes/"
      },
      {
        "ep_name": "issue_2021_w_37_highlights",
        "links": "https://rweekly.org/2021-W37.html"
      },
      {
        "ep_name": "issue_2021_w_37_highlights",
        "links": "https://www.youtube.com/watch?v=0MA_WT7IXL0"
      },
      {
        "ep_name": "issue_2021_w_37_highlights",
        "links": "https://www.cararthompson.com/posts/2021-09-10-setting-up-the-artfulbot/"
      },
      {
        "ep_name": "issue_2021_w_37_highlights",
        "links": "https://github.com/r-lib/rprojroot"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_37_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_36_highlights",
        "ep_date": "2021-09-08",
        "ep_duration": 52,
        "ep_description_short": "Elegant maps with tmap, a data validation ecosystem, and a major release for gitlabr. Episode Links This week's curator: Wolfram Qin Elegant and informative maps with tmap (https://r-tmap.github.io/tmap-book/visual-variables.html) A lightweight data validation ecosystem with R, GitHub, and Slack…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_36_highlights",
        "description_long": "\r \r\n\nElegant maps with tmap, a data validation ecosystem, and a major release for gitlabr.\n\nEpisode Links\n\nThis week's curator: Wolfram Qin\nElegant and informative maps with tmap\nA lightweight data validation ecosystem with R, GitHub, and Slack\n{gitlabr} 2.0 - Communicate with GitLab API from R\nEntire issue available at rweekly.org/2021-W36\n\nSupplement resources\n\nhttps://r-tmap.github.io/tmap/\nGeocomputation in R (authored by Robin Lovelace, Jakub Nowosad, and Jannes Meunchow): https://geocompr.robinlovelace.net/index.html\nhttps://github.com/emilyriederer/data-validation-demo\nhttps://rich-iannone.github.io/pointblank/"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_36_highlights",
        "links": "https://r-tmap.github.io/tmap-book/visual-variables.html"
      },
      {
        "ep_name": "issue_2021_w_36_highlights",
        "links": "https://emilyriederer.netlify.app/post/data-valid-lightweight/"
      },
      {
        "ep_name": "issue_2021_w_36_highlights",
        "links": "https://rtask.thinkr.fr/gitlabr-v2-0-is-on-cran/"
      },
      {
        "ep_name": "issue_2021_w_36_highlights",
        "links": "https://rweekly.org/2021-W36.html"
      },
      {
        "ep_name": "issue_2021_w_36_highlights",
        "links": "https://r-tmap.github.io/tmap/"
      },
      {
        "ep_name": "issue_2021_w_36_highlights",
        "links": "https://geocompr.robinlovelace.net/index.html"
      },
      {
        "ep_name": "issue_2021_w_36_highlights",
        "links": "https://github.com/emilyriederer/data-validation-demo"
      },
      {
        "ep_name": "issue_2021_w_36_highlights",
        "links": "https://rich-iannone.github.io/pointblank/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_36_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_35_highlights",
        "ep_date": "2021-09-01",
        "ep_duration": 55,
        "ep_description_short": "The July top 40 R packages, R Markdown advanced tips video, and colored world maps Episode Links This week's curator: Tony ElHabr (@TonyElHabr (https://twitter.com/TonyElHabr)) July 2021: \"Top 40\" New CRAN Packages (https://rviews.rstudio.com/2021/08/26/july-2021-top-40-new-cran-packages/) R Markdown Advanced Tips to Become a Better Data…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_35_highlights",
        "description_long": "\r \r\n\nThe July top 40 R packages, R Markdown advanced tips video, and colored world maps\n\nEpisode Links\n\nThis week's curator: Tony ElHabr (@TonyElHabr)\nJuly 2021: \"Top 40\" New CRAN Packages\nR Markdown Advanced Tips to Become a Better Data Scientist & RStudio Connect with Tom Mock\nThe World's Countries Colored by Their First Letter\n\nSupplement resources\n\ncodemeta: https://github.com/cboettig/codemeta\nhttps://codemeta.github.io/\nMulticlass classification of dry beans using computer vision and machine learning techniques\nThomas Mock's RMD Marvel GitHub repo: https://github.com/jthomasmock/penguin-project"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_35_highlights",
        "links": "https://twitter.com/TonyElHabr"
      },
      {
        "ep_name": "issue_2021_w_35_highlights",
        "links": "https://rviews.rstudio.com/2021/08/26/july-2021-top-40-new-cran-packages/"
      },
      {
        "ep_name": "issue_2021_w_35_highlights",
        "links": "https://youtu.be/WkF7nqEYF1E"
      },
      {
        "ep_name": "issue_2021_w_35_highlights",
        "links": "https://www.cedricscherer.com/2021/08/27/the-worlds-countries-colored-by-their-first-letter/"
      },
      {
        "ep_name": "issue_2021_w_35_highlights",
        "links": "https://github.com/cboettig/codemeta"
      },
      {
        "ep_name": "issue_2021_w_35_highlights",
        "links": "https://codemeta.github.io/"
      },
      {
        "ep_name": "issue_2021_w_35_highlights",
        "links": "https://www.sciencedirect.com/science/article/abs/pii/S0168169919311573?via%3Dihub"
      },
      {
        "ep_name": "issue_2021_w_35_highlights",
        "links": "https://github.com/jthomasmock/penguin-project"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_35_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_34_highlights",
        "ep_date": "2021-08-24",
        "ep_duration": 20,
        "ep_description_short": "Debugging lessons with source, illustrating the coefficient of variation, and the exciting conclusion to SLICED season one Episode Links This week's curator: Miles McBain (@MilesMcBain (https://twitter.com/MilesMcBain)) Keep your R scripts locally sourced: A lesson from debugging (https://www.tjmahr.com/keep-it-locally-sourced/) Exploring R² and…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_34_highlights",
        "description_long": "\r \r\n\nDebugging lessons with source, illustrating the coefficient of variation, and the exciting conclusion to SLICED season one\n\nEpisode Links\n\nThis week's curator: Miles McBain (@MilesMcBain)\nKeep your R scripts locally sourced: A lesson from debugging\nExploring R² and regression variance with Euler/Venn diagrams\nSLICED CHAMPIONSHIP: COMPETITIVE DATA SCIENCE (S01E12)\n\nSupplement resources\n\nTJ's notestar notebook system buit upon the {targets} package.\n{eulerr}: Area-proportional Euler and Venn diagrams with ellipses\nSLICED season 1 YouTube playlist\nSLICED web site\nPractical AI Episode 144"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_34_highlights",
        "links": "https://twitter.com/MilesMcBain"
      },
      {
        "ep_name": "issue_2021_w_34_highlights",
        "links": "https://www.tjmahr.com/keep-it-locally-sourced/"
      },
      {
        "ep_name": "issue_2021_w_34_highlights",
        "links": "https://www.andrewheiss.com/blog/2021/08/21/r2-euler/"
      },
      {
        "ep_name": "issue_2021_w_34_highlights",
        "links": "https://www.twitch.tv/videos/1121570254"
      },
      {
        "ep_name": "issue_2021_w_34_highlights",
        "links": "https://github.com/tjmahr/notestar"
      },
      {
        "ep_name": "issue_2021_w_34_highlights",
        "links": "https://docs.ropensci.org/targets"
      },
      {
        "ep_name": "issue_2021_w_34_highlights",
        "links": "https://jolars.github.io/eulerr"
      },
      {
        "ep_name": "issue_2021_w_34_highlights",
        "links": "https://www.youtube.com/playlist?list=PL6PX3YIZuHhyQmXKnyZmVDzdgAYbzwgDw"
      },
      {
        "ep_name": "issue_2021_w_34_highlights",
        "links": "https://www.notion.so/SLICED-Show-c7bd26356e3a42279e2dfbafb0480073"
      },
      {
        "ep_name": "issue_2021_w_34_highlights",
        "links": "https://changelog.com/practicalai/144"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_34_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_33_highlights",
        "ep_date": "2021-08-17",
        "ep_duration": 49,
        "ep_description_short": "The new {flow} package for visualization R code, and producing donut charts of COVID-19 cases using R. Episode Links This week's curator: Wolfram Qin (@RbyRyo (https://twitter.com/R_by_Ryo)) {flow} 0.0.2 (https://cran.r-project.org/package=flow): View and Browse Code Using Flow Diagrams. Some Covid Donuts To End The Week…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_33_highlights",
        "description_long": "\r \r\n\nThe new {flow} package for visualization R code, and producing donut charts of COVID-19 cases using R.\n\nEpisode Links\n\nThis week's curator: Wolfram Qin (@R_by_Ryo)\n{flow} 0.0.2: View and Browse Code Using Flow Diagrams.\nSome Covid Donuts To End The Week\nEntire issue available at rweekly.org/2021-W33\n\nSupplement resources:\n\n{boomer} - Debugging tools to inspect the intermediate steps of a call"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_33_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2021_w_33_highlights",
        "links": "https://cran.r-project.org/package=flow"
      },
      {
        "ep_name": "issue_2021_w_33_highlights",
        "links": "https://rud.is/b/2021/08/13/some-covid-donuts-to-end-the-week"
      },
      {
        "ep_name": "issue_2021_w_33_highlights",
        "links": "https://rweekly.org/2021-W33.html"
      },
      {
        "ep_name": "issue_2021_w_33_highlights",
        "links": "https://moodymudskipper.github.io/boomer"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_33_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_32_highlights",
        "ep_date": "2021-08-10",
        "ep_duration": 23,
        "ep_description_short": "Creating mobile-friendly Shiny apps, {gitlabr} 2.0.0, and achieving reproducible workflows with R and Docker Episode Links This week's curator: Ryo Nakagawara (@RbyRyo (https://twitter.com/R_by_Ryo)) Making Shiny apps mobile friendly (https://jnolis.com/blog/shiny_mobile/) {gitlabr} 2.0.0 (https://github.com/statnmap/gitlabr): Access to the…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_32_highlights",
        "description_long": "\r \r\n\nCreating mobile-friendly Shiny apps, {gitlabr} 2.0.0, and achieving reproducible workflows with R and Docker\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara (@R_by_Ryo)\nMaking Shiny apps mobile friendly\n{gitlabr} 2.0.0: Access to the 'Gitlab' API.\nHow to setup a reproducible workflow in R and Docker\nEntire issue available at rweekly.org/2021-W32\n\nSupplement resources:\n\nJesse Mostipak's Twitter thread: Stumbling blocks encountered with learning Shiny\nJacqueline Nolis: I made an entier e-commerce platform on Shiny https://youtu.be/tTgRhJ6lb4w\nhttps://www.rocker-project.org\nMy R development template repository: https://github.com/rpodcast/r_dev_projects"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_32_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2021_w_32_highlights",
        "links": "https://jnolis.com/blog/shiny_mobile/"
      },
      {
        "ep_name": "issue_2021_w_32_highlights",
        "links": "https://github.com/statnmap/gitlabr"
      },
      {
        "ep_name": "issue_2021_w_32_highlights",
        "links": "https://medium.com/@rahul.sangole/reproducible-work-in-r-e7d160d5d198"
      },
      {
        "ep_name": "issue_2021_w_32_highlights",
        "links": "https://rweekly.org/2021-W32.html"
      },
      {
        "ep_name": "issue_2021_w_32_highlights",
        "links": "https://twitter.com/kierisi/status/1418601202636500994"
      },
      {
        "ep_name": "issue_2021_w_32_highlights",
        "links": "https://youtu.be/tTgRhJ6lb4w"
      },
      {
        "ep_name": "issue_2021_w_32_highlights",
        "links": "https://www.rocker-project.org"
      },
      {
        "ep_name": "issue_2021_w_32_highlights",
        "links": "https://github.com/rpodcast/r_dev_projects"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_32_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_31_highlights",
        "ep_date": "2021-08-04",
        "ep_duration": 46,
        "ep_description_short": "Up and running with officedown, testing with a reprex to solve your problems, and a tidy take on performing hypothesis testing with statsExpressions. Episode Links This week's curator: Kelly Bodwin (@KellyBodwin (https://twitter.com/KellyBodwin)) Up and running with Officedown (https://alison.rbind.io/blog/2021-07-officedown/) Reminder to test…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_31_highlights",
        "description_long": "\r \r\n\nUp and running with officedown, testing with a reprex to solve your problems, and a tidy take on performing hypothesis testing with statsExpressions.\n\nEpisode Links\n\nThis week's curator: Kelly Bodwin (@KellyBodwin)\nUp and running with Officedown\nReminder to test with a reprex to help yourself solve your problems (or get help!)\n{statsExpressions} 1.2.0: Add statistical detail to data frames and plots\nEntire issue available at rweekly.org/2021-W31\n\nSupplement resources:\n\nFriction Logs: The Key to Unlocking Product Growth\nMS-OOXML: A pseudo-standard that pretends to be open\nThe officer package: Making PowerPoint slides from R (my presentation from the Advanced R Markdown Workshop)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_31_highlights",
        "links": "https://twitter.com/KellyBodwin"
      },
      {
        "ep_name": "issue_2021_w_31_highlights",
        "links": "https://alison.rbind.io/blog/2021-07-officedown/"
      },
      {
        "ep_name": "issue_2021_w_31_highlights",
        "links": "https://themockup.blog/posts/2021-07-28-reminder-to-test-with-a-reprex/"
      },
      {
        "ep_name": "issue_2021_w_31_highlights",
        "links": "https://indrajeetpatil.github.io/statsExpressions/"
      },
      {
        "ep_name": "issue_2021_w_31_highlights",
        "links": "https://rweekly.org/2021-W31.html"
      },
      {
        "ep_name": "issue_2021_w_31_highlights",
        "links": "https://www.trychameleon.com/blog/friction-logs"
      },
      {
        "ep_name": "issue_2021_w_31_highlights",
        "links": "https://fsfe.org/activities/msooxml/msooxml.en.html"
      },
      {
        "ep_name": "issue_2021_w_31_highlights",
        "links": "https://rpodcast.github.io/officer-advrmarkdown/#1"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_31_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_30_highlights",
        "ep_date": "2021-07-27",
        "ep_duration": 4,
        "ep_description_short": "Top 3 coding best practices from the Shiny contest, improvements in Target Markdown for {targets} 0.6.0, and the new {facetious} package for alternative facets with {ggplot2} Episode Links This week's curator: Eric Nantz (@theRcast (https://twitter.com/thercast)) Top 3 Coding Best Practices from the Shiny Contest…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_30_highlights",
        "description_long": "\r \r\n\nTop 3 coding best practices from the Shiny contest, improvements in Target Markdown for {targets} 0.6.0, and the new {facetious} package for alternative facets with {ggplot2}\n\nEpisode Links\n\nThis week's curator: Eric Nantz (@theRcast)\nTop 3 Coding Best Practices from the Shiny Contest\n{targets} 0.6.0: Dynamic Function-Oriented 'Make'-Like Declarative Workflows\nIntroducing {facetious} - alternate facets for ggplot2\nEntire issue available at rweekly.org/2021-W30\n\nSupplement resources:\n\nRecording of my issue curation livestream!\nEffective communication between Shiny modules\n{targets} 0.6.0 NEWS\nChapter 3 - Target Markdown\nTarget Markdown template format\n{targets} resources from upcoming R in Medicine workshop"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_30_highlights",
        "links": "https://twitter.com/thercast"
      },
      {
        "ep_name": "issue_2021_w_30_highlights",
        "links": "https://blog.rstudio.com/2021/07/22/three-shiny-best-practices-seen-in-the-shiny-contest/"
      },
      {
        "ep_name": "issue_2021_w_30_highlights",
        "links": "https://cran.r-project.org/package=targets"
      },
      {
        "ep_name": "issue_2021_w_30_highlights",
        "links": "https://coolbutuseless.github.io/2021/07/20/introducing-facetious-alternate-facets-for-ggplot2/"
      },
      {
        "ep_name": "issue_2021_w_30_highlights",
        "links": "https://rweekly.org/2021-W30.html"
      },
      {
        "ep_name": "issue_2021_w_30_highlights",
        "links": "https://www.youtube.com/watch?v=cwQAwEnwq6g"
      },
      {
        "ep_name": "issue_2021_w_30_highlights",
        "links": "https://shiny.rstudio.com/articles/communicate-bet-modules.html"
      },
      {
        "ep_name": "issue_2021_w_30_highlights",
        "links": "https://cran.r-project.org/web/packages/targets/news/news.html"
      },
      {
        "ep_name": "issue_2021_w_30_highlights",
        "links": "https://books.ropensci.org/targets/markdown.html"
      },
      {
        "ep_name": "issue_2021_w_30_highlights",
        "links": "https://github.com/ropensci/targets/blob/main/inst/rmarkdown/templates/targets/skeleton/skeleton.Rmd"
      },
      {
        "ep_name": "issue_2021_w_30_highlights",
        "links": "https://wlandau.github.io/rmedicine2021-slides/#30"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_30_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_29_highlights",
        "ep_date": "2021-07-20",
        "ep_duration": 14,
        "ep_description_short": "How to become a better R code detective, a practical introduction to custom fonts, and making error messages your own. Episode Links This week's curator: Jonathan Carroll (@carroll_jono (https://twitter.com/carroll_jono)) How to become a better R code detective? (https://masalmon.eu/2021/07/13/code-detective) Setting up and debugging custom fonts:…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_29_highlights",
        "description_long": "\r \r\n\nHow to become a better R code detective, a practical introduction to custom fonts, and making error messages your own.\n\nEpisode Links\n\nThis week's curator: Jonathan Carroll (@carroll_jono)\nHow to become a better R code detective?\nSetting up and debugging custom fonts: a practical introduction to the all (new) things font in R\nMake error messages your own\nEntire issue available at rweekly.org/2021-W29"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_29_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2021_w_29_highlights",
        "links": "https://masalmon.eu/2021/07/13/code-detective"
      },
      {
        "ep_name": "issue_2021_w_29_highlights",
        "links": "https://yjunechoe.github.io/posts/2021-06-24-setting-up-and-debugging-custom-fonts"
      },
      {
        "ep_name": "issue_2021_w_29_highlights",
        "links": "https://eliocamp.github.io/codigo-r/en/2021/07/wrapper-stop/"
      },
      {
        "ep_name": "issue_2021_w_29_highlights",
        "links": "https://rweekly.org/2021-W29.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_29_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_28_highlights",
        "ep_date": "2021-07-13",
        "ep_duration": 38,
        "ep_description_short": "Creating a package directly from R-Markdown with {fusen}, and a new milestone release of the {googledrive} package Episode Links This week's curator: Batool Almarzouq (@batool664) (https://twitter.com/batool664) {fusen} 0.2.2 (https://cran.r-project.org/package=fusen): Build a Package from R Markdown File googledrive 2.0.0…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_28_highlights",
        "description_long": "\r \r\n\nCreating a package directly from R-Markdown with {fusen}, and a new milestone release of the {googledrive} package\n\nEpisode Links\n\nThis week's curator: Batool Almarzouq (@batool664)\n{fusen} 0.2.2: Build a Package from R Markdown File\ngoogledrive 2.0.0\nEntire issue available at rweekly.org/2021-W28\n\nSupplement Resources\n\nHow to build a package following Rmd Driven Development GitHub Repository\nBatool's presentation from UseR! 2021: Make Your Computational Analysis Citable"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_28_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2021_w_28_highlights",
        "links": "https://cran.r-project.org/package=fusen"
      },
      {
        "ep_name": "issue_2021_w_28_highlights",
        "links": "https://www.tidyverse.org/blog/2021/07/googledrive-2-0-0/"
      },
      {
        "ep_name": "issue_2021_w_28_highlights",
        "links": "https://rweekly.org/2021-W28.html"
      },
      {
        "ep_name": "issue_2021_w_28_highlights",
        "links": "https://github.com/statnmap/user2021.rmdd"
      },
      {
        "ep_name": "issue_2021_w_28_highlights",
        "links": "https://zenodo.org/record/5075932"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_28_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_27_highlights",
        "ep_date": "2021-07-07",
        "ep_duration": 50,
        "ep_description_short": "Practical tips on starting new R projects, and improving a visualization of US streaming market share. Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder)) Draw me a project (https://masalmon.eu/2021/06/30/r-projects/) Improving a Visualization…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_27_highlights",
        "description_long": "\r \r\n\nPractical tips on starting new R projects, and improving a visualization of US streaming market share.\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder)\nDraw me a project\nImproving a Visualization\nEntire issue available at rweekly.org/2021-W27"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_27_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2021_w_27_highlights",
        "links": "https://masalmon.eu/2021/06/30/r-projects/"
      },
      {
        "ep_name": "issue_2021_w_27_highlights",
        "links": "https://jcarroll.com.au/2021/07/02/improving-a-visualization/"
      },
      {
        "ep_name": "issue_2021_w_27_highlights",
        "links": "https://rweekly.org/2021-W27.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_27_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_26_highlights",
        "ep_date": "2021-06-29",
        "ep_duration": 7,
        "ep_description_short": "Creating your own CRAN-like repository with R-universe, results the third annual Shiny contest, and insights on why to use Shiny. Episode Links This week's curator: Colin Faye (@_colinFay (https://twitter.com/_colinfay)) How to create your personal CRAN-like repository on R-universe (https://ropensci.org/blog/2021/06/22/setup-runiverse/) Winners…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_26_highlights",
        "description_long": "\r \r\n\nCreating your own CRAN-like repository with R-universe, results the third annual Shiny contest, and insights on why to use Shiny.\n\nEpisode Links\n\nThis week's curator: Colin Faye (@_colinFay)\nHow to create your personal CRAN-like repository on R-universe\nWinners of the 3rd annual Shiny Contest\nWhy Shiny? Insights from a Shiny Developer\nEntire issue available at rweekly.org/2021-W26\n\nSupplement Resources\n\nhttps://ropensci.org/blog/2021/03/04/r-universe-buildsystem/\nhttps://ropensci.org/commcalls/may2021-r-universe/\n\n\r \r"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_26_highlights",
        "links": "https://twitter.com/_colinfay"
      },
      {
        "ep_name": "issue_2021_w_26_highlights",
        "links": "https://ropensci.org/blog/2021/06/22/setup-runiverse/"
      },
      {
        "ep_name": "issue_2021_w_26_highlights",
        "links": "https://blog.rstudio.com/2021/06/24/winners-of-the-3rd-annual-shiny-contest/"
      },
      {
        "ep_name": "issue_2021_w_26_highlights",
        "links": "https://www.mango-solutions.com/why-shiny-opinions-from-a-shiny-developer/"
      },
      {
        "ep_name": "issue_2021_w_26_highlights",
        "links": "https://rweekly.org/2021-W26.html"
      },
      {
        "ep_name": "issue_2021_w_26_highlights",
        "links": "https://ropensci.org/blog/2021/03/04/r-universe-buildsystem/"
      },
      {
        "ep_name": "issue_2021_w_26_highlights",
        "links": "https://ropensci.org/commcalls/may2021-r-universe/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_26_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_25_highlights",
        "ep_date": "2021-06-23",
        "ep_duration": 3,
        "ep_description_short": "Projecting and tracking COVID-19 infection rates in England with R, leveraging Wikidata to tag scientific abstracts, and a new deep-learning workflow with the luz package Episode Links This week's curator: Robert Hickman (@robwhickman (https://twitter.com/robwhickman)) Tracking SARS-CoV-2 In England with {epidemia}…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_25_highlights",
        "description_long": "\r \r\n\nProjecting and tracking COVID-19 infection rates in England with R, leveraging Wikidata to tag scientific abstracts, and a new deep-learning workflow with the luz package\n\nEpisode Links\n\nThis week's curator: Robert Hickman (@robwhickman)\nTracking SARS-CoV-2 In England with {epidemia}\nTagging the Scientific Abstracts with Wikidata Items\nQue haja luz: More light for torch!\nEntire issue available at rweekly.org/2021-W25\n\nSupplemental Resources\n\n{epidemia} package documentation\nA COVID-19 Model for Local Authorities of the United Kingdom\nHow epidemiology has shaped the COVID pandemic"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_25_highlights",
        "links": "https://twitter.com/robwhickman"
      },
      {
        "ep_name": "issue_2021_w_25_highlights",
        "links": "https://imperialcollegelondon.github.io/epidemia/articles/multiple-obs.html"
      },
      {
        "ep_name": "issue_2021_w_25_highlights",
        "links": "https://dwayzer.netlify.app/posts/2021-06-15-tagging-the-abstracts-with-wikidata-items"
      },
      {
        "ep_name": "issue_2021_w_25_highlights",
        "links": "https://blogs.rstudio.com/tensorflow/posts/2021-06-17-luz"
      },
      {
        "ep_name": "issue_2021_w_25_highlights",
        "links": "https://rweekly.org/2021-W25.html"
      },
      {
        "ep_name": "issue_2021_w_25_highlights",
        "links": "https://imperialcollegelondon.github.io/epidemia/index.html"
      },
      {
        "ep_name": "issue_2021_w_25_highlights",
        "links": "https://rss.org.uk/RSS/media/File-library/News/2021/MishraScott.pdf"
      },
      {
        "ep_name": "issue_2021_w_25_highlights",
        "links": "https://www.nature.com/articles/d41586-021-00183-z"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_25_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_24_highlights",
        "ep_date": "2021-06-15",
        "ep_duration": 9,
        "ep_description_short": "Using Animal Crossing data with the Google Vision API and machine learning, the latest Shiny developer series with Nick Strayer, and ensuring robust database transactions in Shiny Episode Links This week's curator: Tony Elhabr ([@TonyElHabr] Everybody Loves Raymond: Running Animal Crossing Villagers through the Google Vision API…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_24_highlights",
        "description_long": "\r \r\n\nUsing Animal Crossing data with the Google Vision API and machine learning, the latest Shiny developer series with Nick Strayer, and ensuring robust database transactions in Shiny\n\nEpisode Links\n\nThis week's curator: Tony Elhabr ([@TonyElHabr]\nEverybody Loves Raymond: Running Animal Crossing Villagers through the Google Vision API\nShiny Developer Series Episode 21: RStudio software engineer Nick Strayer returns to share how he arrived to RStudio and motivations behind the new Shiny App Stories.\nShiny in Production: Database Transactions\nEntire issue available at rweekly.org/2021-W24"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_24_highlights",
        "links": "https://mdneuzerling.com/post/everybody-loves-raymond-running-animal-crossing-villagers-through-the-google-vision-api/"
      },
      {
        "ep_name": "issue_2021_w_24_highlights",
        "links": "https://www.youtube.com/watch?v=84Vg7HKzd2E"
      },
      {
        "ep_name": "issue_2021_w_24_highlights",
        "links": "https://roh.engineering/posts/2021/06/shiny-in-production-database-transactions/"
      },
      {
        "ep_name": "issue_2021_w_24_highlights",
        "links": "https://rweekly.org/2021-W24.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_24_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_23_highlights",
        "ep_date": "2021-06-08",
        "ep_duration": 57,
        "ep_description_short": "Reusing knitr chunk options, the combo of VS-Code and R in 2021, and say hello to gggrid Episode Links This week's curator: Miles McBain (@MilesMcBain (https://twitter.com/MilesMcBain)) Reusing Code Chunks and Chunk Options with knitr (https://yihui.org/en/2021/05/knitr-reuse/) R in 2021 with VSCode…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_23_highlights",
        "description_long": "\r \r\n\nReusing knitr chunk options, the combo of VS-Code and R in 2021, and say hello to gggrid\n\nEpisode Links\n\nThis week's curator: Miles McBain (@MilesMcBain)\nReusing Code Chunks and Chunk Options with knitr\nR in 2021 with VSCode\n'gggrid' it's g-g-great! Accessing 'grid' from 'ggplot2'\nEntire issue available at rweekly.org/2021-W23"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_23_highlights",
        "links": "https://twitter.com/MilesMcBain"
      },
      {
        "ep_name": "issue_2021_w_23_highlights",
        "links": "https://yihui.org/en/2021/05/knitr-reuse/"
      },
      {
        "ep_name": "issue_2021_w_23_highlights",
        "links": "https://datamares.netlify.app/en/post/r-vscode/"
      },
      {
        "ep_name": "issue_2021_w_23_highlights",
        "links": "https://www.stat.auckland.ac.nz/%7Epaul/Reports/gggrid/gggrid.html"
      },
      {
        "ep_name": "issue_2021_w_23_highlights",
        "links": "https://rweekly.org/2021-W23.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_23_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_22_highlights",
        "ep_date": "2021-06-01",
        "ep_duration": 10,
        "ep_description_short": "Extracting and analyzing Apple health data, and the top 40 CRAN packages for April Episode Links This week's curator: Wolfram Qin (https://github.com/qinwf) Changes in Apple Health Export (https://www.johngoldin.com/blog/2021-05-changes-in-apple-health-export/) April 2021: \"Top 40\" New CRAN Packages…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_22_highlights",
        "description_long": "\r \r\n\nExtracting and analyzing Apple health data, and the top 40 CRAN packages for April\n\nEpisode Links\n\nThis week's curator: Wolfram Qin\nChanges in Apple Health Export\nApril 2021: \"Top 40\" New CRAN Packages\nEntire issue available at rweekly.org/2021-W22\n\nSupplemental Resources\n\nhttps://www.healthcareitnews.com/news/timeline-how-apple-piecing-together-its-secret-healthcare-plan\nhttps://github.com/d-score/childdevdata\nhttps://github.com/forestry-labs/Rforestry\nhttps://github.com/tsuda16k/materialmodifier\n\n\r \r"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_22_highlights",
        "links": "https://github.com/qinwf"
      },
      {
        "ep_name": "issue_2021_w_22_highlights",
        "links": "https://www.johngoldin.com/blog/2021-05-changes-in-apple-health-export/"
      },
      {
        "ep_name": "issue_2021_w_22_highlights",
        "links": "https://rviews.rstudio.com/2021/05/25/april-2021-top-40-new-cran-packages/"
      },
      {
        "ep_name": "issue_2021_w_22_highlights",
        "links": "https://rweekly.org/2021-W22.html"
      },
      {
        "ep_name": "issue_2021_w_22_highlights",
        "links": "https://www.healthcareitnews.com/news/timeline-how-apple-piecing-together-its-secret-healthcare-plan"
      },
      {
        "ep_name": "issue_2021_w_22_highlights",
        "links": "https://github.com/d-score/childdevdata"
      },
      {
        "ep_name": "issue_2021_w_22_highlights",
        "links": "https://github.com/forestry-labs/Rforestry"
      },
      {
        "ep_name": "issue_2021_w_22_highlights",
        "links": "https://github.com/tsuda16k/materialmodifier"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_22_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_21_highlights",
        "ep_date": "2021-05-26",
        "ep_duration": 53,
        "ep_description_short": "The big new features in R 4.1.0, what makes a great function example, and evolution of a ggplot Episode Links This week's curator: Kelly Bodwin (@KellyBodwin (https://twitter.com/KellyBodwin)) New features in R 4.1.0 (https://www.jumpingrivers.com/blog/new-features-r410-pipe-anonymous-functions/) Package documentation: What makes a good example?…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_21_highlights",
        "description_long": "\r \r\n\nThe big new features in R 4.1.0, what makes a great function example, and evolution of a ggplot\n\nEpisode Links\n\nThis week's curator: Kelly Bodwin (@KellyBodwin)\nNew features in R 4.1.0\nPackage documentation: What makes a good example?\nEvolution of a ggplot\nEntire issue available at rweekly.org/2021-W21\n\nSupplemental Resources\n\nFull R 4.1.0 changelog\nWinston Chang's R read-only GitHub Repo mirror of the SVN R code repository for version 4.1.0"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_21_highlights",
        "links": "https://twitter.com/KellyBodwin"
      },
      {
        "ep_name": "issue_2021_w_21_highlights",
        "links": "https://www.jumpingrivers.com/blog/new-features-r410-pipe-anonymous-functions/"
      },
      {
        "ep_name": "issue_2021_w_21_highlights",
        "links": "https://thisisnic.github.io/2021/05/18/r-package-documentation-what-makes-a-good-example/"
      },
      {
        "ep_name": "issue_2021_w_21_highlights",
        "links": "https://www.cedricscherer.com/2019/05/17/the-evolution-of-a-ggplot-ep.-1/"
      },
      {
        "ep_name": "issue_2021_w_21_highlights",
        "links": "https://rweekly.org/2021-W21.html"
      },
      {
        "ep_name": "issue_2021_w_21_highlights",
        "links": "https://cran.r-project.org/doc/manuals/r-devel/NEWS.html"
      },
      {
        "ep_name": "issue_2021_w_21_highlights",
        "links": "https://github.com/wch/r-source/tree/tags/R-4-1-0"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_21_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_20_highlights",
        "ep_date": "2021-05-18",
        "ep_duration": 9,
        "ep_description_short": "A tidymodels approach to the Introduction to Statistical Learning learning labs, exploring class imbalance on the TidyX video series, and encrypting and hosting a R Markdown report. Episode Links This week's curator: Ryo Nakagawara (@RbyRyo (https://twitter.com/R_by_Ryo)) ISLR: tidymodels labs…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_20_highlights",
        "description_long": "\r \r\n\nA tidymodels approach to the Introduction to Statistical Learning learning labs, exploring class imbalance on the TidyX video series, and encrypting and hosting a R Markdown report.\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara (@R_by_Ryo)\nISLR: tidymodels labs: This book aims to be a complement to the 1st version An Introduction to Statistical Learning book with translations of the labs into using the tidymodels set of packages.\nTidyX Episode 59: MLB Pitch Classification - Class Imbalance and Model Evaluation\nEncrypt and host a knitted R Markdown file\nEntire issue available at rweekly.org/2021-W20\n\nSupplemental Resources\n\nAn Introduction to Statistical Learning and The Elements of Statistical Learning official sites with links to download each.\nTidyX MLB Pitch Classification playlist\nMy appearance on TidyX episode 32\n{encryptedRmd}: Password protected markdown HTML reports in R using libsodium\nlibsodium encryption library"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_20_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2021_w_20_highlights",
        "links": "https://emilhvitfeldt.github.io/ISLR-tidymodels-labs/index.html"
      },
      {
        "ep_name": "issue_2021_w_20_highlights",
        "links": "https://www.youtube.com/watch?v=6-y1iEbDQVs"
      },
      {
        "ep_name": "issue_2021_w_20_highlights",
        "links": "https://www.rostrum.blog/2021/05/07/encrypted-rmd/"
      },
      {
        "ep_name": "issue_2021_w_20_highlights",
        "links": "https://rweekly.org/2021-W20.html"
      },
      {
        "ep_name": "issue_2021_w_20_highlights",
        "links": "https://www.statlearning.com"
      },
      {
        "ep_name": "issue_2021_w_20_highlights",
        "links": "https://web.stanford.edu/%7Ehastie/ElemStatLearn/"
      },
      {
        "ep_name": "issue_2021_w_20_highlights",
        "links": "https://www.youtube.com/playlist?list=PLdb0LTjA9iQxP4vsD87_yNUfPnQxBjE-s"
      },
      {
        "ep_name": "issue_2021_w_20_highlights",
        "links": "https://www.youtube.com/watch?v=c7dZqyhd4a4"
      },
      {
        "ep_name": "issue_2021_w_20_highlights",
        "links": "https://github.com/dirkschumacher/encryptedRmd"
      },
      {
        "ep_name": "issue_2021_w_20_highlights",
        "links": "https://doc.libsodium.org/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_20_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_19_highlights",
        "ep_date": "2021-05-11",
        "ep_duration": 59,
        "ep_description_short": "Using the trifecta of map, walk, and pivot for data processing, obtaining quotes from the Friends characters in R, and putting the spolight on Shiny user interfaces in the Shiny Dev Series. Episode Links This week's curator: Hey, it's me, Eric! (@theRcast (https://twitter.com/thercast)) Map, Walk, Pivot…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_19_highlights",
        "description_long": "\r \r\n\nUsing the trifecta of map, walk, and pivot for data processing, obtaining quotes from the Friends characters in R, and putting the spolight on Shiny user interfaces in the Shiny Dev Series.\n\nEpisode Links\n\nThis week's curator: Hey, it's me, Eric! (@theRcast)\nMap, Walk, Pivot\nIntroducing {centralperk}: Get quotes from the main characters of the TV show 'Friends'\nShiny Developer Series Episode 20: Outstanding User Interfaces with David Granjon\nEntire issue available at rweekly.org/2021-W19"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_19_highlights",
        "links": "https://twitter.com/thercast"
      },
      {
        "ep_name": "issue_2021_w_19_highlights",
        "links": "https://kieranhealy.org/blog/archives/2021/05/04/map-walk-pivot/"
      },
      {
        "ep_name": "issue_2021_w_19_highlights",
        "links": "http://Ryo-N7.github.io/2021-05-06-friends-quotes-api/"
      },
      {
        "ep_name": "issue_2021_w_19_highlights",
        "links": "https://www.youtube.com/watch?v=mxvMaoXOm70"
      },
      {
        "ep_name": "issue_2021_w_19_highlights",
        "links": "https://rweekly.org/2021-W19.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_19_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_18_highlights",
        "ep_date": "2021-05-04",
        "ep_duration": 50,
        "ep_description_short": "A call to action for testing R 4.1, a practical guide to unit tests, and a tutorial on creating pizza charts with football data Episode Links This week's curator: Jonathan Carroll (@carroll_jono (https://twitter.com/carroll_jono)) R Can Use Your Help: Testing R Before Release…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_18_highlights",
        "description_long": "\r \r\n\nA call to action for testing R 4.1, a practical guide to unit tests, and a tutorial on creating pizza charts with football data\n\nEpisode Links\n\nThis week's curator: Jonathan Carroll (@carroll_jono)\nR Can Use Your Help: Testing R Before Release\nWriting unit tests in R\nSoccer Percentile Radars/Pizza's Tutorial\nEntire issue available at rweekly.org/2021-W18"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_18_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2021_w_18_highlights",
        "links": "https://developer.r-project.org/Blog/public/2021/04/28/r-can-use-your-help-testing-r-before-release/"
      },
      {
        "ep_name": "issue_2021_w_18_highlights",
        "links": "https://r-critique.com/writing-unit-tests-in-r"
      },
      {
        "ep_name": "issue_2021_w_18_highlights",
        "links": "https://www.gettingbluefingers.com/tutorials/RadarPizzaChart"
      },
      {
        "ep_name": "issue_2021_w_18_highlights",
        "links": "https://rweekly.org/2021-W18.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_18_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_17_highlights",
        "ep_date": "2021-04-27",
        "ep_duration": 37,
        "ep_description_short": "Exploring wikidata with the {tidywikidatar} package, accessibility improvements in {knitr}, and the top 40 new CRAN packages for March. Episode Links This week's curator: Batool Almazrouq (@batool664) (https://twitter.com/batool664) What does Wikidata know about members of the European Parliament?…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_17_highlights",
        "description_long": "\r \r\n\nExploring wikidata with the {tidywikidatar} package, accessibility improvements in {knitr}, and the top 40 new CRAN packages for March.\n\nEpisode Links\n\nThis week's curator: Batool Almazrouq (@batool664)\nWhat does Wikidata know about members of the European Parliament?\nNew in knitr: Improved accessibility with image alt text\nMarch 2021: \"Top 40\" New CRAN Packages\nEntire issue available at rweekly.org/2021-W17\n\nSupplemental Resources\n\nhttps://news.yahoo.com/wikipedia-turns-20-aims-reach-035212015.html\nhttps://github.com/yihui/knitr/releases/tag/v1.32\nhttps://cran.r-project.org/web/packages/pkglite/index.html\nhttps://flujoo.github.io/gm/\n\n\r \r"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_17_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2021_w_17_highlights",
        "links": "https://medium.com/european-data-journalism-network/a-new-r-package-for-exploring-the-wealth-of-information-stored-by-wikidata-fe85e82b6440"
      },
      {
        "ep_name": "issue_2021_w_17_highlights",
        "links": "https://blog.rstudio.com/2021/04/20/knitr-fig-alt/"
      },
      {
        "ep_name": "issue_2021_w_17_highlights",
        "links": "https://rviews.rstudio.com/2021/04/22/march-2021-top-40-new-cran-packages/"
      },
      {
        "ep_name": "issue_2021_w_17_highlights",
        "links": "https://rweekly.org/2021-W17.html"
      },
      {
        "ep_name": "issue_2021_w_17_highlights",
        "links": "https://news.yahoo.com/wikipedia-turns-20-aims-reach-035212015.html"
      },
      {
        "ep_name": "issue_2021_w_17_highlights",
        "links": "https://github.com/yihui/knitr/releases/tag/v1.32"
      },
      {
        "ep_name": "issue_2021_w_17_highlights",
        "links": "https://cran.r-project.org/web/packages/pkglite/index.html"
      },
      {
        "ep_name": "issue_2021_w_17_highlights",
        "links": "https://flujoo.github.io/gm/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_17_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_16_highlights",
        "ep_date": "2021-04-20",
        "ep_duration": 8,
        "ep_description_short": "The latest news from rOpenSci, creating ggplot2 postcards with ggirl, and an introduction to process mining in R Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder)) rOpenSci News Digest, April 2021 (https://ropensci.org/blog/2021/04/16/latest-ropensci-news-digest/) {ggirl} 1.0.1…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_16_highlights",
        "description_long": "\r \r\n\nThe latest news from rOpenSci, creating ggplot2 postcards with ggirl, and an introduction to process mining in R\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder)\nrOpenSci News Digest, April 2021\n{ggirl} 1.0.1: An R package that lets you make ggplots in real life\nProcess Mining in 10 minutes with R\nEntire issue available at rweekly.org/2021-W16\n\nSupplemental Resources\n\nrOpenSci Software Peer Review\n{dataspice} package peer review GH isssue\n{brochure}: Natively multipage Shiny apps\nWhat Process Mining Is, and Why Companies Should Do It\n{bupaR}: Business process analysis in R"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_16_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2021_w_16_highlights",
        "links": "https://ropensci.org/blog/2021/04/16/latest-ropensci-news-digest/"
      },
      {
        "ep_name": "issue_2021_w_16_highlights",
        "links": "https://jnolis.com/blog/introducing_ggirl/"
      },
      {
        "ep_name": "issue_2021_w_16_highlights",
        "links": "https://medium.com/process-mining-and-analytics/process-mining-in-10-minutes-with-r-1ab28ed74e81"
      },
      {
        "ep_name": "issue_2021_w_16_highlights",
        "links": "https://rweekly.org/2021-W16.html"
      },
      {
        "ep_name": "issue_2021_w_16_highlights",
        "links": "https://ropensci.org/software-review"
      },
      {
        "ep_name": "issue_2021_w_16_highlights",
        "links": "https://github.com/ropensci/software-review/issues/426"
      },
      {
        "ep_name": "issue_2021_w_16_highlights",
        "links": "https://github.com/ColinFay/brochure"
      },
      {
        "ep_name": "issue_2021_w_16_highlights",
        "links": "https://hbr.org/2019/04/what-process-mining-is-and-why-companies-should-do-it"
      },
      {
        "ep_name": "issue_2021_w_16_highlights",
        "links": "https://www.bupar.net"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_16_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_15_highlights",
        "ep_date": "2021-04-13",
        "ep_duration": 29,
        "ep_description_short": "reprex 2.0, using Kubernetes and the future package, and SQL in RMarkdown Episode Links This week's curator: Colin Faye (@_colinFay (https://twitter.com/_colinfay)) reprex 2.0.0 (https://www.tidyverse.org/blog/2021/04/reprex-2-0-0/) Using Kubernetes and the Future Package to Easily Parallelize R in the Cloud…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_15_highlights",
        "description_long": "\r \r\n\nreprex 2.0, using Kubernetes and the future package, and SQL in RMarkdown\n\nEpisode Links\n\nThis week's curator: Colin Faye (@_colinFay)\nreprex 2.0.0\nUsing Kubernetes and the Future Package to Easily Parallelize R in the Cloud\nsql-in-rmarkdown\nEntire issue available at rweekly.org/2021-W15\n\nSupplemental Resources\n\nJenny Bryan's rstudio::conf 2020 keynote materials: Object of type 'closure' is not subsettable\nHigh Performance and Parallel Computing CRAN task view\nFuture: Simple Async, Parallel & Distributed Processing in R rstudio::conf 2020 resources\ntidyquery: Query R data frames with SQL"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_15_highlights",
        "links": "https://twitter.com/_colinfay"
      },
      {
        "ep_name": "issue_2021_w_15_highlights",
        "links": "https://www.tidyverse.org/blog/2021/04/reprex-2-0-0/"
      },
      {
        "ep_name": "issue_2021_w_15_highlights",
        "links": "https://www.jottr.org/2021/04/08/future-and-kubernetes/"
      },
      {
        "ep_name": "issue_2021_w_15_highlights",
        "links": "https://sciencificity-blog.netlify.app/posts/2021-03-27-sql-in-rmarkdown/"
      },
      {
        "ep_name": "issue_2021_w_15_highlights",
        "links": "https://rweekly.org/2021-W15.html"
      },
      {
        "ep_name": "issue_2021_w_15_highlights",
        "links": "https://github.com/jennybc/debugging#readme"
      },
      {
        "ep_name": "issue_2021_w_15_highlights",
        "links": "https://cran.r-project.org/web/views/HighPerformanceComputing.html"
      },
      {
        "ep_name": "issue_2021_w_15_highlights",
        "links": "https://www.jottr.org/2020/02/01/future-rstudioconf2020-slides"
      },
      {
        "ep_name": "issue_2021_w_15_highlights",
        "links": "https://github.com/ianmcook/tidyquery"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_15_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_14_highlights",
        "ep_date": "2021-04-05",
        "ep_duration": 56,
        "ep_description_short": "{workflowsets} with tidy models, exploring other {ggplot2} goems, and top 10 R errors Episode Links This week's curator: Robert Hickman (@robwhickman (https://twitter.com/robwhickman)) workflowsets 0.0.1 (https://www.tidyverse.org/blog/2021/03/workflowsets-0-0-1/) Exploring Other ggplot2 Geoms (https://ivelasq.rbind.io/blog/other-geoms/) The top 10…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_14_highlights",
        "description_long": "\r \r\n\n{workflowsets} with tidy models, exploring other {ggplot2} goems, and top 10 R errors\n\nEpisode Links\n\nThis week's curator: Robert Hickman (@robwhickman)\nworkflowsets 0.0.1\nExploring Other ggplot2 Geoms\nThe top 10 R errors, the 7th one will surprise you\nEntire issue available at rweekly.org/2021-W14\n\nSupplemental Resources\n\nScreening many models chapter from Tidy Modeling with R\nExtending ggplot2 vignette"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_14_highlights",
        "links": "https://twitter.com/robwhickman"
      },
      {
        "ep_name": "issue_2021_w_14_highlights",
        "links": "https://www.tidyverse.org/blog/2021/03/workflowsets-0-0-1/"
      },
      {
        "ep_name": "issue_2021_w_14_highlights",
        "links": "https://ivelasq.rbind.io/blog/other-geoms/"
      },
      {
        "ep_name": "issue_2021_w_14_highlights",
        "links": "https://rtask.thinkr.fr/the-top-10-r-mistakes-the-7th-one-will-surprise-you/"
      },
      {
        "ep_name": "issue_2021_w_14_highlights",
        "links": "https://rweekly.org/2021-W14.html"
      },
      {
        "ep_name": "issue_2021_w_14_highlights",
        "links": "https://www.tmwr.org/workflow-sets.html"
      },
      {
        "ep_name": "issue_2021_w_14_highlights",
        "links": "https://www.tmwr.org/"
      },
      {
        "ep_name": "issue_2021_w_14_highlights",
        "links": "https://ggplot2.tidyverse.org/articles/extending-ggplot2.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_14_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_13_highlights",
        "ep_date": "2021-03-30",
        "ep_duration": 58,
        "ep_description_short": "The Minard System in R, ggplot2 wizardry, a slackbot created with plumber and googleCouldRunner Episode Links This week's curator: Tony Elhabr (@TonyElHabr (https://twitter.com/tonyelhabr)) \"The Minard System\" in R (http://minard.schochastics.net/) A guide to creating a Slackbot that sends weekly updates via plumber, googleCloudRunner and Cloud…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_13_highlights",
        "description_long": "\r \r\n\nThe Minard System in R, ggplot2 wizardry, a slackbot created with plumber and googleCouldRunner\n\nEpisode Links\n\nThis week's curator: Tony Elhabr (@TonyElHabr)\n\"The Minard System\" in R\nA guide to creating a Slackbot that sends weekly updates via plumber, googleCloudRunner and Cloud Run\nggplot2 Wizardry: My Favorite Tricks and secrets for Beautiful Plots in R, Cédric Scherer\nEntire issue available at rweekly.org/2021-W13\n\nSupplemental Resources\n\nDataViz History Series: Edward Tufte, Charles Minard, Napoleon and the Russian Campaign of 1812 - Part 2 and Part 5\n{ggplot2} Wizardry recorded talk from UseR Oslo meetup (25 March 2021)\nIntroducing googleCouldRunnner - serverless R on Google Could Platform"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_13_highlights",
        "links": "https://twitter.com/tonyelhabr"
      },
      {
        "ep_name": "issue_2021_w_13_highlights",
        "links": "http://minard.schochastics.net/"
      },
      {
        "ep_name": "issue_2021_w_13_highlights",
        "links": "https://code.markedmondson.me/googleCloudRunner/articles/usecase-slackbot-google-analytics.html"
      },
      {
        "ep_name": "issue_2021_w_13_highlights",
        "links": "https://www.cedricscherer.com/slides/useR2021.pdf"
      },
      {
        "ep_name": "issue_2021_w_13_highlights",
        "links": "https://rweekly.org/2021-W13.html"
      },
      {
        "ep_name": "issue_2021_w_13_highlights",
        "links": "https://datavizblog.com/2013/05/18/dataviz-history-edward-tufte-charles-minard-napoleon-and-the-russian-campaign-of-1812-part-2"
      },
      {
        "ep_name": "issue_2021_w_13_highlights",
        "links": "https://datavizblog.com/2013/05/26/dataviz-history-charles-minards-flow-map-of-napoleons-russian-campaign-of-1812-part-5"
      },
      {
        "ep_name": "issue_2021_w_13_highlights",
        "links": "https://www.youtube.com/watch?v=5KHvEXYtnOo"
      },
      {
        "ep_name": "issue_2021_w_13_highlights",
        "links": "https://code.markedmondson.me/googleCloudRunner-intro/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_13_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_12_highlights",
        "ep_date": "2021-03-23",
        "ep_duration": 1,
        "ep_description_short": "{gt} tables cookbook, best weather cities, and mapping over many files Episode Links This week's curator: Miles McBain (@MilesMcBain (https://twitter.com/MilesMcBain)) The GT Cookbook (https://themockup.blog/static/gt-cookbook.html) Cities with Best (and Worst) Weather, 2021 edition (https://taraskaduk.com/posts/2021-03-14-best-weather-2/) How to…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_12_highlights",
        "description_long": "\r \r\n\n{gt} tables cookbook, best weather cities, and mapping over many files\n\nEpisode Links\n\nThis week's curator: Miles McBain (@MilesMcBain)\nThe GT Cookbook\nCities with Best (and Worst) Weather, 2021 edition\nHow to treat as many files as fit on your hard disk without loops (sorta) nor running out of memory all the while being as lazy as possible\n\nSupplemental Resources\n\nGT Advanced Cookbook\nR-Podcast episode 27: Get the {gt} Tables!\nR-Weekly Highlights Episode 24: {blogdown} v1.0, announcing {pagedreport}, and the rOpenSci Community Contributing Guide\nR-Weekly Highlights episode 5: Guidelines for creating better tables, a controlled vocabulary to name data frame columns, and exploring reactive in Shiny applications\nBruno Rodrigues' YouTube Channel"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_12_highlights",
        "links": "https://twitter.com/MilesMcBain"
      },
      {
        "ep_name": "issue_2021_w_12_highlights",
        "links": "https://themockup.blog/static/gt-cookbook.html"
      },
      {
        "ep_name": "issue_2021_w_12_highlights",
        "links": "https://taraskaduk.com/posts/2021-03-14-best-weather-2/"
      },
      {
        "ep_name": "issue_2021_w_12_highlights",
        "links": "https://www.brodrigues.co/blog/2021-03-19-no_loops_tidyeval/"
      },
      {
        "ep_name": "issue_2021_w_12_highlights",
        "links": "https://themockup.blog/static/gt-cookbook-advanced.html"
      },
      {
        "ep_name": "issue_2021_w_12_highlights",
        "links": "https://r-podcast.org/episode/027-rstudioconf-tables/"
      },
      {
        "ep_name": "issue_2021_w_12_highlights",
        "links": "https://rweekly.fireside.fm/24"
      },
      {
        "ep_name": "issue_2021_w_12_highlights",
        "links": "https://rweekly.fireside.fm/5"
      },
      {
        "ep_name": "issue_2021_w_12_highlights",
        "links": "https://www.youtube.com/channel/UCTZXht1RTL2Duc3eU8MYGzQ"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_12_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_11_highlights",
        "ep_date": "2021-03-16",
        "ep_duration": 12,
        "ep_description_short": "Time series forecasting with torch, automated scraping of stock metrics with GitHub Actions, and default knitr options and hooks. Episode Links This week's curator: Robert Hickman (@robwhickman (https://twitter.com/robwhickman)) Introductory time series forecasting with torch…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_11_highlights",
        "description_long": "\r \r\n\nTime series forecasting with torch, automated scraping of stock metrics with GitHub Actions, and default knitr options and hooks.\n\nEpisode Links\n\nThis week's curator: Robert Hickman (@robwhickman)\nIntroductory time series forecasting with torch\nDaily Stock Gainers Automated Web Scraping in R with Github Actions\nDefault knitr options and hooks\n\nSupplemental Resources\n\nIntroducing Torch for R\nAutomating COVID-19 PDF scraping\n1littlecoder YouTube channel\nShiny Developer Series"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_11_highlights",
        "links": "https://twitter.com/robwhickman"
      },
      {
        "ep_name": "issue_2021_w_11_highlights",
        "links": "https://blogs.rstudio.com/ai/posts/2021-03-10-forecasting-time-series-with-torch_1/"
      },
      {
        "ep_name": "issue_2021_w_11_highlights",
        "links": "https://www.programmingwithr.com/daily-stock-gainers-automated-web-scraping-in-r-with-github-actions/"
      },
      {
        "ep_name": "issue_2021_w_11_highlights",
        "links": "https://www.jumpingrivers.com/blog/knitr-default-options-settings-hooks/"
      },
      {
        "ep_name": "issue_2021_w_11_highlights",
        "links": "https://blogs.rstudio.com/ai/posts/2020-09-29-introducing-torch-for-r"
      },
      {
        "ep_name": "issue_2021_w_11_highlights",
        "links": "https://lapsedgeographer.london/2020-04/automating-pdf-scraping"
      },
      {
        "ep_name": "issue_2021_w_11_highlights",
        "links": "https://www.youtube.com/channel/UCpV_X0VrL8-jg3t6wYGS-1g"
      },
      {
        "ep_name": "issue_2021_w_11_highlights",
        "links": "https://shinydevseries.com"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_11_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_10_highlights",
        "ep_date": "2021-03-09",
        "ep_duration": 40,
        "ep_description_short": "Serverless dashboards, learning tidy evaluation by re-implementing dplyr, and bootstrap confidence intervals with tidy modeling Episode Links This week's curator: Kelly Bodwin (@KellyBodwin (https://twitter.com/KellyBodwin)) Server(shiny)-less dashboards with R, {htmlwidgets} and {crosstalk}…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_10_highlights",
        "description_long": "\r \r\n\nServerless dashboards, learning tidy evaluation by re-implementing dplyr, and bootstrap confidence intervals with tidy modeling\n\nEpisode Links\n\nThis week's curator: Kelly Bodwin (@KellyBodwin)\nServer(shiny)-less dashboards with R, {htmlwidgets} and {crosstalk}\nLearning tidy eval by re-implementing dplyr\nBootstrap Confidence Intervals for Super Bowl Commercials\n\nSupplemental Resources\n\nLearning Tidy Evaluation by Reimplementing dplyr (Government & Public Sector R Conference)\nProgramming with dplyr vignette"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_10_highlights",
        "links": "https://twitter.com/KellyBodwin"
      },
      {
        "ep_name": "issue_2021_w_10_highlights",
        "links": "https://www.brodrigues.co/blog/2021-03-02-no_shiny_dashboard/"
      },
      {
        "ep_name": "issue_2021_w_10_highlights",
        "links": "https://peng-chen.netlify.app/blog/2021-03-02-learn-tidy-eval-by-reimplementing-dplyr/"
      },
      {
        "ep_name": "issue_2021_w_10_highlights",
        "links": "https://juliasilge.com/blog/superbowl-conf-int/"
      },
      {
        "ep_name": "issue_2021_w_10_highlights",
        "links": "https://www.youtube.com/watch?v=WoBbQ5gsbgU&list=PL5J3U8bCF-4neATb4NwXohXN9gxiw4nop&index=2"
      },
      {
        "ep_name": "issue_2021_w_10_highlights",
        "links": "https://dplyr.tidyverse.org/articles/programming.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_10_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_09_highlights",
        "ep_date": "2021-03-02",
        "ep_duration": 26,
        "ep_description_short": "Random effects, GGanimate intro, and updates to dplyr backends Episode Links This week's curator: Ryo Nakagawara (@RbyRyo (https://twitter.com/R_by_Ryo)) Random effects and penalized splines are the same thing (https://www.tjmahr.com/random-effects-penalized-splines-same-thing/) GGanimating a geographic introduction…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_09_highlights",
        "description_long": "\r \r\n\nRandom effects, GGanimate intro, and updates to dplyr backends\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara (@R_by_Ryo)\nRandom effects and penalized splines are the same thing\nGGanimating a geographic introduction\ndplyr backends: multidplyr 0.1.0, dtplyr 1.1.0, dbplyr 2.1.0\n\nSupplemental Resources\n\nhttps://stats.stackexchange.com/questions/55364/mixed-model-in-simple-english\nhttps://towardsdatascience.com/how-linear-mixed-model-works-350950a82911\nhttps://twitter.com/tjmahr/status/1365424619344318466\n\n\r \r"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_09_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2021_w_09_highlights",
        "links": "https://www.tjmahr.com/random-effects-penalized-splines-same-thing/"
      },
      {
        "ep_name": "issue_2021_w_09_highlights",
        "links": "https://www.pipinghotdata.com/posts/2021-02-15-gganimating-a-geographic-introduction/"
      },
      {
        "ep_name": "issue_2021_w_09_highlights",
        "links": "https://www.tidyverse.org/blog/2021/02/dplyr-backends/"
      },
      {
        "ep_name": "issue_2021_w_09_highlights",
        "links": "https://stats.stackexchange.com/questions/55364/mixed-model-in-simple-english"
      },
      {
        "ep_name": "issue_2021_w_09_highlights",
        "links": "https://towardsdatascience.com/how-linear-mixed-model-works-350950a82911"
      },
      {
        "ep_name": "issue_2021_w_09_highlights",
        "links": "https://twitter.com/tjmahr/status/1365424619344318466"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_09_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_08_highlights",
        "ep_date": "2021-02-23",
        "ep_duration": 19,
        "ep_description_short": "Multi-page Shiny apps, R package citation, and refactoring the squashinformr package Episode Links This week's curator: Eric Nantz (@theRcast (https://twitter.com/thercast)) Multi-page {shiny} Applications with {brochure} (https://colinfay.me/brochure-r-package/) Make Your R Package Easier to Cite…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_08_highlights",
        "description_long": "\r \r\n\nMulti-page Shiny apps, R package citation, and refactoring the squashinformr package\n\nEpisode Links\n\nThis week's curator: Eric Nantz (@theRcast)\nMulti-page {shiny} Applications with {brochure}\nMake Your R Package Easier to Cite\nRefactoring {squashinformr}"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_08_highlights",
        "links": "https://twitter.com/thercast"
      },
      {
        "ep_name": "issue_2021_w_08_highlights",
        "links": "https://colinfay.me/brochure-r-package/"
      },
      {
        "ep_name": "issue_2021_w_08_highlights",
        "links": "https://ropensci.org/blog/2021/02/16/package-citation/"
      },
      {
        "ep_name": "issue_2021_w_08_highlights",
        "links": "https://needleinthehay.ca/post/refactoring-squashinformr/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_08_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_07_highlights",
        "ep_date": "2021-02-16",
        "ep_duration": 15,
        "ep_description_short": "Installing packages, {distill} for personal websites, and Shiny app stories Episode Links This week's curator: Jonathan Carroll (@carroll_jono (https://twitter.com/carroll_jono)) The Comprehensive Guide to Installing R Packages from CRAN, Bioconductor, GitHub and Co. (https://thomasadventure.blog/posts/install-r-packages/) Distill it down…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_07_highlights",
        "description_long": "\r \r\n\nInstalling packages, {distill} for personal websites, and Shiny app stories\n\nEpisode Links\n\nThis week's curator: Jonathan Carroll (@carroll_jono)\nThe Comprehensive Guide to Installing R Packages from CRAN, Bioconductor, GitHub and Co.\nDistill it down\nIntroducing Shiny App Stories\n\nSupplemental Resources\n\n20 Years of R\nPackage management basics (Mozilla Developer Network Web Docs)\nSharing on Short Notice: How to Get Your Materials Online with R Markdown\nBuilding a {distill} website}\nShiny Developer Series Episode 1: Shiny Development Past and Future\nShiny Developer Series Episode 5: shinysense and custom javascript visualizations"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_07_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2021_w_07_highlights",
        "links": "https://thomasadventure.blog/posts/install-r-packages/"
      },
      {
        "ep_name": "issue_2021_w_07_highlights",
        "links": "https://education.rstudio.com/blog/2021/02/distill-it-down/"
      },
      {
        "ep_name": "issue_2021_w_07_highlights",
        "links": "https://blog.rstudio.com/2021/02/12/shiny-app-stories/"
      },
      {
        "ep_name": "issue_2021_w_07_highlights",
        "links": "https://github.com/revodavid/20-years-of-R"
      },
      {
        "ep_name": "issue_2021_w_07_highlights",
        "links": "https://developer.mozilla.org/en-US/docs/Learn/Tools_and_testing/Understanding_client-side_tools/Package_management"
      },
      {
        "ep_name": "issue_2021_w_07_highlights",
        "links": "https://rstudio.com/resources/webinars/sharing-on-short-notice-how-to-get-your-materials-online-with-r-markdown/"
      },
      {
        "ep_name": "issue_2021_w_07_highlights",
        "links": "https://lisalendway.netlify.app/posts/2020-12-09-buildingdistill"
      },
      {
        "ep_name": "issue_2021_w_07_highlights",
        "links": "https://shinydevseries.com/post/episode-1-shiny-development-past-and-future/"
      },
      {
        "ep_name": "issue_2021_w_07_highlights",
        "links": "https://shinydevseries.com/post/episode-5-shinysense/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_07_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_06_highlights",
        "ep_date": "2021-02-09",
        "ep_duration": 41,
        "ep_description_short": "Episode Links This week's curator: Tony Elhabr (@TonyElHabr (https://twitter.com/tonyelhabr)) Shiny 1.6: Theming, Caching, Accessibility (https://blog.rstudio.com/2021/02/01/shiny-1-6-0/) Remote Pair Programming in R Using Visual Studio Code and Live Share (https://ivelasq.rbind.io/blog/vscode-live-share/) Lists are my secret weapon for reporting…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_06_highlights",
        "description_long": "\r \r\n\nEpisode Links\n\nThis week's curator: Tony Elhabr (@TonyElHabr)\nShiny 1.6: Theming, Caching, Accessibility\nRemote Pair Programming in R Using Visual Studio Code and Live Share\nLists are my secret weapon for reporting stats with knitr\n\nSupplemental Resources\n\nCustom theming in Shiny & R Markdown with {bslib} & {thematic} (rstudio::global 2021)\nMaking Shiny apps faster with caching (rstudio::global 2021)"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_06_highlights",
        "links": "https://twitter.com/tonyelhabr"
      },
      {
        "ep_name": "issue_2021_w_06_highlights",
        "links": "https://blog.rstudio.com/2021/02/01/shiny-1-6-0/"
      },
      {
        "ep_name": "issue_2021_w_06_highlights",
        "links": "https://ivelasq.rbind.io/blog/vscode-live-share/"
      },
      {
        "ep_name": "issue_2021_w_06_highlights",
        "links": "https://tjmahr.github.io/lists-knitr-secret-weapon/"
      },
      {
        "ep_name": "issue_2021_w_06_highlights",
        "links": "https://rstudio.com/resources/rstudioglobal-2021/custom-theming-in-shiny-and-r-markdown-with-bslib-and-thematic/"
      },
      {
        "ep_name": "issue_2021_w_06_highlights",
        "links": "https://rstudio.com/resources/rstudioglobal-2021/making-shiny-apps-faster-with-caching/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_06_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_05_highlights",
        "ep_date": "2021-02-02",
        "ep_duration": 45,
        "ep_description_short": "rstudio::global 2021 and UseR! 2021 call for abstracts Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder)) rstudio::global 2021 talks (https://rstudio.com/resources/rstudioglobal-2021/) rstudio::global(2021) %>% summarise() (https://clarewest.github.io/blog/post/rstudio-global-2021-summarise/) 15th Mar:…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_05_highlights",
        "description_long": "\r \r\n\nrstudio::global 2021 and UseR! 2021 call for abstracts\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder)\nrstudio::global 2021 talks\nrstudio::global(2021) %>% summarise()\n15th Mar: useR2021 Call for Abstracts\n\nSupplemental Resources\n\nLifelong Learning with R Weekly (rstudio::global 2021)\nYour Public Garden - rstudio::global(2021) Keynote by Vicki Boykis"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_05_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2021_w_05_highlights",
        "links": "https://rstudio.com/resources/rstudioglobal-2021/"
      },
      {
        "ep_name": "issue_2021_w_05_highlights",
        "links": "https://clarewest.github.io/blog/post/rstudio-global-2021-summarise/"
      },
      {
        "ep_name": "issue_2021_w_05_highlights",
        "links": "https://user2021.r-project.org/participation/call-for-abstracts/"
      },
      {
        "ep_name": "issue_2021_w_05_highlights",
        "links": "https://rstudio.com/resources/rstudioglobal-2021/lifelong-learning-with-r-weekly/"
      },
      {
        "ep_name": "issue_2021_w_05_highlights",
        "links": "https://docs.google.com/presentation/d/1RZqE43Y3fWEExGwL3jAZD7uQPDUnt53UZj0GgWo6RtQ/edit#slide=id.g6fe1a5a715_4_4744"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_05_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_04_highlights",
        "ep_date": "2021-01-26",
        "ep_duration": 57,
        "ep_description_short": "{blogdown} v1.0, announcing {pagedreport}, and the rOpenSci Community Contributing Guide Episode Links This week's curator: Colin Faye (@_colinFay (https://twitter.com/_colinfay)) Announcing blogdown v1.0 (https://blog.rstudio.com/2021/01/18/blogdown-v1.0/) Announcing pagedreport…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_04_highlights",
        "description_long": "\r \r\n\n{blogdown} v1.0, announcing {pagedreport}, and the rOpenSci Community Contributing Guide\n\nEpisode Links\n\nThis week's curator: Colin Faye (@_colinFay)\nAnnouncing blogdown v1.0\nAnnouncing pagedreport\nIntroducing the rOpenSci Community Contributing Guide\n\nSupplemental Resources\n\nUp & running with blogdown in 2021\nYihui's perspective on early development of {blogdown} from episode 24 of The R-Podcast\nThe new and improved R-Podcast site\n{pagedown}: Creating beautiful PDFs with R Markdown and CSS (rstudio::conf 2019)\n{pagedreport} gallery"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_04_highlights",
        "links": "https://twitter.com/_colinfay"
      },
      {
        "ep_name": "issue_2021_w_04_highlights",
        "links": "https://blog.rstudio.com/2021/01/18/blogdown-v1.0/"
      },
      {
        "ep_name": "issue_2021_w_04_highlights",
        "links": "https://rfortherestofus.com/2021/01/announcing-pagedreport/"
      },
      {
        "ep_name": "issue_2021_w_04_highlights",
        "links": "https://ropensci.org/blog/2021/01/20/contributing-guide/"
      },
      {
        "ep_name": "issue_2021_w_04_highlights",
        "links": "https://alison.rbind.io/post/new-year-new-blogdown/"
      },
      {
        "ep_name": "issue_2021_w_04_highlights",
        "links": "https://r-podcast.fireside.fm/24?t=1142"
      },
      {
        "ep_name": "issue_2021_w_04_highlights",
        "links": "https://support.rbind.io/2017/04/27/r-podcast-website/"
      },
      {
        "ep_name": "issue_2021_w_04_highlights",
        "links": "https://rstudio.com/resources/rstudioconf-2019/pagedown-creating-beautiful-pdfs-with-r-markdown-and-css/"
      },
      {
        "ep_name": "issue_2021_w_04_highlights",
        "links": "https://github.com/rfortherestofus/pagedreport/issues/14"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_04_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_03_highlights",
        "ep_date": "2021-01-18",
        "ep_duration": 36,
        "ep_description_short": "Data Science as an atomic habit, Japan soccer league season review, Fantasy football scheduling, and UseR! 2021 call for tutorials Episode Links This week's curator: Wolfram King (https://github.com/qinwf) Data science as an atomic habit (https://malco.io/2021/01/04/data-science-as-an-atomic-habit/) J.League Soccer 2020 Season Review with R!…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_03_highlights",
        "description_long": "\r \r\n\nData Science as an atomic habit, Japan soccer league season review, Fantasy football scheduling, and UseR! 2021 call for tutorials\n\nEpisode Links\n\nThis week's curator: Wolfram King\nData science as an atomic habit\nJ.League Soccer 2020 Season Review with R!\nFantasy Football and the Classical Scheduling Problem\nUseR! 2021: Call for Tutorials\n\nSupplemental Resources\n\nBook Review: Atomic Habits\nffsched - R package for simulating schedules and standings for fantasy football\nUseR! 2020 Tutorials Playlist\nLifelong Learning with R Weekly (Wolfram Qin) lightning talk atrstudio::global!\nSession 1: 2021-01-21 10:21 PM - 10:26 PM EST / 2021-01-22 03:21 AM - 03:26 AM UTC\nSession 2: 2021-01-22 10:21 AM - 10:26 AM EST / 2021-01-22 03:21 PM- 03:26 PM UTC"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_03_highlights",
        "links": "https://github.com/qinwf"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "links": "https://malco.io/2021/01/04/data-science-as-an-atomic-habit/"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "links": "http://Ryo-N7.github.io/2021-01-14-jleague-2020-season-review-with-r/"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "links": "https://tonyelhabr.rbind.io/post/fantasy-football-schedule-problem/"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "links": "https://user2021.r-project.org/participation/call-for-tutorials/"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "links": "https://kislayverma.com/books/book-review-atomic-habits"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "links": "https://github.com/tonyelhabr/ffsched/"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "links": "https://www.youtube.com/playlist?list=PL4IzsxWztPdkj6NbIGdhsVd9MluxV05RN"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "links": "https://global.rstudio.com/student/catalog"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      },
      {
        "ep_name": "issue_2021_w_03_highlights"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_03_highlights",
        "chap_timestamp": 21,
        "chap_text": "AM"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "chap_timestamp": 21,
        "chap_text": "PM"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "chap_timestamp": 26,
        "chap_text": "PM UTC"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "chap_timestamp": 26,
        "chap_text": "AM UTC Session 2 20210122"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "chap_timestamp": 21,
        "chap_text": "PM"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "chap_timestamp": 21,
        "chap_text": "AM"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "chap_timestamp": 26,
        "chap_text": "AM EST 20210122"
      },
      {
        "ep_name": "issue_2021_w_03_highlights",
        "chap_timestamp": 26,
        "chap_text": "PM EST 20210122"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_02_highlights",
        "ep_date": "2021-01-11",
        "ep_duration": 45,
        "ep_description_short": "Plots with GitHub Actions, and major updates to {renv} and {fastai} Episode Links This week's curator: Batool Almazrouq (https://twitter.com/batool664) Automatic Rendering of a Plot with GitHub Actions (https://amitlevinson.com/blog/automated-plot-with-github-actions) {renv} 0.12.5 (https://cran.r-project.org/package=renv): Project…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_02_highlights",
        "description_long": "\r \r\n\nPlots with GitHub Actions, and major updates to {renv} and {fastai}\n\nEpisode Links\n\nThis week's curator: Batool Almazrouq\nAutomatic Rendering of a Plot with GitHub Actions\n{renv} 0.12.5: Project Environments\n{fastai} 2.0.2: Interface to fastai\n\nSupplemental Resources\n\nGitHub Actions: built by you, run by us\nR-Podcast Episode 32: RStudio's Big Move and Kevin Ushey\nFully containerized R dev environment with Docker, RStudio, and VS-Code\nWhat does it mean to freeze or unfreeze a model?"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_02_highlights",
        "links": "https://twitter.com/batool664"
      },
      {
        "ep_name": "issue_2021_w_02_highlights",
        "links": "https://amitlevinson.com/blog/automated-plot-with-github-actions"
      },
      {
        "ep_name": "issue_2021_w_02_highlights",
        "links": "https://cran.r-project.org/package=renv"
      },
      {
        "ep_name": "issue_2021_w_02_highlights",
        "links": "https://cran.r-project.org/package=fastai"
      },
      {
        "ep_name": "issue_2021_w_02_highlights",
        "links": "https://github.blog/2018-10-17-action-demos"
      },
      {
        "ep_name": "issue_2021_w_02_highlights",
        "links": "https://r-podcast.org/32"
      },
      {
        "ep_name": "issue_2021_w_02_highlights",
        "links": "https://youtu.be/4wRiPG9LM3o?t=389"
      },
      {
        "ep_name": "issue_2021_w_02_highlights",
        "links": "https://stats.stackexchange.com/questions/393168/what-does-it-mean-to-freeze-or-unfreeze-a-model"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_02_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2021_w_01_highlights",
        "ep_date": "2021-01-05",
        "ep_duration": 17,
        "ep_description_short": "Data Science course in a box, up and running with blogdown, and voting visualization in Switzerland Episode Links This week's curator: Wolfram King (https://github.com/qinwf) Data Science Course in a Box (https://datasciencebox.org/) - The core content of the course focuses on data acquisition and wrangling, exploratory data analysis, data…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2021_w_01_highlights",
        "description_long": "\r \r\n\nData Science course in a box, up and running with blogdown, and voting visualization in Switzerland\n\nEpisode Links\n\nThis week's curator: Wolfram King\nData Science Course in a Box - The core content of the course focuses on data acquisition and wrangling, exploratory data analysis, data visualization, inference, modelling, and effective communication of results.\nUp & running with blogdown in 2021\nA version of the famous visualization - Land doesn't vote, people do\n\nSupplemental Resources\n\nA Fresh Look at Introductory Data Science\nThe R-Podcast Episode 31: Data Science Education with R\n‘For responsible businesses – protecting human rights and the environment’ initiative background"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2021_w_01_highlights",
        "links": "https://github.com/qinwf"
      },
      {
        "ep_name": "issue_2021_w_01_highlights",
        "links": "https://datasciencebox.org/"
      },
      {
        "ep_name": "issue_2021_w_01_highlights",
        "links": "https://alison.rbind.io/post/new-year-new-blogdown/"
      },
      {
        "ep_name": "issue_2021_w_01_highlights",
        "links": "https://github.com/zumbov2/votemapswitzerland"
      },
      {
        "ep_name": "issue_2021_w_01_highlights",
        "links": "https://www.tandfonline.com/doi/full/10.1080/10691898.2020.1804497"
      },
      {
        "ep_name": "issue_2021_w_01_highlights",
        "links": "https://r-podcast.org/31"
      },
      {
        "ep_name": "issue_2021_w_01_highlights",
        "links": "https://www.admin.ch/gov/en/start/documentation/votes/20201129/iniziativa-popolare-per-imprese-responsabili-a-tutela-dell-essere-umano-e-dell-ambiente.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2021_w_01_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_52_highlights",
        "ep_date": "2020-12-28",
        "ep_duration": 34,
        "ep_description_short": "R Markdown family updates & table contest results Episode Links This week's curator: Wolfram King (https://github.com/qinwf) Winners of the 2020 RStudio Table Contest (https://blog.rstudio.com/2020/12/23/winners-of-the-2020-rstudio-table-contest/) Latest News from the R Markdown Family (https://blog.rstudio.com/2020/12/21/rmd-news/) Supplemental…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_52_highlights",
        "description_long": "\r \r\n\nR Markdown family updates & table contest results\n\nEpisode Links\n\nThis week's curator: Wolfram King\nWinners of the 2020 RStudio Table Contest\nLatest News from the R Markdown Family\n\nSupplemental Resources\n\nEditable DataTables in R Shiny using SQL"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_52_highlights",
        "links": "https://github.com/qinwf"
      },
      {
        "ep_name": "issue_2020_52_highlights",
        "links": "https://blog.rstudio.com/2020/12/23/winners-of-the-2020-rstudio-table-contest/"
      },
      {
        "ep_name": "issue_2020_52_highlights",
        "links": "https://blog.rstudio.com/2020/12/21/rmd-news/"
      },
      {
        "ep_name": "issue_2020_52_highlights",
        "links": "https://www.nielsvandervelden.com/post/sql_datatable/editable-datatables-in-r-shiny-using-sql/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_52_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_51_highlights",
        "ep_date": "2020-12-21",
        "ep_duration": 35,
        "ep_description_short": "Targetopia, extracting JSON data, and ggrepel update Episode Links This week's curator: Ryo Nakagawara (@RbyRyo (https://twitter.com/R_by_Ryo)) The targetopia: An R package ecosystem for democratized reproducible pipelines at scale (https://wlandau.github.io/posts/2020-12-14-targetopia/) Extracting JSON data from websites and public APIs with R…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_51_highlights",
        "description_long": "\r \r\n\nTargetopia, extracting JSON data, and ggrepel update\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara (@R_by_Ryo)\nThe targetopia: An R package ecosystem for democratized reproducible pipelines at scale\nExtracting JSON data from websites and public APIs with R\n{ggrepel}: Automatically Position Non-Overlapping Text Labels with ggplot2.\nEntire issue available at rweekly.org/2020-51\n\nSupplement resources\n\n{targets} statement of need\n{stantargets}\n{ggrepel} 0.9.0 changelog"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_51_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2020_51_highlights",
        "links": "https://wlandau.github.io/posts/2020-12-14-targetopia/"
      },
      {
        "ep_name": "issue_2020_51_highlights",
        "links": "https://themockup.blog/posts/2020-12-13-extracting-json-from-websites-and-public-apis-with-r/"
      },
      {
        "ep_name": "issue_2020_51_highlights",
        "links": "https://cran.r-project.org/package=ggrepel"
      },
      {
        "ep_name": "issue_2020_51_highlights",
        "links": "https://rweekly.org/2020-51"
      },
      {
        "ep_name": "issue_2020_51_highlights",
        "links": "https://wlandau.github.io/targets/articles/need.html"
      },
      {
        "ep_name": "issue_2020_51_highlights",
        "links": "https://wlandau.github.io/stantargets"
      },
      {
        "ep_name": "issue_2020_51_highlights",
        "links": "https://github.com/slowkow/ggrepel/blob/master/NEWS.md"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_51_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_50_highlights",
        "ep_date": "2020-12-14",
        "ep_duration": 26,
        "ep_description_short": "Underrated tidyverse functions, bullet chart variants, and AWS Lambda with R Episode Links This week's curator: Eric Nantz (@theRcast (https://twitter.com/theRcast)) Underrated Tidyverse Functions (https://hugo-portfolio-example.netlify.app/projects/tidyverse_functions/) Bullet Chart Variants in R…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_50_highlights",
        "description_long": "\r \r\n\nUnderrated tidyverse functions, bullet chart variants, and AWS Lambda with R\n\nEpisode Links\n\nThis week's curator: Eric Nantz (@theRcast)\nUnderrated Tidyverse Functions\nBullet Chart Variants in R\nR on AWS Lambda with containers\nEntire issue available at rweekly.org/2020-50"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_50_highlights",
        "links": "https://twitter.com/theRcast"
      },
      {
        "ep_name": "issue_2020_50_highlights",
        "links": "https://hugo-portfolio-example.netlify.app/projects/tidyverse_functions/"
      },
      {
        "ep_name": "issue_2020_50_highlights",
        "links": "https://themockup.blog/posts/2020-11-29-bullet-chart-variants-in-r/"
      },
      {
        "ep_name": "issue_2020_50_highlights",
        "links": "https://mdneuzerling.com/post/r-on-aws-lambda-with-containers/"
      },
      {
        "ep_name": "issue_2020_50_highlights",
        "links": "https://rweekly.org/2020-50"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_50_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_49_highlights",
        "ep_date": "2020-12-07",
        "ep_duration": 35,
        "ep_description_short": "Extended ggplot2 tutorial, static code analysis, and a customized visual CV with ggplot2 Episode Links This week's curator: Jonathan Carroll (@carroll_jono (https://twitter.com/carroll_jono)) An extended version of \"A ggplot2 Tutorial for Beautiful Plotting\"…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_49_highlights",
        "description_long": "\r \r\n\nExtended ggplot2 tutorial, static code analysis, and a customized visual CV with ggplot2\n\nEpisode Links\n\nThis week's curator: Jonathan Carroll (@carroll_jono)\nAn extended version of \"A ggplot2 Tutorial for Beautiful Plotting\"\nA brief introduction to the basics of R's static code analysis\nCreation of a custom visual CV by ggplot hacking\nEntire issue available at rweekly.org/2020-49"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_49_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2020_49_highlights",
        "links": "https://cedricscherer.netlify.app/2019/08/05/a-ggplot2-tutorial-for-beautiful-plotting-in-r/"
      },
      {
        "ep_name": "issue_2020_49_highlights",
        "links": "https://renkun.me/2020/11/08/using-parse-data-to-analyze-r-code/"
      },
      {
        "ep_name": "issue_2020_49_highlights",
        "links": "http://adomingues.github.io/2020/11/25/visual-cv/"
      },
      {
        "ep_name": "issue_2020_49_highlights",
        "links": "https://rweekly.org/2020-49"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_49_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_48_highlights",
        "ep_date": "2020-12-01",
        "ep_duration": 15,
        "ep_description_short": "About this episode Your first R package, magrittr 2.0, and Engineering Shiny use case Episode Links This week's curator: Maelle Salmon (@ma_salmon (https://twitter.com/ma_salmon)) Your first R package in 1 hour (https://www.pipinghotdata.com/posts/2020-10-25-your-first-r-package-in-1-hour/) magrittr 2.0 is here!…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_48_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nYour first R package, magrittr 2.0, and Engineering Shiny use case\n\nEpisode Links\n\nThis week's curator: Maelle Salmon (@ma_salmon)\nYour first R package in 1 hour\nmagrittr 2.0 is here!\nUse case from \"Engineering Production-Grade Shiny Apps\" - Building an App, from Start to Finish\nEntire issue available at rweekly.org/2020-48\n\nSupplement Resources\n\nRecording of Shannon's workshop on YouTube: youtu.be/xcXzaEmZ-m4"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_48_highlights",
        "links": "https://twitter.com/ma_salmon"
      },
      {
        "ep_name": "issue_2020_48_highlights",
        "links": "https://www.pipinghotdata.com/posts/2020-10-25-your-first-r-package-in-1-hour/"
      },
      {
        "ep_name": "issue_2020_48_highlights",
        "links": "https://www.tidyverse.org/blog/2020/11/magrittr-2-0-is-here/"
      },
      {
        "ep_name": "issue_2020_48_highlights",
        "links": "https://engineering-shiny.org/use-case-building-an-app-from-start-to-finish.html"
      },
      {
        "ep_name": "issue_2020_48_highlights",
        "links": "https://rweekly.org/2020-48"
      },
      {
        "ep_name": "issue_2020_48_highlights",
        "links": "https://youtu.be/xcXzaEmZ-m4"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_48_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_47_highlights",
        "ep_date": "2020-11-24",
        "ep_duration": 53,
        "ep_description_short": "About this episode Testthat utility belt, NHS-R conference, and application of Bayesian networks to sports injury prediction Episode Links This week's curator: Jon Calder (@jonmcalder (https://twitter.com/jonmcalder)) NHS-R 2020 Week Long Conference -- so much great content, so little time to catch it all...…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_47_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nTestthat utility belt, NHS-R conference, and application of Bayesian networks to sports injury prediction\n\nEpisode Links\n\nThis week's curator: Jon Calder (@jonmcalder)\nNHS-R 2020 Week Long Conference -- so much great content, so little time to catch it all...\nHelper code and files for your testthat tests\nBayesian networks and sports injuries with {bnlearn}\nEntire issue available at rweekly.org/2020-47\n\nSupplement Resources\n\nhttps://nhsrcommunity.com/blog/nhs-meets-r/"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_47_highlights",
        "links": "https://twitter.com/jonmcalder"
      },
      {
        "ep_name": "issue_2020_47_highlights",
        "links": "https://nhsrcommunity.com/blog/nhs-r-2020-week-long-conference-so-much-great-content-so-little-time-to-catch-it-all/"
      },
      {
        "ep_name": "issue_2020_47_highlights",
        "links": "https://blog.r-hub.io/2020/11/18/testthat-utility-belt/"
      },
      {
        "ep_name": "issue_2020_47_highlights",
        "links": "https://www.hfshr.xyz/posts/2020-11-01-bayesian-networks-with-bnlearn/"
      },
      {
        "ep_name": "issue_2020_47_highlights",
        "links": "https://rweekly.org/2020-47"
      },
      {
        "ep_name": "issue_2020_47_highlights",
        "links": "https://nhsrcommunity.com/blog/nhs-meets-r/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_47_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_46_highlights",
        "ep_date": "2020-11-16",
        "ep_duration": 23,
        "ep_description_short": "About this episode Open-access tools to find conronaviruses, developing inside containers, and error handling Episode Links This week's curator: Colin Faye (@_colinFay (https://twitter.com/_colinfay)) Using Open-Access Tools (rentrez, taxize) to Find Coronaviruses, Their Genetic Sequences, and Their Hosts…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_46_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nOpen-access tools to find conronaviruses, developing inside containers, and error handling\n\nEpisode Links\n\nThis week's curator: Colin Faye (@_colinFay)\nUsing Open-Access Tools (rentrez, taxize) to Find Coronaviruses, Their Genetic Sequences, and Their Hosts\nHow to develop inside a Docker container to ease collaboration?\nYAPOEH! (Yet another post on error handling)\nEntire issue available at rweekly.org/2020-46"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_46_highlights",
        "links": "https://twitter.com/_colinfay"
      },
      {
        "ep_name": "issue_2020_46_highlights",
        "links": "https://ropensci.org/blog/2020/11/10/coronaviruses-and-hosts/"
      },
      {
        "ep_name": "issue_2020_46_highlights",
        "links": "https://rtask.thinkr.fr/how-to-develop-inside-a-docker-container-to-ease-collaboration/"
      },
      {
        "ep_name": "issue_2020_46_highlights",
        "links": "https://adisarid.github.io/post/yet-another-post-on-error-handling/"
      },
      {
        "ep_name": "issue_2020_46_highlights",
        "links": "https://rweekly.org/2020-46"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_46_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_45_highlights",
        "ep_date": "2020-11-10",
        "ep_duration": 9,
        "ep_description_short": "About this episode Single source publishing, rainbow parentheses, and VisiumExperiment Episode Links This week's curator: Robert Hickman (@robwhickman (https://twitter.com/robwhickman)) Single-source publishing for R users (https://masalmon.eu/2020/11/06/single-source-publishing-r/) RStudio 1.4 Preview: Rainbow Parentheses…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_45_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nSingle source publishing, rainbow parentheses, and VisiumExperiment\n\nEpisode Links\n\nThis week's curator: Robert Hickman (@robwhickman)\nSingle-source publishing for R users\nRStudio 1.4 Preview: Rainbow Parentheses\nUsing VisiumExperiment at spatialLIBD package\nEntire issue available at rweekly.org/2020-45\n\nSupplement Links\n\nhttps://github.com/maelle/bspagedjs\nhttps://bookdown.org/"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_45_highlights",
        "links": "https://twitter.com/robwhickman"
      },
      {
        "ep_name": "issue_2020_45_highlights",
        "links": "https://masalmon.eu/2020/11/06/single-source-publishing-r/"
      },
      {
        "ep_name": "issue_2020_45_highlights",
        "links": "https://blog.rstudio.com/2020/11/04/rstudio-1-4-preview-rainbow-parentheses/"
      },
      {
        "ep_name": "issue_2020_45_highlights",
        "links": "http://LieberInstitute.github.io/rstatsclub/2020/11/06/using-visiumexperiment-at-spatiallibd-package/"
      },
      {
        "ep_name": "issue_2020_45_highlights",
        "links": "https://rweekly.org/2020-45"
      },
      {
        "ep_name": "issue_2020_45_highlights",
        "links": "https://github.com/maelle/bspagedjs"
      },
      {
        "ep_name": "issue_2020_45_highlights",
        "links": "https://bookdown.org/"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_45_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_44_highlights",
        "ep_date": "2020-11-02",
        "ep_duration": 12,
        "ep_description_short": "About this episode {emphatic} highlighting, analyzing open political data, and helping data-science learners Episode Links This week's curator: Tony Elhabr (@TonyElHabr (https://twitter.com/tonyelhabr)) {emphatic} (https://github.com/coolbutuseless/emphatic): Augments the output of data.frames and matrices in R by adding user-defined ANSI…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_44_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\n{emphatic} highlighting, analyzing open political data, and helping data-science learners\n\nEpisode Links\n\nThis week's curator: Tony Elhabr (@TonyElHabr)\n{emphatic}: Augments the output of data.frames and matrices in R by adding user-defined ANSI highlighting.\nA guide to accessing & analyzing open source American political data using R\nLet’s stop doubly-screwing data science learners\nEntire issue available at rweekly.org/2020-44\n\nSupplement Links\n\n{pillar} format columns with colour\n{crayon} R package for colored terminal output\nANSI escape codes\nJason Timm's blog\nThe {drake} post\nThe {drake} R package user manual"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_44_highlights",
        "links": "https://twitter.com/tonyelhabr"
      },
      {
        "ep_name": "issue_2020_44_highlights",
        "links": "https://github.com/coolbutuseless/emphatic"
      },
      {
        "ep_name": "issue_2020_44_highlights",
        "links": "https://github.com/jaytimm/American-political-data-and-R"
      },
      {
        "ep_name": "issue_2020_44_highlights",
        "links": "https://milesmcbain.micro.blog/2020/10/28/lets-stop-doublyscrewing.html"
      },
      {
        "ep_name": "issue_2020_44_highlights",
        "links": "https://rweekly.org/2020-44"
      },
      {
        "ep_name": "issue_2020_44_highlights",
        "links": "https://pillar.r-lib.org"
      },
      {
        "ep_name": "issue_2020_44_highlights",
        "links": "https://github.com/r-lib/crayon"
      },
      {
        "ep_name": "issue_2020_44_highlights",
        "links": "https://en.wikipedia.org/wiki/ANSI_escape_code"
      },
      {
        "ep_name": "issue_2020_44_highlights",
        "links": "https://www.jtimm.net"
      },
      {
        "ep_name": "issue_2020_44_highlights",
        "links": "https://www.milesmcbain.com/posts/the-drake-post"
      },
      {
        "ep_name": "issue_2020_44_highlights",
        "links": "https://books.ropensci.org/drake"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_44_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_43_highlights",
        "ep_date": "2020-10-26",
        "ep_duration": 25,
        "ep_description_short": "About this episode Rolling averages with {slider}, personal art map, and flood mapping Episode Links This week's curator: Miles McBain (@MilesMcBain (https://twitter.com/MilesMcBain)) Rolling Averages with {slider} and Covid Data (https://www.njtierney.com/post/2020/10/20/roll-avg-covid/) Personal Art Map with R…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_43_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nRolling averages with {slider}, personal art map, and flood mapping\n\nEpisode Links\n\nThis week's curator: Miles McBain (@MilesMcBain)\nRolling Averages with {slider} and Covid Data\nPersonal Art Map with R\nFlood mapping and rapid impact assessment in Niamey\nEntire issue available at rweekly.org/2020-43\n\nSupplement Links\n\nMelt the Clock: Tidy time series analysis by Earo Wang\n{slider} - Sliding Window Functions\nhttps://inequality.media.mit.edu/\n{sen2r} - Find, download, and process sentinel-2 data"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_43_highlights",
        "links": "https://twitter.com/MilesMcBain"
      },
      {
        "ep_name": "issue_2020_43_highlights",
        "links": "https://www.njtierney.com/post/2020/10/20/roll-avg-covid/"
      },
      {
        "ep_name": "issue_2020_43_highlights",
        "links": "http://estebanmoro.org/post/2020-10-19-personal-art-map-with-r/"
      },
      {
        "ep_name": "issue_2020_43_highlights",
        "links": "https://www.ahmadoudicko.com/posts/2020/09/flood-mapping-and-rapid-impact-assessment-in-niamey/"
      },
      {
        "ep_name": "issue_2020_43_highlights",
        "links": "https://rweekly.org/2020-43"
      },
      {
        "ep_name": "issue_2020_43_highlights",
        "links": "https://slides.earo.me/rstudioconf19/#1"
      },
      {
        "ep_name": "issue_2020_43_highlights",
        "links": "https://davisvaughan.github.io/slider/"
      },
      {
        "ep_name": "issue_2020_43_highlights",
        "links": "https://inequality.media.mit.edu/"
      },
      {
        "ep_name": "issue_2020_43_highlights",
        "links": "http://sen2r.ranghetti.info/index.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_43_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_42_highlights",
        "ep_date": "2020-10-19",
        "ep_duration": 33,
        "ep_description_short": "About this episode Climate animation, decomposition and smoothing with R and python, and a Raspberry Pi dashboard Episode Links This week's curator: Ryo Nakagawara (@RbyRyo (https://twitter.com/R_by_Ryo)) Climate animation of maximum temperatures (https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/) Decomposition and…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_42_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nClimate animation, decomposition and smoothing with R and python, and a Raspberry Pi dashboard\n\nEpisode Links\n\nThis week's curator: Ryo Nakagawara (@R_by_Ryo)\nClimate animation of maximum temperatures\nDecomposition and Smoothing with data.table, reticulate, and spatstat\nRaspberry Pi E-Paper Dashboard with R\nEntire issue available at rweekly.org/2020-42"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_42_highlights",
        "links": "https://twitter.com/R_by_Ryo"
      },
      {
        "ep_name": "issue_2020_42_highlights",
        "links": "https://dominicroye.github.io/en/2020/climate-animation-of-maximum-temperatures/"
      },
      {
        "ep_name": "issue_2020_42_highlights",
        "links": "https://tonyelhabr.rbind.io/post/decomposition-smoothing-soccer/"
      },
      {
        "ep_name": "issue_2020_42_highlights",
        "links": "https://blog.schochastics.net/post/raspberry-pi-e-paper-dashboard-with-r/"
      },
      {
        "ep_name": "issue_2020_42_highlights",
        "links": "https://rweekly.org/2020-42"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_42_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_41_highlights",
        "ep_date": "2020-10-12",
        "ep_duration": 11,
        "ep_description_short": "About this episode Topics in package development, contributing to ROpenSci, and shining a light on learnr Episode Links This week's curator: Eric Nantz (@theRcast (https://twitter.com/thercast)) Picking and researching blog topics about R package development (https://blog.r-hub.io/2020/10/09/topic-research/) Hacktober? Any Month is a Good Month to…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_41_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nTopics in package development, contributing to ROpenSci, and shining a light on learnr\n\nEpisode Links\n\nThis week's curator: Eric Nantz (@theRcast)\nPicking and researching blog topics about R package development\nHacktober? Any Month is a Good Month to Contribute to rOpenSci\nShiny Developer Series Episode 14 - Shining a Light on {learnr}\nEntire issue available at rweekly.org/2020-41\n\nSupplement Links\n\nR Packages 2nd Edition\nR-package-devel mailing list\nWriting R Extensions\nrOpenSci Community Contributing Guide\nMaintaining an R Package - Community Call Summary\nExploring missing values in naniar\nsortable widget and learnr demonstration\nCreating a New RWeekly Issue: Hands-on Demonstration"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://twitter.com/thercast"
      },
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://blog.r-hub.io/2020/10/09/topic-research/"
      },
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://ropensci.org/blog/2020/10/06/hacktober2020/"
      },
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://shinydevseries.com/post/episode-14-barrett3/"
      },
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://rweekly.org/2020-41"
      },
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://r-pkgs.org/"
      },
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://stat.ethz.ch/mailman/listinfo/r-package-devel"
      },
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://cran.r-project.org/doc/manuals/r-release/R-exts.html"
      },
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://contributing.ropensci.org/"
      },
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://ropensci.org/blog/2020/07/14/commcall-maintaining-pkg/"
      },
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://allisonhorst.shinyapps.io/missingexplorer/"
      },
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://rstudio.github.io/sortable/tutorials/tutorial_question_rank.html"
      },
      {
        "ep_name": "issue_2020_41_highlights",
        "links": "https://www.youtube.com/watch?v=tnclyMsy638"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_41_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_40_highlights",
        "ep_date": "2020-10-05",
        "ep_duration": 52,
        "ep_description_short": "About this episode Visual markdown editing, stat layers in ggplot2, and learnr tutorials in a package Episode Links This week's curator: Jonathan Carroll (@carroll_jono (https://twitter.com/carroll_jono)) RStudio v1.4 Preview: Visual Markdown Editing (https://blog.rstudio.com/2020/09/30/rstudio-v1-4-preview-visual-markdown-editing/) How to deliver…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_40_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nVisual markdown editing, stat layers in ggplot2, and learnr tutorials in a package\n\nEpisode Links\n\nThis week's curator: Jonathan Carroll (@carroll_jono)\nRStudio v1.4 Preview: Visual Markdown Editing\nHow to deliver learnr tutorials in a package\nDemystifying stat_ layers in {ggplot2}\nEntire issue available at rweekly.org/2020-40\n\nSupplement Links\n\nVisual R Markdown documentation\nIntroducing learnr\nShiny Developer Series Episode 14 - Shining a Light on learnr\nDistill for R Markdown - Creating a Blog"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_40_highlights",
        "links": "https://twitter.com/carroll_jono"
      },
      {
        "ep_name": "issue_2020_40_highlights",
        "links": "https://blog.rstudio.com/2020/09/30/rstudio-v1-4-preview-visual-markdown-editing/"
      },
      {
        "ep_name": "issue_2020_40_highlights",
        "links": "https://education.rstudio.com/blog/2020/09/delivering-learnr-tutorials-in-a-package/"
      },
      {
        "ep_name": "issue_2020_40_highlights",
        "links": "https://yjunechoe.github.io/posts/2020-09-26-demystifying-stat-layers-ggplot2/"
      },
      {
        "ep_name": "issue_2020_40_highlights",
        "links": "https://rweekly.org/2020-40"
      },
      {
        "ep_name": "issue_2020_40_highlights",
        "links": "https://rstudio.github.io/visual-markdown-editing"
      },
      {
        "ep_name": "issue_2020_40_highlights",
        "links": "https://blog.rstudio.com/2017/07/11/introducing-learnr/"
      },
      {
        "ep_name": "issue_2020_40_highlights",
        "links": "https://shinydevseries.com/post/episode-14-barrett3/"
      },
      {
        "ep_name": "issue_2020_40_highlights",
        "links": "https://rstudio.github.io/distill/blog.html"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_40_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_39_highlights",
        "ep_date": "2020-09-28",
        "ep_duration": 29,
        "ep_description_short": "About this episode A calendar right in your R console, accessibility tooling for Shiny, and shinydashboardPlus v2.0 Episode Links This week's curator: Maelle Salmon (@ma_salmon (https://twitter.com/ma_salmon)) A Calendar in Your R Console (https://www.garrickadenbuie.com/blog/r-console-calendar/) accessibility (a11y) tooling for shiny…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_39_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nA calendar right in your R console, accessibility tooling for Shiny, and shinydashboardPlus v2.0\n\nEpisode Links\n\nThis week's curator: Maelle Salmon (@ma_salmon)\nA Calendar in Your R Console\naccessibility (a11y) tooling for shiny\n\n{shinydashboardPlus 2.0.0}: extensions for shinydashboard\n\nEntire issue available at rweekly.org/2020-39"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_39_highlights",
        "links": "https://twitter.com/ma_salmon"
      },
      {
        "ep_name": "issue_2020_39_highlights",
        "links": "https://www.garrickadenbuie.com/blog/r-console-calendar/"
      },
      {
        "ep_name": "issue_2020_39_highlights",
        "links": "https://github.com/ewenme/shinya11y"
      },
      {
        "ep_name": "issue_2020_39_highlights",
        "links": "https://rinterface.github.io/shinydashboardPlus/articles/shinydashboardPlus.html#what-changes-in-v2-0-0"
      },
      {
        "ep_name": "issue_2020_39_highlights",
        "links": "https://rweekly.org/2020-39"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_39_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_38_highlights",
        "ep_date": "2020-09-21",
        "ep_duration": 15,
        "ep_description_short": "About this episode Making learning to code friendlier with art, ggforce functions, and debugging in VSCode Episode Links It's a Bird, It's a Plane ... It's a ggforce function (https://ihaddadenfodil.com/post/it-s-a-bird-it-s-a-plane-it-s-a-ggforce-function/) Making Learning to Code Friendlier with Art — An Interview with Dr. Allison Horst…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_38_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nMaking learning to code friendlier with art, ggforce functions, and debugging in VSCode\n\nEpisode Links\n\nIt's a Bird, It's a Plane ... It's a ggforce function\nMaking Learning to Code Friendlier with Art — An Interview with Dr. Allison Horst\nIntroduction to debugging R in VSCode\nEntire issue available at rweekly.org/2020-38\nThis week's curator: Jon Calder @jonmcalder"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_38_highlights",
        "links": "https://ihaddadenfodil.com/post/it-s-a-bird-it-s-a-plane-it-s-a-ggforce-function/"
      },
      {
        "ep_name": "issue_2020_38_highlights",
        "links": "https://www.dataquest.io/blog/making-learning-to-code-friendlier-with-art-allison-horst-interview/"
      },
      {
        "ep_name": "issue_2020_38_highlights",
        "links": "https://renkun.me/2020/09/13/debugging-r-in-vscode/"
      },
      {
        "ep_name": "issue_2020_38_highlights",
        "links": "https://rweekly.org/2020-38"
      },
      {
        "ep_name": "issue_2020_38_highlights",
        "links": "https://twitter.com/jonmcalder"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_38_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_37_highlights",
        "ep_date": "2020-09-14",
        "ep_duration": 28,
        "ep_description_short": "About this episode Guidelines for creating better tables, a controlled vocabulary to name data frame columns, and exploring reactivity in Shiny applications. Episode Links 10+ Guidelines for Better Tables in R: Make tables people ACTUALLY want to read. (https://themockup.blog/posts/2020-09-04-10-table-rules-in-r/) Column Names as Contracts…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_37_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nGuidelines for creating better tables, a controlled vocabulary to name data frame columns, and exploring reactivity in Shiny applications.\n\nEpisode Links\n\n10+ Guidelines for Better Tables in R: Make tables people ACTUALLY want to read.\nColumn Names as Contracts\nEpisode 12: Barret Schloerke Part 1 (reactlog)\nEntire issue available at rweekly.org/2020-37"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_37_highlights",
        "links": "https://themockup.blog/posts/2020-09-04-10-table-rules-in-r/"
      },
      {
        "ep_name": "issue_2020_37_highlights",
        "links": "https://emilyriederer.netlify.app/post/column-name-contracts/"
      },
      {
        "ep_name": "issue_2020_37_highlights",
        "links": "https://shinydevseries.com/post/episode-12-barrett1/"
      },
      {
        "ep_name": "issue_2020_37_highlights",
        "links": "https://rweekly.org/2020-37"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_37_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_36_highlights",
        "ep_date": "2020-09-07",
        "ep_duration": 59,
        "ep_description_short": "About this episode A stunning combination of physics and 3-D visualization, behind the curtain of package installation, and an alternative workflow for error handling in functions. Episode Links Plinko Statistics: Insights from the Bean Machine (https://www.tylermw.com/plinko-statistics-insights-from-the-bean-machine/) State of R packages in your…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_36_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nA stunning combination of physics and 3-D visualization, behind the curtain of package installation, and an alternative workflow for error handling in functions.\n\nEpisode Links\n\nPlinko Statistics: Insights from the Bean Machine\nState of R packages in your library\nHandling errors using purrr's possibly() and safely()\nEntire issue available at rweekly.org/2020-36\nThe R-Weekly Patreon: www.patreon.com/rweekly"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_36_highlights",
        "links": "https://www.tylermw.com/plinko-statistics-insights-from-the-bean-machine/"
      },
      {
        "ep_name": "issue_2020_36_highlights",
        "links": "https://blog.r-hub.io/2020/09/03/keep.source/"
      },
      {
        "ep_name": "issue_2020_36_highlights",
        "links": "https://aosmith.rbind.io/2020/08/31/handling-errors/"
      },
      {
        "ep_name": "issue_2020_36_highlights",
        "links": "https://rweekly.org/2020-36"
      },
      {
        "ep_name": "issue_2020_36_highlights",
        "links": "https://www.patreon.com/rweekly"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_36_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_35_highlights",
        "ep_date": "2020-08-31",
        "ep_duration": 30,
        "ep_description_short": "About this episode A substantial update to the magrittr package coming soon, creating visualizations in D3 from an R user's perspective, and a big book of R. Episode Links magrittr 2.0 is coming soon (https://www.tidyverse.org/blog/2020/08/magrittr-2-0/) D3 to R to D3 (https://maya.rbind.io/post/2020/d3-to-r-to-d3/) Big Book of R…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_35_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nA substantial update to the magrittr package coming soon, creating visualizations in D3 from an R user's perspective, and a big book of R.\n\nEpisode Links\n\nmagrittr 2.0 is coming soon\nD3 to R to D3\nBig Book of R\nEntire issue available at rweekly.org/2020-35\nDetails on how to submit resources and becoming an editor on the RWeekly team: github.com/rweekly/rweekly.org"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_35_highlights",
        "links": "https://www.tidyverse.org/blog/2020/08/magrittr-2-0/"
      },
      {
        "ep_name": "issue_2020_35_highlights",
        "links": "https://maya.rbind.io/post/2020/d3-to-r-to-d3/"
      },
      {
        "ep_name": "issue_2020_35_highlights",
        "links": "https://www.bigbookofr.com/"
      },
      {
        "ep_name": "issue_2020_35_highlights",
        "links": "https://rweekly.org/2020-35"
      },
      {
        "ep_name": "issue_2020_35_highlights",
        "links": "https://github.com/rweekly/rweekly.org"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_35_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_34_highlights",
        "ep_date": "2020-08-24",
        "ep_duration": 2,
        "ep_description_short": "About this episode Choosing an operating system for R users, examining regression techniques, and inside the development of dittodb / generating data from truncated distributions Episode Links Best OS for R users (https://www.jimhester.com/post/2020-08-20-best-os-for-r/) Lines of best fit (http://freerangestats.info/blog/2020/08/23/highered-ols)…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_34_highlights",
        "description_long": "\r \r\n\nAbout this episode\n\nChoosing an operating system for R users, examining regression techniques, and inside the development of dittodb / generating data from truncated distributions\n\nEpisode Links\n\nBest OS for R users\nLines of best fit\nGenerating data from a truncated distribution\nEntire issue available at rweekly.org/2020-34\nCreating a new RWeekly issue demonstration: youtu.be/tnclyMsy638"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_34_highlights",
        "links": "https://www.jimhester.com/post/2020-08-20-best-os-for-r/"
      },
      {
        "ep_name": "issue_2020_34_highlights",
        "links": "http://freerangestats.info/blog/2020/08/23/highered-ols"
      },
      {
        "ep_name": "issue_2020_34_highlights",
        "links": "https://www.rdatagen.net/post/generating-data-from-a-truncated-distribution/"
      },
      {
        "ep_name": "issue_2020_34_highlights",
        "links": "https://rweekly.org/2020-34"
      },
      {
        "ep_name": "issue_2020_34_highlights",
        "links": "https://youtu.be/tnclyMsy638"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_34_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "issue_2020_33_highlights",
        "ep_date": "2020-08-17",
        "ep_duration": 17,
        "ep_description_short": "About this episode Exploring comic book creation with the tidyverse and ggplot2, and updates to the showtext and shinycssloader packages on CRAN. Episode Links A visualization exploring types of comic transitions as described in Scott McCloud's \"Understanding Comics\". (https://github.com/sharlagelfand/understanding-comics) {showtext} 0.9…"
      }
    ],
    "description_long": [
      {
        "ep_name": "issue_2020_33_highlights",
        "description_long": "\r \r\nAbout this episode\n\nExploring comic book creation with the tidyverse and ggplot2, and updates to the showtext and shinycssloader packages on CRAN.\n\nEpisode Links\nA visualization exploring types of comic transitions as described in Scott McCloud's \"Understanding Comics\".\n{showtext} 0.9: Using Fonts More Easily in R Graphs\n{shinycssloaders} v1.0: You can now use your own image, plus 3 years' worth of new features!\nEntire issue available at rweekly.org/2020-33"
      }
    ],
    "links": [
      {
        "ep_name": "issue_2020_33_highlights",
        "links": "https://github.com/sharlagelfand/understanding-comics"
      },
      {
        "ep_name": "issue_2020_33_highlights",
        "links": "https://cran.r-project.org/package=showtext"
      },
      {
        "ep_name": "issue_2020_33_highlights",
        "links": "https://deanattali.com/blog/shinycssloaders-v1.0/"
      },
      {
        "ep_name": "issue_2020_33_highlights",
        "links": "https://rweekly.org/2020-33"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "issue_2020_33_highlights"
      }
    ]
  },
  {
    "metadata": [
      {
        "ep_name": "introduction",
        "ep_date": "2020-08-13",
        "ep_duration": 47,
        "ep_description_short": "In this introduction episode, Eric Nantz shares an introduction to the RWeekly community project as well as the movitation for creating this brand new RWeekly Highlights podcast! Episode Links rweekly.org (https://rweekly.org) github.com/rweekly/rweekly.org (https://github.com/rweekly/rweekly.org)"
      }
    ],
    "description_long": [
      {
        "ep_name": "introduction",
        "description_long": "\r \r\n\nIn this introduction episode, Eric Nantz shares an introduction to the RWeekly community project as well as the movitation for creating this brand new RWeekly Highlights podcast!\n\nEpisode Links\nrweekly.org\ngithub.com/rweekly/rweekly.org"
      }
    ],
    "links": [
      {
        "ep_name": "introduction",
        "links": "https://rweekly.org"
      },
      {
        "ep_name": "introduction",
        "links": "https://github.com/rweekly/rweekly.org"
      }
    ],
    "transcript": [],
    "chapters": [
      {
        "ep_name": "introduction"
      }
    ]
  }
]
